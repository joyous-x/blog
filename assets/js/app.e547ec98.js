(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(n){function e(e){for(var r,i,s=e[0],l=e[1],c=e[2],p=0,u=[];p<s.length;p++)i=s[p],Object.prototype.hasOwnProperty.call(o,i)&&o[i]&&u.push(o[i][0]),o[i]=0;for(r in l)Object.prototype.hasOwnProperty.call(l,r)&&(n[r]=l[r]);for(d&&d(e);u.length;)u.shift()();return a.push.apply(a,c||[]),t()}function t(){for(var n,e=0;e<a.length;e++){for(var t=a[e],r=!0,s=1;s<t.length;s++){var l=t[s];0!==o[l]&&(r=!1)}r&&(a.splice(e--,1),n=i(i.s=t[0]))}return n}var r={},o={1:0},a=[];function i(e){if(r[e])return r[e].exports;var t=r[e]={i:e,l:!1,exports:{}};return n[e].call(t.exports,t,t.exports,i),t.l=!0,t.exports}i.e=function(n){var e=[],t=o[n];if(0!==t)if(t)e.push(t[2]);else{var r=new Promise((function(e,r){t=o[n]=[e,r]}));e.push(t[2]=r);var a,s=document.createElement("script");s.charset="utf-8",s.timeout=120,i.nc&&s.setAttribute("nonce",i.nc),s.src=function(n){return i.p+"assets/js/"+({}[n]||n)+"."+{2:"28675651",3:"43c8fac8",4:"2601732b",5:"51de14ae",6:"e4c709ef",7:"681cd789",8:"2cadde1b",9:"11d27c1c",10:"aebb1a9d",11:"bdb676ad",12:"9450141c",13:"ec96994d",14:"8a40b7ae",15:"14324128",16:"ffe9b698",17:"57d71aa3",18:"414462aa",19:"340f2415",20:"9bead936",21:"99388ba3",22:"8add7339",23:"4a244f91",24:"4182fce2",25:"aa828b7a",26:"f6f7f1ca",27:"9ebdd156",28:"8c759ea2",29:"ee6fa1e0",30:"26552b07",31:"eb3fce00",32:"3d5f5948",33:"2c46ca70",34:"2b3a2cc6",35:"fbbcd62d",36:"375ab7ea",37:"f18da370",38:"93cdea6a",39:"fa6a2de4",40:"68d5acb3",41:"735a32f6",42:"2dcfb427",43:"d1d1c767",44:"8374d8a6",45:"f3b5663a",46:"dffbcf73",47:"8af1db5b",48:"a14ca5ac",49:"77471881",50:"833ba9c6",51:"565e7811",52:"a00a1ea2",53:"f026bc0d",54:"26bb1b5c",55:"19c9c3b1",56:"e45cc4fa",57:"7541d446",58:"29ddc7c0",59:"c66016a6",60:"80f30ca2",61:"196d3936",62:"a8191475",63:"1d11e7ae",64:"af88a7ea",65:"23d9093e",66:"700efe50",67:"aa1afb45",68:"c3093474",69:"46bc4c32",70:"53a9893c",71:"6d27c9a8",72:"371c02d5",73:"6f41f3d6",74:"e6aeb90b",75:"3b999111",76:"888c5f54",77:"36e1ab88",78:"d94ab9be",79:"88baeb00",80:"9d9ca817",81:"d783cd89",82:"93b3bcbe",83:"279e2d4a",84:"d5f1c016",85:"7e2ec985",86:"f02cbda5",87:"e3c549cd",88:"ade652b2",89:"14ffa288",90:"2bc06a43",91:"ec70111c",92:"935af665",93:"d605f686",94:"aadbe865",95:"4b68d679",96:"1add5eb0",97:"06b6b1d1",98:"af4e0cb1",99:"4f6e22c1",100:"c2ffbde4",101:"f896fa45",102:"c4e2f559",103:"81568839",104:"fafbf0fb",105:"127ec06c"}[n]+".js"}(n);var l=new Error;a=function(e){s.onerror=s.onload=null,clearTimeout(c);var t=o[n];if(0!==t){if(t){var r=e&&("load"===e.type?"missing":e.type),a=e&&e.target&&e.target.src;l.message="Loading chunk "+n+" failed.\n("+r+": "+a+")",l.name="ChunkLoadError",l.type=r,l.request=a,t[1](l)}o[n]=void 0}};var c=setTimeout((function(){a({type:"timeout",target:s})}),12e4);s.onerror=s.onload=a,document.head.appendChild(s)}return Promise.all(e)},i.m=n,i.c=r,i.d=function(n,e,t){i.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:t})},i.r=function(n){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})},i.t=function(n,e){if(1&e&&(n=i(n)),8&e)return n;if(4&e&&"object"==typeof n&&n&&n.__esModule)return n;var t=Object.create(null);if(i.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:n}),2&e&&"string"!=typeof n)for(var r in n)i.d(t,r,function(e){return n[e]}.bind(null,r));return t},i.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return i.d(e,"a",e),e},i.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},i.p="/blog/",i.oe=function(n){throw console.error(n),n};var s=window.webpackJsonp=window.webpackJsonp||[],l=s.push.bind(s);s.push=e,s=s.slice();for(var c=0;c<s.length;c++)e(s[c]);var d=l;a.push([229,0]),t()}([function(n,e){var t=function(n){return n&&n.Math==Math&&n};n.exports=t("object"==typeof globalThis&&globalThis)||t("object"==typeof window&&window)||t("object"==typeof self&&self)||t("object"==typeof global&&global)||function(){return this}()||Function("return this")()},function(n,e,t){var r=t(0),o=t(37).f,a=t(25),i=t(14),s=t(105),l=t(112),c=t(102);n.exports=function(n,e){var t,d,p,u,m,f=n.target,h=n.global,g=n.stat;if(t=h?r:g?r[f]||s(f,{}):(r[f]||{}).prototype)for(d in e){if(u=e[d],p=n.noTargetGet?(m=o(t,d))&&m.value:t[d],!c(h?d:f+(g?".":"#")+d,n.forced)&&void 0!==p){if(typeof u==typeof p)continue;l(u,p)}(n.sham||p&&p.sham)&&a(u,"sham",!0),i(t,d,u,n)}}},function(n,e,t){var r=t(58),o=Function.prototype,a=o.bind,i=o.call,s=r&&a.bind(i,i);n.exports=r?function(n){return n&&s(n)}:function(n){return n&&function(){return i.apply(n,arguments)}}},function(n,e){n.exports=function(n){try{return!!n()}catch(n){return!0}}},function(n,e,t){var r=t(117),o=t(14),a=t(248);r||o(Object.prototype,"toString",a,{unsafe:!0})},function(n,e){n.exports=function(n){return"function"==typeof n}},function(n,e,t){var r=t(0),o=t(77),a=t(10),i=t(78),s=t(106),l=t(146),c=o("wks"),d=r.Symbol,p=d&&d.for,u=l?d:d&&d.withoutSetter||i;n.exports=function(n){if(!a(c,n)||!s&&"string"!=typeof c[n]){var e="Symbol."+n;s&&a(d,n)?c[n]=d[n]:c[n]=l&&p?p(e):u(e)}return c[n]}},function(n,e,t){var r=t(3);n.exports=!r((function(){return 7!=Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(n,e,t){var r=t(0),o=t(9),a=r.String,i=r.TypeError;n.exports=function(n){if(o(n))return n;throw i(a(n)+" is not an object")}},function(n,e,t){var r=t(5);n.exports=function(n){return"object"==typeof n?null!==n:r(n)}},function(n,e,t){var r=t(2),o=t(16),a=r({}.hasOwnProperty);n.exports=Object.hasOwn||function(n,e){return a(o(n),e)}},function(n,e,t){var r=t(58),o=Function.prototype.call;n.exports=r?o.bind(o):function(){return o.apply(o,arguments)}},function(n,e,t){var r=t(0),o=t(86),a=r.String;n.exports=function(n){if("Symbol"===o(n))throw TypeError("Cannot convert a Symbol value to a string");return a(n)}},function(n,e,t){var r=t(0),o=t(7),a=t(148),i=t(147),s=t(8),l=t(80),c=r.TypeError,d=Object.defineProperty,p=Object.getOwnPropertyDescriptor;e.f=o?i?function(n,e,t){if(s(n),e=l(e),s(t),"function"==typeof n&&"prototype"===e&&"value"in t&&"writable"in t&&!t.writable){var r=p(n,e);r&&r.writable&&(n[e]=t.value,t={configurable:"configurable"in t?t.configurable:r.configurable,enumerable:"enumerable"in t?t.enumerable:r.enumerable,writable:!1})}return d(n,e,t)}:d:function(n,e,t){if(s(n),e=l(e),s(t),a)try{return d(n,e,t)}catch(n){}if("get"in t||"set"in t)throw c("Accessors not supported");return"value"in t&&(n[e]=t.value),n}},function(n,e,t){var r=t(0),o=t(5),a=t(10),i=t(25),s=t(105),l=t(85),c=t(40),d=t(75).CONFIGURABLE,p=c.get,u=c.enforce,m=String(String).split("String");(n.exports=function(n,e,t,l){var c,p=!!l&&!!l.unsafe,f=!!l&&!!l.enumerable,h=!!l&&!!l.noTargetGet,g=l&&void 0!==l.name?l.name:e;o(t)&&("Symbol("===String(g).slice(0,7)&&(g="["+String(g).replace(/^Symbol\(([^)]*)\)/,"$1")+"]"),(!a(t,"name")||d&&t.name!==g)&&i(t,"name",g),(c=u(t)).source||(c.source=m.join("string"==typeof g?g:""))),n!==r?(p?!h&&n[e]&&(f=!0):delete n[e],f?n[e]=t:i(n,e,t)):f?n[e]=t:s(e,t)})(Function.prototype,"toString",(function(){return o(this)&&p(this).source||l(this)}))},function(n,e,t){"use strict";function r(n,e,t,r,o,a,i,s){var l,c="function"==typeof n?n.options:n;if(e&&(c.render=e,c.staticRenderFns=t,c._compiled=!0),r&&(c.functional=!0),a&&(c._scopeId="data-v-"+a),i?(l=function(n){(n=n||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(n=__VUE_SSR_CONTEXT__),o&&o.call(this,n),n&&n._registeredComponents&&n._registeredComponents.add(i)},c._ssrRegister=l):o&&(l=s?function(){o.call(this,(c.functional?this.parent:this).$root.$options.shadowRoot)}:o),l)if(c.functional){c._injectStyles=l;var d=c.render;c.render=function(n,e){return l.call(e),d(n,e)}}else{var p=c.beforeCreate;c.beforeCreate=p?[].concat(p,l):[l]}return{exports:n,options:c}}t.d(e,"a",(function(){return r}))},function(n,e,t){var r=t(0),o=t(18),a=r.Object;n.exports=function(n){return a(o(n))}},function(n,e,t){var r=t(0),o=t(5),a=function(n){return o(n)?n:void 0};n.exports=function(n,e){return arguments.length<2?a(r[n]):r[n]&&r[n][e]}},function(n,e,t){var r=t(0).TypeError;n.exports=function(n){if(null==n)throw r("Can't call method on "+n);return n}},function(n,e,t){var r=t(57),o=t(18);n.exports=function(n){return r(o(n))}},function(n,e,t){"use strict";var r=t(167).charAt,o=t(12),a=t(40),i=t(152),s=a.set,l=a.getterFor("String Iterator");i(String,"String",(function(n){s(this,{type:"String Iterator",string:o(n),index:0})}),(function(){var n,e=l(this),t=e.string,o=e.index;return o>=t.length?{value:void 0,done:!0}:(n=r(t,o),e.index+=n.length,{value:n,done:!1})}))},function(n,e,t){"use strict";var r=t(1),o=t(91);r({target:"RegExp",proto:!0,forced:/./.exec!==o},{exec:o})},function(n,e,t){var r=t(0),o=t(168),a=t(169),i=t(145),s=t(25),l=t(6),c=l("iterator"),d=l("toStringTag"),p=i.values,u=function(n,e){if(n){if(n[c]!==p)try{s(n,c,p)}catch(e){n[c]=p}if(n[d]||s(n,d,e),o[e])for(var t in i)if(n[t]!==i[t])try{s(n,t,i[t])}catch(e){n[t]=i[t]}}};for(var m in o)u(r[m]&&r[m].prototype,m);u(a,"DOMTokenList")},function(n,e,t){"use strict";var r=t(1),o=t(54).filter;r({target:"Array",proto:!0,forced:!t(89)("filter")},{filter:function(n){return o(this,n,arguments.length>1?arguments[1]:void 0)}})},function(n,e,t){var r=t(2),o=r({}.toString),a=r("".slice);n.exports=function(n){return a(o(n),8,-1)}},function(n,e,t){var r=t(7),o=t(13),a=t(49);n.exports=r?function(n,e,t){return o.f(n,e,a(1,t))}:function(n,e,t){return n[e]=t,n}},function(n,e){var t=Array.isArray;n.exports=t},function(n,e){n.exports=!1},function(n,e,t){var r=t(17);n.exports=r("navigator","userAgent")||""},function(n,e,t){var r=t(48);n.exports=function(n){return r(n.length)}},function(n,e,t){var r=t(14),o=t(263),a=Error.prototype;a.toString!==o&&r(a,"toString",o)},function(n,e,t){var r=t(186),o="object"==typeof self&&self&&self.Object===Object&&self,a=r||o||Function("return this")();n.exports=a},function(n,e,t){"use strict";var r=t(1),o=t(176);r({target:"Array",proto:!0,forced:[].forEach!=o},{forEach:o})},function(n,e,t){var r=t(0),o=t(168),a=t(169),i=t(176),s=t(25),l=function(n){if(n&&n.forEach!==i)try{s(n,"forEach",i)}catch(e){n.forEach=i}};for(var c in o)o[c]&&l(r[c]&&r[c].prototype);l(a)},function(n,e,t){var r=t(2);n.exports=r({}.isPrototypeOf)},function(n,e,t){var r,o=t(8),a=t(107),i=t(110),s=t(60),l=t(151),c=t(79),d=t(84),p=d("IE_PROTO"),u=function(){},m=function(n){return"<script>"+n+"<\/script>"},f=function(n){n.write(m("")),n.close();var e=n.parentWindow.Object;return n=null,e},h=function(){try{r=new ActiveXObject("htmlfile")}catch(n){}var n,e;h="undefined"!=typeof document?document.domain&&r?f(r):((e=c("iframe")).style.display="none",l.appendChild(e),e.src=String("javascript:"),(n=e.contentWindow.document).open(),n.write(m("document.F=Object")),n.close(),n.F):f(r);for(var t=i.length;t--;)delete h.prototype[i[t]];return h()};s[p]=!0,n.exports=Object.create||function(n,e){var t;return null!==n?(u.prototype=o(n),t=new u,u.prototype=null,t[p]=n):t=h(),void 0===e?t:a.f(t,e)}},function(n,e,t){var r=t(0),o=t(5),a=t(82),i=r.TypeError;n.exports=function(n){if(o(n))return n;throw i(a(n)+" is not a function")}},function(n,e,t){var r=t(7),o=t(11),a=t(111),i=t(49),s=t(19),l=t(80),c=t(10),d=t(148),p=Object.getOwnPropertyDescriptor;e.f=r?p:function(n,e){if(n=s(n),e=l(e),d)try{return p(n,e)}catch(n){}if(c(n,e))return i(!o(a.f,n,e),n[e])}},function(n,e,t){var r=t(58),o=Function.prototype,a=o.apply,i=o.call;n.exports="object"==typeof Reflect&&Reflect.apply||(r?i.bind(a):function(){return i.apply(a,arguments)})},function(n,e,t){"use strict";t.d(e,"a",(function(){return a}));t(101),t(68),t(23),t(4),t(377),t(32),t(33),t(171),t(378),t(97);function r(n,e,t){return e in n?Object.defineProperty(n,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):n[e]=t,n}function o(n,e){var t=Object.keys(n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(n);e&&(r=r.filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable}))),t.push.apply(t,r)}return t}function a(n){for(var e=1;e<arguments.length;e++){var t=null!=arguments[e]?arguments[e]:{};e%2?o(Object(t),!0).forEach((function(e){r(n,e,t[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(t,e))}))}return n}},function(n,e,t){var r,o,a,i=t(231),s=t(0),l=t(2),c=t(9),d=t(25),p=t(10),u=t(104),m=t(84),f=t(60),h=s.TypeError,g=s.WeakMap;if(i||u.state){var v=u.state||(u.state=new g),b=l(v.get),y=l(v.has),x=l(v.set);r=function(n,e){if(y(v,n))throw new h("Object already initialized");return e.facade=n,x(v,n,e),e},o=function(n){return b(v,n)||{}},a=function(n){return y(v,n)}}else{var _=m("state");f[_]=!0,r=function(n,e){if(p(n,_))throw new h("Object already initialized");return e.facade=n,d(n,_,e),e},o=function(n){return p(n,_)?n[_]:{}},a=function(n){return p(n,_)}}n.exports={set:r,get:o,has:a,enforce:function(n){return a(n)?o(n):r(n,{})},getterFor:function(n){return function(e){var t;if(!c(e)||(t=o(e)).type!==n)throw h("Incompatible receiver, "+n+" required");return t}}}},function(n,e,t){var r=t(1),o=t(0),a=t(38),i=t(259),s=o.WebAssembly,l=7!==Error("e",{cause:7}).cause,c=function(n,e){var t={};t[n]=i(n,e,l),r({global:!0,forced:l},t)},d=function(n,e){if(s&&s[n]){var t={};t[n]=i("WebAssembly."+n,e,l),r({target:"WebAssembly",stat:!0,forced:l},t)}};c("Error",(function(n){return function(e){return a(n,this,arguments)}})),c("EvalError",(function(n){return function(e){return a(n,this,arguments)}})),c("RangeError",(function(n){return function(e){return a(n,this,arguments)}})),c("ReferenceError",(function(n){return function(e){return a(n,this,arguments)}})),c("SyntaxError",(function(n){return function(e){return a(n,this,arguments)}})),c("TypeError",(function(n){return function(e){return a(n,this,arguments)}})),c("URIError",(function(n){return function(e){return a(n,this,arguments)}})),d("CompileError",(function(n){return function(e){return a(n,this,arguments)}})),d("LinkError",(function(n){return function(e){return a(n,this,arguments)}})),d("RuntimeError",(function(n){return function(e){return a(n,this,arguments)}}))},function(n,e,t){var r=t(284),o=t(287);n.exports=function(n,e){var t=o(n,e);return r(t)?t:void 0}},function(n,e,t){"use strict";t.d(e,"e",(function(){return r})),t.d(e,"b",(function(){return a})),t.d(e,"j",(function(){return i})),t.d(e,"g",(function(){return l})),t.d(e,"h",(function(){return c})),t.d(e,"i",(function(){return d})),t.d(e,"c",(function(){return p})),t.d(e,"f",(function(){return u})),t.d(e,"l",(function(){return m})),t.d(e,"m",(function(){return f})),t.d(e,"d",(function(){return g})),t.d(e,"k",(function(){return v})),t.d(e,"n",(function(){return b})),t.d(e,"a",(function(){return x}));t(21),t(52),t(219),t(74),t(136),t(184),t(44),t(32),t(4),t(33),t(23),t(76),t(137),t(133),t(72),t(205),t(30),t(144);var r=/#.*$/,o=/\.(md|html)$/,a=/\/$/,i=/^[a-z]+:/i;function s(n){return decodeURI(n).replace(r,"").replace(o,"")}function l(n){return i.test(n)}function c(n){return/^mailto:/.test(n)}function d(n){return/^tel:/.test(n)}function p(n){if(l(n))return n;var e=n.match(r),t=e?e[0]:"",o=s(n);return a.test(o)?n:o+".html"+t}function u(n,e){var t=n.hash,o=function(n){var e=n.match(r);if(e)return e[0]}(e);return(!o||t===o)&&s(n.path)===s(e)}function m(n,e,t){if(l(e))return{type:"external",path:e};t&&(e=function(n,e,t){var r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;var o=e.split("/");t&&o[o.length-1]||o.pop();for(var a=n.replace(/^\//,"").split("/"),i=0;i<a.length;i++){var s=a[i];".."===s?o.pop():"."!==s&&o.push(s)}""!==o[0]&&o.unshift("");return o.join("/")}(e,t));for(var r=s(e),o=0;o<n.length;o++)if(s(n[o].regularPath)===r)return Object.assign({},n[o],{type:"page",path:p(n[o].path)});return console.error('[vuepress] No matching page found for sidebar item "'.concat(e,'"')),{}}function f(n,e,t,r){var o=t.pages,a=t.themeConfig,i=r&&a.locales&&a.locales[r]||a;if("auto"===(n.frontmatter.sidebar||i.sidebar||a.sidebar))return h(n);var s=i.sidebar||a.sidebar;if(s){var l=function(n,e){if(Array.isArray(e))return{base:"/",config:e};for(var t in e)if(0===(r=n,/(\.html|\/)$/.test(r)?r:r+"/").indexOf(encodeURI(t)))return{base:t,config:e[t]};var r;return{}}(e,s),c=l.base,d=l.config;return"auto"===d?h(n):d?d.map((function(n){return function n(e,t,r){var o=arguments.length>3&&void 0!==arguments[3]?arguments[3]:1;if("string"==typeof e)return m(t,e,r);if(Array.isArray(e))return Object.assign(m(t,e[0],r),{title:e[1]});o>3&&console.error("[vuepress] detected a too deep nested sidebar group.");var a=e.children||[];return 0===a.length&&e.path?Object.assign(m(t,e.path,r),{title:e.title}):{type:"group",path:e.path,title:e.title,sidebarDepth:e.sidebarDepth,initialOpenGroupIndex:e.initialOpenGroupIndex,children:a.map((function(e){return n(e,t,r,o+1)})),collapsable:!1!==e.collapsable}}(n,o,c)})):[]}return[]}function h(n){var e=g(n.headers||[]);return[{type:"group",collapsable:!1,title:n.title,path:null,children:e.map((function(e){return{type:"auto",title:e.title,basePath:n.path,path:n.path+"#"+e.slug,children:e.children||[]}}))}]}function g(n){var e;return(n=n.map((function(n){return Object.assign({},n)}))).forEach((function(n){2===n.level?e=n:e&&(e.children||(e.children=[])).push(n)})),n.filter((function(n){return 2===n.level}))}function v(n){return Object.assign(n,{type:n.items&&n.items.length?"links":"link"})}function b(n){return Object.prototype.toString.call(n).match(/\[object (.*?)\]/)[1].toLowerCase()}function y(n){var e=n.frontmatter.date||n.lastUpdated||new Date,t=new Date(e);return"Invalid Date"==t&&e&&(t=new Date(e.replace(/-/g,"/"))),t.getTime()}function x(n,e){return y(e)-y(n)}},function(n,e,t){"use strict";var r=t(1),o=t(54).map;r({target:"Array",proto:!0,forced:!t(89)("map")},{map:function(n){return o(this,n,arguments.length>1?arguments[1]:void 0)}})},function(n,e){n.exports=function(n){return null!=n&&"object"==typeof n}},function(n,e,t){var r,o,a=t(0),i=t(28),s=a.process,l=a.Deno,c=s&&s.versions||l&&l.version,d=c&&c.v8;d&&(o=(r=d.split("."))[0]>0&&r[0]<4?1:+(r[0]+r[1])),!o&&i&&(!(r=i.match(/Edge\/(\d+)/))||r[1]>=74)&&(r=i.match(/Chrome\/(\d+)/))&&(o=+r[1]),n.exports=o},function(n,e,t){var r=t(36);n.exports=function(n,e){var t=n[e];return null==t?void 0:r(t)}},function(n,e,t){var r=t(59),o=Math.min;n.exports=function(n){return n>0?o(r(n),9007199254740991):0}},function(n,e){n.exports=function(n,e){return{enumerable:!(1&n),configurable:!(2&n),writable:!(4&n),value:e}}},function(n,e,t){"use strict";var r=t(3);n.exports=function(n,e){var t=[][n];return!!t&&r((function(){t.call(null,e||function(){return 1},1)}))}},function(n,e,t){"use strict";var r=t(1),o=t(0),a=t(66),i=t(87),s=t(9),l=t(109),c=t(29),d=t(19),p=t(67),u=t(6),m=t(89),f=t(65),h=m("slice"),g=u("species"),v=o.Array,b=Math.max;r({target:"Array",proto:!0,forced:!h},{slice:function(n,e){var t,r,o,u=d(this),m=c(u),h=l(n,m),y=l(void 0===e?m:e,m);if(a(u)&&(t=u.constructor,(i(t)&&(t===v||a(t.prototype))||s(t)&&null===(t=t[g]))&&(t=void 0),t===v||void 0===t))return f(u,h,y);for(r=new(void 0===t?v:t)(b(y-h,0)),o=0;h<y;h++,o++)h in u&&p(r,o,u[h]);return r.length=o,r}})},function(n,e,t){"use strict";var r=t(38),o=t(11),a=t(2),i=t(121),s=t(3),l=t(8),c=t(5),d=t(59),p=t(48),u=t(12),m=t(18),f=t(122),h=t(47),g=t(264),v=t(123),b=t(6)("replace"),y=Math.max,x=Math.min,_=a([].concat),k=a([].push),w=a("".indexOf),T=a("".slice),S="$0"==="a".replace(/./,"$0"),P=!!/./[b]&&""===/./[b]("a","$0");i("replace",(function(n,e,t){var a=P?"$":"$0";return[function(n,t){var r=m(this),a=null==n?void 0:h(n,b);return a?o(a,n,r,t):o(e,u(r),n,t)},function(n,o){var i=l(this),s=u(n);if("string"==typeof o&&-1===w(o,a)&&-1===w(o,"$<")){var m=t(e,i,s,o);if(m.done)return m.value}var h=c(o);h||(o=u(o));var b=i.global;if(b){var S=i.unicode;i.lastIndex=0}for(var P=[];;){var C=v(i,s);if(null===C)break;if(k(P,C),!b)break;""===u(C[0])&&(i.lastIndex=f(s,p(i.lastIndex),S))}for(var I,E="",A=0,D=0;D<P.length;D++){for(var O=u((C=P[D])[0]),L=y(x(d(C.index),s.length),0),j=[],R=1;R<C.length;R++)k(j,void 0===(I=C[R])?I:String(I));var z=C.groups;if(h){var M=_([O],j,L,s);void 0!==z&&k(M,z);var N=u(r(o,void 0,M))}else N=g(O,s,L,j,z,o);L>=A&&(E+=T(s,A,L)+N,A=L+O.length)}return E+T(s,A)}]}),!!s((function(){var n=/./;return n.exec=function(){var n=[];return n.groups={a:"7"},n},"7"!=="".replace(n,"$<a>")}))||!S||P)},function(n,e,t){var r=t(150),o=t(110).concat("length","prototype");e.f=Object.getOwnPropertyNames||function(n){return r(n,o)}},function(n,e,t){var r=t(64),o=t(2),a=t(57),i=t(16),s=t(29),l=t(170),c=o([].push),d=function(n){var e=1==n,t=2==n,o=3==n,d=4==n,p=6==n,u=7==n,m=5==n||p;return function(f,h,g,v){for(var b,y,x=i(f),_=a(x),k=r(h,g),w=s(_),T=0,S=v||l,P=e?S(f,w):t||u?S(f,0):void 0;w>T;T++)if((m||T in _)&&(y=k(b=_[T],T,x),n))if(e)P[T]=y;else if(y)switch(n){case 3:return!0;case 5:return b;case 6:return T;case 2:c(P,b)}else switch(n){case 4:return!1;case 7:c(P,b)}return p?-1:o||d?d:P}};n.exports={forEach:d(0),map:d(1),filter:d(2),some:d(3),every:d(4),find:d(5),findIndex:d(6),filterReject:d(7)}},function(n,e,t){var r=t(7),o=t(75).EXISTS,a=t(2),i=t(13).f,s=Function.prototype,l=a(s.toString),c=/function\b(?:\s|\/\*[\S\s]*?\*\/|\/\/[^\n\r]*[\n\r]+)*([^\s(/]*)/,d=a(c.exec);r&&!o&&i(s,"name",{configurable:!0,get:function(){try{return d(c,l(this))[1]}catch(n){return""}}})},function(n,e,t){var r=t(69),o=t(269),a=t(270),i=r?r.toStringTag:void 0;n.exports=function(n){return null==n?void 0===n?"[object Undefined]":"[object Null]":i&&i in Object(n)?o(n):a(n)}},function(n,e,t){var r=t(0),o=t(2),a=t(3),i=t(24),s=r.Object,l=o("".split);n.exports=a((function(){return!s("z").propertyIsEnumerable(0)}))?function(n){return"String"==i(n)?l(n,""):s(n)}:s},function(n,e,t){var r=t(3);n.exports=!r((function(){var n=function(){}.bind();return"function"!=typeof n||n.hasOwnProperty("prototype")}))},function(n,e){var t=Math.ceil,r=Math.floor;n.exports=function(n){var e=+n;return e!=e||0===e?0:(e>0?r:t)(e)}},function(n,e){n.exports={}},function(n,e){n.exports={}},function(n,e,t){var r=t(13).f,o=t(10),a=t(6)("toStringTag");n.exports=function(n,e,t){n&&!t&&(n=n.prototype),n&&!o(n,a)&&r(n,a,{configurable:!0,value:e})}},function(n,e,t){var r=t(2),o=t(8),a=t(233);n.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var n,e=!1,t={};try{(n=r(Object.getOwnPropertyDescriptor(Object.prototype,"__proto__").set))(t,[]),e=t instanceof Array}catch(n){}return function(t,r){return o(t),a(r),e?n(t,r):t.__proto__=r,t}}():void 0)},function(n,e,t){var r=t(2),o=t(36),a=t(58),i=r(r.bind);n.exports=function(n,e){return o(n),void 0===e?n:a?i(n,e):function(){return n.apply(e,arguments)}}},function(n,e,t){var r=t(2);n.exports=r([].slice)},function(n,e,t){var r=t(24);n.exports=Array.isArray||function(n){return"Array"==r(n)}},function(n,e,t){"use strict";var r=t(80),o=t(13),a=t(49);n.exports=function(n,e,t){var i=r(e);i in n?o.f(n,i,a(0,t)):n[i]=t}},function(n,e,t){"use strict";var r=t(1),o=t(0),a=t(17),i=t(38),s=t(11),l=t(2),c=t(27),d=t(7),p=t(106),u=t(3),m=t(10),f=t(66),h=t(5),g=t(9),v=t(34),b=t(81),y=t(8),x=t(16),_=t(19),k=t(80),w=t(12),T=t(49),S=t(35),P=t(83),C=t(53),I=t(178),E=t(114),A=t(37),D=t(13),O=t(107),L=t(111),j=t(65),R=t(14),z=t(77),M=t(84),N=t(60),F=t(78),q=t(6),U=t(179),B=t(180),G=t(62),H=t(40),V=t(54).forEach,$=M("hidden"),W=q("toPrimitive"),K=H.set,X=H.getterFor("Symbol"),Q=Object.prototype,Y=o.Symbol,Z=Y&&Y.prototype,J=o.TypeError,nn=o.QObject,en=a("JSON","stringify"),tn=A.f,rn=D.f,on=I.f,an=L.f,sn=l([].push),ln=z("symbols"),cn=z("op-symbols"),dn=z("string-to-symbol-registry"),pn=z("symbol-to-string-registry"),un=z("wks"),mn=!nn||!nn.prototype||!nn.prototype.findChild,fn=d&&u((function(){return 7!=S(rn({},"a",{get:function(){return rn(this,"a",{value:7}).a}})).a}))?function(n,e,t){var r=tn(Q,e);r&&delete Q[e],rn(n,e,t),r&&n!==Q&&rn(Q,e,r)}:rn,hn=function(n,e){var t=ln[n]=S(Z);return K(t,{type:"Symbol",tag:n,description:e}),d||(t.description=e),t},gn=function(n,e,t){n===Q&&gn(cn,e,t),y(n);var r=k(e);return y(t),m(ln,r)?(t.enumerable?(m(n,$)&&n[$][r]&&(n[$][r]=!1),t=S(t,{enumerable:T(0,!1)})):(m(n,$)||rn(n,$,T(1,{})),n[$][r]=!0),fn(n,r,t)):rn(n,r,t)},vn=function(n,e){y(n);var t=_(e),r=P(t).concat(_n(t));return V(r,(function(e){d&&!s(bn,t,e)||gn(n,e,t[e])})),n},bn=function(n){var e=k(n),t=s(an,this,e);return!(this===Q&&m(ln,e)&&!m(cn,e))&&(!(t||!m(this,e)||!m(ln,e)||m(this,$)&&this[$][e])||t)},yn=function(n,e){var t=_(n),r=k(e);if(t!==Q||!m(ln,r)||m(cn,r)){var o=tn(t,r);return!o||!m(ln,r)||m(t,$)&&t[$][r]||(o.enumerable=!0),o}},xn=function(n){var e=on(_(n)),t=[];return V(e,(function(n){m(ln,n)||m(N,n)||sn(t,n)})),t},_n=function(n){var e=n===Q,t=on(e?cn:_(n)),r=[];return V(t,(function(n){!m(ln,n)||e&&!m(Q,n)||sn(r,ln[n])})),r};(p||(R(Z=(Y=function(){if(v(Z,this))throw J("Symbol is not a constructor");var n=arguments.length&&void 0!==arguments[0]?w(arguments[0]):void 0,e=F(n),t=function(n){this===Q&&s(t,cn,n),m(this,$)&&m(this[$],e)&&(this[$][e]=!1),fn(this,e,T(1,n))};return d&&mn&&fn(Q,e,{configurable:!0,set:t}),hn(e,n)}).prototype,"toString",(function(){return X(this).tag})),R(Y,"withoutSetter",(function(n){return hn(F(n),n)})),L.f=bn,D.f=gn,O.f=vn,A.f=yn,C.f=I.f=xn,E.f=_n,U.f=function(n){return hn(q(n),n)},d&&(rn(Z,"description",{configurable:!0,get:function(){return X(this).description}}),c||R(Q,"propertyIsEnumerable",bn,{unsafe:!0}))),r({global:!0,wrap:!0,forced:!p,sham:!p},{Symbol:Y}),V(P(un),(function(n){B(n)})),r({target:"Symbol",stat:!0,forced:!p},{for:function(n){var e=w(n);if(m(dn,e))return dn[e];var t=Y(e);return dn[e]=t,pn[t]=e,t},keyFor:function(n){if(!b(n))throw J(n+" is not a symbol");if(m(pn,n))return pn[n]},useSetter:function(){mn=!0},useSimple:function(){mn=!1}}),r({target:"Object",stat:!0,forced:!p,sham:!d},{create:function(n,e){return void 0===e?S(n):vn(S(n),e)},defineProperty:gn,defineProperties:vn,getOwnPropertyDescriptor:yn}),r({target:"Object",stat:!0,forced:!p},{getOwnPropertyNames:xn,getOwnPropertySymbols:_n}),r({target:"Object",stat:!0,forced:u((function(){E.f(1)}))},{getOwnPropertySymbols:function(n){return E.f(x(n))}}),en)&&r({target:"JSON",stat:!0,forced:!p||u((function(){var n=Y();return"[null]"!=en([n])||"{}"!=en({a:n})||"{}"!=en(Object(n))}))},{stringify:function(n,e,t){var r=j(arguments),o=e;if((g(e)||void 0!==n)&&!b(n))return f(e)||(e=function(n,e){if(h(o)&&(e=s(o,this,n,e)),!b(e))return e}),r[1]=e,i(en,null,r)}});if(!Z[W]){var kn=Z.valueOf;R(Z,W,(function(n){return s(kn,this)}))}G(Y,"Symbol"),N[$]=!0},function(n,e,t){var r=t(31).Symbol;n.exports=r},function(n,e,t){"use strict";t.d(e,"a",(function(){return a}));t(76);var r=t(71);t(68),t(90),t(4),t(120),t(20),t(22),t(181);var o=t(98);t(41),t(30);function a(n){return function(n){if(Array.isArray(n))return Object(r.a)(n)}(n)||function(n){if("undefined"!=typeof Symbol&&null!=n[Symbol.iterator]||null!=n["@@iterator"])return Array.from(n)}(n)||Object(o.a)(n)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}},function(n,e,t){"use strict";function r(n,e){(null==e||e>n.length)&&(e=n.length);for(var t=0,r=new Array(e);t<e;t++)r[t]=n[t];return r}t.d(e,"a",(function(){return r}))},function(n,e,t){"use strict";var r=t(1),o=t(0),a=t(3),i=t(66),s=t(9),l=t(16),c=t(29),d=t(67),p=t(170),u=t(89),m=t(6),f=t(46),h=m("isConcatSpreadable"),g=o.TypeError,v=f>=51||!a((function(){var n=[];return n[h]=!1,n.concat()[0]!==n})),b=u("concat"),y=function(n){if(!s(n))return!1;var e=n[h];return void 0!==e?!!e:i(n)};r({target:"Array",proto:!0,forced:!v||!b},{concat:function(n){var e,t,r,o,a,i=l(this),s=p(i,0),u=0;for(e=-1,r=arguments.length;e<r;e++)if(y(a=-1===e?i:arguments[e])){if(u+(o=c(a))>9007199254740991)throw g("Maximum allowed index exceeded");for(t=0;t<o;t++,u++)t in a&&d(s,u,a[t])}else{if(u>=9007199254740991)throw g("Maximum allowed index exceeded");d(s,u++,a)}return s.length=u,s}})},function(n,e,t){var r=t(1),o=t(0),a=t(38),i=t(5),s=t(28),l=t(65),c=t(162),d=/MSIE .\./.test(s),p=o.Function,u=function(n){return function(e,t){var r=c(arguments.length,1)>2,o=i(e)?e:p(e),s=r?l(arguments,2):void 0;return n(r?function(){a(o,this,s)}:o,t)}};r({global:!0,bind:!0,forced:d},{setTimeout:u(o.setTimeout),setInterval:u(o.setInterval)})},function(n,e,t){"use strict";t(21);var r,o,a=t(1),i=t(0),s=t(11),l=t(2),c=t(5),d=t(9),p=(r=!1,(o=/[ac]/).exec=function(){return r=!0,/./.exec.apply(this,arguments)},!0===o.test("abc")&&r),u=i.Error,m=l(/./.test);a({target:"RegExp",proto:!0,forced:!p},{test:function(n){var e=this.exec;if(!c(e))return m(this,n);var t=s(e,this,n);if(null!==t&&!d(t))throw new u("RegExp exec method returned something other than an Object or null");return!!t}})},function(n,e,t){var r=t(7),o=t(10),a=Function.prototype,i=r&&Object.getOwnPropertyDescriptor,s=o(a,"name"),l=s&&"something"===function(){}.name,c=s&&(!r||r&&i(a,"name").configurable);n.exports={EXISTS:s,PROPER:l,CONFIGURABLE:c}},function(n,e,t){t(1)({target:"Array",stat:!0},{isArray:t(66)})},function(n,e,t){var r=t(27),o=t(104);(n.exports=function(n,e){return o[n]||(o[n]=void 0!==e?e:{})})("versions",[]).push({version:"3.21.1",mode:r?"pure":"global",copyright:"© 2014-2022 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.21.1/LICENSE",source:"https://github.com/zloirock/core-js"})},function(n,e,t){var r=t(2),o=0,a=Math.random(),i=r(1..toString);n.exports=function(n){return"Symbol("+(void 0===n?"":n)+")_"+i(++o+a,36)}},function(n,e,t){var r=t(0),o=t(9),a=r.document,i=o(a)&&o(a.createElement);n.exports=function(n){return i?a.createElement(n):{}}},function(n,e,t){var r=t(149),o=t(81);n.exports=function(n){var e=r(n,"string");return o(e)?e:e+""}},function(n,e,t){var r=t(0),o=t(17),a=t(5),i=t(34),s=t(146),l=r.Object;n.exports=s?function(n){return"symbol"==typeof n}:function(n){var e=o("Symbol");return a(e)&&i(e.prototype,l(n))}},function(n,e,t){var r=t(0).String;n.exports=function(n){try{return r(n)}catch(n){return"Object"}}},function(n,e,t){var r=t(150),o=t(110);n.exports=Object.keys||function(n){return r(n,o)}},function(n,e,t){var r=t(77),o=t(78),a=r("keys");n.exports=function(n){return a[n]||(a[n]=o(n))}},function(n,e,t){var r=t(2),o=t(5),a=t(104),i=r(Function.toString);o(a.inspectSource)||(a.inspectSource=function(n){return i(n)}),n.exports=a.inspectSource},function(n,e,t){var r=t(0),o=t(117),a=t(5),i=t(24),s=t(6)("toStringTag"),l=r.Object,c="Arguments"==i(function(){return arguments}());n.exports=o?i:function(n){var e,t,r;return void 0===n?"Undefined":null===n?"Null":"string"==typeof(t=function(n,e){try{return n[e]}catch(n){}}(e=l(n),s))?t:c?i(e):"Object"==(r=i(e))&&a(e.callee)?"Arguments":r}},function(n,e,t){var r=t(2),o=t(3),a=t(5),i=t(86),s=t(17),l=t(85),c=function(){},d=[],p=s("Reflect","construct"),u=/^\s*(?:class|function)\b/,m=r(u.exec),f=!u.exec(c),h=function(n){if(!a(n))return!1;try{return p(c,d,n),!0}catch(n){return!1}},g=function(n){if(!a(n))return!1;switch(i(n)){case"AsyncFunction":case"GeneratorFunction":case"AsyncGeneratorFunction":return!1}try{return f||!!m(u,l(n))}catch(n){return!0}};g.sham=!0,n.exports=!p||o((function(){var n;return h(h.call)||!h(Object)||!h((function(){n=!0}))||n}))?g:h},function(n,e,t){var r=t(24),o=t(0);n.exports="process"==r(o.process)},function(n,e,t){var r=t(3),o=t(6),a=t(46),i=o("species");n.exports=function(n){return a>=51||!r((function(){var e=[];return(e.constructor={})[i]=function(){return{foo:1}},1!==e[n](Boolean).foo}))}},function(n,e,t){"use strict";var r=t(1),o=t(7),a=t(0),i=t(2),s=t(10),l=t(5),c=t(34),d=t(12),p=t(13).f,u=t(112),m=a.Symbol,f=m&&m.prototype;if(o&&l(m)&&(!("description"in f)||void 0!==m().description)){var h={},g=function(){var n=arguments.length<1||void 0===arguments[0]?void 0:d(arguments[0]),e=c(f,this)?new m(n):void 0===n?m():m(n);return""===n&&(h[e]=!0),e};u(g,m),g.prototype=f,f.constructor=g;var v="Symbol(test)"==String(m("test")),b=i(f.toString),y=i(f.valueOf),x=/^Symbol\((.*)\)[^)]+$/,_=i("".replace),k=i("".slice);p(f,"description",{configurable:!0,get:function(){var n=y(this),e=b(n);if(s(h,n))return"";var t=v?k(e,7,-1):_(e,x,"$1");return""===t?void 0:t}}),r({global:!0,forced:!0},{Symbol:g})}},function(n,e,t){"use strict";var r,o,a=t(11),i=t(2),s=t(12),l=t(140),c=t(103),d=t(77),p=t(35),u=t(40).get,m=t(220),f=t(224),h=d("native-string-replace",String.prototype.replace),g=RegExp.prototype.exec,v=g,b=i("".charAt),y=i("".indexOf),x=i("".replace),_=i("".slice),k=(o=/b*/g,a(g,r=/a/,"a"),a(g,o,"a"),0!==r.lastIndex||0!==o.lastIndex),w=c.BROKEN_CARET,T=void 0!==/()??/.exec("")[1];(k||T||w||m||f)&&(v=function(n){var e,t,r,o,i,c,d,m=this,f=u(m),S=s(n),P=f.raw;if(P)return P.lastIndex=m.lastIndex,e=a(v,P,S),m.lastIndex=P.lastIndex,e;var C=f.groups,I=w&&m.sticky,E=a(l,m),A=m.source,D=0,O=S;if(I&&(E=x(E,"y",""),-1===y(E,"g")&&(E+="g"),O=_(S,m.lastIndex),m.lastIndex>0&&(!m.multiline||m.multiline&&"\n"!==b(S,m.lastIndex-1))&&(A="(?: "+A+")",O=" "+O,D++),t=new RegExp("^(?:"+A+")",E)),T&&(t=new RegExp("^"+A+"$(?!\\s)",E)),k&&(r=m.lastIndex),o=a(g,I?t:m,O),I?o?(o.input=_(o.input,D),o[0]=_(o[0],D),o.index=m.lastIndex,m.lastIndex+=o[0].length):m.lastIndex=0:k&&o&&(m.lastIndex=m.global?o.index+o[0].length:r),T&&o&&o.length>1&&a(h,o[0],t,(function(){for(i=1;i<arguments.length-2;i++)void 0===arguments[i]&&(o[i]=void 0)})),o&&C)for(o.groups=c=p(null),i=0;i<C.length;i++)c[(d=C[i])[0]]=o[d[1]];return o}),n.exports=v},function(n,e,t){var r=t(274),o=t(275),a=t(276),i=t(277),s=t(278);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=o,l.prototype.get=a,l.prototype.has=i,l.prototype.set=s,n.exports=l},function(n,e,t){var r=t(188);n.exports=function(n,e){for(var t=n.length;t--;)if(r(n[t][0],e))return t;return-1}},function(n,e,t){var r=t(42)(Object,"create");n.exports=r},function(n,e,t){var r=t(296);n.exports=function(n,e){var t=n.__data__;return r(e)?t["string"==typeof e?"string":"hash"]:t.map}},function(n,e,t){var r=t(131);n.exports=function(n){if("string"==typeof n||r(n))return n;var e=n+"";return"0"==e&&1/n==-1/0?"-0":e}},function(n,e,t){var r=t(1),o=t(7),a=t(13).f;r({target:"Object",stat:!0,forced:Object.defineProperty!==a,sham:!o},{defineProperty:a})},function(n,e,t){"use strict";t.d(e,"a",(function(){return o}));t(51),t(4),t(55),t(181),t(20),t(21),t(74);var r=t(71);function o(n,e){if(n){if("string"==typeof n)return Object(r.a)(n,e);var t=Object.prototype.toString.call(n).slice(8,-1);return"Object"===t&&n.constructor&&(t=n.constructor.name),"Map"===t||"Set"===t?Array.from(n):"Arguments"===t||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t)?Object(r.a)(n,e):void 0}}},function(n,e,t){var r,o;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(o="function"==typeof(r=function(){var n,e,t={version:"0.2.0"},r=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function o(n,e,t){return n<e?e:n>t?t:n}function a(n){return 100*(-1+n)}t.configure=function(n){var e,t;for(e in n)void 0!==(t=n[e])&&n.hasOwnProperty(e)&&(r[e]=t);return this},t.status=null,t.set=function(n){var e=t.isStarted();n=o(n,r.minimum,1),t.status=1===n?null:n;var l=t.render(!e),c=l.querySelector(r.barSelector),d=r.speed,p=r.easing;return l.offsetWidth,i((function(e){""===r.positionUsing&&(r.positionUsing=t.getPositioningCSS()),s(c,function(n,e,t){var o;return(o="translate3d"===r.positionUsing?{transform:"translate3d("+a(n)+"%,0,0)"}:"translate"===r.positionUsing?{transform:"translate("+a(n)+"%,0)"}:{"margin-left":a(n)+"%"}).transition="all "+e+"ms "+t,o}(n,d,p)),1===n?(s(l,{transition:"none",opacity:1}),l.offsetWidth,setTimeout((function(){s(l,{transition:"all "+d+"ms linear",opacity:0}),setTimeout((function(){t.remove(),e()}),d)}),d)):setTimeout(e,d)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var n=function(){setTimeout((function(){t.status&&(t.trickle(),n())}),r.trickleSpeed)};return r.trickle&&n(),this},t.done=function(n){return n||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(n){var e=t.status;return e?("number"!=typeof n&&(n=(1-e)*o(Math.random()*e,.1,.95)),e=o(e+n,0,.994),t.set(e)):t.start()},t.trickle=function(){return t.inc(Math.random()*r.trickleRate)},n=0,e=0,t.promise=function(r){return r&&"resolved"!==r.state()?(0===e&&t.start(),n++,e++,r.always((function(){0==--e?(n=0,t.done()):t.set((n-e)/n)})),this):this},t.render=function(n){if(t.isRendered())return document.getElementById("nprogress");c(document.documentElement,"nprogress-busy");var e=document.createElement("div");e.id="nprogress",e.innerHTML=r.template;var o,i=e.querySelector(r.barSelector),l=n?"-100":a(t.status||0),d=document.querySelector(r.parent);return s(i,{transition:"all 0 linear",transform:"translate3d("+l+"%,0,0)"}),r.showSpinner||(o=e.querySelector(r.spinnerSelector))&&u(o),d!=document.body&&c(d,"nprogress-custom-parent"),d.appendChild(e),e},t.remove=function(){d(document.documentElement,"nprogress-busy"),d(document.querySelector(r.parent),"nprogress-custom-parent");var n=document.getElementById("nprogress");n&&u(n)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var n=document.body.style,e="WebkitTransform"in n?"Webkit":"MozTransform"in n?"Moz":"msTransform"in n?"ms":"OTransform"in n?"O":"";return e+"Perspective"in n?"translate3d":e+"Transform"in n?"translate":"margin"};var i=function(){var n=[];function e(){var t=n.shift();t&&t(e)}return function(t){n.push(t),1==n.length&&e()}}(),s=function(){var n=["Webkit","O","Moz","ms"],e={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(n,e){return e.toUpperCase()})),e[t]||(e[t]=function(e){var t=document.body.style;if(e in t)return e;for(var r,o=n.length,a=e.charAt(0).toUpperCase()+e.slice(1);o--;)if((r=n[o]+a)in t)return r;return e}(t))}function r(n,e,r){e=t(e),n.style[e]=r}return function(n,e){var t,o,a=arguments;if(2==a.length)for(t in e)void 0!==(o=e[t])&&e.hasOwnProperty(t)&&r(n,t,o);else r(n,a[1],a[2])}}();function l(n,e){return("string"==typeof n?n:p(n)).indexOf(" "+e+" ")>=0}function c(n,e){var t=p(n),r=t+e;l(t,e)||(n.className=r.substring(1))}function d(n,e){var t,r=p(n);l(n,e)&&(t=r.replace(" "+e+" "," "),n.className=t.substring(1,t.length-1))}function p(n){return(" "+(n.className||"")+" ").replace(/\s+/gi," ")}function u(n){n&&n.parentNode&&n.parentNode.removeChild(n)}return t})?r.call(e,t,e,n):r)||(n.exports=o)},function(n){n.exports=JSON.parse('{"name":"vuepress-plugin-comment","version":"0.7.3","description":"Comment plugin in vuepress, such as Gitalk, Valine...","main":"index.js","scripts":{"test":"echo \\"Error: no test specified\\" && exit 1"},"repository":{"type":"git","url":"git+ssh://git@github.com/dongyuanxin/vuepress-plugin-comment.git"},"keywords":["vuepress","comment","plugin","vue","gitalk","valine"],"author":"dongyuanxin","license":"MIT","bugs":{"url":"https://github.com/dongyuanxin/vuepress-plugin-comment/issues"},"homepage":"https://github.com/dongyuanxin/vuepress-plugin-comment#readme","dependencies":{"ejs":"^2.6.1","gitalk":"^1.5.0","gitalk-fix":"^1.5.2","i":"^0.3.6","npm":"^6.9.0","valine":"^1.3.9"}}')},function(n,e,t){var r=t(1),o=t(16),a=t(83);r({target:"Object",stat:!0,forced:t(3)((function(){a(1)}))},{keys:function(n){return a(o(n))}})},function(n,e,t){var r=t(3),o=t(5),a=/#|\.prototype\./,i=function(n,e){var t=l[s(n)];return t==d||t!=c&&(o(e)?r(e):!!e)},s=i.normalize=function(n){return String(n).replace(a,".").toLowerCase()},l=i.data={},c=i.NATIVE="N",d=i.POLYFILL="P";n.exports=i},function(n,e,t){var r=t(3),o=t(0).RegExp,a=r((function(){var n=o("a","y");return n.lastIndex=2,null!=n.exec("abcd")})),i=a||r((function(){return!o("a","y").sticky})),s=a||r((function(){var n=o("^r","gy");return n.lastIndex=2,null!=n.exec("str")}));n.exports={BROKEN_CARET:s,MISSED_STICKY:i,UNSUPPORTED_Y:a}},function(n,e,t){var r=t(0),o=t(105),a=r["__core-js_shared__"]||o("__core-js_shared__",{});n.exports=a},function(n,e,t){var r=t(0),o=Object.defineProperty;n.exports=function(n,e){try{o(r,n,{value:e,configurable:!0,writable:!0})}catch(t){r[n]=e}return e}},function(n,e,t){var r=t(46),o=t(3);n.exports=!!Object.getOwnPropertySymbols&&!o((function(){var n=Symbol();return!String(n)||!(Object(n)instanceof Symbol)||!Symbol.sham&&r&&r<41}))},function(n,e,t){var r=t(7),o=t(147),a=t(13),i=t(8),s=t(19),l=t(83);e.f=r&&!o?Object.defineProperties:function(n,e){i(n);for(var t,r=s(e),o=l(e),c=o.length,d=0;c>d;)a.f(n,t=o[d++],r[t]);return n}},function(n,e,t){var r=t(19),o=t(109),a=t(29),i=function(n){return function(e,t,i){var s,l=r(e),c=a(l),d=o(i,c);if(n&&t!=t){for(;c>d;)if((s=l[d++])!=s)return!0}else for(;c>d;d++)if((n||d in l)&&l[d]===t)return n||d||0;return!n&&-1}};n.exports={includes:i(!0),indexOf:i(!1)}},function(n,e,t){var r=t(59),o=Math.max,a=Math.min;n.exports=function(n,e){var t=r(n);return t<0?o(t+e,0):a(t,e)}},function(n,e){n.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(n,e,t){"use strict";var r={}.propertyIsEnumerable,o=Object.getOwnPropertyDescriptor,a=o&&!r.call({1:2},1);e.f=a?function(n){var e=o(this,n);return!!e&&e.enumerable}:r},function(n,e,t){var r=t(10),o=t(113),a=t(37),i=t(13);n.exports=function(n,e,t){for(var s=o(e),l=i.f,c=a.f,d=0;d<s.length;d++){var p=s[d];r(n,p)||t&&r(t,p)||l(n,p,c(e,p))}}},function(n,e,t){var r=t(17),o=t(2),a=t(53),i=t(114),s=t(8),l=o([].concat);n.exports=r("Reflect","ownKeys")||function(n){var e=a.f(s(n)),t=i.f;return t?l(e,t(n)):e}},function(n,e){e.f=Object.getOwnPropertySymbols},function(n,e,t){var r=t(0),o=t(10),a=t(5),i=t(16),s=t(84),l=t(154),c=s("IE_PROTO"),d=r.Object,p=d.prototype;n.exports=l?d.getPrototypeOf:function(n){var e=i(n);if(o(e,c))return e[c];var t=e.constructor;return a(t)&&e instanceof t?t.prototype:e instanceof d?p:null}},function(n,e,t){var r=t(86),o=t(47),a=t(61),i=t(6)("iterator");n.exports=function(n){if(null!=n)return o(n,i)||o(n,"@@iterator")||a[r(n)]}},function(n,e,t){var r={};r[t(6)("toStringTag")]="z",n.exports="[object z]"===String(r)},function(n,e,t){var r=t(8),o=t(160),a=t(6)("species");n.exports=function(n,e){var t,i=r(n).constructor;return void 0===i||null==(t=r(i)[a])?e:o(t)}},function(n,e,t){var r=t(0),o=t(109),a=t(29),i=t(67),s=r.Array,l=Math.max;n.exports=function(n,e,t){for(var r=a(n),c=o(e,r),d=o(void 0===t?r:t,r),p=s(l(d-c,0)),u=0;c<d;c++,u++)i(p,u,n[c]);return p.length=u,p}},function(n,e,t){t(180)("iterator")},function(n,e,t){"use strict";t(21);var r=t(2),o=t(14),a=t(91),i=t(3),s=t(6),l=t(25),c=s("species"),d=RegExp.prototype;n.exports=function(n,e,t,p){var u=s(n),m=!i((function(){var e={};return e[u]=function(){return 7},7!=""[n](e)})),f=m&&!i((function(){var e=!1,t=/a/;return"split"===n&&((t={}).constructor={},t.constructor[c]=function(){return t},t.flags="",t[u]=/./[u]),t.exec=function(){return e=!0,null},t[u](""),!e}));if(!m||!f||t){var h=r(/./[u]),g=e(u,""[n],(function(n,e,t,o,i){var s=r(n),l=e.exec;return l===a||l===d.exec?m&&!i?{done:!0,value:h(e,t,o)}:{done:!0,value:s(t,e,o)}:{done:!1}}));o(String.prototype,n,g[0]),o(d,u,g[1])}p&&l(d[u],"sham",!0)}},function(n,e,t){"use strict";var r=t(167).charAt;n.exports=function(n,e,t){return e+(t?r(n,e).length:1)}},function(n,e,t){var r=t(0),o=t(11),a=t(8),i=t(5),s=t(24),l=t(91),c=r.TypeError;n.exports=function(n,e){var t=n.exec;if(i(t)){var r=o(t,n,e);return null!==r&&a(r),r}if("RegExp"===s(n))return o(l,n,e);throw c("RegExp#exec called on incompatible receiver")}},function(n,e,t){var r=t(268),o=t(45),a=Object.prototype,i=a.hasOwnProperty,s=a.propertyIsEnumerable,l=r(function(){return arguments}())?r:function(n){return o(n)&&i.call(n,"callee")&&!s.call(n,"callee")};n.exports=l},function(n,e,t){var r=t(42)(t(31),"Map");n.exports=r},function(n,e){n.exports=function(n){var e=typeof n;return null!=n&&("object"==e||"function"==e)}},function(n,e,t){var r=t(288),o=t(295),a=t(297),i=t(298),s=t(299);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=o,l.prototype.get=a,l.prototype.has=i,l.prototype.set=s,n.exports=l},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n){t[++e]=n})),t}},function(n,e){n.exports=function(n){return"number"==typeof n&&n>-1&&n%1==0&&n<=9007199254740991}},function(n,e,t){var r=t(26),o=t(131),a=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,i=/^\w*$/;n.exports=function(n,e){if(r(n))return!1;var t=typeof n;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=n&&!o(n))||(i.test(n)||!a.test(n)||null!=e&&n in Object(e))}},function(n,e,t){var r=t(56),o=t(45);n.exports=function(n){return"symbol"==typeof n||o(n)&&"[object Symbol]"==r(n)}},function(n,e){n.exports=function(n){return n}},function(n,e,t){var r=t(2),o=t(14),a=Date.prototype,i=r(a.toString),s=r(a.getTime);"Invalid Date"!=String(new Date(NaN))&&o(a,"toString",(function(){var n=s(this);return n==n?i(this):"Invalid Date"}))},function(n,e,t){var r=t(1),o=t(0),a=t(62);r({global:!0},{Reflect:{}}),a(o.Reflect,"Reflect",!0)},function(n,e,t){"use strict";var r=t(1),o=t(54).some;r({target:"Array",proto:!0,forced:!t(50)("some")},{some:function(n){return o(this,n,arguments.length>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r=t(38),o=t(11),a=t(2),i=t(121),s=t(139),l=t(8),c=t(18),d=t(118),p=t(122),u=t(48),m=t(12),f=t(47),h=t(119),g=t(123),v=t(91),b=t(103),y=t(3),x=b.UNSUPPORTED_Y,_=Math.min,k=[].push,w=a(/./.exec),T=a(k),S=a("".slice);i("split",(function(n,e,t){var a;return a="c"=="abbc".split(/(b)*/)[1]||4!="test".split(/(?:)/,-1).length||2!="ab".split(/(?:ab)*/).length||4!=".".split(/(.?)(.?)/).length||".".split(/()()/).length>1||"".split(/.?/).length?function(n,t){var a=m(c(this)),i=void 0===t?4294967295:t>>>0;if(0===i)return[];if(void 0===n)return[a];if(!s(n))return o(e,a,n,i);for(var l,d,p,u=[],f=(n.ignoreCase?"i":"")+(n.multiline?"m":"")+(n.unicode?"u":"")+(n.sticky?"y":""),g=0,b=new RegExp(n.source,f+"g");(l=o(v,b,a))&&!((d=b.lastIndex)>g&&(T(u,S(a,g,l.index)),l.length>1&&l.index<a.length&&r(k,u,h(l,1)),p=l[0].length,g=d,u.length>=i));)b.lastIndex===l.index&&b.lastIndex++;return g===a.length?!p&&w(b,"")||T(u,""):T(u,S(a,g)),u.length>i?h(u,0,i):u}:"0".split(void 0,0).length?function(n,t){return void 0===n&&0===t?[]:o(e,this,n,t)}:e,[function(e,t){var r=c(this),i=null==e?void 0:f(e,n);return i?o(i,e,r,t):o(a,m(r),e,t)},function(n,r){var o=l(this),i=m(n),s=t(a,o,i,r,a!==e);if(s.done)return s.value;var c=d(o,RegExp),f=o.unicode,h=(o.ignoreCase?"i":"")+(o.multiline?"m":"")+(o.unicode?"u":"")+(x?"g":"y"),v=new c(x?"^(?:"+o.source+")":o,h),b=void 0===r?4294967295:r>>>0;if(0===b)return[];if(0===i.length)return null===g(v,i)?[i]:[];for(var y=0,k=0,w=[];k<i.length;){v.lastIndex=x?0:k;var P,C=g(v,x?S(i,k):i);if(null===C||(P=_(u(v.lastIndex+(x?k:0)),i.length))===y)k=p(i,k,f);else{if(T(w,S(i,y,k)),w.length===b)return w;for(var I=1;I<=C.length-1;I++)if(T(w,C[I]),w.length===b)return w;k=y=P}}return T(w,S(i,y)),w}]}),!!y((function(){var n=/(?:)/,e=n.exec;n.exec=function(){return e.apply(this,arguments)};var t="ab".split(n);return 2!==t.length||"a"!==t[0]||"b"!==t[1]})),x)},function(n,e,t){"use strict";var r=t(1),o=t(2),a=t(108).indexOf,i=t(50),s=o([].indexOf),l=!!s&&1/s([1],1,-0)<0,c=i("indexOf");r({target:"Array",proto:!0,forced:l||!c},{indexOf:function(n){var e=arguments.length>1?arguments[1]:void 0;return l?s(this,n,e)||0:a(this,n,e)}})},function(n,e,t){var r=t(6),o=t(35),a=t(13),i=r("unscopables"),s=Array.prototype;null==s[i]&&a.f(s,i,{configurable:!0,value:o(null)}),n.exports=function(n){s[i][n]=!0}},function(n,e,t){var r=t(9),o=t(24),a=t(6)("match");n.exports=function(n){var e;return r(n)&&(void 0!==(e=n[a])?!!e:"RegExp"==o(n))}},function(n,e,t){"use strict";var r=t(8);n.exports=function(){var n=r(this),e="";return n.global&&(e+="g"),n.ignoreCase&&(e+="i"),n.multiline&&(e+="m"),n.dotAll&&(e+="s"),n.unicode&&(e+="u"),n.sticky&&(e+="y"),e}},function(n,e,t){var r=t(5),o=t(9),a=t(63);n.exports=function(n,e,t){var i,s;return a&&r(i=e.constructor)&&i!==t&&o(s=i.prototype)&&s!==t.prototype&&a(n,s),n}},function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},function(n,e){var t=/^\s+|\s+$/g,r=/^[-+]0x[0-9a-f]+$/i,o=/^0b[01]+$/i,a=/^0o[0-7]+$/i,i=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,l="object"==typeof self&&self&&self.Object===Object&&self,c=s||l||Function("return this")(),d=Object.prototype.toString,p=Math.max,u=Math.min,m=function(){return c.Date.now()};function f(n){var e=typeof n;return!!n&&("object"==e||"function"==e)}function h(n){if("number"==typeof n)return n;if(function(n){return"symbol"==typeof n||function(n){return!!n&&"object"==typeof n}(n)&&"[object Symbol]"==d.call(n)}(n))return NaN;if(f(n)){var e="function"==typeof n.valueOf?n.valueOf():n;n=f(e)?e+"":e}if("string"!=typeof n)return 0===n?n:+n;n=n.replace(t,"");var s=o.test(n);return s||a.test(n)?i(n.slice(2),s?2:8):r.test(n)?NaN:+n}n.exports=function(n,e,t){var r,o,a,i,s,l,c=0,d=!1,g=!1,v=!0;if("function"!=typeof n)throw new TypeError("Expected a function");function b(e){var t=r,a=o;return r=o=void 0,c=e,i=n.apply(a,t)}function y(n){return c=n,s=setTimeout(_,e),d?b(n):i}function x(n){var t=n-l;return void 0===l||t>=e||t<0||g&&n-c>=a}function _(){var n=m();if(x(n))return k(n);s=setTimeout(_,function(n){var t=e-(n-l);return g?u(t,a-(n-c)):t}(n))}function k(n){return s=void 0,v&&r?b(n):(r=o=void 0,i)}function w(){var n=m(),t=x(n);if(r=arguments,o=this,l=n,t){if(void 0===s)return y(l);if(g)return s=setTimeout(_,e),b(l)}return void 0===s&&(s=setTimeout(_,e)),i}return e=h(e)||0,f(t)&&(d=!!t.leading,a=(g="maxWait"in t)?p(h(t.maxWait)||0,e):a,v="trailing"in t?!!t.trailing:v),w.cancel=function(){void 0!==s&&clearTimeout(s),c=0,r=l=o=s=void 0},w.flush=function(){return void 0===s?i:k(m())},w}},function(n,e,t){"use strict";var r=t(2),o=t(75).PROPER,a=t(14),i=t(8),s=t(34),l=t(12),c=t(3),d=t(140),p=RegExp.prototype,u=p.toString,m=r(d),f=c((function(){return"/a/b"!=u.call({source:"a",flags:"b"})})),h=o&&"toString"!=u.name;(f||h)&&a(RegExp.prototype,"toString",(function(){var n=i(this),e=l(n.source),t=n.flags;return"/"+e+"/"+l(void 0===t&&s(p,n)&&!("flags"in p)?m(n):t)}),{unsafe:!0})},function(n,e,t){"use strict";var r=t(19),o=t(138),a=t(61),i=t(40),s=t(13).f,l=t(152),c=t(27),d=t(7),p=i.set,u=i.getterFor("Array Iterator");n.exports=l(Array,"Array",(function(n,e){p(this,{type:"Array Iterator",target:r(n),index:0,kind:e})}),(function(){var n=u(this),e=n.target,t=n.kind,r=n.index++;return!e||r>=e.length?(n.target=void 0,{value:void 0,done:!0}):"keys"==t?{value:r,done:!1}:"values"==t?{value:e[r],done:!1}:{value:[r,e[r]],done:!1}}),"values");var m=a.Arguments=a.Array;if(o("keys"),o("values"),o("entries"),!c&&d&&"values"!==m.name)try{s(m,"name",{value:"values"})}catch(n){}},function(n,e,t){var r=t(106);n.exports=r&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(n,e,t){var r=t(7),o=t(3);n.exports=r&&o((function(){return 42!=Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(n,e,t){var r=t(7),o=t(3),a=t(79);n.exports=!r&&!o((function(){return 7!=Object.defineProperty(a("div"),"a",{get:function(){return 7}}).a}))},function(n,e,t){var r=t(0),o=t(11),a=t(9),i=t(81),s=t(47),l=t(230),c=t(6),d=r.TypeError,p=c("toPrimitive");n.exports=function(n,e){if(!a(n)||i(n))return n;var t,r=s(n,p);if(r){if(void 0===e&&(e="default"),t=o(r,n,e),!a(t)||i(t))return t;throw d("Can't convert object to primitive value")}return void 0===e&&(e="number"),l(n,e)}},function(n,e,t){var r=t(2),o=t(10),a=t(19),i=t(108).indexOf,s=t(60),l=r([].push);n.exports=function(n,e){var t,r=a(n),c=0,d=[];for(t in r)!o(s,t)&&o(r,t)&&l(d,t);for(;e.length>c;)o(r,t=e[c++])&&(~i(d,t)||l(d,t));return d}},function(n,e,t){var r=t(17);n.exports=r("document","documentElement")},function(n,e,t){"use strict";var r=t(1),o=t(11),a=t(27),i=t(75),s=t(5),l=t(232),c=t(115),d=t(63),p=t(62),u=t(25),m=t(14),f=t(6),h=t(61),g=t(153),v=i.PROPER,b=i.CONFIGURABLE,y=g.IteratorPrototype,x=g.BUGGY_SAFARI_ITERATORS,_=f("iterator"),k=function(){return this};n.exports=function(n,e,t,i,f,g,w){l(t,e,i);var T,S,P,C=function(n){if(n===f&&O)return O;if(!x&&n in A)return A[n];switch(n){case"keys":case"values":case"entries":return function(){return new t(this,n)}}return function(){return new t(this)}},I=e+" Iterator",E=!1,A=n.prototype,D=A[_]||A["@@iterator"]||f&&A[f],O=!x&&D||C(f),L="Array"==e&&A.entries||D;if(L&&(T=c(L.call(new n)))!==Object.prototype&&T.next&&(a||c(T)===y||(d?d(T,y):s(T[_])||m(T,_,k)),p(T,I,!0,!0),a&&(h[I]=k)),v&&"values"==f&&D&&"values"!==D.name&&(!a&&b?u(A,"name","values"):(E=!0,O=function(){return o(D,this)})),f)if(S={values:C("values"),keys:g?O:C("keys"),entries:C("entries")},w)for(P in S)(x||E||!(P in A))&&m(A,P,S[P]);else r({target:e,proto:!0,forced:x||E},S);return a&&!w||A[_]===O||m(A,_,O,{name:f}),h[e]=O,S}},function(n,e,t){"use strict";var r,o,a,i=t(3),s=t(5),l=t(35),c=t(115),d=t(14),p=t(6),u=t(27),m=p("iterator"),f=!1;[].keys&&("next"in(a=[].keys())?(o=c(c(a)))!==Object.prototype&&(r=o):f=!0),null==r||i((function(){var n={};return r[m].call(n)!==n}))?r={}:u&&(r=l(r)),s(r[m])||d(r,m,(function(){return this})),n.exports={IteratorPrototype:r,BUGGY_SAFARI_ITERATORS:f}},function(n,e,t){var r=t(3);n.exports=!r((function(){function n(){}return n.prototype.constructor=null,Object.getPrototypeOf(new n)!==n.prototype}))},function(n,e,t){var r=t(0);n.exports=r.Promise},function(n,e,t){var r=t(6),o=t(61),a=r("iterator"),i=Array.prototype;n.exports=function(n){return void 0!==n&&(o.Array===n||i[a]===n)}},function(n,e,t){var r=t(0),o=t(11),a=t(36),i=t(8),s=t(82),l=t(116),c=r.TypeError;n.exports=function(n,e){var t=arguments.length<2?l(n):e;if(a(t))return i(o(t,n));throw c(s(n)+" is not iterable")}},function(n,e,t){var r=t(11),o=t(8),a=t(47);n.exports=function(n,e,t){var i,s;o(n);try{if(!(i=a(n,"return"))){if("throw"===e)throw t;return t}i=r(i,n)}catch(n){s=!0,i=n}if("throw"===e)throw t;if(s)throw i;return o(i),t}},function(n,e,t){var r=t(6)("iterator"),o=!1;try{var a=0,i={next:function(){return{done:!!a++}},return:function(){o=!0}};i[r]=function(){return this},Array.from(i,(function(){throw 2}))}catch(n){}n.exports=function(n,e){if(!e&&!o)return!1;var t=!1;try{var a={};a[r]=function(){return{next:function(){return{done:t=!0}}}},n(a)}catch(n){}return t}},function(n,e,t){var r=t(0),o=t(87),a=t(82),i=r.TypeError;n.exports=function(n){if(o(n))return n;throw i(a(n)+" is not a constructor")}},function(n,e,t){var r,o,a,i,s=t(0),l=t(38),c=t(64),d=t(5),p=t(10),u=t(3),m=t(151),f=t(65),h=t(79),g=t(162),v=t(163),b=t(88),y=s.setImmediate,x=s.clearImmediate,_=s.process,k=s.Dispatch,w=s.Function,T=s.MessageChannel,S=s.String,P=0,C={};try{r=s.location}catch(n){}var I=function(n){if(p(C,n)){var e=C[n];delete C[n],e()}},E=function(n){return function(){I(n)}},A=function(n){I(n.data)},D=function(n){s.postMessage(S(n),r.protocol+"//"+r.host)};y&&x||(y=function(n){g(arguments.length,1);var e=d(n)?n:w(n),t=f(arguments,1);return C[++P]=function(){l(e,void 0,t)},o(P),P},x=function(n){delete C[n]},b?o=function(n){_.nextTick(E(n))}:k&&k.now?o=function(n){k.now(E(n))}:T&&!v?(i=(a=new T).port2,a.port1.onmessage=A,o=c(i.postMessage,i)):s.addEventListener&&d(s.postMessage)&&!s.importScripts&&r&&"file:"!==r.protocol&&!u(D)?(o=D,s.addEventListener("message",A,!1)):o="onreadystatechange"in h("script")?function(n){m.appendChild(h("script")).onreadystatechange=function(){m.removeChild(this),I(n)}}:function(n){setTimeout(E(n),0)}),n.exports={set:y,clear:x}},function(n,e,t){var r=t(0).TypeError;n.exports=function(n,e){if(n<e)throw r("Not enough arguments");return n}},function(n,e,t){var r=t(28);n.exports=/(?:ipad|iphone|ipod).*applewebkit/i.test(r)},function(n,e,t){var r=t(8),o=t(9),a=t(165);n.exports=function(n,e){if(r(n),o(e)&&e.constructor===n)return e;var t=a.f(n);return(0,t.resolve)(e),t.promise}},function(n,e,t){"use strict";var r=t(36),o=function(n){var e,t;this.promise=new n((function(n,r){if(void 0!==e||void 0!==t)throw TypeError("Bad Promise constructor");e=n,t=r})),this.resolve=r(e),this.reject=r(t)};n.exports.f=function(n){return new o(n)}},function(n,e,t){var r=function(n){"use strict";var e=Object.prototype,t=e.hasOwnProperty,r="function"==typeof Symbol?Symbol:{},o=r.iterator||"@@iterator",a=r.asyncIterator||"@@asyncIterator",i=r.toStringTag||"@@toStringTag";function s(n,e,t){return Object.defineProperty(n,e,{value:t,enumerable:!0,configurable:!0,writable:!0}),n[e]}try{s({},"")}catch(n){s=function(n,e,t){return n[e]=t}}function l(n,e,t,r){var o=e&&e.prototype instanceof p?e:p,a=Object.create(o.prototype),i=new w(r||[]);return a._invoke=function(n,e,t){var r="suspendedStart";return function(o,a){if("executing"===r)throw new Error("Generator is already running");if("completed"===r){if("throw"===o)throw a;return S()}for(t.method=o,t.arg=a;;){var i=t.delegate;if(i){var s=x(i,t);if(s){if(s===d)continue;return s}}if("next"===t.method)t.sent=t._sent=t.arg;else if("throw"===t.method){if("suspendedStart"===r)throw r="completed",t.arg;t.dispatchException(t.arg)}else"return"===t.method&&t.abrupt("return",t.arg);r="executing";var l=c(n,e,t);if("normal"===l.type){if(r=t.done?"completed":"suspendedYield",l.arg===d)continue;return{value:l.arg,done:t.done}}"throw"===l.type&&(r="completed",t.method="throw",t.arg=l.arg)}}}(n,t,i),a}function c(n,e,t){try{return{type:"normal",arg:n.call(e,t)}}catch(n){return{type:"throw",arg:n}}}n.wrap=l;var d={};function p(){}function u(){}function m(){}var f={};s(f,o,(function(){return this}));var h=Object.getPrototypeOf,g=h&&h(h(T([])));g&&g!==e&&t.call(g,o)&&(f=g);var v=m.prototype=p.prototype=Object.create(f);function b(n){["next","throw","return"].forEach((function(e){s(n,e,(function(n){return this._invoke(e,n)}))}))}function y(n,e){var r;this._invoke=function(o,a){function i(){return new e((function(r,i){!function r(o,a,i,s){var l=c(n[o],n,a);if("throw"!==l.type){var d=l.arg,p=d.value;return p&&"object"==typeof p&&t.call(p,"__await")?e.resolve(p.__await).then((function(n){r("next",n,i,s)}),(function(n){r("throw",n,i,s)})):e.resolve(p).then((function(n){d.value=n,i(d)}),(function(n){return r("throw",n,i,s)}))}s(l.arg)}(o,a,r,i)}))}return r=r?r.then(i,i):i()}}function x(n,e){var t=n.iterator[e.method];if(void 0===t){if(e.delegate=null,"throw"===e.method){if(n.iterator.return&&(e.method="return",e.arg=void 0,x(n,e),"throw"===e.method))return d;e.method="throw",e.arg=new TypeError("The iterator does not provide a 'throw' method")}return d}var r=c(t,n.iterator,e.arg);if("throw"===r.type)return e.method="throw",e.arg=r.arg,e.delegate=null,d;var o=r.arg;return o?o.done?(e[n.resultName]=o.value,e.next=n.nextLoc,"return"!==e.method&&(e.method="next",e.arg=void 0),e.delegate=null,d):o:(e.method="throw",e.arg=new TypeError("iterator result is not an object"),e.delegate=null,d)}function _(n){var e={tryLoc:n[0]};1 in n&&(e.catchLoc=n[1]),2 in n&&(e.finallyLoc=n[2],e.afterLoc=n[3]),this.tryEntries.push(e)}function k(n){var e=n.completion||{};e.type="normal",delete e.arg,n.completion=e}function w(n){this.tryEntries=[{tryLoc:"root"}],n.forEach(_,this),this.reset(!0)}function T(n){if(n){var e=n[o];if(e)return e.call(n);if("function"==typeof n.next)return n;if(!isNaN(n.length)){var r=-1,a=function e(){for(;++r<n.length;)if(t.call(n,r))return e.value=n[r],e.done=!1,e;return e.value=void 0,e.done=!0,e};return a.next=a}}return{next:S}}function S(){return{value:void 0,done:!0}}return u.prototype=m,s(v,"constructor",m),s(m,"constructor",u),u.displayName=s(m,i,"GeneratorFunction"),n.isGeneratorFunction=function(n){var e="function"==typeof n&&n.constructor;return!!e&&(e===u||"GeneratorFunction"===(e.displayName||e.name))},n.mark=function(n){return Object.setPrototypeOf?Object.setPrototypeOf(n,m):(n.__proto__=m,s(n,i,"GeneratorFunction")),n.prototype=Object.create(v),n},n.awrap=function(n){return{__await:n}},b(y.prototype),s(y.prototype,a,(function(){return this})),n.AsyncIterator=y,n.async=function(e,t,r,o,a){void 0===a&&(a=Promise);var i=new y(l(e,t,r,o),a);return n.isGeneratorFunction(t)?i:i.next().then((function(n){return n.done?n.value:i.next()}))},b(v),s(v,i,"Generator"),s(v,o,(function(){return this})),s(v,"toString",(function(){return"[object Generator]"})),n.keys=function(n){var e=[];for(var t in n)e.push(t);return e.reverse(),function t(){for(;e.length;){var r=e.pop();if(r in n)return t.value=r,t.done=!1,t}return t.done=!0,t}},n.values=T,w.prototype={constructor:w,reset:function(n){if(this.prev=0,this.next=0,this.sent=this._sent=void 0,this.done=!1,this.delegate=null,this.method="next",this.arg=void 0,this.tryEntries.forEach(k),!n)for(var e in this)"t"===e.charAt(0)&&t.call(this,e)&&!isNaN(+e.slice(1))&&(this[e]=void 0)},stop:function(){this.done=!0;var n=this.tryEntries[0].completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(n){if(this.done)throw n;var e=this;function r(t,r){return i.type="throw",i.arg=n,e.next=t,r&&(e.method="next",e.arg=void 0),!!r}for(var o=this.tryEntries.length-1;o>=0;--o){var a=this.tryEntries[o],i=a.completion;if("root"===a.tryLoc)return r("end");if(a.tryLoc<=this.prev){var s=t.call(a,"catchLoc"),l=t.call(a,"finallyLoc");if(s&&l){if(this.prev<a.catchLoc)return r(a.catchLoc,!0);if(this.prev<a.finallyLoc)return r(a.finallyLoc)}else if(s){if(this.prev<a.catchLoc)return r(a.catchLoc,!0)}else{if(!l)throw new Error("try statement without catch or finally");if(this.prev<a.finallyLoc)return r(a.finallyLoc)}}}},abrupt:function(n,e){for(var r=this.tryEntries.length-1;r>=0;--r){var o=this.tryEntries[r];if(o.tryLoc<=this.prev&&t.call(o,"finallyLoc")&&this.prev<o.finallyLoc){var a=o;break}}a&&("break"===n||"continue"===n)&&a.tryLoc<=e&&e<=a.finallyLoc&&(a=null);var i=a?a.completion:{};return i.type=n,i.arg=e,a?(this.method="next",this.next=a.finallyLoc,d):this.complete(i)},complete:function(n,e){if("throw"===n.type)throw n.arg;return"break"===n.type||"continue"===n.type?this.next=n.arg:"return"===n.type?(this.rval=this.arg=n.arg,this.method="return",this.next="end"):"normal"===n.type&&e&&(this.next=e),d},finish:function(n){for(var e=this.tryEntries.length-1;e>=0;--e){var t=this.tryEntries[e];if(t.finallyLoc===n)return this.complete(t.completion,t.afterLoc),k(t),d}},catch:function(n){for(var e=this.tryEntries.length-1;e>=0;--e){var t=this.tryEntries[e];if(t.tryLoc===n){var r=t.completion;if("throw"===r.type){var o=r.arg;k(t)}return o}}throw new Error("illegal catch attempt")},delegateYield:function(n,e,t){return this.delegate={iterator:T(n),resultName:e,nextLoc:t},"next"===this.method&&(this.arg=void 0),d}},n}(n.exports);try{regeneratorRuntime=r}catch(n){"object"==typeof globalThis?globalThis.regeneratorRuntime=r:Function("r","regeneratorRuntime = r")(r)}},function(n,e,t){var r=t(2),o=t(59),a=t(12),i=t(18),s=r("".charAt),l=r("".charCodeAt),c=r("".slice),d=function(n){return function(e,t){var r,d,p=a(i(e)),u=o(t),m=p.length;return u<0||u>=m?n?"":void 0:(r=l(p,u))<55296||r>56319||u+1===m||(d=l(p,u+1))<56320||d>57343?n?s(p,u):r:n?c(p,u,u+2):d-56320+(r-55296<<10)+65536}};n.exports={codeAt:d(!1),charAt:d(!0)}},function(n,e){n.exports={CSSRuleList:0,CSSStyleDeclaration:0,CSSValueList:0,ClientRectList:0,DOMRectList:0,DOMStringList:0,DOMTokenList:1,DataTransferItemList:0,FileList:0,HTMLAllCollection:0,HTMLCollection:0,HTMLFormElement:0,HTMLSelectElement:0,MediaList:0,MimeTypeArray:0,NamedNodeMap:0,NodeList:1,PaintRequestList:0,Plugin:0,PluginArray:0,SVGLengthList:0,SVGNumberList:0,SVGPathSegList:0,SVGPointList:0,SVGStringList:0,SVGTransformList:0,SourceBufferList:0,StyleSheetList:0,TextTrackCueList:0,TextTrackList:0,TouchList:0}},function(n,e,t){var r=t(79)("span").classList,o=r&&r.constructor&&r.constructor.prototype;n.exports=o===Object.prototype?void 0:o},function(n,e,t){var r=t(249);n.exports=function(n,e){return new(r(n))(0===e?0:e)}},function(n,e,t){var r=t(1),o=t(7),a=t(113),i=t(19),s=t(37),l=t(67);r({target:"Object",stat:!0,sham:!o},{getOwnPropertyDescriptors:function(n){for(var e,t,r=i(n),o=s.f,c=a(r),d={},p=0;c.length>p;)void 0!==(t=o(r,e=c[p++]))&&l(d,e,t);return d}})},function(n,e,t){var r=t(1),o=t(3),a=t(16),i=t(115),s=t(154);r({target:"Object",stat:!0,forced:o((function(){i(1)})),sham:!s},{getPrototypeOf:function(n){return i(a(n))}})},function(n,e,t){"use strict";var r,o=t(1),a=t(2),i=t(37).f,s=t(48),l=t(12),c=t(174),d=t(18),p=t(175),u=t(27),m=a("".startsWith),f=a("".slice),h=Math.min,g=p("startsWith");o({target:"String",proto:!0,forced:!!(u||g||(r=i(String.prototype,"startsWith"),!r||r.writable))&&!g},{startsWith:function(n){var e=l(d(this));c(n);var t=s(h(arguments.length>1?arguments[1]:void 0,e.length)),r=l(n);return m?m(e,r,t):f(e,t,t+r.length)===r}})},function(n,e,t){var r=t(0),o=t(139),a=r.TypeError;n.exports=function(n){if(o(n))throw a("The method doesn't accept regular expressions");return n}},function(n,e,t){var r=t(6)("match");n.exports=function(n){var e=/./;try{"/./"[n](e)}catch(t){try{return e[r]=!1,"/./"[n](e)}catch(n){}}return!1}},function(n,e,t){"use strict";var r=t(54).forEach,o=t(50)("forEach");n.exports=o?[].forEach:function(n){return r(this,n,arguments.length>1?arguments[1]:void 0)}},function(n,e,t){var r=t(3);n.exports=!r((function(){return Object.isExtensible(Object.preventExtensions({}))}))},function(n,e,t){var r=t(24),o=t(19),a=t(53).f,i=t(119),s="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[];n.exports.f=function(n){return s&&"Window"==r(n)?function(n){try{return a(n)}catch(n){return i(s)}}(n):a(o(n))}},function(n,e,t){var r=t(6);e.f=r},function(n,e,t){var r=t(256),o=t(10),a=t(179),i=t(13).f;n.exports=function(n){var e=r.Symbol||(r.Symbol={});o(e,n)||i(e,n,{value:a.f(n)})}},function(n,e,t){var r=t(1),o=t(257);r({target:"Array",stat:!0,forced:!t(159)((function(n){Array.from(n)}))},{from:o})},function(n,e,t){var r=t(12);n.exports=function(n,e){return void 0===n?arguments.length<2?"":e:r(n)}},function(n,e,t){t(1)({target:"Object",stat:!0,sham:!t(7)},{create:t(35)})},function(n,e,t){"use strict";var r=t(1),o=t(2),a=t(57),i=t(19),s=t(50),l=o([].join),c=a!=Object,d=s("join",",");r({target:"Array",proto:!0,forced:c||!d},{join:function(n){return l(i(this),void 0===n?",":n)}})},function(n,e){n.exports=function(n,e){for(var t=-1,r=e.length,o=n.length;++t<r;)n[o+t]=e[t];return n}},function(n,e){var t="object"==typeof global&&global&&global.Object===Object&&global;n.exports=t},function(n,e,t){var r=t(92),o=t(279),a=t(280),i=t(281),s=t(282),l=t(283);function c(n){var e=this.__data__=new r(n);this.size=e.size}c.prototype.clear=o,c.prototype.delete=a,c.prototype.get=i,c.prototype.has=s,c.prototype.set=l,n.exports=c},function(n,e){n.exports=function(n,e){return n===e||n!=n&&e!=e}},function(n,e,t){var r=t(56),o=t(126);n.exports=function(n){if(!o(n))return!1;var e=r(n);return"[object Function]"==e||"[object GeneratorFunction]"==e||"[object AsyncFunction]"==e||"[object Proxy]"==e}},function(n,e){var t=Function.prototype.toString;n.exports=function(n){if(null!=n){try{return t.call(n)}catch(n){}try{return n+""}catch(n){}}return""}},function(n,e,t){var r=t(300),o=t(45);n.exports=function n(e,t,a,i,s){return e===t||(null==e||null==t||!o(e)&&!o(t)?e!=e&&t!=t:r(e,t,a,i,n,s))}},function(n,e,t){var r=t(193),o=t(303),a=t(194);n.exports=function(n,e,t,i,s,l){var c=1&t,d=n.length,p=e.length;if(d!=p&&!(c&&p>d))return!1;var u=l.get(n),m=l.get(e);if(u&&m)return u==e&&m==n;var f=-1,h=!0,g=2&t?new r:void 0;for(l.set(n,e),l.set(e,n);++f<d;){var v=n[f],b=e[f];if(i)var y=c?i(b,v,f,e,n,l):i(v,b,f,n,e,l);if(void 0!==y){if(y)continue;h=!1;break}if(g){if(!o(e,(function(n,e){if(!a(g,e)&&(v===n||s(v,n,t,i,l)))return g.push(e)}))){h=!1;break}}else if(v!==b&&!s(v,b,t,i,l)){h=!1;break}}return l.delete(n),l.delete(e),h}},function(n,e,t){var r=t(127),o=t(301),a=t(302);function i(n){var e=-1,t=null==n?0:n.length;for(this.__data__=new r;++e<t;)this.add(n[e])}i.prototype.add=i.prototype.push=o,i.prototype.has=a,n.exports=i},function(n,e){n.exports=function(n,e){return n.has(e)}},function(n,e,t){var r=t(313),o=t(319),a=t(199);n.exports=function(n){return a(n)?r(n):o(n)}},function(n,e,t){(function(n){var r=t(31),o=t(315),a=e&&!e.nodeType&&e,i=a&&"object"==typeof n&&n&&!n.nodeType&&n,s=i&&i.exports===a?r.Buffer:void 0,l=(s?s.isBuffer:void 0)||o;n.exports=l}).call(this,t(142)(n))},function(n,e){var t=/^(?:0|[1-9]\d*)$/;n.exports=function(n,e){var r=typeof n;return!!(e=null==e?9007199254740991:e)&&("number"==r||"symbol"!=r&&t.test(n))&&n>-1&&n%1==0&&n<e}},function(n,e,t){var r=t(316),o=t(317),a=t(318),i=a&&a.isTypedArray,s=i?o(i):r;n.exports=s},function(n,e,t){var r=t(189),o=t(129);n.exports=function(n){return null!=n&&o(n.length)&&!r(n)}},function(n,e,t){var r=t(42)(t(31),"Set");n.exports=r},function(n,e,t){var r=t(126);n.exports=function(n){return n==n&&!r(n)}},function(n,e){n.exports=function(n,e){return function(t){return null!=t&&(t[n]===e&&(void 0!==e||n in Object(t)))}}},function(n,e,t){var r=t(204),o=t(96);n.exports=function(n,e){for(var t=0,a=(e=r(e,n)).length;null!=n&&t<a;)n=n[o(e[t++])];return t&&t==a?n:void 0}},function(n,e,t){var r=t(26),o=t(130),a=t(330),i=t(333);n.exports=function(n,e){return r(n)?n:o(n,e)?[n]:a(i(n))}},function(n,e,t){"use strict";var r=t(1),o=t(363).start;r({target:"String",proto:!0,forced:t(365)},{padStart:function(n){return o(this,n,arguments.length>1?arguments[1]:void 0)}})},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){t(1)({target:"Object",stat:!0},{setPrototypeOf:t(63)})},function(n,e,t){var r=t(1),o=t(17),a=t(38),i=t(386),s=t(160),l=t(8),c=t(9),d=t(35),p=t(3),u=o("Reflect","construct"),m=Object.prototype,f=[].push,h=p((function(){function n(){}return!(u((function(){}),[],n)instanceof n)})),g=!p((function(){u((function(){}))})),v=h||g;r({target:"Reflect",stat:!0,forced:v,sham:v},{construct:function(n,e){s(n),l(e);var t=arguments.length<3?n:s(arguments[2]);if(g&&!h)return u(n,e,t);if(n==t){switch(e.length){case 0:return new n;case 1:return new n(e[0]);case 2:return new n(e[0],e[1]);case 3:return new n(e[0],e[1],e[2]);case 4:return new n(e[0],e[1],e[2],e[3])}var r=[null];return a(f,r,e),new(a(i,n,r))}var o=t.prototype,p=d(c(o)?o:m),v=a(n,p,e);return c(v)?v:p}})},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(266),o=t(271),a=t(342),i=t(350),s=t(359),l=t(227),c=a((function(n){var e=l(n);return s(e)&&(e=void 0),i(r(n,1,s,!0),o(e,2))}));n.exports=c},function(n,e,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var r=/["'&<>]/;n.exports=function(n){var e,t=""+n,o=r.exec(t);if(!o)return t;var a="",i=0,s=0;for(i=o.index;i<t.length;i++){switch(t.charCodeAt(i)){case 34:e="&quot;";break;case 38:e="&amp;";break;case 39:e="&#39;";break;case 60:e="&lt;";break;case 62:e="&gt;";break;default:continue}s!==i&&(a+=t.substring(s,i)),s=i+1,a+=e}return s!==i?a+t.substring(s,i):a}},function(n,e,t){"use strict";
/**
 * @file Embedded JavaScript templating engine. {@link http://ejs.co}
 * @author Matthew Eernisse <mde@fleegix.org>
 * @author Tiancheng "Timothy" Gu <timothygu99@gmail.com>
 * @project EJS
 * @license {@link http://www.apache.org/licenses/LICENSE-2.0 Apache License, Version 2.0}
 */var r=t(380),o=t(381),a=t(382),i=!1,s=t(383).version,l=["delimiter","scope","context","debug","compileDebug","client","_with","rmWhitespace","strict","filename","async"],c=l.concat("cache"),d=/^\uFEFF/;function p(n,t){var o,a,i=t.views,s=/^[A-Za-z]+:\\|^\//.exec(n);if(s&&s.length)o=e.resolveInclude(n.replace(/^\/*/,""),t.root||"/",!0);else if(t.filename&&(a=e.resolveInclude(n,t.filename),r.existsSync(a)&&(o=a)),o||Array.isArray(i)&&i.some((function(t){return a=e.resolveInclude(n,t,!0),r.existsSync(a)}))&&(o=a),!o)throw new Error('Could not find the include file "'+t.escapeFunction(n)+'"');return o}function u(n,t){var r,o=n.filename,a=arguments.length>1;if(n.cache){if(!o)throw new Error("cache option requires a filename");if(r=e.cache.get(o))return r;a||(t=f(o).toString().replace(d,""))}else if(!a){if(!o)throw new Error("Internal EJS error: no file name or template provided");t=f(o).toString().replace(d,"")}return r=e.compile(t,n),n.cache&&e.cache.set(o,r),r}function m(n,t,r){var o;if(!r){if("function"==typeof e.promiseImpl)return new e.promiseImpl((function(e,r){try{e(o=u(n)(t))}catch(n){r(n)}}));throw new Error("Please provide a callback function")}try{o=u(n)(t)}catch(n){return r(n)}r(null,o)}function f(n){return e.fileLoader(n)}function h(n,e,t,r,o){var a=e.split("\n"),i=Math.max(r-3,0),s=Math.min(a.length,r+3),l=o(t),c=a.slice(i,s).map((function(n,e){var t=e+i+1;return(t==r?" >> ":"    ")+t+"| "+n})).join("\n");throw n.path=l,n.message=(l||"ejs")+":"+r+"\n"+c+"\n\n"+n.message,n}function g(n){return n.replace(/;(\s*$)/,"$1")}function v(n,t){t=t||{};var r={};this.templateText=n,this.mode=null,this.truncate=!1,this.currentLine=1,this.source="",this.dependencies=[],r.client=t.client||!1,r.escapeFunction=t.escape||t.escapeFunction||a.escapeXML,r.compileDebug=!1!==t.compileDebug,r.debug=!!t.debug,r.filename=t.filename,r.openDelimiter=t.openDelimiter||e.openDelimiter||"<",r.closeDelimiter=t.closeDelimiter||e.closeDelimiter||">",r.delimiter=t.delimiter||e.delimiter||"%",r.strict=t.strict||!1,r.context=t.context,r.cache=t.cache||!1,r.rmWhitespace=t.rmWhitespace,r.root=t.root,r.outputFunctionName=t.outputFunctionName,r.localsName=t.localsName||e.localsName||"locals",r.views=t.views,r.async=t.async,r.destructuredLocals=t.destructuredLocals,r.legacyInclude=void 0===t.legacyInclude||!!t.legacyInclude,r.strict?r._with=!1:r._with=void 0===t._with||t._with,this.opts=r,this.regex=this.createRegex()}e.cache=a.cache,e.fileLoader=r.readFileSync,e.localsName="locals",e.promiseImpl=new Function("return this;")().Promise,e.resolveInclude=function(n,e,t){var r=o.dirname,a=o.extname,i=(0,o.resolve)(t?e:r(e),n);return a(n)||(i+=".ejs"),i},e.compile=function(n,e){return e&&e.scope&&(i||(console.warn("`scope` option is deprecated and will be removed in EJS 3"),i=!0),e.context||(e.context=e.scope),delete e.scope),new v(n,e).compile()},e.render=function(n,e,t){var r=e||{},o=t||{};return 2==arguments.length&&a.shallowCopyFromList(o,r,l),u(o,n)(r)},e.renderFile=function(){var n,e,t,r=Array.prototype.slice.call(arguments),o=r.shift(),i={filename:o};return"function"==typeof arguments[arguments.length-1]&&(n=r.pop()),r.length?(e=r.shift(),r.length?a.shallowCopy(i,r.pop()):(e.settings&&(e.settings.views&&(i.views=e.settings.views),e.settings["view cache"]&&(i.cache=!0),(t=e.settings["view options"])&&a.shallowCopy(i,t)),a.shallowCopyFromList(i,e,c)),i.filename=o):e={},m(i,e,n)},e.Template=v,e.clearCache=function(){e.cache.reset()},v.modes={EVAL:"eval",ESCAPED:"escaped",RAW:"raw",COMMENT:"comment",LITERAL:"literal"},v.prototype={createRegex:function(){var n="(<%%|%%>|<%=|<%-|<%_|<%#|<%|%>|-%>|_%>)",e=a.escapeRegExpChars(this.opts.delimiter),t=a.escapeRegExpChars(this.opts.openDelimiter),r=a.escapeRegExpChars(this.opts.closeDelimiter);return n=n.replace(/%/g,e).replace(/</g,t).replace(/>/g,r),new RegExp(n)},compile:function(){var n,e,t,r=this.opts,i="",s="",l=r.escapeFunction;if(!this.source){if(this.generateSource(),i+='  var __output = "";\n  function __append(s) { if (s !== undefined && s !== null) __output += s }\n',r.outputFunctionName&&(i+="  var "+r.outputFunctionName+" = __append;\n"),r.destructuredLocals&&r.destructuredLocals.length){for(var c="  var __locals = ("+r.localsName+" || {}),\n",d=0;d<r.destructuredLocals.length;d++){var m=r.destructuredLocals[d];d>0&&(c+=",\n  "),c+=m+" = __locals."+m}i+=c+";\n"}!1!==r._with&&(i+="  with ("+r.localsName+" || {}) {\n",s+="  }\n"),s+="  return __output;\n",this.source=i+this.source+s}n=r.compileDebug?"var __line = 1\n  , __lines = "+JSON.stringify(this.templateText)+"\n  , __filename = "+(r.filename?JSON.stringify(r.filename):"undefined")+";\ntry {\n"+this.source+"} catch (e) {\n  rethrow(e, __lines, __filename, __line, escapeFn);\n}\n":this.source,r.client&&(n="escapeFn = escapeFn || "+l.toString()+";\n"+n,r.compileDebug&&(n="rethrow = rethrow || "+h.toString()+";\n"+n)),r.strict&&(n='"use strict";\n'+n),r.debug&&console.log(n),r.compileDebug&&r.filename&&(n=n+"\n//# sourceURL="+r.filename+"\n");try{if(r.async)try{t=new Function("return (async function(){}).constructor;")()}catch(n){throw n instanceof SyntaxError?new Error("This environment does not support async/await"):n}else t=Function;e=new t(r.localsName+", escapeFn, include, rethrow",n)}catch(n){throw n instanceof SyntaxError&&(r.filename&&(n.message+=" in "+r.filename),n.message+=" while compiling ejs\n\n",n.message+="If the above error is not helpful, you may want to try EJS-Lint:\n",n.message+="https://github.com/RyanZim/EJS-Lint",r.async||(n.message+="\n",n.message+="Or, if you meant to create an async function, pass `async: true` as an option.")),n}var f=r.client?e:function(n){return e.apply(r.context,[n||{},l,function(e,t){var o=a.shallowCopy({},n);return t&&(o=a.shallowCopy(o,t)),function(n,e){var t=a.shallowCopy({},e);return t.filename=p(n,t),u(t)}(e,r)(o)},h])};if(f.dependencies=this.dependencies,r.filename&&"function"==typeof Object.defineProperty){var g=r.filename,v=o.basename(g,o.extname(g));try{Object.defineProperty(f,"name",{value:v,writable:!1,enumerable:!1,configurable:!0})}catch(n){}}return f},generateSource:function(){var n=this.opts;n.rmWhitespace&&(this.templateText=this.templateText.replace(/[\r\n]+/g,"\n").replace(/^\s+|\s+$/gm,"")),this.templateText=this.templateText.replace(/[ \t]*<%_/gm,"<%_").replace(/_%>[ \t]*/gm,"_%>");var t=this,r=this.parseTemplateText(),o=this.opts.delimiter,i=this.opts.openDelimiter,s=this.opts.closeDelimiter;r&&r.length&&r.forEach((function(l,c){var u,m,h,g,b,y;if(0===l.indexOf(i+o)&&0!==l.indexOf(i+o+o)&&(m=r[c+2])!=o+s&&m!="-"+o+s&&m!="_"+o+s)throw new Error('Could not find matching close tag for "'+l+'".');if(n.legacyInclude&&(h=l.match(/^\s*include\s+(\S+)/))&&(u=r[c-1])&&(u==i+o||u==i+o+"-"||u==i+o+"_"))return g=a.shallowCopy({},t.opts),b=function(n,e){var t,r,o=a.shallowCopy({},e);r=f(t=p(n,o)).toString().replace(d,""),o.filename=t;var i=new v(r,o);return i.generateSource(),{source:i.source,filename:t,template:r}}(h[1],g),y=t.opts.compileDebug?"    ; (function(){\n      var __line = 1\n      , __lines = "+JSON.stringify(b.template)+"\n      , __filename = "+JSON.stringify(b.filename)+";\n      try {\n"+b.source+"      } catch (e) {\n        rethrow(e, __lines, __filename, __line, escapeFn);\n      }\n    ; }).call(this)\n":"    ; (function(){\n"+b.source+"    ; }).call(this)\n",t.source+=y,void t.dependencies.push(e.resolveInclude(h[1],g.filename));t.scanLine(l)}))},parseTemplateText:function(){for(var n,e=this.templateText,t=this.regex,r=t.exec(e),o=[];r;)0!==(n=r.index)&&(o.push(e.substring(0,n)),e=e.slice(n)),o.push(r[0]),e=e.slice(r[0].length),r=t.exec(e);return e&&o.push(e),o},_addOutput:function(n){if(this.truncate&&(n=n.replace(/^(?:\r\n|\r|\n)/,""),this.truncate=!1),!n)return n;n=(n=(n=(n=n.replace(/\\/g,"\\\\")).replace(/\n/g,"\\n")).replace(/\r/g,"\\r")).replace(/"/g,'\\"'),this.source+='    ; __append("'+n+'")\n'},scanLine:function(n){var e,t=this.opts.delimiter,r=this.opts.openDelimiter,o=this.opts.closeDelimiter;switch(e=n.split("\n").length-1,n){case r+t:case r+t+"_":this.mode=v.modes.EVAL;break;case r+t+"=":this.mode=v.modes.ESCAPED;break;case r+t+"-":this.mode=v.modes.RAW;break;case r+t+"#":this.mode=v.modes.COMMENT;break;case r+t+t:this.mode=v.modes.LITERAL,this.source+='    ; __append("'+n.replace(r+t+t,r+t)+'")\n';break;case t+t+o:this.mode=v.modes.LITERAL,this.source+='    ; __append("'+n.replace(t+t+o,t+o)+'")\n';break;case t+o:case"-"+t+o:case"_"+t+o:this.mode==v.modes.LITERAL&&this._addOutput(n),this.mode=null,this.truncate=0===n.indexOf("-")||0===n.indexOf("_");break;default:if(this.mode){switch(this.mode){case v.modes.EVAL:case v.modes.ESCAPED:case v.modes.RAW:n.lastIndexOf("//")>n.lastIndexOf("\n")&&(n+="\n")}switch(this.mode){case v.modes.EVAL:this.source+="    ; "+n+"\n";break;case v.modes.ESCAPED:this.source+="    ; __append(escapeFn("+g(n)+"))\n";break;case v.modes.RAW:this.source+="    ; __append("+g(n)+")\n";break;case v.modes.COMMENT:break;case v.modes.LITERAL:this._addOutput(n)}}else this._addOutput(n)}this.opts.compileDebug&&e&&(this.currentLine+=e,this.source+="    ; __line = "+this.currentLine+"\n")}},e.escapeXML=a.escapeXML,e.__express=e.renderFile,e.VERSION=s,e.name="ejs","undefined"!=typeof window&&(window.ejs=e)},function(n,e,t){"use strict";t.r(e);var r={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},o=(t(366),t(15)),a=Object(o.a)(r,(function(){var n=this.$createElement;return(this._self._c||n)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"4f1e9d0c",null);e.default=a.exports},function(n,e,t){"use strict";t.r(e);t(32),t(4),t(33),t(44),t(23);var r={name:"CodeGroup",data:function(){return{codeTabs:[],activeCodeTabIndex:-1}},watch:{activeCodeTabIndex:function(n){this.codeTabs.forEach((function(n){n.elm.classList.remove("theme-code-block__active")})),this.codeTabs[n].elm.classList.add("theme-code-block__active")}},mounted:function(){var n=this;this.codeTabs=(this.$slots.default||[]).filter((function(n){return Boolean(n.componentOptions)})).map((function(e,t){return""===e.componentOptions.propsData.active&&(n.activeCodeTabIndex=t),{title:e.componentOptions.propsData.title,elm:e.elm}})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab:function(n){this.activeCodeTabIndex=n}}},o=(t(367),t(15)),a=Object(o.a)(r,(function(){var n=this,e=n.$createElement,t=n._self._c||e;return t("div",{staticClass:"theme-code-group"},[t("div",{staticClass:"theme-code-group__nav"},[t("ul",{staticClass:"theme-code-group__ul"},n._l(n.codeTabs,(function(e,r){return t("li",{key:e.title,staticClass:"theme-code-group__li"},[t("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":r===n.activeCodeTabIndex},on:{click:function(e){return n.changeCodeTab(r)}}},[n._v("\n            "+n._s(e.title)+"\n          ")])])})),0)]),n._v(" "),n._t("default"),n._v(" "),n.codeTabs.length<1?t("pre",{staticClass:"pre-blank"},[n._v("// Make sure to add code blocks to your code group")]):n._e()],2)}),[],!1,null,"2f5f1757",null);e.default=a.exports},function(n,e,t){"use strict";var r=t(7),o=t(0),a=t(2),i=t(102),s=t(14),l=t(10),c=t(141),d=t(34),p=t(81),u=t(149),m=t(3),f=t(53).f,h=t(37).f,g=t(13).f,v=t(362),b=t(221).trim,y=o.Number,x=y.prototype,_=o.TypeError,k=a("".slice),w=a("".charCodeAt),T=function(n){var e=u(n,"number");return"bigint"==typeof e?e:S(e)},S=function(n){var e,t,r,o,a,i,s,l,c=u(n,"number");if(p(c))throw _("Cannot convert a Symbol value to a number");if("string"==typeof c&&c.length>2)if(c=b(c),43===(e=w(c,0))||45===e){if(88===(t=w(c,2))||120===t)return NaN}else if(48===e){switch(w(c,1)){case 66:case 98:r=2,o=49;break;case 79:case 111:r=8,o=55;break;default:return+c}for(i=(a=k(c,2)).length,s=0;s<i;s++)if((l=w(a,s))<48||l>o)return NaN;return parseInt(a,r)}return+c};if(i("Number",!y(" 0o1")||!y("0b1")||y("+0x1"))){for(var P,C=function(n){var e=arguments.length<1?0:y(T(n)),t=this;return d(x,t)&&m((function(){v(t)}))?c(Object(e),t,C):e},I=r?f(y):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,isFinite,isInteger,isNaN,isSafeInteger,parseFloat,parseInt,fromString,range".split(","),E=0;I.length>E;E++)l(y,P=I[E])&&!l(C,P)&&g(C,P,h(y,P));C.prototype=x,x.constructor=C,s(o,"Number",C)}},function(n,e,t){"use strict";var r=t(11),o=t(121),a=t(8),i=t(48),s=t(12),l=t(18),c=t(47),d=t(122),p=t(123);o("match",(function(n,e,t){return[function(e){var t=l(this),o=null==e?void 0:c(e,n);return o?r(o,e,t):new RegExp(e)[n](s(t))},function(n){var r=a(this),o=s(n),l=t(e,r,o);if(l.done)return l.value;if(!r.global)return p(r,o);var c=r.unicode;r.lastIndex=0;for(var u,m=[],f=0;null!==(u=p(r,o));){var h=s(u[0]);m[f]=h,""===h&&(r.lastIndex=d(o,i(r.lastIndex),c)),f++}return 0===f?null:m}]}))},function(n,e,t){var r=t(3),o=t(0).RegExp;n.exports=r((function(){var n=o(".","s");return!(n.dotAll&&n.exec("\n")&&"s"===n.flags)}))},function(n,e,t){var r=t(2),o=t(18),a=t(12),i=t(222),s=r("".replace),l="["+i+"]",c=RegExp("^"+l+l+"*"),d=RegExp(l+l+"*$"),p=function(n){return function(e){var t=a(o(e));return 1&n&&(t=s(t,c,"")),2&n&&(t=s(t,d,"")),t}};n.exports={start:p(1),end:p(2),trim:p(3)}},function(n,e){n.exports="\t\n\v\f\r                　\u2028\u2029\ufeff"},function(n,e,t){"use strict";var r=t(17),o=t(13),a=t(6),i=t(7),s=a("species");n.exports=function(n){var e=r(n),t=o.f;i&&e&&!e[s]&&t(e,s,{configurable:!0,get:function(){return this}})}},function(n,e,t){var r=t(3),o=t(0).RegExp;n.exports=r((function(){var n=o("(?<a>b)","g");return"b"!==n.exec("b").groups.a||"bc"!=="b".replace(n,"$<a>c")}))},function(n,e,t){"use strict";var r=t(1),o=t(108).includes,a=t(138);r({target:"Array",proto:!0},{includes:function(n){return o(this,n,arguments.length>1?arguments[1]:void 0)}}),a("includes")},function(n,e,t){"use strict";var r=t(1),o=t(2),a=t(174),i=t(18),s=t(12),l=t(175),c=o("".indexOf);r({target:"String",proto:!0,forced:!l("includes")},{includes:function(n){return!!~c(s(i(this)),s(a(n)),arguments.length>1?arguments[1]:void 0)}})},function(n,e){n.exports=function(n){var e=null==n?0:n.length;return e?n[e-1]:void 0}},function(n,e,t){var r=t(0),o=t(7),a=t(103).MISSED_STICKY,i=t(24),s=t(13).f,l=t(40).get,c=RegExp.prototype,d=r.TypeError;o&&a&&s(c,"sticky",{configurable:!0,get:function(){if(this!==c){if("RegExp"===i(this))return!!l(this).sticky;throw d("Incompatible receiver, RegExp required")}}})},function(n,e,t){n.exports=t(389)},function(n,e,t){var r=t(0),o=t(11),a=t(5),i=t(9),s=r.TypeError;n.exports=function(n,e){var t,r;if("string"===e&&a(t=n.toString)&&!i(r=o(t,n)))return r;if(a(t=n.valueOf)&&!i(r=o(t,n)))return r;if("string"!==e&&a(t=n.toString)&&!i(r=o(t,n)))return r;throw s("Can't convert object to primitive value")}},function(n,e,t){var r=t(0),o=t(5),a=t(85),i=r.WeakMap;n.exports=o(i)&&/native code/.test(a(i))},function(n,e,t){"use strict";var r=t(153).IteratorPrototype,o=t(35),a=t(49),i=t(62),s=t(61),l=function(){return this};n.exports=function(n,e,t,c){var d=e+" Iterator";return n.prototype=o(r,{next:a(+!c,t)}),i(n,d,!1,!0),s[d]=l,n}},function(n,e,t){var r=t(0),o=t(5),a=r.String,i=r.TypeError;n.exports=function(n){if("object"==typeof n||o(n))return n;throw i("Can't set "+a(n)+" as a prototype")}},function(n,e,t){"use strict";var r,o,a,i,s=t(1),l=t(27),c=t(0),d=t(17),p=t(11),u=t(155),m=t(14),f=t(235),h=t(63),g=t(62),v=t(223),b=t(36),y=t(5),x=t(9),_=t(236),k=t(85),w=t(237),T=t(159),S=t(118),P=t(161).set,C=t(238),I=t(164),E=t(241),A=t(165),D=t(242),O=t(243),L=t(40),j=t(102),R=t(6),z=t(244),M=t(88),N=t(46),F=R("species"),q="Promise",U=L.getterFor(q),B=L.set,G=L.getterFor(q),H=u&&u.prototype,V=u,$=H,W=c.TypeError,K=c.document,X=c.process,Q=A.f,Y=Q,Z=!!(K&&K.createEvent&&c.dispatchEvent),J=y(c.PromiseRejectionEvent),nn=!1,en=j(q,(function(){var n=k(V),e=n!==String(V);if(!e&&66===N)return!0;if(l&&!$.finally)return!0;if(N>=51&&/native code/.test(n))return!1;var t=new V((function(n){n(1)})),r=function(n){n((function(){}),(function(){}))};return(t.constructor={})[F]=r,!(nn=t.then((function(){}))instanceof r)||!e&&z&&!J})),tn=en||!T((function(n){V.all(n).catch((function(){}))})),rn=function(n){var e;return!(!x(n)||!y(e=n.then))&&e},on=function(n,e){var t,r,o,a=e.value,i=1==e.state,s=i?n.ok:n.fail,l=n.resolve,c=n.reject,d=n.domain;try{s?(i||(2===e.rejection&&dn(e),e.rejection=1),!0===s?t=a:(d&&d.enter(),t=s(a),d&&(d.exit(),o=!0)),t===n.promise?c(W("Promise-chain cycle")):(r=rn(t))?p(r,t,l,c):l(t)):c(a)}catch(n){d&&!o&&d.exit(),c(n)}},an=function(n,e){n.notified||(n.notified=!0,C((function(){for(var t,r=n.reactions;t=r.get();)on(t,n);n.notified=!1,e&&!n.rejection&&ln(n)})))},sn=function(n,e,t){var r,o;Z?((r=K.createEvent("Event")).promise=e,r.reason=t,r.initEvent(n,!1,!0),c.dispatchEvent(r)):r={promise:e,reason:t},!J&&(o=c["on"+n])?o(r):"unhandledrejection"===n&&E("Unhandled promise rejection",t)},ln=function(n){p(P,c,(function(){var e,t=n.facade,r=n.value;if(cn(n)&&(e=D((function(){M?X.emit("unhandledRejection",r,t):sn("unhandledrejection",t,r)})),n.rejection=M||cn(n)?2:1,e.error))throw e.value}))},cn=function(n){return 1!==n.rejection&&!n.parent},dn=function(n){p(P,c,(function(){var e=n.facade;M?X.emit("rejectionHandled",e):sn("rejectionhandled",e,n.value)}))},pn=function(n,e,t){return function(r){n(e,r,t)}},un=function(n,e,t){n.done||(n.done=!0,t&&(n=t),n.value=e,n.state=2,an(n,!0))},mn=function(n,e,t){if(!n.done){n.done=!0,t&&(n=t);try{if(n.facade===e)throw W("Promise can't be resolved itself");var r=rn(e);r?C((function(){var t={done:!1};try{p(r,e,pn(mn,t,n),pn(un,t,n))}catch(e){un(t,e,n)}})):(n.value=e,n.state=1,an(n,!1))}catch(e){un({done:!1},e,n)}}};if(en&&($=(V=function(n){_(this,$),b(n),p(r,this);var e=U(this);try{n(pn(mn,e),pn(un,e))}catch(n){un(e,n)}}).prototype,(r=function(n){B(this,{type:q,done:!1,notified:!1,parent:!1,reactions:new O,rejection:!1,state:0,value:void 0})}).prototype=f($,{then:function(n,e){var t=G(this),r=Q(S(this,V));return t.parent=!0,r.ok=!y(n)||n,r.fail=y(e)&&e,r.domain=M?X.domain:void 0,0==t.state?t.reactions.add(r):C((function(){on(r,t)})),r.promise},catch:function(n){return this.then(void 0,n)}}),o=function(){var n=new r,e=U(n);this.promise=n,this.resolve=pn(mn,e),this.reject=pn(un,e)},A.f=Q=function(n){return n===V||n===a?new o(n):Y(n)},!l&&y(u)&&H!==Object.prototype)){i=H.then,nn||(m(H,"then",(function(n,e){var t=this;return new V((function(n,e){p(i,t,n,e)})).then(n,e)}),{unsafe:!0}),m(H,"catch",$.catch,{unsafe:!0}));try{delete H.constructor}catch(n){}h&&h(H,$)}s({global:!0,wrap:!0,forced:en},{Promise:V}),g(V,q,!1,!0),v(q),a=d(q),s({target:q,stat:!0,forced:en},{reject:function(n){var e=Q(this);return p(e.reject,void 0,n),e.promise}}),s({target:q,stat:!0,forced:l||en},{resolve:function(n){return I(l&&this===a?V:this,n)}}),s({target:q,stat:!0,forced:tn},{all:function(n){var e=this,t=Q(e),r=t.resolve,o=t.reject,a=D((function(){var t=b(e.resolve),a=[],i=0,s=1;w(n,(function(n){var l=i++,c=!1;s++,p(t,e,n).then((function(n){c||(c=!0,a[l]=n,--s||r(a))}),o)})),--s||r(a)}));return a.error&&o(a.value),t.promise},race:function(n){var e=this,t=Q(e),r=t.reject,o=D((function(){var o=b(e.resolve);w(n,(function(n){p(o,e,n).then(t.resolve,r)}))}));return o.error&&r(o.value),t.promise}})},function(n,e,t){var r=t(14);n.exports=function(n,e,t){for(var o in e)r(n,o,e[o],t);return n}},function(n,e,t){var r=t(0),o=t(34),a=r.TypeError;n.exports=function(n,e){if(o(e,n))return n;throw a("Incorrect invocation")}},function(n,e,t){var r=t(0),o=t(64),a=t(11),i=t(8),s=t(82),l=t(156),c=t(29),d=t(34),p=t(157),u=t(116),m=t(158),f=r.TypeError,h=function(n,e){this.stopped=n,this.result=e},g=h.prototype;n.exports=function(n,e,t){var r,v,b,y,x,_,k,w=t&&t.that,T=!(!t||!t.AS_ENTRIES),S=!(!t||!t.IS_ITERATOR),P=!(!t||!t.INTERRUPTED),C=o(e,w),I=function(n){return r&&m(r,"normal",n),new h(!0,n)},E=function(n){return T?(i(n),P?C(n[0],n[1],I):C(n[0],n[1])):P?C(n,I):C(n)};if(S)r=n;else{if(!(v=u(n)))throw f(s(n)+" is not iterable");if(l(v)){for(b=0,y=c(n);y>b;b++)if((x=E(n[b]))&&d(g,x))return x;return new h(!1)}r=p(n,v)}for(_=r.next;!(k=a(_,r)).done;){try{x=E(k.value)}catch(n){m(r,"throw",n)}if("object"==typeof x&&x&&d(g,x))return x}return new h(!1)}},function(n,e,t){var r,o,a,i,s,l,c,d,p=t(0),u=t(64),m=t(37).f,f=t(161).set,h=t(163),g=t(239),v=t(240),b=t(88),y=p.MutationObserver||p.WebKitMutationObserver,x=p.document,_=p.process,k=p.Promise,w=m(p,"queueMicrotask"),T=w&&w.value;T||(r=function(){var n,e;for(b&&(n=_.domain)&&n.exit();o;){e=o.fn,o=o.next;try{e()}catch(n){throw o?i():a=void 0,n}}a=void 0,n&&n.enter()},h||b||v||!y||!x?!g&&k&&k.resolve?((c=k.resolve(void 0)).constructor=k,d=u(c.then,c),i=function(){d(r)}):b?i=function(){_.nextTick(r)}:(f=u(f,p),i=function(){f(r)}):(s=!0,l=x.createTextNode(""),new y(r).observe(l,{characterData:!0}),i=function(){l.data=s=!s})),n.exports=T||function(n){var e={fn:n,next:void 0};a&&(a.next=e),o||(o=e,i()),a=e}},function(n,e,t){var r=t(28),o=t(0);n.exports=/ipad|iphone|ipod/i.test(r)&&void 0!==o.Pebble},function(n,e,t){var r=t(28);n.exports=/web0s(?!.*chrome)/i.test(r)},function(n,e,t){var r=t(0);n.exports=function(n,e){var t=r.console;t&&t.error&&(1==arguments.length?t.error(n):t.error(n,e))}},function(n,e){n.exports=function(n){try{return{error:!1,value:n()}}catch(n){return{error:!0,value:n}}}},function(n,e){var t=function(){this.head=null,this.tail=null};t.prototype={add:function(n){var e={item:n,next:null};this.head?this.tail.next=e:this.head=e,this.tail=e},get:function(){var n=this.head;if(n)return this.head=n.next,this.tail===n&&(this.tail=null),n.item}},n.exports=t},function(n,e){n.exports="object"==typeof window},function(n,e,t){var r=t(1),o=t(246);r({target:"Object",stat:!0,forced:Object.assign!==o},{assign:o})},function(n,e,t){"use strict";var r=t(7),o=t(2),a=t(11),i=t(3),s=t(83),l=t(114),c=t(111),d=t(16),p=t(57),u=Object.assign,m=Object.defineProperty,f=o([].concat);n.exports=!u||i((function(){if(r&&1!==u({b:1},u(m({},"a",{enumerable:!0,get:function(){m(this,"b",{value:3,enumerable:!1})}}),{b:2})).b)return!0;var n={},e={},t=Symbol();return n[t]=7,"abcdefghijklmnopqrst".split("").forEach((function(n){e[n]=n})),7!=u({},n)[t]||"abcdefghijklmnopqrst"!=s(u({},e)).join("")}))?function(n,e){for(var t=d(n),o=arguments.length,i=1,u=l.f,m=c.f;o>i;)for(var h,g=p(arguments[i++]),v=u?f(s(g),u(g)):s(g),b=v.length,y=0;b>y;)h=v[y++],r&&!a(m,g,h)||(t[h]=g[h]);return t}:u},function(n,e,t){"use strict";var r=t(1),o=t(27),a=t(155),i=t(3),s=t(17),l=t(5),c=t(118),d=t(164),p=t(14);if(r({target:"Promise",proto:!0,real:!0,forced:!!a&&i((function(){a.prototype.finally.call({then:function(){}},(function(){}))}))},{finally:function(n){var e=c(this,s("Promise")),t=l(n);return this.then(t?function(t){return d(e,n()).then((function(){return t}))}:n,t?function(t){return d(e,n()).then((function(){throw t}))}:n)}}),!o&&l(a)){var u=s("Promise").prototype.finally;a.prototype.finally!==u&&p(a.prototype,"finally",u,{unsafe:!0})}},function(n,e,t){"use strict";var r=t(117),o=t(86);n.exports=r?{}.toString:function(){return"[object "+o(this)+"]"}},function(n,e,t){var r=t(0),o=t(66),a=t(87),i=t(9),s=t(6)("species"),l=r.Array;n.exports=function(n){var e;return o(n)&&(e=n.constructor,(a(e)&&(e===l||o(e.prototype))||i(e)&&null===(e=e[s]))&&(e=void 0)),void 0===e?l:e}},function(n,e,t){"use strict";var r=t(1),o=t(251).left,a=t(50),i=t(46),s=t(88);r({target:"Array",proto:!0,forced:!a("reduce")||!s&&i>79&&i<83},{reduce:function(n){var e=arguments.length;return o(this,n,e,e>1?arguments[1]:void 0)}})},function(n,e,t){var r=t(0),o=t(36),a=t(16),i=t(57),s=t(29),l=r.TypeError,c=function(n){return function(e,t,r,c){o(t);var d=a(e),p=i(d),u=s(d),m=n?u-1:0,f=n?-1:1;if(r<2)for(;;){if(m in p){c=p[m],m+=f;break}if(m+=f,n?m<0:u<=m)throw l("Reduce of empty array with no initial value")}for(;n?m>=0:u>m;m+=f)m in p&&(c=t(c,p[m],m,d));return c}};n.exports={left:c(!1),right:c(!0)}},function(n,e,t){var r=t(1),o=t(177),a=t(3),i=t(9),s=t(253).onFreeze,l=Object.freeze;r({target:"Object",stat:!0,forced:a((function(){l(1)})),sham:!o},{freeze:function(n){return l&&i(n)?l(s(n)):n}})},function(n,e,t){var r=t(1),o=t(2),a=t(60),i=t(9),s=t(10),l=t(13).f,c=t(53),d=t(178),p=t(254),u=t(78),m=t(177),f=!1,h=u("meta"),g=0,v=function(n){l(n,h,{value:{objectID:"O"+g++,weakData:{}}})},b=n.exports={enable:function(){b.enable=function(){},f=!0;var n=c.f,e=o([].splice),t={};t[h]=1,n(t).length&&(c.f=function(t){for(var r=n(t),o=0,a=r.length;o<a;o++)if(r[o]===h){e(r,o,1);break}return r},r({target:"Object",stat:!0,forced:!0},{getOwnPropertyNames:d.f}))},fastKey:function(n,e){if(!i(n))return"symbol"==typeof n?n:("string"==typeof n?"S":"P")+n;if(!s(n,h)){if(!p(n))return"F";if(!e)return"E";v(n)}return n[h].objectID},getWeakData:function(n,e){if(!s(n,h)){if(!p(n))return!0;if(!e)return!1;v(n)}return n[h].weakData},onFreeze:function(n){return m&&f&&p(n)&&!s(n,h)&&v(n),n}};a[h]=!0},function(n,e,t){var r=t(3),o=t(9),a=t(24),i=t(255),s=Object.isExtensible,l=r((function(){s(1)}));n.exports=l||i?function(n){return!!o(n)&&((!i||"ArrayBuffer"!=a(n))&&(!s||s(n)))}:s},function(n,e,t){var r=t(3);n.exports=r((function(){if("function"==typeof ArrayBuffer){var n=new ArrayBuffer(8);Object.isExtensible(n)&&Object.defineProperty(n,"a",{value:8})}}))},function(n,e,t){var r=t(0);n.exports=r},function(n,e,t){"use strict";var r=t(0),o=t(64),a=t(11),i=t(16),s=t(258),l=t(156),c=t(87),d=t(29),p=t(67),u=t(157),m=t(116),f=r.Array;n.exports=function(n){var e=i(n),t=c(this),r=arguments.length,h=r>1?arguments[1]:void 0,g=void 0!==h;g&&(h=o(h,r>2?arguments[2]:void 0));var v,b,y,x,_,k,w=m(e),T=0;if(!w||this==f&&l(w))for(v=d(e),b=t?new this(v):f(v);v>T;T++)k=g?h(e[T],T):e[T],p(b,T,k);else for(_=(x=u(e,w)).next,b=t?new this:[];!(y=a(_,x)).done;T++)k=g?s(x,h,[y.value,T],!0):y.value,p(b,T,k);return b.length=T,b}},function(n,e,t){var r=t(8),o=t(158);n.exports=function(n,e,t,a){try{return a?e(r(t)[0],t[1]):e(t)}catch(e){o(n,"throw",e)}}},function(n,e,t){"use strict";var r=t(17),o=t(10),a=t(25),i=t(34),s=t(63),l=t(112),c=t(141),d=t(182),p=t(260),u=t(261),m=t(262),f=t(27);n.exports=function(n,e,t,h){var g=h?2:1,v=n.split("."),b=v[v.length-1],y=r.apply(null,v);if(y){var x=y.prototype;if(!f&&o(x,"cause")&&delete x.cause,!t)return y;var _=r("Error"),k=e((function(n,e){var t=d(h?e:n,void 0),r=h?new y(n):new y;return void 0!==t&&a(r,"message",t),m&&a(r,"stack",u(r.stack,2)),this&&i(x,this)&&c(r,this,k),arguments.length>g&&p(r,arguments[g]),r}));if(k.prototype=x,"Error"!==b&&(s?s(k,_):l(k,_,{name:!0})),l(k,y),!f)try{x.name!==b&&a(x,"name",b),x.constructor=k}catch(n){}return k}}},function(n,e,t){var r=t(9),o=t(25);n.exports=function(n,e){r(e)&&"cause"in e&&o(n,"cause",e.cause)}},function(n,e,t){var r=t(2)("".replace),o=String(Error("zxcasd").stack),a=/\n\s*at [^:]*:[^\n]*/,i=a.test(o);n.exports=function(n,e){if(i&&"string"==typeof n)for(;e--;)n=r(n,a,"");return n}},function(n,e,t){var r=t(3),o=t(49);n.exports=!r((function(){var n=Error("a");return!("stack"in n)||(Object.defineProperty(n,"stack",o(1,7)),7!==n.stack)}))},function(n,e,t){"use strict";var r=t(7),o=t(3),a=t(8),i=t(35),s=t(182),l=Error.prototype.toString,c=o((function(){if(r){var n=i(Object.defineProperty({},"name",{get:function(){return this===n}}));if("true"!==l.call(n))return!0}return"2: 1"!==l.call({message:1,name:2})||"Error"!==l.call({})}));n.exports=c?function(){var n=a(this),e=s(n.name,"Error"),t=s(n.message);return e?t?e+": "+t:e:t}:l},function(n,e,t){var r=t(2),o=t(16),a=Math.floor,i=r("".charAt),s=r("".replace),l=r("".slice),c=/\$([$&'`]|\d{1,2}|<[^>]*>)/g,d=/\$([$&'`]|\d{1,2})/g;n.exports=function(n,e,t,r,p,u){var m=t+n.length,f=r.length,h=d;return void 0!==p&&(p=o(p),h=c),s(u,h,(function(o,s){var c;switch(i(s,0)){case"$":return"$";case"&":return n;case"`":return l(e,0,t);case"'":return l(e,m);case"<":c=p[l(s,1,-1)];break;default:var d=+s;if(0===d)return o;if(d>f){var u=a(d/10);return 0===u?o:u<=f?void 0===r[u-1]?i(s,1):r[u-1]+i(s,1):o}c=r[d-1]}return void 0===c?"":c}))}},function(n,e,t){var r=t(1),o=t(0),a=t(17),i=t(38),s=t(2),l=t(3),c=o.Array,d=a("JSON","stringify"),p=s(/./.exec),u=s("".charAt),m=s("".charCodeAt),f=s("".replace),h=s(1..toString),g=/[\uD800-\uDFFF]/g,v=/^[\uD800-\uDBFF]$/,b=/^[\uDC00-\uDFFF]$/,y=function(n,e,t){var r=u(t,e-1),o=u(t,e+1);return p(v,n)&&!p(b,o)||p(b,n)&&!p(v,r)?"\\u"+h(m(n,0),16):n},x=l((function(){return'"\\udf06\\ud834"'!==d("\udf06\ud834")||'"\\udead"'!==d("\udead")}));d&&r({target:"JSON",stat:!0,forced:x},{stringify:function(n,e,t){for(var r=0,o=arguments.length,a=c(o);r<o;r++)a[r]=arguments[r];var s=i(d,null,a);return"string"==typeof s?f(s,g,y):s}})},function(n,e,t){var r=t(185),o=t(267);n.exports=function n(e,t,a,i,s){var l=-1,c=e.length;for(a||(a=o),s||(s=[]);++l<c;){var d=e[l];t>0&&a(d)?t>1?n(d,t-1,a,i,s):r(s,d):i||(s[s.length]=d)}return s}},function(n,e,t){var r=t(69),o=t(124),a=t(26),i=r?r.isConcatSpreadable:void 0;n.exports=function(n){return a(n)||o(n)||!!(i&&n&&n[i])}},function(n,e,t){var r=t(56),o=t(45);n.exports=function(n){return o(n)&&"[object Arguments]"==r(n)}},function(n,e,t){var r=t(69),o=Object.prototype,a=o.hasOwnProperty,i=o.toString,s=r?r.toStringTag:void 0;n.exports=function(n){var e=a.call(n,s),t=n[s];try{n[s]=void 0;var r=!0}catch(n){}var o=i.call(n);return r&&(e?n[s]=t:delete n[s]),o}},function(n,e){var t=Object.prototype.toString;n.exports=function(n){return t.call(n)}},function(n,e,t){var r=t(272),o=t(328),a=t(132),i=t(26),s=t(339);n.exports=function(n){return"function"==typeof n?n:null==n?a:"object"==typeof n?i(n)?o(n[0],n[1]):r(n):s(n)}},function(n,e,t){var r=t(273),o=t(327),a=t(202);n.exports=function(n){var e=o(n);return 1==e.length&&e[0][2]?a(e[0][0],e[0][1]):function(t){return t===n||r(t,n,e)}}},function(n,e,t){var r=t(187),o=t(191);n.exports=function(n,e,t,a){var i=t.length,s=i,l=!a;if(null==n)return!s;for(n=Object(n);i--;){var c=t[i];if(l&&c[2]?c[1]!==n[c[0]]:!(c[0]in n))return!1}for(;++i<s;){var d=(c=t[i])[0],p=n[d],u=c[1];if(l&&c[2]){if(void 0===p&&!(d in n))return!1}else{var m=new r;if(a)var f=a(p,u,d,n,e,m);if(!(void 0===f?o(u,p,3,a,m):f))return!1}}return!0}},function(n,e){n.exports=function(){this.__data__=[],this.size=0}},function(n,e,t){var r=t(93),o=Array.prototype.splice;n.exports=function(n){var e=this.__data__,t=r(e,n);return!(t<0)&&(t==e.length-1?e.pop():o.call(e,t,1),--this.size,!0)}},function(n,e,t){var r=t(93);n.exports=function(n){var e=this.__data__,t=r(e,n);return t<0?void 0:e[t][1]}},function(n,e,t){var r=t(93);n.exports=function(n){return r(this.__data__,n)>-1}},function(n,e,t){var r=t(93);n.exports=function(n,e){var t=this.__data__,o=r(t,n);return o<0?(++this.size,t.push([n,e])):t[o][1]=e,this}},function(n,e,t){var r=t(92);n.exports=function(){this.__data__=new r,this.size=0}},function(n,e){n.exports=function(n){var e=this.__data__,t=e.delete(n);return this.size=e.size,t}},function(n,e){n.exports=function(n){return this.__data__.get(n)}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e,t){var r=t(92),o=t(125),a=t(127);n.exports=function(n,e){var t=this.__data__;if(t instanceof r){var i=t.__data__;if(!o||i.length<199)return i.push([n,e]),this.size=++t.size,this;t=this.__data__=new a(i)}return t.set(n,e),this.size=t.size,this}},function(n,e,t){var r=t(189),o=t(285),a=t(126),i=t(190),s=/^\[object .+?Constructor\]$/,l=Function.prototype,c=Object.prototype,d=l.toString,p=c.hasOwnProperty,u=RegExp("^"+d.call(p).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");n.exports=function(n){return!(!a(n)||o(n))&&(r(n)?u:s).test(i(n))}},function(n,e,t){var r,o=t(286),a=(r=/[^.]+$/.exec(o&&o.keys&&o.keys.IE_PROTO||""))?"Symbol(src)_1."+r:"";n.exports=function(n){return!!a&&a in n}},function(n,e,t){var r=t(31)["__core-js_shared__"];n.exports=r},function(n,e){n.exports=function(n,e){return null==n?void 0:n[e]}},function(n,e,t){var r=t(289),o=t(92),a=t(125);n.exports=function(){this.size=0,this.__data__={hash:new r,map:new(a||o),string:new r}}},function(n,e,t){var r=t(290),o=t(291),a=t(292),i=t(293),s=t(294);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=o,l.prototype.get=a,l.prototype.has=i,l.prototype.set=s,n.exports=l},function(n,e,t){var r=t(94);n.exports=function(){this.__data__=r?r(null):{},this.size=0}},function(n,e){n.exports=function(n){var e=this.has(n)&&delete this.__data__[n];return this.size-=e?1:0,e}},function(n,e,t){var r=t(94),o=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;if(r){var t=e[n];return"__lodash_hash_undefined__"===t?void 0:t}return o.call(e,n)?e[n]:void 0}},function(n,e,t){var r=t(94),o=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;return r?void 0!==e[n]:o.call(e,n)}},function(n,e,t){var r=t(94);n.exports=function(n,e){var t=this.__data__;return this.size+=this.has(n)?0:1,t[n]=r&&void 0===e?"__lodash_hash_undefined__":e,this}},function(n,e,t){var r=t(95);n.exports=function(n){var e=r(this,n).delete(n);return this.size-=e?1:0,e}},function(n,e){n.exports=function(n){var e=typeof n;return"string"==e||"number"==e||"symbol"==e||"boolean"==e?"__proto__"!==n:null===n}},function(n,e,t){var r=t(95);n.exports=function(n){return r(this,n).get(n)}},function(n,e,t){var r=t(95);n.exports=function(n){return r(this,n).has(n)}},function(n,e,t){var r=t(95);n.exports=function(n,e){var t=r(this,n),o=t.size;return t.set(n,e),this.size+=t.size==o?0:1,this}},function(n,e,t){var r=t(187),o=t(192),a=t(304),i=t(307),s=t(323),l=t(26),c=t(196),d=t(198),p="[object Object]",u=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,m,f,h){var g=l(n),v=l(e),b=g?"[object Array]":s(n),y=v?"[object Array]":s(e),x=(b="[object Arguments]"==b?p:b)==p,_=(y="[object Arguments]"==y?p:y)==p,k=b==y;if(k&&c(n)){if(!c(e))return!1;g=!0,x=!1}if(k&&!x)return h||(h=new r),g||d(n)?o(n,e,t,m,f,h):a(n,e,b,t,m,f,h);if(!(1&t)){var w=x&&u.call(n,"__wrapped__"),T=_&&u.call(e,"__wrapped__");if(w||T){var S=w?n.value():n,P=T?e.value():e;return h||(h=new r),f(S,P,t,m,h)}}return!!k&&(h||(h=new r),i(n,e,t,m,f,h))}},function(n,e){n.exports=function(n){return this.__data__.set(n,"__lodash_hash_undefined__"),this}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length;++t<r;)if(e(n[t],t,n))return!0;return!1}},function(n,e,t){var r=t(69),o=t(305),a=t(188),i=t(192),s=t(306),l=t(128),c=r?r.prototype:void 0,d=c?c.valueOf:void 0;n.exports=function(n,e,t,r,c,p,u){switch(t){case"[object DataView]":if(n.byteLength!=e.byteLength||n.byteOffset!=e.byteOffset)return!1;n=n.buffer,e=e.buffer;case"[object ArrayBuffer]":return!(n.byteLength!=e.byteLength||!p(new o(n),new o(e)));case"[object Boolean]":case"[object Date]":case"[object Number]":return a(+n,+e);case"[object Error]":return n.name==e.name&&n.message==e.message;case"[object RegExp]":case"[object String]":return n==e+"";case"[object Map]":var m=s;case"[object Set]":var f=1&r;if(m||(m=l),n.size!=e.size&&!f)return!1;var h=u.get(n);if(h)return h==e;r|=2,u.set(n,e);var g=i(m(n),m(e),r,c,p,u);return u.delete(n),g;case"[object Symbol]":if(d)return d.call(n)==d.call(e)}return!1}},function(n,e,t){var r=t(31).Uint8Array;n.exports=r},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n,r){t[++e]=[r,n]})),t}},function(n,e,t){var r=t(308),o=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,a,i,s){var l=1&t,c=r(n),d=c.length;if(d!=r(e).length&&!l)return!1;for(var p=d;p--;){var u=c[p];if(!(l?u in e:o.call(e,u)))return!1}var m=s.get(n),f=s.get(e);if(m&&f)return m==e&&f==n;var h=!0;s.set(n,e),s.set(e,n);for(var g=l;++p<d;){var v=n[u=c[p]],b=e[u];if(a)var y=l?a(b,v,u,e,n,s):a(v,b,u,n,e,s);if(!(void 0===y?v===b||i(v,b,t,a,s):y)){h=!1;break}g||(g="constructor"==u)}if(h&&!g){var x=n.constructor,_=e.constructor;x==_||!("constructor"in n)||!("constructor"in e)||"function"==typeof x&&x instanceof x&&"function"==typeof _&&_ instanceof _||(h=!1)}return s.delete(n),s.delete(e),h}},function(n,e,t){var r=t(309),o=t(310),a=t(195);n.exports=function(n){return r(n,a,o)}},function(n,e,t){var r=t(185),o=t(26);n.exports=function(n,e,t){var a=e(n);return o(n)?a:r(a,t(n))}},function(n,e,t){var r=t(311),o=t(312),a=Object.prototype.propertyIsEnumerable,i=Object.getOwnPropertySymbols,s=i?function(n){return null==n?[]:(n=Object(n),r(i(n),(function(e){return a.call(n,e)})))}:o;n.exports=s},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,o=0,a=[];++t<r;){var i=n[t];e(i,t,n)&&(a[o++]=i)}return a}},function(n,e){n.exports=function(){return[]}},function(n,e,t){var r=t(314),o=t(124),a=t(26),i=t(196),s=t(197),l=t(198),c=Object.prototype.hasOwnProperty;n.exports=function(n,e){var t=a(n),d=!t&&o(n),p=!t&&!d&&i(n),u=!t&&!d&&!p&&l(n),m=t||d||p||u,f=m?r(n.length,String):[],h=f.length;for(var g in n)!e&&!c.call(n,g)||m&&("length"==g||p&&("offset"==g||"parent"==g)||u&&("buffer"==g||"byteLength"==g||"byteOffset"==g)||s(g,h))||f.push(g);return f}},function(n,e){n.exports=function(n,e){for(var t=-1,r=Array(n);++t<n;)r[t]=e(t);return r}},function(n,e){n.exports=function(){return!1}},function(n,e,t){var r=t(56),o=t(129),a=t(45),i={};i["[object Float32Array]"]=i["[object Float64Array]"]=i["[object Int8Array]"]=i["[object Int16Array]"]=i["[object Int32Array]"]=i["[object Uint8Array]"]=i["[object Uint8ClampedArray]"]=i["[object Uint16Array]"]=i["[object Uint32Array]"]=!0,i["[object Arguments]"]=i["[object Array]"]=i["[object ArrayBuffer]"]=i["[object Boolean]"]=i["[object DataView]"]=i["[object Date]"]=i["[object Error]"]=i["[object Function]"]=i["[object Map]"]=i["[object Number]"]=i["[object Object]"]=i["[object RegExp]"]=i["[object Set]"]=i["[object String]"]=i["[object WeakMap]"]=!1,n.exports=function(n){return a(n)&&o(n.length)&&!!i[r(n)]}},function(n,e){n.exports=function(n){return function(e){return n(e)}}},function(n,e,t){(function(n){var r=t(186),o=e&&!e.nodeType&&e,a=o&&"object"==typeof n&&n&&!n.nodeType&&n,i=a&&a.exports===o&&r.process,s=function(){try{var n=a&&a.require&&a.require("util").types;return n||i&&i.binding&&i.binding("util")}catch(n){}}();n.exports=s}).call(this,t(142)(n))},function(n,e,t){var r=t(320),o=t(321),a=Object.prototype.hasOwnProperty;n.exports=function(n){if(!r(n))return o(n);var e=[];for(var t in Object(n))a.call(n,t)&&"constructor"!=t&&e.push(t);return e}},function(n,e){var t=Object.prototype;n.exports=function(n){var e=n&&n.constructor;return n===("function"==typeof e&&e.prototype||t)}},function(n,e,t){var r=t(322)(Object.keys,Object);n.exports=r},function(n,e){n.exports=function(n,e){return function(t){return n(e(t))}}},function(n,e,t){var r=t(324),o=t(125),a=t(325),i=t(200),s=t(326),l=t(56),c=t(190),d=c(r),p=c(o),u=c(a),m=c(i),f=c(s),h=l;(r&&"[object DataView]"!=h(new r(new ArrayBuffer(1)))||o&&"[object Map]"!=h(new o)||a&&"[object Promise]"!=h(a.resolve())||i&&"[object Set]"!=h(new i)||s&&"[object WeakMap]"!=h(new s))&&(h=function(n){var e=l(n),t="[object Object]"==e?n.constructor:void 0,r=t?c(t):"";if(r)switch(r){case d:return"[object DataView]";case p:return"[object Map]";case u:return"[object Promise]";case m:return"[object Set]";case f:return"[object WeakMap]"}return e}),n.exports=h},function(n,e,t){var r=t(42)(t(31),"DataView");n.exports=r},function(n,e,t){var r=t(42)(t(31),"Promise");n.exports=r},function(n,e,t){var r=t(42)(t(31),"WeakMap");n.exports=r},function(n,e,t){var r=t(201),o=t(195);n.exports=function(n){for(var e=o(n),t=e.length;t--;){var a=e[t],i=n[a];e[t]=[a,i,r(i)]}return e}},function(n,e,t){var r=t(191),o=t(329),a=t(336),i=t(130),s=t(201),l=t(202),c=t(96);n.exports=function(n,e){return i(n)&&s(e)?l(c(n),e):function(t){var i=o(t,n);return void 0===i&&i===e?a(t,n):r(e,i,3)}}},function(n,e,t){var r=t(203);n.exports=function(n,e,t){var o=null==n?void 0:r(n,e);return void 0===o?t:o}},function(n,e,t){var r=t(331),o=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,a=/\\(\\)?/g,i=r((function(n){var e=[];return 46===n.charCodeAt(0)&&e.push(""),n.replace(o,(function(n,t,r,o){e.push(r?o.replace(a,"$1"):t||n)})),e}));n.exports=i},function(n,e,t){var r=t(332);n.exports=function(n){var e=r(n,(function(n){return 500===t.size&&t.clear(),n})),t=e.cache;return e}},function(n,e,t){var r=t(127);function o(n,e){if("function"!=typeof n||null!=e&&"function"!=typeof e)throw new TypeError("Expected a function");var t=function(){var r=arguments,o=e?e.apply(this,r):r[0],a=t.cache;if(a.has(o))return a.get(o);var i=n.apply(this,r);return t.cache=a.set(o,i)||a,i};return t.cache=new(o.Cache||r),t}o.Cache=r,n.exports=o},function(n,e,t){var r=t(334);n.exports=function(n){return null==n?"":r(n)}},function(n,e,t){var r=t(69),o=t(335),a=t(26),i=t(131),s=r?r.prototype:void 0,l=s?s.toString:void 0;n.exports=function n(e){if("string"==typeof e)return e;if(a(e))return o(e,n)+"";if(i(e))return l?l.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,o=Array(r);++t<r;)o[t]=e(n[t],t,n);return o}},function(n,e,t){var r=t(337),o=t(338);n.exports=function(n,e){return null!=n&&o(n,e,r)}},function(n,e){n.exports=function(n,e){return null!=n&&e in Object(n)}},function(n,e,t){var r=t(204),o=t(124),a=t(26),i=t(197),s=t(129),l=t(96);n.exports=function(n,e,t){for(var c=-1,d=(e=r(e,n)).length,p=!1;++c<d;){var u=l(e[c]);if(!(p=null!=n&&t(n,u)))break;n=n[u]}return p||++c!=d?p:!!(d=null==n?0:n.length)&&s(d)&&i(u,d)&&(a(n)||o(n))}},function(n,e,t){var r=t(340),o=t(341),a=t(130),i=t(96);n.exports=function(n){return a(n)?r(i(n)):o(n)}},function(n,e){n.exports=function(n){return function(e){return null==e?void 0:e[n]}}},function(n,e,t){var r=t(203);n.exports=function(n){return function(e){return r(e,n)}}},function(n,e,t){var r=t(132),o=t(343),a=t(345);n.exports=function(n,e){return a(o(n,e,r),n+"")}},function(n,e,t){var r=t(344),o=Math.max;n.exports=function(n,e,t){return e=o(void 0===e?n.length-1:e,0),function(){for(var a=arguments,i=-1,s=o(a.length-e,0),l=Array(s);++i<s;)l[i]=a[e+i];i=-1;for(var c=Array(e+1);++i<e;)c[i]=a[i];return c[e]=t(l),r(n,this,c)}}},function(n,e){n.exports=function(n,e,t){switch(t.length){case 0:return n.call(e);case 1:return n.call(e,t[0]);case 2:return n.call(e,t[0],t[1]);case 3:return n.call(e,t[0],t[1],t[2])}return n.apply(e,t)}},function(n,e,t){var r=t(346),o=t(349)(r);n.exports=o},function(n,e,t){var r=t(347),o=t(348),a=t(132),i=o?function(n,e){return o(n,"toString",{configurable:!0,enumerable:!1,value:r(e),writable:!0})}:a;n.exports=i},function(n,e){n.exports=function(n){return function(){return n}}},function(n,e,t){var r=t(42),o=function(){try{var n=r(Object,"defineProperty");return n({},"",{}),n}catch(n){}}();n.exports=o},function(n,e){var t=Date.now;n.exports=function(n){var e=0,r=0;return function(){var o=t(),a=16-(o-r);if(r=o,a>0){if(++e>=800)return arguments[0]}else e=0;return n.apply(void 0,arguments)}}},function(n,e,t){var r=t(193),o=t(351),a=t(356),i=t(194),s=t(357),l=t(128);n.exports=function(n,e,t){var c=-1,d=o,p=n.length,u=!0,m=[],f=m;if(t)u=!1,d=a;else if(p>=200){var h=e?null:s(n);if(h)return l(h);u=!1,d=i,f=new r}else f=e?[]:m;n:for(;++c<p;){var g=n[c],v=e?e(g):g;if(g=t||0!==g?g:0,u&&v==v){for(var b=f.length;b--;)if(f[b]===v)continue n;e&&f.push(v),m.push(g)}else d(f,v,t)||(f!==m&&f.push(v),m.push(g))}return m}},function(n,e,t){var r=t(352);n.exports=function(n,e){return!!(null==n?0:n.length)&&r(n,e,0)>-1}},function(n,e,t){var r=t(353),o=t(354),a=t(355);n.exports=function(n,e,t){return e==e?a(n,e,t):r(n,o,t)}},function(n,e){n.exports=function(n,e,t,r){for(var o=n.length,a=t+(r?1:-1);r?a--:++a<o;)if(e(n[a],a,n))return a;return-1}},function(n,e){n.exports=function(n){return n!=n}},function(n,e){n.exports=function(n,e,t){for(var r=t-1,o=n.length;++r<o;)if(n[r]===e)return r;return-1}},function(n,e){n.exports=function(n,e,t){for(var r=-1,o=null==n?0:n.length;++r<o;)if(t(e,n[r]))return!0;return!1}},function(n,e,t){var r=t(200),o=t(358),a=t(128),i=r&&1/a(new r([,-0]))[1]==1/0?function(n){return new r(n)}:o;n.exports=i},function(n,e){n.exports=function(){}},function(n,e,t){var r=t(199),o=t(45);n.exports=function(n){return o(n)&&r(n)}},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(2);n.exports=r(1..valueOf)},function(n,e,t){var r=t(2),o=t(48),a=t(12),i=t(364),s=t(18),l=r(i),c=r("".slice),d=Math.ceil,p=function(n){return function(e,t,r){var i,p,u=a(s(e)),m=o(t),f=u.length,h=void 0===r?" ":a(r);return m<=f||""==h?u:((p=l(h,d((i=m-f)/h.length))).length>i&&(p=c(p,0,i)),n?u+p:p+u)}};n.exports={start:p(!1),end:p(!0)}},function(n,e,t){"use strict";var r=t(0),o=t(59),a=t(12),i=t(18),s=r.RangeError;n.exports=function(n){var e=a(i(this)),t="",r=o(n);if(r<0||r==1/0)throw s("Wrong number of repetitions");for(;r>0;(r>>>=1)&&(e+=e))1&r&&(t+=e);return t}},function(n,e,t){var r=t(28);n.exports=/Version\/10(?:\.\d+){1,2}(?: [\w./]+)?(?: Mobile\/\w+)? Safari\//.test(r)},function(n,e,t){"use strict";t(206)},function(n,e,t){"use strict";t(207)},function(n,e,t){"use strict";var r=t(1),o=t(2),a=t(36),i=t(16),s=t(29),l=t(12),c=t(3),d=t(369),p=t(50),u=t(370),m=t(371),f=t(46),h=t(372),g=[],v=o(g.sort),b=o(g.push),y=c((function(){g.sort(void 0)})),x=c((function(){g.sort(null)})),_=p("sort"),k=!c((function(){if(f)return f<70;if(!(u&&u>3)){if(m)return!0;if(h)return h<603;var n,e,t,r,o="";for(n=65;n<76;n++){switch(e=String.fromCharCode(n),n){case 66:case 69:case 70:case 72:t=3;break;case 68:case 71:t=4;break;default:t=2}for(r=0;r<47;r++)g.push({k:e+r,v:t})}for(g.sort((function(n,e){return e.v-n.v})),r=0;r<g.length;r++)e=g[r].k.charAt(0),o.charAt(o.length-1)!==e&&(o+=e);return"DGBEFHACIJK"!==o}}));r({target:"Array",proto:!0,forced:y||!x||!_||!k},{sort:function(n){void 0!==n&&a(n);var e=i(this);if(k)return void 0===n?v(e):v(e,n);var t,r,o=[],c=s(e);for(r=0;r<c;r++)r in e&&b(o,e[r]);for(d(o,function(n){return function(e,t){return void 0===t?-1:void 0===e?1:void 0!==n?+n(e,t)||0:l(e)>l(t)?1:-1}}(n)),t=o.length,r=0;r<t;)e[r]=o[r++];for(;r<c;)delete e[r++];return e}})},function(n,e,t){var r=t(119),o=Math.floor,a=function(n,e){var t=n.length,l=o(t/2);return t<8?i(n,e):s(n,a(r(n,0,l),e),a(r(n,l),e),e)},i=function(n,e){for(var t,r,o=n.length,a=1;a<o;){for(r=a,t=n[a];r&&e(n[r-1],t)>0;)n[r]=n[--r];r!==a++&&(n[r]=t)}return n},s=function(n,e,t,r){for(var o=e.length,a=t.length,i=0,s=0;i<o||s<a;)n[i+s]=i<o&&s<a?r(e[i],t[s])<=0?e[i++]:t[s++]:i<o?e[i++]:t[s++];return n};n.exports=a},function(n,e,t){var r=t(28).match(/firefox\/(\d+)/i);n.exports=!!r&&+r[1]},function(n,e,t){var r=t(28);n.exports=/MSIE|Trident/.test(r)},function(n,e,t){var r=t(28).match(/AppleWebKit\/(\d+)\./);n.exports=!!r&&+r[1]},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(1),o=t(3),a=t(19),i=t(37).f,s=t(7),l=o((function(){i(1)}));r({target:"Object",stat:!0,forced:!s||l,sham:!s},{getOwnPropertyDescriptor:function(n,e){return i(a(n),e)}})},function(n,e,t){var r=t(1),o=t(7),a=t(107).f;r({target:"Object",stat:!0,forced:Object.defineProperties!==a,sham:!o},{defineProperties:a})},function(n,e,t){t(1)({target:"Reflect",stat:!0},{ownKeys:t(113)})},function(n,e){},function(n,e){function t(n,e){for(var t=0,r=n.length-1;r>=0;r--){var o=n[r];"."===o?n.splice(r,1):".."===o?(n.splice(r,1),t++):t&&(n.splice(r,1),t--)}if(e)for(;t--;t)n.unshift("..");return n}function r(n,e){if(n.filter)return n.filter(e);for(var t=[],r=0;r<n.length;r++)e(n[r],r,n)&&t.push(n[r]);return t}e.resolve=function(){for(var n="",e=!1,o=arguments.length-1;o>=-1&&!e;o--){var a=o>=0?arguments[o]:process.cwd();if("string"!=typeof a)throw new TypeError("Arguments to path.resolve must be strings");a&&(n=a+"/"+n,e="/"===a.charAt(0))}return(e?"/":"")+(n=t(r(n.split("/"),(function(n){return!!n})),!e).join("/"))||"."},e.normalize=function(n){var a=e.isAbsolute(n),i="/"===o(n,-1);return(n=t(r(n.split("/"),(function(n){return!!n})),!a).join("/"))||a||(n="."),n&&i&&(n+="/"),(a?"/":"")+n},e.isAbsolute=function(n){return"/"===n.charAt(0)},e.join=function(){var n=Array.prototype.slice.call(arguments,0);return e.normalize(r(n,(function(n,e){if("string"!=typeof n)throw new TypeError("Arguments to path.join must be strings");return n})).join("/"))},e.relative=function(n,t){function r(n){for(var e=0;e<n.length&&""===n[e];e++);for(var t=n.length-1;t>=0&&""===n[t];t--);return e>t?[]:n.slice(e,t-e+1)}n=e.resolve(n).substr(1),t=e.resolve(t).substr(1);for(var o=r(n.split("/")),a=r(t.split("/")),i=Math.min(o.length,a.length),s=i,l=0;l<i;l++)if(o[l]!==a[l]){s=l;break}var c=[];for(l=s;l<o.length;l++)c.push("..");return(c=c.concat(a.slice(s))).join("/")},e.sep="/",e.delimiter=":",e.dirname=function(n){if("string"!=typeof n&&(n+=""),0===n.length)return".";for(var e=n.charCodeAt(0),t=47===e,r=-1,o=!0,a=n.length-1;a>=1;--a)if(47===(e=n.charCodeAt(a))){if(!o){r=a;break}}else o=!1;return-1===r?t?"/":".":t&&1===r?"/":n.slice(0,r)},e.basename=function(n,e){var t=function(n){"string"!=typeof n&&(n+="");var e,t=0,r=-1,o=!0;for(e=n.length-1;e>=0;--e)if(47===n.charCodeAt(e)){if(!o){t=e+1;break}}else-1===r&&(o=!1,r=e+1);return-1===r?"":n.slice(t,r)}(n);return e&&t.substr(-1*e.length)===e&&(t=t.substr(0,t.length-e.length)),t},e.extname=function(n){"string"!=typeof n&&(n+="");for(var e=-1,t=0,r=-1,o=!0,a=0,i=n.length-1;i>=0;--i){var s=n.charCodeAt(i);if(47!==s)-1===r&&(o=!1,r=i+1),46===s?-1===e?e=i:1!==a&&(a=1):-1!==e&&(a=-1);else if(!o){t=i+1;break}}return-1===e||-1===r||0===a||1===a&&e===r-1&&e===t+1?"":n.slice(e,r)};var o="b"==="ab".substr(-1)?function(n,e,t){return n.substr(e,t)}:function(n,e,t){return e<0&&(e=n.length+e),n.substr(e,t)}},function(n,e,t){"use strict";var r=/[|\\{}()[\]^$+*?.]/g;e.escapeRegExpChars=function(n){return n?String(n).replace(r,"\\$&"):""};var o={"&":"&amp;","<":"&lt;",">":"&gt;",'"':"&#34;","'":"&#39;"},a=/[&<>'"]/g;function i(n){return o[n]||n}e.escapeXML=function(n){return null==n?"":String(n).replace(a,i)},e.escapeXML.toString=function(){return Function.prototype.toString.call(this)+';\nvar _ENCODE_HTML_RULES = {\n      "&": "&amp;"\n    , "<": "&lt;"\n    , ">": "&gt;"\n    , \'"\': "&#34;"\n    , "\'": "&#39;"\n    }\n  , _MATCH_HTML = /[&<>\'"]/g;\nfunction encode_char(c) {\n  return _ENCODE_HTML_RULES[c] || c;\n};\n'},e.shallowCopy=function(n,e){for(var t in e=e||{})n[t]=e[t];return n},e.shallowCopyFromList=function(n,e,t){for(var r=0;r<t.length;r++){var o=t[r];void 0!==e[o]&&(n[o]=e[o])}return n},e.cache={_data:{},set:function(n,e){this._data[n]=e},get:function(n){return this._data[n]},remove:function(n){delete this._data[n]},reset:function(){this._data={}}}},function(n){n.exports=JSON.parse('{"name":"ejs","description":"Embedded JavaScript templates","keywords":["template","engine","ejs"],"version":"2.7.4","author":"Matthew Eernisse <mde@fleegix.org> (http://fleegix.org)","license":"Apache-2.0","main":"./lib/ejs.js","repository":{"type":"git","url":"git://github.com/mde/ejs.git"},"bugs":"https://github.com/mde/ejs/issues","homepage":"https://github.com/mde/ejs","dependencies":{},"devDependencies":{"browserify":"^13.1.1","eslint":"^4.14.0","git-directory-deploy":"^1.5.1","jake":"^10.3.1","jsdoc":"^3.4.0","lru-cache":"^4.0.1","mocha":"^5.0.5","uglify-js":"^3.3.16"},"engines":{"node":">=0.10.0"},"scripts":{"test":"mocha","postinstall":"node ./postinstall.js"}}')},function(n,e,t){var r=t(1),o=t(0),a=t(2),i=o.Date,s=a(i.prototype.getTime);r({target:"Date",stat:!0},{now:function(){return s(new i)}})},function(n,e,t){"use strict";t(208)},function(n,e,t){"use strict";var r=t(0),o=t(2),a=t(36),i=t(9),s=t(10),l=t(65),c=t(58),d=r.Function,p=o([].concat),u=o([].join),m={},f=function(n,e,t){if(!s(m,e)){for(var r=[],o=0;o<e;o++)r[o]="a["+o+"]";m[e]=d("C,a","return new C("+u(r,",")+")")}return m[e](n,t)};n.exports=c?d.bind:function(n){var e=a(this),t=e.prototype,r=l(arguments,1),o=function(){var t=p(r,l(arguments));return this instanceof o?f(e,t.length,t):e.apply(n,t)};return i(t)&&(o.prototype=t),o}},function(n,e,t){"use strict";t(211)},function(n,e,t){"use strict";t(212)},function(n,e,t){"use strict";t.r(e);t(145),t(234),t(245),t(247),t(4);function r(n,e,t,r,o,a,i){try{var s=n[a](i),l=s.value}catch(n){return void t(n)}s.done?e(l):Promise.resolve(l).then(r,o)}function o(n){return function(){var e=this,t=arguments;return new Promise((function(o,a){var i=n.apply(e,t);function s(n){r(i,o,a,s,l,"next",n)}function l(n){r(i,o,a,s,l,"throw",n)}s(void 0)}))}}t(166),t(51),t(20),t(22),t(44),t(23);var a=Object.freeze({});function i(n){return null==n}function s(n){return null!=n}function l(n){return!0===n}function c(n){return"string"==typeof n||"number"==typeof n||"symbol"==typeof n||"boolean"==typeof n}function d(n){return null!==n&&"object"==typeof n}var p=Object.prototype.toString;function u(n){return"[object Object]"===p.call(n)}function m(n){return"[object RegExp]"===p.call(n)}function f(n){var e=parseFloat(String(n));return e>=0&&Math.floor(e)===e&&isFinite(n)}function h(n){return s(n)&&"function"==typeof n.then&&"function"==typeof n.catch}function g(n){return null==n?"":Array.isArray(n)||u(n)&&n.toString===p?JSON.stringify(n,null,2):String(n)}function v(n){var e=parseFloat(n);return isNaN(e)?n:e}function b(n,e){for(var t=Object.create(null),r=n.split(","),o=0;o<r.length;o++)t[r[o]]=!0;return e?function(n){return t[n.toLowerCase()]}:function(n){return t[n]}}b("slot,component",!0);var y=b("key,ref,slot,slot-scope,is");function x(n,e){if(n.length){var t=n.indexOf(e);if(t>-1)return n.splice(t,1)}}var _=Object.prototype.hasOwnProperty;function k(n,e){return _.call(n,e)}function w(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var T=/-(\w)/g,S=w((function(n){return n.replace(T,(function(n,e){return e?e.toUpperCase():""}))})),P=w((function(n){return n.charAt(0).toUpperCase()+n.slice(1)})),C=/\B([A-Z])/g,I=w((function(n){return n.replace(C,"-$1").toLowerCase()}));var E=Function.prototype.bind?function(n,e){return n.bind(e)}:function(n,e){function t(t){var r=arguments.length;return r?r>1?n.apply(e,arguments):n.call(e,t):n.call(e)}return t._length=n.length,t};function A(n,e){e=e||0;for(var t=n.length-e,r=new Array(t);t--;)r[t]=n[t+e];return r}function D(n,e){for(var t in e)n[t]=e[t];return n}function O(n){for(var e={},t=0;t<n.length;t++)n[t]&&D(e,n[t]);return e}function L(n,e,t){}var j=function(n,e,t){return!1},R=function(n){return n};function z(n,e){if(n===e)return!0;var t=d(n),r=d(e);if(!t||!r)return!t&&!r&&String(n)===String(e);try{var o=Array.isArray(n),a=Array.isArray(e);if(o&&a)return n.length===e.length&&n.every((function(n,t){return z(n,e[t])}));if(n instanceof Date&&e instanceof Date)return n.getTime()===e.getTime();if(o||a)return!1;var i=Object.keys(n),s=Object.keys(e);return i.length===s.length&&i.every((function(t){return z(n[t],e[t])}))}catch(n){return!1}}function M(n,e){for(var t=0;t<n.length;t++)if(z(n[t],e))return t;return-1}function N(n){var e=!1;return function(){e||(e=!0,n.apply(this,arguments))}}var F=["component","directive","filter"],q=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch"],U={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:j,isReservedAttr:j,isUnknownElement:j,getTagNamespace:L,parsePlatformTagName:R,mustUseProp:j,async:!0,_lifecycleHooks:q},B=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function G(n,e,t,r){Object.defineProperty(n,e,{value:t,enumerable:!!r,writable:!0,configurable:!0})}var H=new RegExp("[^"+B.source+".$_\\d]");var V,$="__proto__"in{},W="undefined"!=typeof window,K="undefined"!=typeof WXEnvironment&&!!WXEnvironment.platform,X=K&&WXEnvironment.platform.toLowerCase(),Q=W&&window.navigator.userAgent.toLowerCase(),Y=Q&&/msie|trident/.test(Q),Z=Q&&Q.indexOf("msie 9.0")>0,J=Q&&Q.indexOf("edge/")>0,nn=(Q&&Q.indexOf("android"),Q&&/iphone|ipad|ipod|ios/.test(Q)||"ios"===X),en=(Q&&/chrome\/\d+/.test(Q),Q&&/phantomjs/.test(Q),Q&&Q.match(/firefox\/(\d+)/)),tn={}.watch,rn=!1;if(W)try{var on={};Object.defineProperty(on,"passive",{get:function(){rn=!0}}),window.addEventListener("test-passive",null,on)}catch(n){}var an=function(){return void 0===V&&(V=!W&&!K&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),V},sn=W&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function ln(n){return"function"==typeof n&&/native code/.test(n.toString())}var cn,dn="undefined"!=typeof Symbol&&ln(Symbol)&&"undefined"!=typeof Reflect&&ln(Reflect.ownKeys);cn="undefined"!=typeof Set&&ln(Set)?Set:function(){function n(){this.set=Object.create(null)}return n.prototype.has=function(n){return!0===this.set[n]},n.prototype.add=function(n){this.set[n]=!0},n.prototype.clear=function(){this.set=Object.create(null)},n}();var pn=L,un=0,mn=function(){this.id=un++,this.subs=[]};mn.prototype.addSub=function(n){this.subs.push(n)},mn.prototype.removeSub=function(n){x(this.subs,n)},mn.prototype.depend=function(){mn.target&&mn.target.addDep(this)},mn.prototype.notify=function(){var n=this.subs.slice();for(var e=0,t=n.length;e<t;e++)n[e].update()},mn.target=null;var fn=[];function hn(n){fn.push(n),mn.target=n}function gn(){fn.pop(),mn.target=fn[fn.length-1]}var vn=function(n,e,t,r,o,a,i,s){this.tag=n,this.data=e,this.children=t,this.text=r,this.elm=o,this.ns=void 0,this.context=a,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=e&&e.key,this.componentOptions=i,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1},bn={child:{configurable:!0}};bn.child.get=function(){return this.componentInstance},Object.defineProperties(vn.prototype,bn);var yn=function(n){void 0===n&&(n="");var e=new vn;return e.text=n,e.isComment=!0,e};function xn(n){return new vn(void 0,void 0,void 0,String(n))}function _n(n){var e=new vn(n.tag,n.data,n.children&&n.children.slice(),n.text,n.elm,n.context,n.componentOptions,n.asyncFactory);return e.ns=n.ns,e.isStatic=n.isStatic,e.key=n.key,e.isComment=n.isComment,e.fnContext=n.fnContext,e.fnOptions=n.fnOptions,e.fnScopeId=n.fnScopeId,e.asyncMeta=n.asyncMeta,e.isCloned=!0,e}var kn=Array.prototype,wn=Object.create(kn);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(n){var e=kn[n];G(wn,n,(function(){for(var t=[],r=arguments.length;r--;)t[r]=arguments[r];var o,a=e.apply(this,t),i=this.__ob__;switch(n){case"push":case"unshift":o=t;break;case"splice":o=t.slice(2)}return o&&i.observeArray(o),i.dep.notify(),a}))}));var Tn=Object.getOwnPropertyNames(wn),Sn=!0;function Pn(n){Sn=n}var Cn=function(n){this.value=n,this.dep=new mn,this.vmCount=0,G(n,"__ob__",this),Array.isArray(n)?($?function(n,e){n.__proto__=e}(n,wn):function(n,e,t){for(var r=0,o=t.length;r<o;r++){var a=t[r];G(n,a,e[a])}}(n,wn,Tn),this.observeArray(n)):this.walk(n)};function In(n,e){var t;if(d(n)&&!(n instanceof vn))return k(n,"__ob__")&&n.__ob__ instanceof Cn?t=n.__ob__:Sn&&!an()&&(Array.isArray(n)||u(n))&&Object.isExtensible(n)&&!n._isVue&&(t=new Cn(n)),e&&t&&t.vmCount++,t}function En(n,e,t,r,o){var a=new mn,i=Object.getOwnPropertyDescriptor(n,e);if(!i||!1!==i.configurable){var s=i&&i.get,l=i&&i.set;s&&!l||2!==arguments.length||(t=n[e]);var c=!o&&In(t);Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){var e=s?s.call(n):t;return mn.target&&(a.depend(),c&&(c.dep.depend(),Array.isArray(e)&&On(e))),e},set:function(e){var r=s?s.call(n):t;e===r||e!=e&&r!=r||s&&!l||(l?l.call(n,e):t=e,c=!o&&In(e),a.notify())}})}}function An(n,e,t){if(Array.isArray(n)&&f(e))return n.length=Math.max(n.length,e),n.splice(e,1,t),t;if(e in n&&!(e in Object.prototype))return n[e]=t,t;var r=n.__ob__;return n._isVue||r&&r.vmCount?t:r?(En(r.value,e,t),r.dep.notify(),t):(n[e]=t,t)}function Dn(n,e){if(Array.isArray(n)&&f(e))n.splice(e,1);else{var t=n.__ob__;n._isVue||t&&t.vmCount||k(n,e)&&(delete n[e],t&&t.dep.notify())}}function On(n){for(var e=void 0,t=0,r=n.length;t<r;t++)(e=n[t])&&e.__ob__&&e.__ob__.dep.depend(),Array.isArray(e)&&On(e)}Cn.prototype.walk=function(n){for(var e=Object.keys(n),t=0;t<e.length;t++)En(n,e[t])},Cn.prototype.observeArray=function(n){for(var e=0,t=n.length;e<t;e++)In(n[e])};var Ln=U.optionMergeStrategies;function jn(n,e){if(!e)return n;for(var t,r,o,a=dn?Reflect.ownKeys(e):Object.keys(e),i=0;i<a.length;i++)"__ob__"!==(t=a[i])&&(r=n[t],o=e[t],k(n,t)?r!==o&&u(r)&&u(o)&&jn(r,o):An(n,t,o));return n}function Rn(n,e,t){return t?function(){var r="function"==typeof e?e.call(t,t):e,o="function"==typeof n?n.call(t,t):n;return r?jn(r,o):o}:e?n?function(){return jn("function"==typeof e?e.call(this,this):e,"function"==typeof n?n.call(this,this):n)}:e:n}function zn(n,e){var t=e?n?n.concat(e):Array.isArray(e)?e:[e]:n;return t?function(n){for(var e=[],t=0;t<n.length;t++)-1===e.indexOf(n[t])&&e.push(n[t]);return e}(t):t}function Mn(n,e,t,r){var o=Object.create(n||null);return e?D(o,e):o}Ln.data=function(n,e,t){return t?Rn(n,e,t):e&&"function"!=typeof e?n:Rn(n,e)},q.forEach((function(n){Ln[n]=zn})),F.forEach((function(n){Ln[n+"s"]=Mn})),Ln.watch=function(n,e,t,r){if(n===tn&&(n=void 0),e===tn&&(e=void 0),!e)return Object.create(n||null);if(!n)return e;var o={};for(var a in D(o,n),e){var i=o[a],s=e[a];i&&!Array.isArray(i)&&(i=[i]),o[a]=i?i.concat(s):Array.isArray(s)?s:[s]}return o},Ln.props=Ln.methods=Ln.inject=Ln.computed=function(n,e,t,r){if(!n)return e;var o=Object.create(null);return D(o,n),e&&D(o,e),o},Ln.provide=Rn;var Nn=function(n,e){return void 0===e?n:e};function Fn(n,e,t){if("function"==typeof e&&(e=e.options),function(n,e){var t=n.props;if(t){var r,o,a={};if(Array.isArray(t))for(r=t.length;r--;)"string"==typeof(o=t[r])&&(a[S(o)]={type:null});else if(u(t))for(var i in t)o=t[i],a[S(i)]=u(o)?o:{type:o};else 0;n.props=a}}(e),function(n,e){var t=n.inject;if(t){var r=n.inject={};if(Array.isArray(t))for(var o=0;o<t.length;o++)r[t[o]]={from:t[o]};else if(u(t))for(var a in t){var i=t[a];r[a]=u(i)?D({from:a},i):{from:i}}else 0}}(e),function(n){var e=n.directives;if(e)for(var t in e){var r=e[t];"function"==typeof r&&(e[t]={bind:r,update:r})}}(e),!e._base&&(e.extends&&(n=Fn(n,e.extends,t)),e.mixins))for(var r=0,o=e.mixins.length;r<o;r++)n=Fn(n,e.mixins[r],t);var a,i={};for(a in n)s(a);for(a in e)k(n,a)||s(a);function s(r){var o=Ln[r]||Nn;i[r]=o(n[r],e[r],t,r)}return i}function qn(n,e,t,r){if("string"==typeof t){var o=n[e];if(k(o,t))return o[t];var a=S(t);if(k(o,a))return o[a];var i=P(a);return k(o,i)?o[i]:o[t]||o[a]||o[i]}}function Un(n,e,t,r){var o=e[n],a=!k(t,n),i=t[n],s=Vn(Boolean,o.type);if(s>-1)if(a&&!k(o,"default"))i=!1;else if(""===i||i===I(n)){var l=Vn(String,o.type);(l<0||s<l)&&(i=!0)}if(void 0===i){i=function(n,e,t){if(!k(e,"default"))return;var r=e.default;0;if(n&&n.$options.propsData&&void 0===n.$options.propsData[t]&&void 0!==n._props[t])return n._props[t];return"function"==typeof r&&"Function"!==Gn(e.type)?r.call(n):r}(r,o,n);var c=Sn;Pn(!0),In(i),Pn(c)}return i}var Bn=/^\s*function (\w+)/;function Gn(n){var e=n&&n.toString().match(Bn);return e?e[1]:""}function Hn(n,e){return Gn(n)===Gn(e)}function Vn(n,e){if(!Array.isArray(e))return Hn(e,n)?0:-1;for(var t=0,r=e.length;t<r;t++)if(Hn(e[t],n))return t;return-1}function $n(n,e,t){hn();try{if(e)for(var r=e;r=r.$parent;){var o=r.$options.errorCaptured;if(o)for(var a=0;a<o.length;a++)try{if(!1===o[a].call(r,n,e,t))return}catch(n){Kn(n,r,"errorCaptured hook")}}Kn(n,e,t)}finally{gn()}}function Wn(n,e,t,r,o){var a;try{(a=t?n.apply(e,t):n.call(e))&&!a._isVue&&h(a)&&!a._handled&&(a.catch((function(n){return $n(n,r,o+" (Promise/async)")})),a._handled=!0)}catch(n){$n(n,r,o)}return a}function Kn(n,e,t){if(U.errorHandler)try{return U.errorHandler.call(null,n,e,t)}catch(e){e!==n&&Xn(e,null,"config.errorHandler")}Xn(n,e,t)}function Xn(n,e,t){if(!W&&!K||"undefined"==typeof console)throw n;console.error(n)}var Qn,Yn=!1,Zn=[],Jn=!1;function ne(){Jn=!1;var n=Zn.slice(0);Zn.length=0;for(var e=0;e<n.length;e++)n[e]()}if("undefined"!=typeof Promise&&ln(Promise)){var ee=Promise.resolve();Qn=function(){ee.then(ne),nn&&setTimeout(L)},Yn=!0}else if(Y||"undefined"==typeof MutationObserver||!ln(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())Qn="undefined"!=typeof setImmediate&&ln(setImmediate)?function(){setImmediate(ne)}:function(){setTimeout(ne,0)};else{var te=1,re=new MutationObserver(ne),oe=document.createTextNode(String(te));re.observe(oe,{characterData:!0}),Qn=function(){te=(te+1)%2,oe.data=String(te)},Yn=!0}function ae(n,e){var t;if(Zn.push((function(){if(n)try{n.call(e)}catch(n){$n(n,e,"nextTick")}else t&&t(e)})),Jn||(Jn=!0,Qn()),!n&&"undefined"!=typeof Promise)return new Promise((function(n){t=n}))}var ie=new cn;function se(n){!function n(e,t){var r,o,a=Array.isArray(e);if(!a&&!d(e)||Object.isFrozen(e)||e instanceof vn)return;if(e.__ob__){var i=e.__ob__.dep.id;if(t.has(i))return;t.add(i)}if(a)for(r=e.length;r--;)n(e[r],t);else for(o=Object.keys(e),r=o.length;r--;)n(e[o[r]],t)}(n,ie),ie.clear()}var le=w((function(n){var e="&"===n.charAt(0),t="~"===(n=e?n.slice(1):n).charAt(0),r="!"===(n=t?n.slice(1):n).charAt(0);return{name:n=r?n.slice(1):n,once:t,capture:r,passive:e}}));function ce(n,e){function t(){var n=arguments,r=t.fns;if(!Array.isArray(r))return Wn(r,null,arguments,e,"v-on handler");for(var o=r.slice(),a=0;a<o.length;a++)Wn(o[a],null,n,e,"v-on handler")}return t.fns=n,t}function de(n,e,t,r,o,a){var s,c,d,p;for(s in n)c=n[s],d=e[s],p=le(s),i(c)||(i(d)?(i(c.fns)&&(c=n[s]=ce(c,a)),l(p.once)&&(c=n[s]=o(p.name,c,p.capture)),t(p.name,c,p.capture,p.passive,p.params)):c!==d&&(d.fns=c,n[s]=d));for(s in e)i(n[s])&&r((p=le(s)).name,e[s],p.capture)}function pe(n,e,t){var r;n instanceof vn&&(n=n.data.hook||(n.data.hook={}));var o=n[e];function a(){t.apply(this,arguments),x(r.fns,a)}i(o)?r=ce([a]):s(o.fns)&&l(o.merged)?(r=o).fns.push(a):r=ce([o,a]),r.merged=!0,n[e]=r}function ue(n,e,t,r,o){if(s(e)){if(k(e,t))return n[t]=e[t],o||delete e[t],!0;if(k(e,r))return n[t]=e[r],o||delete e[r],!0}return!1}function me(n){return c(n)?[xn(n)]:Array.isArray(n)?function n(e,t){var r,o,a,d,p=[];for(r=0;r<e.length;r++)i(o=e[r])||"boolean"==typeof o||(a=p.length-1,d=p[a],Array.isArray(o)?o.length>0&&(fe((o=n(o,(t||"")+"_"+r))[0])&&fe(d)&&(p[a]=xn(d.text+o[0].text),o.shift()),p.push.apply(p,o)):c(o)?fe(d)?p[a]=xn(d.text+o):""!==o&&p.push(xn(o)):fe(o)&&fe(d)?p[a]=xn(d.text+o.text):(l(e._isVList)&&s(o.tag)&&i(o.key)&&s(t)&&(o.key="__vlist"+t+"_"+r+"__"),p.push(o)));return p}(n):void 0}function fe(n){return s(n)&&s(n.text)&&!1===n.isComment}function he(n,e){if(n){for(var t=Object.create(null),r=dn?Reflect.ownKeys(n):Object.keys(n),o=0;o<r.length;o++){var a=r[o];if("__ob__"!==a){for(var i=n[a].from,s=e;s;){if(s._provided&&k(s._provided,i)){t[a]=s._provided[i];break}s=s.$parent}if(!s)if("default"in n[a]){var l=n[a].default;t[a]="function"==typeof l?l.call(e):l}else 0}}return t}}function ge(n,e){if(!n||!n.length)return{};for(var t={},r=0,o=n.length;r<o;r++){var a=n[r],i=a.data;if(i&&i.attrs&&i.attrs.slot&&delete i.attrs.slot,a.context!==e&&a.fnContext!==e||!i||null==i.slot)(t.default||(t.default=[])).push(a);else{var s=i.slot,l=t[s]||(t[s]=[]);"template"===a.tag?l.push.apply(l,a.children||[]):l.push(a)}}for(var c in t)t[c].every(ve)&&delete t[c];return t}function ve(n){return n.isComment&&!n.asyncFactory||" "===n.text}function be(n){return n.isComment&&n.asyncFactory}function ye(n,e,t){var r,o=Object.keys(e).length>0,i=n?!!n.$stable:!o,s=n&&n.$key;if(n){if(n._normalized)return n._normalized;if(i&&t&&t!==a&&s===t.$key&&!o&&!t.$hasNormal)return t;for(var l in r={},n)n[l]&&"$"!==l[0]&&(r[l]=xe(e,l,n[l]))}else r={};for(var c in e)c in r||(r[c]=_e(e,c));return n&&Object.isExtensible(n)&&(n._normalized=r),G(r,"$stable",i),G(r,"$key",s),G(r,"$hasNormal",o),r}function xe(n,e,t){var r=function(){var n=arguments.length?t.apply(null,arguments):t({}),e=(n=n&&"object"==typeof n&&!Array.isArray(n)?[n]:me(n))&&n[0];return n&&(!e||1===n.length&&e.isComment&&!be(e))?void 0:n};return t.proxy&&Object.defineProperty(n,e,{get:r,enumerable:!0,configurable:!0}),r}function _e(n,e){return function(){return n[e]}}function ke(n,e){var t,r,o,a,i;if(Array.isArray(n)||"string"==typeof n)for(t=new Array(n.length),r=0,o=n.length;r<o;r++)t[r]=e(n[r],r);else if("number"==typeof n)for(t=new Array(n),r=0;r<n;r++)t[r]=e(r+1,r);else if(d(n))if(dn&&n[Symbol.iterator]){t=[];for(var l=n[Symbol.iterator](),c=l.next();!c.done;)t.push(e(c.value,t.length)),c=l.next()}else for(a=Object.keys(n),t=new Array(a.length),r=0,o=a.length;r<o;r++)i=a[r],t[r]=e(n[i],i,r);return s(t)||(t=[]),t._isVList=!0,t}function we(n,e,t,r){var o,a=this.$scopedSlots[n];a?(t=t||{},r&&(t=D(D({},r),t)),o=a(t)||("function"==typeof e?e():e)):o=this.$slots[n]||("function"==typeof e?e():e);var i=t&&t.slot;return i?this.$createElement("template",{slot:i},o):o}function Te(n){return qn(this.$options,"filters",n)||R}function Se(n,e){return Array.isArray(n)?-1===n.indexOf(e):n!==e}function Pe(n,e,t,r,o){var a=U.keyCodes[e]||t;return o&&r&&!U.keyCodes[e]?Se(o,r):a?Se(a,n):r?I(r)!==e:void 0===n}function Ce(n,e,t,r,o){if(t)if(d(t)){var a;Array.isArray(t)&&(t=O(t));var i=function(i){if("class"===i||"style"===i||y(i))a=n;else{var s=n.attrs&&n.attrs.type;a=r||U.mustUseProp(e,s,i)?n.domProps||(n.domProps={}):n.attrs||(n.attrs={})}var l=S(i),c=I(i);l in a||c in a||(a[i]=t[i],o&&((n.on||(n.on={}))["update:"+i]=function(n){t[i]=n}))};for(var s in t)i(s)}else;return n}function Ie(n,e){var t=this._staticTrees||(this._staticTrees=[]),r=t[n];return r&&!e||Ae(r=t[n]=this.$options.staticRenderFns[n].call(this._renderProxy,null,this),"__static__"+n,!1),r}function Ee(n,e,t){return Ae(n,"__once__"+e+(t?"_"+t:""),!0),n}function Ae(n,e,t){if(Array.isArray(n))for(var r=0;r<n.length;r++)n[r]&&"string"!=typeof n[r]&&De(n[r],e+"_"+r,t);else De(n,e,t)}function De(n,e,t){n.isStatic=!0,n.key=e,n.isOnce=t}function Oe(n,e){if(e)if(u(e)){var t=n.on=n.on?D({},n.on):{};for(var r in e){var o=t[r],a=e[r];t[r]=o?[].concat(o,a):a}}else;return n}function Le(n,e,t,r){e=e||{$stable:!t};for(var o=0;o<n.length;o++){var a=n[o];Array.isArray(a)?Le(a,e,t):a&&(a.proxy&&(a.fn.proxy=!0),e[a.key]=a.fn)}return r&&(e.$key=r),e}function je(n,e){for(var t=0;t<e.length;t+=2){var r=e[t];"string"==typeof r&&r&&(n[e[t]]=e[t+1])}return n}function Re(n,e){return"string"==typeof n?e+n:n}function ze(n){n._o=Ee,n._n=v,n._s=g,n._l=ke,n._t=we,n._q=z,n._i=M,n._m=Ie,n._f=Te,n._k=Pe,n._b=Ce,n._v=xn,n._e=yn,n._u=Le,n._g=Oe,n._d=je,n._p=Re}function Me(n,e,t,r,o){var i,s=this,c=o.options;k(r,"_uid")?(i=Object.create(r))._original=r:(i=r,r=r._original);var d=l(c._compiled),p=!d;this.data=n,this.props=e,this.children=t,this.parent=r,this.listeners=n.on||a,this.injections=he(c.inject,r),this.slots=function(){return s.$slots||ye(n.scopedSlots,s.$slots=ge(t,r)),s.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return ye(n.scopedSlots,this.slots())}}),d&&(this.$options=c,this.$slots=this.slots(),this.$scopedSlots=ye(n.scopedSlots,this.$slots)),c._scopeId?this._c=function(n,e,t,o){var a=He(i,n,e,t,o,p);return a&&!Array.isArray(a)&&(a.fnScopeId=c._scopeId,a.fnContext=r),a}:this._c=function(n,e,t,r){return He(i,n,e,t,r,p)}}function Ne(n,e,t,r,o){var a=_n(n);return a.fnContext=t,a.fnOptions=r,e.slot&&((a.data||(a.data={})).slot=e.slot),a}function Fe(n,e){for(var t in e)n[S(t)]=e[t]}ze(Me.prototype);var qe={init:function(n,e){if(n.componentInstance&&!n.componentInstance._isDestroyed&&n.data.keepAlive){var t=n;qe.prepatch(t,t)}else{(n.componentInstance=function(n,e){var t={_isComponent:!0,_parentVnode:n,parent:e},r=n.data.inlineTemplate;s(r)&&(t.render=r.render,t.staticRenderFns=r.staticRenderFns);return new n.componentOptions.Ctor(t)}(n,Je)).$mount(e?n.elm:void 0,e)}},prepatch:function(n,e){var t=e.componentOptions;!function(n,e,t,r,o){0;var i=r.data.scopedSlots,s=n.$scopedSlots,l=!!(i&&!i.$stable||s!==a&&!s.$stable||i&&n.$scopedSlots.$key!==i.$key||!i&&n.$scopedSlots.$key),c=!!(o||n.$options._renderChildren||l);n.$options._parentVnode=r,n.$vnode=r,n._vnode&&(n._vnode.parent=r);if(n.$options._renderChildren=o,n.$attrs=r.data.attrs||a,n.$listeners=t||a,e&&n.$options.props){Pn(!1);for(var d=n._props,p=n.$options._propKeys||[],u=0;u<p.length;u++){var m=p[u],f=n.$options.props;d[m]=Un(m,f,e,n)}Pn(!0),n.$options.propsData=e}t=t||a;var h=n.$options._parentListeners;n.$options._parentListeners=t,Ze(n,t,h),c&&(n.$slots=ge(o,r.context),n.$forceUpdate());0}(e.componentInstance=n.componentInstance,t.propsData,t.listeners,e,t.children)},insert:function(n){var e,t=n.context,r=n.componentInstance;r._isMounted||(r._isMounted=!0,rt(r,"mounted")),n.data.keepAlive&&(t._isMounted?((e=r)._inactive=!1,at.push(e)):tt(r,!0))},destroy:function(n){var e=n.componentInstance;e._isDestroyed||(n.data.keepAlive?function n(e,t){if(t&&(e._directInactive=!0,et(e)))return;if(!e._inactive){e._inactive=!0;for(var r=0;r<e.$children.length;r++)n(e.$children[r]);rt(e,"deactivated")}}(e,!0):e.$destroy())}},Ue=Object.keys(qe);function Be(n,e,t,r,o){if(!i(n)){var c=t.$options._base;if(d(n)&&(n=c.extend(n)),"function"==typeof n){var p;if(i(n.cid)&&void 0===(n=function(n,e){if(l(n.error)&&s(n.errorComp))return n.errorComp;if(s(n.resolved))return n.resolved;var t=$e;t&&s(n.owners)&&-1===n.owners.indexOf(t)&&n.owners.push(t);if(l(n.loading)&&s(n.loadingComp))return n.loadingComp;if(t&&!s(n.owners)){var r=n.owners=[t],o=!0,a=null,c=null;t.$on("hook:destroyed",(function(){return x(r,t)}));var p=function(n){for(var e=0,t=r.length;e<t;e++)r[e].$forceUpdate();n&&(r.length=0,null!==a&&(clearTimeout(a),a=null),null!==c&&(clearTimeout(c),c=null))},u=N((function(t){n.resolved=We(t,e),o?r.length=0:p(!0)})),m=N((function(e){s(n.errorComp)&&(n.error=!0,p(!0))})),f=n(u,m);return d(f)&&(h(f)?i(n.resolved)&&f.then(u,m):h(f.component)&&(f.component.then(u,m),s(f.error)&&(n.errorComp=We(f.error,e)),s(f.loading)&&(n.loadingComp=We(f.loading,e),0===f.delay?n.loading=!0:a=setTimeout((function(){a=null,i(n.resolved)&&i(n.error)&&(n.loading=!0,p(!1))}),f.delay||200)),s(f.timeout)&&(c=setTimeout((function(){c=null,i(n.resolved)&&m(null)}),f.timeout)))),o=!1,n.loading?n.loadingComp:n.resolved}}(p=n,c)))return function(n,e,t,r,o){var a=yn();return a.asyncFactory=n,a.asyncMeta={data:e,context:t,children:r,tag:o},a}(p,e,t,r,o);e=e||{},St(n),s(e.model)&&function(n,e){var t=n.model&&n.model.prop||"value",r=n.model&&n.model.event||"input";(e.attrs||(e.attrs={}))[t]=e.model.value;var o=e.on||(e.on={}),a=o[r],i=e.model.callback;s(a)?(Array.isArray(a)?-1===a.indexOf(i):a!==i)&&(o[r]=[i].concat(a)):o[r]=i}(n.options,e);var u=function(n,e,t){var r=e.options.props;if(!i(r)){var o={},a=n.attrs,l=n.props;if(s(a)||s(l))for(var c in r){var d=I(c);ue(o,l,c,d,!0)||ue(o,a,c,d,!1)}return o}}(e,n);if(l(n.options.functional))return function(n,e,t,r,o){var i=n.options,l={},c=i.props;if(s(c))for(var d in c)l[d]=Un(d,c,e||a);else s(t.attrs)&&Fe(l,t.attrs),s(t.props)&&Fe(l,t.props);var p=new Me(t,l,o,r,n),u=i.render.call(null,p._c,p);if(u instanceof vn)return Ne(u,t,p.parent,i,p);if(Array.isArray(u)){for(var m=me(u)||[],f=new Array(m.length),h=0;h<m.length;h++)f[h]=Ne(m[h],t,p.parent,i,p);return f}}(n,u,e,t,r);var m=e.on;if(e.on=e.nativeOn,l(n.options.abstract)){var f=e.slot;e={},f&&(e.slot=f)}!function(n){for(var e=n.hook||(n.hook={}),t=0;t<Ue.length;t++){var r=Ue[t],o=e[r],a=qe[r];o===a||o&&o._merged||(e[r]=o?Ge(a,o):a)}}(e);var g=n.options.name||o;return new vn("vue-component-"+n.cid+(g?"-"+g:""),e,void 0,void 0,void 0,t,{Ctor:n,propsData:u,listeners:m,tag:o,children:r},p)}}}function Ge(n,e){var t=function(t,r){n(t,r),e(t,r)};return t._merged=!0,t}function He(n,e,t,r,o,a){return(Array.isArray(t)||c(t))&&(o=r,r=t,t=void 0),l(a)&&(o=2),function(n,e,t,r,o){if(s(t)&&s(t.__ob__))return yn();s(t)&&s(t.is)&&(e=t.is);if(!e)return yn();0;Array.isArray(r)&&"function"==typeof r[0]&&((t=t||{}).scopedSlots={default:r[0]},r.length=0);2===o?r=me(r):1===o&&(r=function(n){for(var e=0;e<n.length;e++)if(Array.isArray(n[e]))return Array.prototype.concat.apply([],n);return n}(r));var a,c;if("string"==typeof e){var p;c=n.$vnode&&n.$vnode.ns||U.getTagNamespace(e),a=U.isReservedTag(e)?new vn(U.parsePlatformTagName(e),t,r,void 0,void 0,n):t&&t.pre||!s(p=qn(n.$options,"components",e))?new vn(e,t,r,void 0,void 0,n):Be(p,t,n,r,e)}else a=Be(e,t,n,r);return Array.isArray(a)?a:s(a)?(s(c)&&function n(e,t,r){e.ns=t,"foreignObject"===e.tag&&(t=void 0,r=!0);if(s(e.children))for(var o=0,a=e.children.length;o<a;o++){var c=e.children[o];s(c.tag)&&(i(c.ns)||l(r)&&"svg"!==c.tag)&&n(c,t,r)}}(a,c),s(t)&&function(n){d(n.style)&&se(n.style);d(n.class)&&se(n.class)}(t),a):yn()}(n,e,t,r,o)}var Ve,$e=null;function We(n,e){return(n.__esModule||dn&&"Module"===n[Symbol.toStringTag])&&(n=n.default),d(n)?e.extend(n):n}function Ke(n){if(Array.isArray(n))for(var e=0;e<n.length;e++){var t=n[e];if(s(t)&&(s(t.componentOptions)||be(t)))return t}}function Xe(n,e){Ve.$on(n,e)}function Qe(n,e){Ve.$off(n,e)}function Ye(n,e){var t=Ve;return function r(){var o=e.apply(null,arguments);null!==o&&t.$off(n,r)}}function Ze(n,e,t){Ve=n,de(e,t||{},Xe,Qe,Ye,n),Ve=void 0}var Je=null;function nt(n){var e=Je;return Je=n,function(){Je=e}}function et(n){for(;n&&(n=n.$parent);)if(n._inactive)return!0;return!1}function tt(n,e){if(e){if(n._directInactive=!1,et(n))return}else if(n._directInactive)return;if(n._inactive||null===n._inactive){n._inactive=!1;for(var t=0;t<n.$children.length;t++)tt(n.$children[t]);rt(n,"activated")}}function rt(n,e){hn();var t=n.$options[e],r=e+" hook";if(t)for(var o=0,a=t.length;o<a;o++)Wn(t[o],n,null,n,r);n._hasHookEvent&&n.$emit("hook:"+e),gn()}var ot=[],at=[],it={},st=!1,lt=!1,ct=0;var dt=0,pt=Date.now;if(W&&!Y){var ut=window.performance;ut&&"function"==typeof ut.now&&pt()>document.createEvent("Event").timeStamp&&(pt=function(){return ut.now()})}function mt(){var n,e;for(dt=pt(),lt=!0,ot.sort((function(n,e){return n.id-e.id})),ct=0;ct<ot.length;ct++)(n=ot[ct]).before&&n.before(),e=n.id,it[e]=null,n.run();var t=at.slice(),r=ot.slice();ct=ot.length=at.length=0,it={},st=lt=!1,function(n){for(var e=0;e<n.length;e++)n[e]._inactive=!0,tt(n[e],!0)}(t),function(n){var e=n.length;for(;e--;){var t=n[e],r=t.vm;r._watcher===t&&r._isMounted&&!r._isDestroyed&&rt(r,"updated")}}(r),sn&&U.devtools&&sn.emit("flush")}var ft=0,ht=function(n,e,t,r,o){this.vm=n,o&&(n._watcher=this),n._watchers.push(this),r?(this.deep=!!r.deep,this.user=!!r.user,this.lazy=!!r.lazy,this.sync=!!r.sync,this.before=r.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++ft,this.active=!0,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new cn,this.newDepIds=new cn,this.expression="","function"==typeof e?this.getter=e:(this.getter=function(n){if(!H.test(n)){var e=n.split(".");return function(n){for(var t=0;t<e.length;t++){if(!n)return;n=n[e[t]]}return n}}}(e),this.getter||(this.getter=L)),this.value=this.lazy?void 0:this.get()};ht.prototype.get=function(){var n;hn(this);var e=this.vm;try{n=this.getter.call(e,e)}catch(n){if(!this.user)throw n;$n(n,e,'getter for watcher "'+this.expression+'"')}finally{this.deep&&se(n),gn(),this.cleanupDeps()}return n},ht.prototype.addDep=function(n){var e=n.id;this.newDepIds.has(e)||(this.newDepIds.add(e),this.newDeps.push(n),this.depIds.has(e)||n.addSub(this))},ht.prototype.cleanupDeps=function(){for(var n=this.deps.length;n--;){var e=this.deps[n];this.newDepIds.has(e.id)||e.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},ht.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():function(n){var e=n.id;if(null==it[e]){if(it[e]=!0,lt){for(var t=ot.length-1;t>ct&&ot[t].id>n.id;)t--;ot.splice(t+1,0,n)}else ot.push(n);st||(st=!0,ae(mt))}}(this)},ht.prototype.run=function(){if(this.active){var n=this.get();if(n!==this.value||d(n)||this.deep){var e=this.value;if(this.value=n,this.user){var t='callback for watcher "'+this.expression+'"';Wn(this.cb,this.vm,[n,e],this.vm,t)}else this.cb.call(this.vm,n,e)}}},ht.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},ht.prototype.depend=function(){for(var n=this.deps.length;n--;)this.deps[n].depend()},ht.prototype.teardown=function(){if(this.active){this.vm._isBeingDestroyed||x(this.vm._watchers,this);for(var n=this.deps.length;n--;)this.deps[n].removeSub(this);this.active=!1}};var gt={enumerable:!0,configurable:!0,get:L,set:L};function vt(n,e,t){gt.get=function(){return this[e][t]},gt.set=function(n){this[e][t]=n},Object.defineProperty(n,t,gt)}function bt(n){n._watchers=[];var e=n.$options;e.props&&function(n,e){var t=n.$options.propsData||{},r=n._props={},o=n.$options._propKeys=[];n.$parent&&Pn(!1);var a=function(a){o.push(a);var i=Un(a,e,t,n);En(r,a,i),a in n||vt(n,"_props",a)};for(var i in e)a(i);Pn(!0)}(n,e.props),e.methods&&function(n,e){n.$options.props;for(var t in e)n[t]="function"!=typeof e[t]?L:E(e[t],n)}(n,e.methods),e.data?function(n){var e=n.$options.data;u(e=n._data="function"==typeof e?function(n,e){hn();try{return n.call(e,e)}catch(n){return $n(n,e,"data()"),{}}finally{gn()}}(e,n):e||{})||(e={});var t=Object.keys(e),r=n.$options.props,o=(n.$options.methods,t.length);for(;o--;){var a=t[o];0,r&&k(r,a)||(i=void 0,36!==(i=(a+"").charCodeAt(0))&&95!==i&&vt(n,"_data",a))}var i;In(e,!0)}(n):In(n._data={},!0),e.computed&&function(n,e){var t=n._computedWatchers=Object.create(null),r=an();for(var o in e){var a=e[o],i="function"==typeof a?a:a.get;0,r||(t[o]=new ht(n,i||L,L,yt)),o in n||xt(n,o,a)}}(n,e.computed),e.watch&&e.watch!==tn&&function(n,e){for(var t in e){var r=e[t];if(Array.isArray(r))for(var o=0;o<r.length;o++)wt(n,t,r[o]);else wt(n,t,r)}}(n,e.watch)}var yt={lazy:!0};function xt(n,e,t){var r=!an();"function"==typeof t?(gt.get=r?_t(e):kt(t),gt.set=L):(gt.get=t.get?r&&!1!==t.cache?_t(e):kt(t.get):L,gt.set=t.set||L),Object.defineProperty(n,e,gt)}function _t(n){return function(){var e=this._computedWatchers&&this._computedWatchers[n];if(e)return e.dirty&&e.evaluate(),mn.target&&e.depend(),e.value}}function kt(n){return function(){return n.call(this,this)}}function wt(n,e,t,r){return u(t)&&(r=t,t=t.handler),"string"==typeof t&&(t=n[t]),n.$watch(e,t,r)}var Tt=0;function St(n){var e=n.options;if(n.super){var t=St(n.super);if(t!==n.superOptions){n.superOptions=t;var r=function(n){var e,t=n.options,r=n.sealedOptions;for(var o in t)t[o]!==r[o]&&(e||(e={}),e[o]=t[o]);return e}(n);r&&D(n.extendOptions,r),(e=n.options=Fn(t,n.extendOptions)).name&&(e.components[e.name]=n)}}return e}function Pt(n){this._init(n)}function Ct(n){n.cid=0;var e=1;n.extend=function(n){n=n||{};var t=this,r=t.cid,o=n._Ctor||(n._Ctor={});if(o[r])return o[r];var a=n.name||t.options.name;var i=function(n){this._init(n)};return(i.prototype=Object.create(t.prototype)).constructor=i,i.cid=e++,i.options=Fn(t.options,n),i.super=t,i.options.props&&function(n){var e=n.options.props;for(var t in e)vt(n.prototype,"_props",t)}(i),i.options.computed&&function(n){var e=n.options.computed;for(var t in e)xt(n.prototype,t,e[t])}(i),i.extend=t.extend,i.mixin=t.mixin,i.use=t.use,F.forEach((function(n){i[n]=t[n]})),a&&(i.options.components[a]=i),i.superOptions=t.options,i.extendOptions=n,i.sealedOptions=D({},i.options),o[r]=i,i}}function It(n){return n&&(n.Ctor.options.name||n.tag)}function Et(n,e){return Array.isArray(n)?n.indexOf(e)>-1:"string"==typeof n?n.split(",").indexOf(e)>-1:!!m(n)&&n.test(e)}function At(n,e){var t=n.cache,r=n.keys,o=n._vnode;for(var a in t){var i=t[a];if(i){var s=i.name;s&&!e(s)&&Dt(t,a,r,o)}}}function Dt(n,e,t,r){var o=n[e];!o||r&&o.tag===r.tag||o.componentInstance.$destroy(),n[e]=null,x(t,e)}Pt.prototype._init=function(n){var e=this;e._uid=Tt++,e._isVue=!0,n&&n._isComponent?function(n,e){var t=n.$options=Object.create(n.constructor.options),r=e._parentVnode;t.parent=e.parent,t._parentVnode=r;var o=r.componentOptions;t.propsData=o.propsData,t._parentListeners=o.listeners,t._renderChildren=o.children,t._componentTag=o.tag,e.render&&(t.render=e.render,t.staticRenderFns=e.staticRenderFns)}(e,n):e.$options=Fn(St(e.constructor),n||{},e),e._renderProxy=e,e._self=e,function(n){var e=n.$options,t=e.parent;if(t&&!e.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(n)}n.$parent=t,n.$root=t?t.$root:n,n.$children=[],n.$refs={},n._watcher=null,n._inactive=null,n._directInactive=!1,n._isMounted=!1,n._isDestroyed=!1,n._isBeingDestroyed=!1}(e),function(n){n._events=Object.create(null),n._hasHookEvent=!1;var e=n.$options._parentListeners;e&&Ze(n,e)}(e),function(n){n._vnode=null,n._staticTrees=null;var e=n.$options,t=n.$vnode=e._parentVnode,r=t&&t.context;n.$slots=ge(e._renderChildren,r),n.$scopedSlots=a,n._c=function(e,t,r,o){return He(n,e,t,r,o,!1)},n.$createElement=function(e,t,r,o){return He(n,e,t,r,o,!0)};var o=t&&t.data;En(n,"$attrs",o&&o.attrs||a,null,!0),En(n,"$listeners",e._parentListeners||a,null,!0)}(e),rt(e,"beforeCreate"),function(n){var e=he(n.$options.inject,n);e&&(Pn(!1),Object.keys(e).forEach((function(t){En(n,t,e[t])})),Pn(!0))}(e),bt(e),function(n){var e=n.$options.provide;e&&(n._provided="function"==typeof e?e.call(n):e)}(e),rt(e,"created"),e.$options.el&&e.$mount(e.$options.el)},function(n){var e={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(n.prototype,"$data",e),Object.defineProperty(n.prototype,"$props",t),n.prototype.$set=An,n.prototype.$delete=Dn,n.prototype.$watch=function(n,e,t){if(u(e))return wt(this,n,e,t);(t=t||{}).user=!0;var r=new ht(this,n,e,t);if(t.immediate){var o='callback for immediate watcher "'+r.expression+'"';hn(),Wn(e,this,[r.value],this,o),gn()}return function(){r.teardown()}}}(Pt),function(n){var e=/^hook:/;n.prototype.$on=function(n,t){var r=this;if(Array.isArray(n))for(var o=0,a=n.length;o<a;o++)r.$on(n[o],t);else(r._events[n]||(r._events[n]=[])).push(t),e.test(n)&&(r._hasHookEvent=!0);return r},n.prototype.$once=function(n,e){var t=this;function r(){t.$off(n,r),e.apply(t,arguments)}return r.fn=e,t.$on(n,r),t},n.prototype.$off=function(n,e){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(Array.isArray(n)){for(var r=0,o=n.length;r<o;r++)t.$off(n[r],e);return t}var a,i=t._events[n];if(!i)return t;if(!e)return t._events[n]=null,t;for(var s=i.length;s--;)if((a=i[s])===e||a.fn===e){i.splice(s,1);break}return t},n.prototype.$emit=function(n){var e=this,t=e._events[n];if(t){t=t.length>1?A(t):t;for(var r=A(arguments,1),o='event handler for "'+n+'"',a=0,i=t.length;a<i;a++)Wn(t[a],e,r,e,o)}return e}}(Pt),function(n){n.prototype._update=function(n,e){var t=this,r=t.$el,o=t._vnode,a=nt(t);t._vnode=n,t.$el=o?t.__patch__(o,n):t.__patch__(t.$el,n,e,!1),a(),r&&(r.__vue__=null),t.$el&&(t.$el.__vue__=t),t.$vnode&&t.$parent&&t.$vnode===t.$parent._vnode&&(t.$parent.$el=t.$el)},n.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},n.prototype.$destroy=function(){var n=this;if(!n._isBeingDestroyed){rt(n,"beforeDestroy"),n._isBeingDestroyed=!0;var e=n.$parent;!e||e._isBeingDestroyed||n.$options.abstract||x(e.$children,n),n._watcher&&n._watcher.teardown();for(var t=n._watchers.length;t--;)n._watchers[t].teardown();n._data.__ob__&&n._data.__ob__.vmCount--,n._isDestroyed=!0,n.__patch__(n._vnode,null),rt(n,"destroyed"),n.$off(),n.$el&&(n.$el.__vue__=null),n.$vnode&&(n.$vnode.parent=null)}}}(Pt),function(n){ze(n.prototype),n.prototype.$nextTick=function(n){return ae(n,this)},n.prototype._render=function(){var n,e=this,t=e.$options,r=t.render,o=t._parentVnode;o&&(e.$scopedSlots=ye(o.data.scopedSlots,e.$slots,e.$scopedSlots)),e.$vnode=o;try{$e=e,n=r.call(e._renderProxy,e.$createElement)}catch(t){$n(t,e,"render"),n=e._vnode}finally{$e=null}return Array.isArray(n)&&1===n.length&&(n=n[0]),n instanceof vn||(n=yn()),n.parent=o,n}}(Pt);var Ot=[String,RegExp,Array],Lt={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:Ot,exclude:Ot,max:[String,Number]},methods:{cacheVNode:function(){var n=this.cache,e=this.keys,t=this.vnodeToCache,r=this.keyToCache;if(t){var o=t.tag,a=t.componentInstance,i=t.componentOptions;n[r]={name:It(i),tag:o,componentInstance:a},e.push(r),this.max&&e.length>parseInt(this.max)&&Dt(n,e[0],e,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var n in this.cache)Dt(this.cache,n,this.keys)},mounted:function(){var n=this;this.cacheVNode(),this.$watch("include",(function(e){At(n,(function(n){return Et(e,n)}))})),this.$watch("exclude",(function(e){At(n,(function(n){return!Et(e,n)}))}))},updated:function(){this.cacheVNode()},render:function(){var n=this.$slots.default,e=Ke(n),t=e&&e.componentOptions;if(t){var r=It(t),o=this.include,a=this.exclude;if(o&&(!r||!Et(o,r))||a&&r&&Et(a,r))return e;var i=this.cache,s=this.keys,l=null==e.key?t.Ctor.cid+(t.tag?"::"+t.tag:""):e.key;i[l]?(e.componentInstance=i[l].componentInstance,x(s,l),s.push(l)):(this.vnodeToCache=e,this.keyToCache=l),e.data.keepAlive=!0}return e||n&&n[0]}}};!function(n){var e={get:function(){return U}};Object.defineProperty(n,"config",e),n.util={warn:pn,extend:D,mergeOptions:Fn,defineReactive:En},n.set=An,n.delete=Dn,n.nextTick=ae,n.observable=function(n){return In(n),n},n.options=Object.create(null),F.forEach((function(e){n.options[e+"s"]=Object.create(null)})),n.options._base=n,D(n.options.components,Lt),function(n){n.use=function(n){var e=this._installedPlugins||(this._installedPlugins=[]);if(e.indexOf(n)>-1)return this;var t=A(arguments,1);return t.unshift(this),"function"==typeof n.install?n.install.apply(n,t):"function"==typeof n&&n.apply(null,t),e.push(n),this}}(n),function(n){n.mixin=function(n){return this.options=Fn(this.options,n),this}}(n),Ct(n),function(n){F.forEach((function(e){n[e]=function(n,t){return t?("component"===e&&u(t)&&(t.name=t.name||n,t=this.options._base.extend(t)),"directive"===e&&"function"==typeof t&&(t={bind:t,update:t}),this.options[e+"s"][n]=t,t):this.options[e+"s"][n]}}))}(n)}(Pt),Object.defineProperty(Pt.prototype,"$isServer",{get:an}),Object.defineProperty(Pt.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Pt,"FunctionalRenderContext",{value:Me}),Pt.version="2.6.14";var jt=b("style,class"),Rt=b("input,textarea,option,select,progress"),zt=b("contenteditable,draggable,spellcheck"),Mt=b("events,caret,typing,plaintext-only"),Nt=b("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),Ft="http://www.w3.org/1999/xlink",qt=function(n){return":"===n.charAt(5)&&"xlink"===n.slice(0,5)},Ut=function(n){return qt(n)?n.slice(6,n.length):""},Bt=function(n){return null==n||!1===n};function Gt(n){for(var e=n.data,t=n,r=n;s(r.componentInstance);)(r=r.componentInstance._vnode)&&r.data&&(e=Ht(r.data,e));for(;s(t=t.parent);)t&&t.data&&(e=Ht(e,t.data));return function(n,e){if(s(n)||s(e))return Vt(n,$t(e));return""}(e.staticClass,e.class)}function Ht(n,e){return{staticClass:Vt(n.staticClass,e.staticClass),class:s(n.class)?[n.class,e.class]:e.class}}function Vt(n,e){return n?e?n+" "+e:n:e||""}function $t(n){return Array.isArray(n)?function(n){for(var e,t="",r=0,o=n.length;r<o;r++)s(e=$t(n[r]))&&""!==e&&(t&&(t+=" "),t+=e);return t}(n):d(n)?function(n){var e="";for(var t in n)n[t]&&(e&&(e+=" "),e+=t);return e}(n):"string"==typeof n?n:""}var Wt={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},Kt=b("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),Xt=b("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),Qt=function(n){return Kt(n)||Xt(n)};var Yt=Object.create(null);var Zt=b("text,number,password,search,email,tel,url");var Jt=Object.freeze({createElement:function(n,e){var t=document.createElement(n);return"select"!==n||e.data&&e.data.attrs&&void 0!==e.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(n,e){return document.createElementNS(Wt[n],e)},createTextNode:function(n){return document.createTextNode(n)},createComment:function(n){return document.createComment(n)},insertBefore:function(n,e,t){n.insertBefore(e,t)},removeChild:function(n,e){n.removeChild(e)},appendChild:function(n,e){n.appendChild(e)},parentNode:function(n){return n.parentNode},nextSibling:function(n){return n.nextSibling},tagName:function(n){return n.tagName},setTextContent:function(n,e){n.textContent=e},setStyleScope:function(n,e){n.setAttribute(e,"")}}),nr={create:function(n,e){er(e)},update:function(n,e){n.data.ref!==e.data.ref&&(er(n,!0),er(e))},destroy:function(n){er(n,!0)}};function er(n,e){var t=n.data.ref;if(s(t)){var r=n.context,o=n.componentInstance||n.elm,a=r.$refs;e?Array.isArray(a[t])?x(a[t],o):a[t]===o&&(a[t]=void 0):n.data.refInFor?Array.isArray(a[t])?a[t].indexOf(o)<0&&a[t].push(o):a[t]=[o]:a[t]=o}}var tr=new vn("",{},[]),rr=["create","activate","update","remove","destroy"];function or(n,e){return n.key===e.key&&n.asyncFactory===e.asyncFactory&&(n.tag===e.tag&&n.isComment===e.isComment&&s(n.data)===s(e.data)&&function(n,e){if("input"!==n.tag)return!0;var t,r=s(t=n.data)&&s(t=t.attrs)&&t.type,o=s(t=e.data)&&s(t=t.attrs)&&t.type;return r===o||Zt(r)&&Zt(o)}(n,e)||l(n.isAsyncPlaceholder)&&i(e.asyncFactory.error))}function ar(n,e,t){var r,o,a={};for(r=e;r<=t;++r)s(o=n[r].key)&&(a[o]=r);return a}var ir={create:sr,update:sr,destroy:function(n){sr(n,tr)}};function sr(n,e){(n.data.directives||e.data.directives)&&function(n,e){var t,r,o,a=n===tr,i=e===tr,s=cr(n.data.directives,n.context),l=cr(e.data.directives,e.context),c=[],d=[];for(t in l)r=s[t],o=l[t],r?(o.oldValue=r.value,o.oldArg=r.arg,pr(o,"update",e,n),o.def&&o.def.componentUpdated&&d.push(o)):(pr(o,"bind",e,n),o.def&&o.def.inserted&&c.push(o));if(c.length){var p=function(){for(var t=0;t<c.length;t++)pr(c[t],"inserted",e,n)};a?pe(e,"insert",p):p()}d.length&&pe(e,"postpatch",(function(){for(var t=0;t<d.length;t++)pr(d[t],"componentUpdated",e,n)}));if(!a)for(t in s)l[t]||pr(s[t],"unbind",n,n,i)}(n,e)}var lr=Object.create(null);function cr(n,e){var t,r,o=Object.create(null);if(!n)return o;for(t=0;t<n.length;t++)(r=n[t]).modifiers||(r.modifiers=lr),o[dr(r)]=r,r.def=qn(e.$options,"directives",r.name);return o}function dr(n){return n.rawName||n.name+"."+Object.keys(n.modifiers||{}).join(".")}function pr(n,e,t,r,o){var a=n.def&&n.def[e];if(a)try{a(t.elm,n,t,r,o)}catch(r){$n(r,t.context,"directive "+n.name+" "+e+" hook")}}var ur=[nr,ir];function mr(n,e){var t=e.componentOptions;if(!(s(t)&&!1===t.Ctor.options.inheritAttrs||i(n.data.attrs)&&i(e.data.attrs))){var r,o,a=e.elm,l=n.data.attrs||{},c=e.data.attrs||{};for(r in s(c.__ob__)&&(c=e.data.attrs=D({},c)),c)o=c[r],l[r]!==o&&fr(a,r,o,e.data.pre);for(r in(Y||J)&&c.value!==l.value&&fr(a,"value",c.value),l)i(c[r])&&(qt(r)?a.removeAttributeNS(Ft,Ut(r)):zt(r)||a.removeAttribute(r))}}function fr(n,e,t,r){r||n.tagName.indexOf("-")>-1?hr(n,e,t):Nt(e)?Bt(t)?n.removeAttribute(e):(t="allowfullscreen"===e&&"EMBED"===n.tagName?"true":e,n.setAttribute(e,t)):zt(e)?n.setAttribute(e,function(n,e){return Bt(e)||"false"===e?"false":"contenteditable"===n&&Mt(e)?e:"true"}(e,t)):qt(e)?Bt(t)?n.removeAttributeNS(Ft,Ut(e)):n.setAttributeNS(Ft,e,t):hr(n,e,t)}function hr(n,e,t){if(Bt(t))n.removeAttribute(e);else{if(Y&&!Z&&"TEXTAREA"===n.tagName&&"placeholder"===e&&""!==t&&!n.__ieph){var r=function(e){e.stopImmediatePropagation(),n.removeEventListener("input",r)};n.addEventListener("input",r),n.__ieph=!0}n.setAttribute(e,t)}}var gr={create:mr,update:mr};function vr(n,e){var t=e.elm,r=e.data,o=n.data;if(!(i(r.staticClass)&&i(r.class)&&(i(o)||i(o.staticClass)&&i(o.class)))){var a=Gt(e),l=t._transitionClasses;s(l)&&(a=Vt(a,$t(l))),a!==t._prevClass&&(t.setAttribute("class",a),t._prevClass=a)}}var br,yr={create:vr,update:vr};function xr(n,e,t){var r=br;return function o(){var a=e.apply(null,arguments);null!==a&&wr(n,o,t,r)}}var _r=Yn&&!(en&&Number(en[1])<=53);function kr(n,e,t,r){if(_r){var o=dt,a=e;e=a._wrapper=function(n){if(n.target===n.currentTarget||n.timeStamp>=o||n.timeStamp<=0||n.target.ownerDocument!==document)return a.apply(this,arguments)}}br.addEventListener(n,e,rn?{capture:t,passive:r}:t)}function wr(n,e,t,r){(r||br).removeEventListener(n,e._wrapper||e,t)}function Tr(n,e){if(!i(n.data.on)||!i(e.data.on)){var t=e.data.on||{},r=n.data.on||{};br=e.elm,function(n){if(s(n.__r)){var e=Y?"change":"input";n[e]=[].concat(n.__r,n[e]||[]),delete n.__r}s(n.__c)&&(n.change=[].concat(n.__c,n.change||[]),delete n.__c)}(t),de(t,r,kr,wr,xr,e.context),br=void 0}}var Sr,Pr={create:Tr,update:Tr};function Cr(n,e){if(!i(n.data.domProps)||!i(e.data.domProps)){var t,r,o=e.elm,a=n.data.domProps||{},l=e.data.domProps||{};for(t in s(l.__ob__)&&(l=e.data.domProps=D({},l)),a)t in l||(o[t]="");for(t in l){if(r=l[t],"textContent"===t||"innerHTML"===t){if(e.children&&(e.children.length=0),r===a[t])continue;1===o.childNodes.length&&o.removeChild(o.childNodes[0])}if("value"===t&&"PROGRESS"!==o.tagName){o._value=r;var c=i(r)?"":String(r);Ir(o,c)&&(o.value=c)}else if("innerHTML"===t&&Xt(o.tagName)&&i(o.innerHTML)){(Sr=Sr||document.createElement("div")).innerHTML="<svg>"+r+"</svg>";for(var d=Sr.firstChild;o.firstChild;)o.removeChild(o.firstChild);for(;d.firstChild;)o.appendChild(d.firstChild)}else if(r!==a[t])try{o[t]=r}catch(n){}}}}function Ir(n,e){return!n.composing&&("OPTION"===n.tagName||function(n,e){var t=!0;try{t=document.activeElement!==n}catch(n){}return t&&n.value!==e}(n,e)||function(n,e){var t=n.value,r=n._vModifiers;if(s(r)){if(r.number)return v(t)!==v(e);if(r.trim)return t.trim()!==e.trim()}return t!==e}(n,e))}var Er={create:Cr,update:Cr},Ar=w((function(n){var e={},t=/:(.+)/;return n.split(/;(?![^(]*\))/g).forEach((function(n){if(n){var r=n.split(t);r.length>1&&(e[r[0].trim()]=r[1].trim())}})),e}));function Dr(n){var e=Or(n.style);return n.staticStyle?D(n.staticStyle,e):e}function Or(n){return Array.isArray(n)?O(n):"string"==typeof n?Ar(n):n}var Lr,jr=/^--/,Rr=/\s*!important$/,zr=function(n,e,t){if(jr.test(e))n.style.setProperty(e,t);else if(Rr.test(t))n.style.setProperty(I(e),t.replace(Rr,""),"important");else{var r=Nr(e);if(Array.isArray(t))for(var o=0,a=t.length;o<a;o++)n.style[r]=t[o];else n.style[r]=t}},Mr=["Webkit","Moz","ms"],Nr=w((function(n){if(Lr=Lr||document.createElement("div").style,"filter"!==(n=S(n))&&n in Lr)return n;for(var e=n.charAt(0).toUpperCase()+n.slice(1),t=0;t<Mr.length;t++){var r=Mr[t]+e;if(r in Lr)return r}}));function Fr(n,e){var t=e.data,r=n.data;if(!(i(t.staticStyle)&&i(t.style)&&i(r.staticStyle)&&i(r.style))){var o,a,l=e.elm,c=r.staticStyle,d=r.normalizedStyle||r.style||{},p=c||d,u=Or(e.data.style)||{};e.data.normalizedStyle=s(u.__ob__)?D({},u):u;var m=function(n,e){var t,r={};if(e)for(var o=n;o.componentInstance;)(o=o.componentInstance._vnode)&&o.data&&(t=Dr(o.data))&&D(r,t);(t=Dr(n.data))&&D(r,t);for(var a=n;a=a.parent;)a.data&&(t=Dr(a.data))&&D(r,t);return r}(e,!0);for(a in p)i(m[a])&&zr(l,a,"");for(a in m)(o=m[a])!==p[a]&&zr(l,a,null==o?"":o)}}var qr={create:Fr,update:Fr},Ur=/\s+/;function Br(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(Ur).forEach((function(e){return n.classList.add(e)})):n.classList.add(e);else{var t=" "+(n.getAttribute("class")||"")+" ";t.indexOf(" "+e+" ")<0&&n.setAttribute("class",(t+e).trim())}}function Gr(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(Ur).forEach((function(e){return n.classList.remove(e)})):n.classList.remove(e),n.classList.length||n.removeAttribute("class");else{for(var t=" "+(n.getAttribute("class")||"")+" ",r=" "+e+" ";t.indexOf(r)>=0;)t=t.replace(r," ");(t=t.trim())?n.setAttribute("class",t):n.removeAttribute("class")}}function Hr(n){if(n){if("object"==typeof n){var e={};return!1!==n.css&&D(e,Vr(n.name||"v")),D(e,n),e}return"string"==typeof n?Vr(n):void 0}}var Vr=w((function(n){return{enterClass:n+"-enter",enterToClass:n+"-enter-to",enterActiveClass:n+"-enter-active",leaveClass:n+"-leave",leaveToClass:n+"-leave-to",leaveActiveClass:n+"-leave-active"}})),$r=W&&!Z,Wr="transition",Kr="transitionend",Xr="animation",Qr="animationend";$r&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(Wr="WebkitTransition",Kr="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(Xr="WebkitAnimation",Qr="webkitAnimationEnd"));var Yr=W?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(n){return n()};function Zr(n){Yr((function(){Yr(n)}))}function Jr(n,e){var t=n._transitionClasses||(n._transitionClasses=[]);t.indexOf(e)<0&&(t.push(e),Br(n,e))}function no(n,e){n._transitionClasses&&x(n._transitionClasses,e),Gr(n,e)}function eo(n,e,t){var r=ro(n,e),o=r.type,a=r.timeout,i=r.propCount;if(!o)return t();var s="transition"===o?Kr:Qr,l=0,c=function(){n.removeEventListener(s,d),t()},d=function(e){e.target===n&&++l>=i&&c()};setTimeout((function(){l<i&&c()}),a+1),n.addEventListener(s,d)}var to=/\b(transform|all)(,|$)/;function ro(n,e){var t,r=window.getComputedStyle(n),o=(r[Wr+"Delay"]||"").split(", "),a=(r[Wr+"Duration"]||"").split(", "),i=oo(o,a),s=(r[Xr+"Delay"]||"").split(", "),l=(r[Xr+"Duration"]||"").split(", "),c=oo(s,l),d=0,p=0;return"transition"===e?i>0&&(t="transition",d=i,p=a.length):"animation"===e?c>0&&(t="animation",d=c,p=l.length):p=(t=(d=Math.max(i,c))>0?i>c?"transition":"animation":null)?"transition"===t?a.length:l.length:0,{type:t,timeout:d,propCount:p,hasTransform:"transition"===t&&to.test(r[Wr+"Property"])}}function oo(n,e){for(;n.length<e.length;)n=n.concat(n);return Math.max.apply(null,e.map((function(e,t){return ao(e)+ao(n[t])})))}function ao(n){return 1e3*Number(n.slice(0,-1).replace(",","."))}function io(n,e){var t=n.elm;s(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var r=Hr(n.data.transition);if(!i(r)&&!s(t._enterCb)&&1===t.nodeType){for(var o=r.css,a=r.type,l=r.enterClass,c=r.enterToClass,p=r.enterActiveClass,u=r.appearClass,m=r.appearToClass,f=r.appearActiveClass,h=r.beforeEnter,g=r.enter,b=r.afterEnter,y=r.enterCancelled,x=r.beforeAppear,_=r.appear,k=r.afterAppear,w=r.appearCancelled,T=r.duration,S=Je,P=Je.$vnode;P&&P.parent;)S=P.context,P=P.parent;var C=!S._isMounted||!n.isRootInsert;if(!C||_||""===_){var I=C&&u?u:l,E=C&&f?f:p,A=C&&m?m:c,D=C&&x||h,O=C&&"function"==typeof _?_:g,L=C&&k||b,j=C&&w||y,R=v(d(T)?T.enter:T);0;var z=!1!==o&&!Z,M=co(O),F=t._enterCb=N((function(){z&&(no(t,A),no(t,E)),F.cancelled?(z&&no(t,I),j&&j(t)):L&&L(t),t._enterCb=null}));n.data.show||pe(n,"insert",(function(){var e=t.parentNode,r=e&&e._pending&&e._pending[n.key];r&&r.tag===n.tag&&r.elm._leaveCb&&r.elm._leaveCb(),O&&O(t,F)})),D&&D(t),z&&(Jr(t,I),Jr(t,E),Zr((function(){no(t,I),F.cancelled||(Jr(t,A),M||(lo(R)?setTimeout(F,R):eo(t,a,F)))}))),n.data.show&&(e&&e(),O&&O(t,F)),z||M||F()}}}function so(n,e){var t=n.elm;s(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var r=Hr(n.data.transition);if(i(r)||1!==t.nodeType)return e();if(!s(t._leaveCb)){var o=r.css,a=r.type,l=r.leaveClass,c=r.leaveToClass,p=r.leaveActiveClass,u=r.beforeLeave,m=r.leave,f=r.afterLeave,h=r.leaveCancelled,g=r.delayLeave,b=r.duration,y=!1!==o&&!Z,x=co(m),_=v(d(b)?b.leave:b);0;var k=t._leaveCb=N((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[n.key]=null),y&&(no(t,c),no(t,p)),k.cancelled?(y&&no(t,l),h&&h(t)):(e(),f&&f(t)),t._leaveCb=null}));g?g(w):w()}function w(){k.cancelled||(!n.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[n.key]=n),u&&u(t),y&&(Jr(t,l),Jr(t,p),Zr((function(){no(t,l),k.cancelled||(Jr(t,c),x||(lo(_)?setTimeout(k,_):eo(t,a,k)))}))),m&&m(t,k),y||x||k())}}function lo(n){return"number"==typeof n&&!isNaN(n)}function co(n){if(i(n))return!1;var e=n.fns;return s(e)?co(Array.isArray(e)?e[0]:e):(n._length||n.length)>1}function po(n,e){!0!==e.data.show&&io(e)}var uo=function(n){var e,t,r={},o=n.modules,a=n.nodeOps;for(e=0;e<rr.length;++e)for(r[rr[e]]=[],t=0;t<o.length;++t)s(o[t][rr[e]])&&r[rr[e]].push(o[t][rr[e]]);function d(n){var e=a.parentNode(n);s(e)&&a.removeChild(e,n)}function p(n,e,t,o,i,c,d){if(s(n.elm)&&s(c)&&(n=c[d]=_n(n)),n.isRootInsert=!i,!function(n,e,t,o){var a=n.data;if(s(a)){var i=s(n.componentInstance)&&a.keepAlive;if(s(a=a.hook)&&s(a=a.init)&&a(n,!1),s(n.componentInstance))return u(n,e),m(t,n.elm,o),l(i)&&function(n,e,t,o){var a,i=n;for(;i.componentInstance;)if(i=i.componentInstance._vnode,s(a=i.data)&&s(a=a.transition)){for(a=0;a<r.activate.length;++a)r.activate[a](tr,i);e.push(i);break}m(t,n.elm,o)}(n,e,t,o),!0}}(n,e,t,o)){var p=n.data,h=n.children,b=n.tag;s(b)?(n.elm=n.ns?a.createElementNS(n.ns,b):a.createElement(b,n),v(n),f(n,h,e),s(p)&&g(n,e),m(t,n.elm,o)):l(n.isComment)?(n.elm=a.createComment(n.text),m(t,n.elm,o)):(n.elm=a.createTextNode(n.text),m(t,n.elm,o))}}function u(n,e){s(n.data.pendingInsert)&&(e.push.apply(e,n.data.pendingInsert),n.data.pendingInsert=null),n.elm=n.componentInstance.$el,h(n)?(g(n,e),v(n)):(er(n),e.push(n))}function m(n,e,t){s(n)&&(s(t)?a.parentNode(t)===n&&a.insertBefore(n,e,t):a.appendChild(n,e))}function f(n,e,t){if(Array.isArray(e)){0;for(var r=0;r<e.length;++r)p(e[r],t,n.elm,null,!0,e,r)}else c(n.text)&&a.appendChild(n.elm,a.createTextNode(String(n.text)))}function h(n){for(;n.componentInstance;)n=n.componentInstance._vnode;return s(n.tag)}function g(n,t){for(var o=0;o<r.create.length;++o)r.create[o](tr,n);s(e=n.data.hook)&&(s(e.create)&&e.create(tr,n),s(e.insert)&&t.push(n))}function v(n){var e;if(s(e=n.fnScopeId))a.setStyleScope(n.elm,e);else for(var t=n;t;)s(e=t.context)&&s(e=e.$options._scopeId)&&a.setStyleScope(n.elm,e),t=t.parent;s(e=Je)&&e!==n.context&&e!==n.fnContext&&s(e=e.$options._scopeId)&&a.setStyleScope(n.elm,e)}function y(n,e,t,r,o,a){for(;r<=o;++r)p(t[r],a,n,e,!1,t,r)}function x(n){var e,t,o=n.data;if(s(o))for(s(e=o.hook)&&s(e=e.destroy)&&e(n),e=0;e<r.destroy.length;++e)r.destroy[e](n);if(s(e=n.children))for(t=0;t<n.children.length;++t)x(n.children[t])}function _(n,e,t){for(;e<=t;++e){var r=n[e];s(r)&&(s(r.tag)?(k(r),x(r)):d(r.elm))}}function k(n,e){if(s(e)||s(n.data)){var t,o=r.remove.length+1;for(s(e)?e.listeners+=o:e=function(n,e){function t(){0==--t.listeners&&d(n)}return t.listeners=e,t}(n.elm,o),s(t=n.componentInstance)&&s(t=t._vnode)&&s(t.data)&&k(t,e),t=0;t<r.remove.length;++t)r.remove[t](n,e);s(t=n.data.hook)&&s(t=t.remove)?t(n,e):e()}else d(n.elm)}function w(n,e,t,r){for(var o=t;o<r;o++){var a=e[o];if(s(a)&&or(n,a))return o}}function T(n,e,t,o,c,d){if(n!==e){s(e.elm)&&s(o)&&(e=o[c]=_n(e));var u=e.elm=n.elm;if(l(n.isAsyncPlaceholder))s(e.asyncFactory.resolved)?C(n.elm,e,t):e.isAsyncPlaceholder=!0;else if(l(e.isStatic)&&l(n.isStatic)&&e.key===n.key&&(l(e.isCloned)||l(e.isOnce)))e.componentInstance=n.componentInstance;else{var m,f=e.data;s(f)&&s(m=f.hook)&&s(m=m.prepatch)&&m(n,e);var g=n.children,v=e.children;if(s(f)&&h(e)){for(m=0;m<r.update.length;++m)r.update[m](n,e);s(m=f.hook)&&s(m=m.update)&&m(n,e)}i(e.text)?s(g)&&s(v)?g!==v&&function(n,e,t,r,o){var l,c,d,u=0,m=0,f=e.length-1,h=e[0],g=e[f],v=t.length-1,b=t[0],x=t[v],k=!o;for(0;u<=f&&m<=v;)i(h)?h=e[++u]:i(g)?g=e[--f]:or(h,b)?(T(h,b,r,t,m),h=e[++u],b=t[++m]):or(g,x)?(T(g,x,r,t,v),g=e[--f],x=t[--v]):or(h,x)?(T(h,x,r,t,v),k&&a.insertBefore(n,h.elm,a.nextSibling(g.elm)),h=e[++u],x=t[--v]):or(g,b)?(T(g,b,r,t,m),k&&a.insertBefore(n,g.elm,h.elm),g=e[--f],b=t[++m]):(i(l)&&(l=ar(e,u,f)),i(c=s(b.key)?l[b.key]:w(b,e,u,f))?p(b,r,n,h.elm,!1,t,m):or(d=e[c],b)?(T(d,b,r,t,m),e[c]=void 0,k&&a.insertBefore(n,d.elm,h.elm)):p(b,r,n,h.elm,!1,t,m),b=t[++m]);u>f?y(n,i(t[v+1])?null:t[v+1].elm,t,m,v,r):m>v&&_(e,u,f)}(u,g,v,t,d):s(v)?(s(n.text)&&a.setTextContent(u,""),y(u,null,v,0,v.length-1,t)):s(g)?_(g,0,g.length-1):s(n.text)&&a.setTextContent(u,""):n.text!==e.text&&a.setTextContent(u,e.text),s(f)&&s(m=f.hook)&&s(m=m.postpatch)&&m(n,e)}}}function S(n,e,t){if(l(t)&&s(n.parent))n.parent.data.pendingInsert=e;else for(var r=0;r<e.length;++r)e[r].data.hook.insert(e[r])}var P=b("attrs,class,staticClass,staticStyle,key");function C(n,e,t,r){var o,a=e.tag,i=e.data,c=e.children;if(r=r||i&&i.pre,e.elm=n,l(e.isComment)&&s(e.asyncFactory))return e.isAsyncPlaceholder=!0,!0;if(s(i)&&(s(o=i.hook)&&s(o=o.init)&&o(e,!0),s(o=e.componentInstance)))return u(e,t),!0;if(s(a)){if(s(c))if(n.hasChildNodes())if(s(o=i)&&s(o=o.domProps)&&s(o=o.innerHTML)){if(o!==n.innerHTML)return!1}else{for(var d=!0,p=n.firstChild,m=0;m<c.length;m++){if(!p||!C(p,c[m],t,r)){d=!1;break}p=p.nextSibling}if(!d||p)return!1}else f(e,c,t);if(s(i)){var h=!1;for(var v in i)if(!P(v)){h=!0,g(e,t);break}!h&&i.class&&se(i.class)}}else n.data!==e.text&&(n.data=e.text);return!0}return function(n,e,t,o){if(!i(e)){var c,d=!1,u=[];if(i(n))d=!0,p(e,u);else{var m=s(n.nodeType);if(!m&&or(n,e))T(n,e,u,null,null,o);else{if(m){if(1===n.nodeType&&n.hasAttribute("data-server-rendered")&&(n.removeAttribute("data-server-rendered"),t=!0),l(t)&&C(n,e,u))return S(e,u,!0),n;c=n,n=new vn(a.tagName(c).toLowerCase(),{},[],void 0,c)}var f=n.elm,g=a.parentNode(f);if(p(e,u,f._leaveCb?null:g,a.nextSibling(f)),s(e.parent))for(var v=e.parent,b=h(e);v;){for(var y=0;y<r.destroy.length;++y)r.destroy[y](v);if(v.elm=e.elm,b){for(var k=0;k<r.create.length;++k)r.create[k](tr,v);var w=v.data.hook.insert;if(w.merged)for(var P=1;P<w.fns.length;P++)w.fns[P]()}else er(v);v=v.parent}s(g)?_([n],0,0):s(n.tag)&&x(n)}}return S(e,u,d),e.elm}s(n)&&x(n)}}({nodeOps:Jt,modules:[gr,yr,Pr,Er,qr,W?{create:po,activate:po,remove:function(n,e){!0!==n.data.show?so(n,e):e()}}:{}].concat(ur)});Z&&document.addEventListener("selectionchange",(function(){var n=document.activeElement;n&&n.vmodel&&xo(n,"input")}));var mo={inserted:function(n,e,t,r){"select"===t.tag?(r.elm&&!r.elm._vOptions?pe(t,"postpatch",(function(){mo.componentUpdated(n,e,t)})):fo(n,e,t.context),n._vOptions=[].map.call(n.options,vo)):("textarea"===t.tag||Zt(n.type))&&(n._vModifiers=e.modifiers,e.modifiers.lazy||(n.addEventListener("compositionstart",bo),n.addEventListener("compositionend",yo),n.addEventListener("change",yo),Z&&(n.vmodel=!0)))},componentUpdated:function(n,e,t){if("select"===t.tag){fo(n,e,t.context);var r=n._vOptions,o=n._vOptions=[].map.call(n.options,vo);if(o.some((function(n,e){return!z(n,r[e])})))(n.multiple?e.value.some((function(n){return go(n,o)})):e.value!==e.oldValue&&go(e.value,o))&&xo(n,"change")}}};function fo(n,e,t){ho(n,e,t),(Y||J)&&setTimeout((function(){ho(n,e,t)}),0)}function ho(n,e,t){var r=e.value,o=n.multiple;if(!o||Array.isArray(r)){for(var a,i,s=0,l=n.options.length;s<l;s++)if(i=n.options[s],o)a=M(r,vo(i))>-1,i.selected!==a&&(i.selected=a);else if(z(vo(i),r))return void(n.selectedIndex!==s&&(n.selectedIndex=s));o||(n.selectedIndex=-1)}}function go(n,e){return e.every((function(e){return!z(e,n)}))}function vo(n){return"_value"in n?n._value:n.value}function bo(n){n.target.composing=!0}function yo(n){n.target.composing&&(n.target.composing=!1,xo(n.target,"input"))}function xo(n,e){var t=document.createEvent("HTMLEvents");t.initEvent(e,!0,!0),n.dispatchEvent(t)}function _o(n){return!n.componentInstance||n.data&&n.data.transition?n:_o(n.componentInstance._vnode)}var ko={model:mo,show:{bind:function(n,e,t){var r=e.value,o=(t=_o(t)).data&&t.data.transition,a=n.__vOriginalDisplay="none"===n.style.display?"":n.style.display;r&&o?(t.data.show=!0,io(t,(function(){n.style.display=a}))):n.style.display=r?a:"none"},update:function(n,e,t){var r=e.value;!r!=!e.oldValue&&((t=_o(t)).data&&t.data.transition?(t.data.show=!0,r?io(t,(function(){n.style.display=n.__vOriginalDisplay})):so(t,(function(){n.style.display="none"}))):n.style.display=r?n.__vOriginalDisplay:"none")},unbind:function(n,e,t,r,o){o||(n.style.display=n.__vOriginalDisplay)}}},wo={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function To(n){var e=n&&n.componentOptions;return e&&e.Ctor.options.abstract?To(Ke(e.children)):n}function So(n){var e={},t=n.$options;for(var r in t.propsData)e[r]=n[r];var o=t._parentListeners;for(var a in o)e[S(a)]=o[a];return e}function Po(n,e){if(/\d-keep-alive$/.test(e.tag))return n("keep-alive",{props:e.componentOptions.propsData})}var Co=function(n){return n.tag||be(n)},Io=function(n){return"show"===n.name},Eo={name:"transition",props:wo,abstract:!0,render:function(n){var e=this,t=this.$slots.default;if(t&&(t=t.filter(Co)).length){0;var r=this.mode;0;var o=t[0];if(function(n){for(;n=n.parent;)if(n.data.transition)return!0}(this.$vnode))return o;var a=To(o);if(!a)return o;if(this._leaving)return Po(n,o);var i="__transition-"+this._uid+"-";a.key=null==a.key?a.isComment?i+"comment":i+a.tag:c(a.key)?0===String(a.key).indexOf(i)?a.key:i+a.key:a.key;var s=(a.data||(a.data={})).transition=So(this),l=this._vnode,d=To(l);if(a.data.directives&&a.data.directives.some(Io)&&(a.data.show=!0),d&&d.data&&!function(n,e){return e.key===n.key&&e.tag===n.tag}(a,d)&&!be(d)&&(!d.componentInstance||!d.componentInstance._vnode.isComment)){var p=d.data.transition=D({},s);if("out-in"===r)return this._leaving=!0,pe(p,"afterLeave",(function(){e._leaving=!1,e.$forceUpdate()})),Po(n,o);if("in-out"===r){if(be(a))return l;var u,m=function(){u()};pe(s,"afterEnter",m),pe(s,"enterCancelled",m),pe(p,"delayLeave",(function(n){u=n}))}}return o}}},Ao=D({tag:String,moveClass:String},wo);function Do(n){n.elm._moveCb&&n.elm._moveCb(),n.elm._enterCb&&n.elm._enterCb()}function Oo(n){n.data.newPos=n.elm.getBoundingClientRect()}function Lo(n){var e=n.data.pos,t=n.data.newPos,r=e.left-t.left,o=e.top-t.top;if(r||o){n.data.moved=!0;var a=n.elm.style;a.transform=a.WebkitTransform="translate("+r+"px,"+o+"px)",a.transitionDuration="0s"}}delete Ao.mode;var jo={Transition:Eo,TransitionGroup:{props:Ao,beforeMount:function(){var n=this,e=this._update;this._update=function(t,r){var o=nt(n);n.__patch__(n._vnode,n.kept,!1,!0),n._vnode=n.kept,o(),e.call(n,t,r)}},render:function(n){for(var e=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),r=this.prevChildren=this.children,o=this.$slots.default||[],a=this.children=[],i=So(this),s=0;s<o.length;s++){var l=o[s];if(l.tag)if(null!=l.key&&0!==String(l.key).indexOf("__vlist"))a.push(l),t[l.key]=l,(l.data||(l.data={})).transition=i;else;}if(r){for(var c=[],d=[],p=0;p<r.length;p++){var u=r[p];u.data.transition=i,u.data.pos=u.elm.getBoundingClientRect(),t[u.key]?c.push(u):d.push(u)}this.kept=n(e,null,c),this.removed=d}return n(e,null,a)},updated:function(){var n=this.prevChildren,e=this.moveClass||(this.name||"v")+"-move";n.length&&this.hasMove(n[0].elm,e)&&(n.forEach(Do),n.forEach(Oo),n.forEach(Lo),this._reflow=document.body.offsetHeight,n.forEach((function(n){if(n.data.moved){var t=n.elm,r=t.style;Jr(t,e),r.transform=r.WebkitTransform=r.transitionDuration="",t.addEventListener(Kr,t._moveCb=function n(r){r&&r.target!==t||r&&!/transform$/.test(r.propertyName)||(t.removeEventListener(Kr,n),t._moveCb=null,no(t,e))})}})))},methods:{hasMove:function(n,e){if(!$r)return!1;if(this._hasMove)return this._hasMove;var t=n.cloneNode();n._transitionClasses&&n._transitionClasses.forEach((function(n){Gr(t,n)})),Br(t,e),t.style.display="none",this.$el.appendChild(t);var r=ro(t);return this.$el.removeChild(t),this._hasMove=r.hasTransform}}}};Pt.config.mustUseProp=function(n,e,t){return"value"===t&&Rt(n)&&"button"!==e||"selected"===t&&"option"===n||"checked"===t&&"input"===n||"muted"===t&&"video"===n},Pt.config.isReservedTag=Qt,Pt.config.isReservedAttr=jt,Pt.config.getTagNamespace=function(n){return Xt(n)?"svg":"math"===n?"math":void 0},Pt.config.isUnknownElement=function(n){if(!W)return!0;if(Qt(n))return!1;if(n=n.toLowerCase(),null!=Yt[n])return Yt[n];var e=document.createElement(n);return n.indexOf("-")>-1?Yt[n]=e.constructor===window.HTMLUnknownElement||e.constructor===window.HTMLElement:Yt[n]=/HTMLUnknownElement/.test(e.toString())},D(Pt.options.directives,ko),D(Pt.options.components,jo),Pt.prototype.__patch__=W?uo:L,Pt.prototype.$mount=function(n,e){return function(n,e,t){var r;return n.$el=e,n.$options.render||(n.$options.render=yn),rt(n,"beforeMount"),r=function(){n._update(n._render(),t)},new ht(n,r,L,{before:function(){n._isMounted&&!n._isDestroyed&&rt(n,"beforeUpdate")}},!0),t=!1,null==n.$vnode&&(n._isMounted=!0,rt(n,"mounted")),n}(this,n=n&&W?function(n){if("string"==typeof n){var e=document.querySelector(n);return e||document.createElement("div")}return n}(n):void 0,e)},W&&setTimeout((function(){U.devtools&&sn&&sn.emit("init",Pt)}),0);var Ro=Pt;
/*!
  * vue-router v3.5.3
  * (c) 2021 Evan You
  * @license MIT
  */function zo(n,e){for(var t in e)n[t]=e[t];return n}var Mo=/[!'()*]/g,No=function(n){return"%"+n.charCodeAt(0).toString(16)},Fo=/%2C/g,qo=function(n){return encodeURIComponent(n).replace(Mo,No).replace(Fo,",")};function Uo(n){try{return decodeURIComponent(n)}catch(n){0}return n}var Bo=function(n){return null==n||"object"==typeof n?n:String(n)};function Go(n){var e={};return(n=n.trim().replace(/^(\?|#|&)/,""))?(n.split("&").forEach((function(n){var t=n.replace(/\+/g," ").split("="),r=Uo(t.shift()),o=t.length>0?Uo(t.join("=")):null;void 0===e[r]?e[r]=o:Array.isArray(e[r])?e[r].push(o):e[r]=[e[r],o]})),e):e}function Ho(n){var e=n?Object.keys(n).map((function(e){var t=n[e];if(void 0===t)return"";if(null===t)return qo(e);if(Array.isArray(t)){var r=[];return t.forEach((function(n){void 0!==n&&(null===n?r.push(qo(e)):r.push(qo(e)+"="+qo(n)))})),r.join("&")}return qo(e)+"="+qo(t)})).filter((function(n){return n.length>0})).join("&"):null;return e?"?"+e:""}var Vo=/\/?$/;function $o(n,e,t,r){var o=r&&r.options.stringifyQuery,a=e.query||{};try{a=Wo(a)}catch(n){}var i={name:e.name||n&&n.name,meta:n&&n.meta||{},path:e.path||"/",hash:e.hash||"",query:a,params:e.params||{},fullPath:Qo(e,o),matched:n?Xo(n):[]};return t&&(i.redirectedFrom=Qo(t,o)),Object.freeze(i)}function Wo(n){if(Array.isArray(n))return n.map(Wo);if(n&&"object"==typeof n){var e={};for(var t in n)e[t]=Wo(n[t]);return e}return n}var Ko=$o(null,{path:"/"});function Xo(n){for(var e=[];n;)e.unshift(n),n=n.parent;return e}function Qo(n,e){var t=n.path,r=n.query;void 0===r&&(r={});var o=n.hash;return void 0===o&&(o=""),(t||"/")+(e||Ho)(r)+o}function Yo(n,e,t){return e===Ko?n===e:!!e&&(n.path&&e.path?n.path.replace(Vo,"")===e.path.replace(Vo,"")&&(t||n.hash===e.hash&&Zo(n.query,e.query)):!(!n.name||!e.name)&&(n.name===e.name&&(t||n.hash===e.hash&&Zo(n.query,e.query)&&Zo(n.params,e.params))))}function Zo(n,e){if(void 0===n&&(n={}),void 0===e&&(e={}),!n||!e)return n===e;var t=Object.keys(n).sort(),r=Object.keys(e).sort();return t.length===r.length&&t.every((function(t,o){var a=n[t];if(r[o]!==t)return!1;var i=e[t];return null==a||null==i?a===i:"object"==typeof a&&"object"==typeof i?Zo(a,i):String(a)===String(i)}))}function Jo(n){for(var e=0;e<n.matched.length;e++){var t=n.matched[e];for(var r in t.instances){var o=t.instances[r],a=t.enteredCbs[r];if(o&&a){delete t.enteredCbs[r];for(var i=0;i<a.length;i++)o._isBeingDestroyed||a[i](o)}}}}var na={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(n,e){var t=e.props,r=e.children,o=e.parent,a=e.data;a.routerView=!0;for(var i=o.$createElement,s=t.name,l=o.$route,c=o._routerViewCache||(o._routerViewCache={}),d=0,p=!1;o&&o._routerRoot!==o;){var u=o.$vnode?o.$vnode.data:{};u.routerView&&d++,u.keepAlive&&o._directInactive&&o._inactive&&(p=!0),o=o.$parent}if(a.routerViewDepth=d,p){var m=c[s],f=m&&m.component;return f?(m.configProps&&ea(f,a,m.route,m.configProps),i(f,a,r)):i()}var h=l.matched[d],g=h&&h.components[s];if(!h||!g)return c[s]=null,i();c[s]={component:g},a.registerRouteInstance=function(n,e){var t=h.instances[s];(e&&t!==n||!e&&t===n)&&(h.instances[s]=e)},(a.hook||(a.hook={})).prepatch=function(n,e){h.instances[s]=e.componentInstance},a.hook.init=function(n){n.data.keepAlive&&n.componentInstance&&n.componentInstance!==h.instances[s]&&(h.instances[s]=n.componentInstance),Jo(l)};var v=h.props&&h.props[s];return v&&(zo(c[s],{route:l,configProps:v}),ea(g,a,l,v)),i(g,a,r)}};function ea(n,e,t,r){var o=e.props=function(n,e){switch(typeof e){case"undefined":return;case"object":return e;case"function":return e(n);case"boolean":return e?n.params:void 0;default:0}}(t,r);if(o){o=e.props=zo({},o);var a=e.attrs=e.attrs||{};for(var i in o)n.props&&i in n.props||(a[i]=o[i],delete o[i])}}function ta(n,e,t){var r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;var o=e.split("/");t&&o[o.length-1]||o.pop();for(var a=n.replace(/^\//,"").split("/"),i=0;i<a.length;i++){var s=a[i];".."===s?o.pop():"."!==s&&o.push(s)}return""!==o[0]&&o.unshift(""),o.join("/")}function ra(n){return n.replace(/\/+/g,"/")}var oa=Array.isArray||function(n){return"[object Array]"==Object.prototype.toString.call(n)},aa=ya,ia=pa,sa=function(n,e){return ma(pa(n,e),e)},la=ma,ca=ba,da=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function pa(n,e){for(var t,r=[],o=0,a=0,i="",s=e&&e.delimiter||"/";null!=(t=da.exec(n));){var l=t[0],c=t[1],d=t.index;if(i+=n.slice(a,d),a=d+l.length,c)i+=c[1];else{var p=n[a],u=t[2],m=t[3],f=t[4],h=t[5],g=t[6],v=t[7];i&&(r.push(i),i="");var b=null!=u&&null!=p&&p!==u,y="+"===g||"*"===g,x="?"===g||"*"===g,_=t[2]||s,k=f||h;r.push({name:m||o++,prefix:u||"",delimiter:_,optional:x,repeat:y,partial:b,asterisk:!!v,pattern:k?ha(k):v?".*":"[^"+fa(_)+"]+?"})}}return a<n.length&&(i+=n.substr(a)),i&&r.push(i),r}function ua(n){return encodeURI(n).replace(/[\/?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()}))}function ma(n,e){for(var t=new Array(n.length),r=0;r<n.length;r++)"object"==typeof n[r]&&(t[r]=new RegExp("^(?:"+n[r].pattern+")$",va(e)));return function(e,r){for(var o="",a=e||{},i=(r||{}).pretty?ua:encodeURIComponent,s=0;s<n.length;s++){var l=n[s];if("string"!=typeof l){var c,d=a[l.name];if(null==d){if(l.optional){l.partial&&(o+=l.prefix);continue}throw new TypeError('Expected "'+l.name+'" to be defined')}if(oa(d)){if(!l.repeat)throw new TypeError('Expected "'+l.name+'" to not repeat, but received `'+JSON.stringify(d)+"`");if(0===d.length){if(l.optional)continue;throw new TypeError('Expected "'+l.name+'" to not be empty')}for(var p=0;p<d.length;p++){if(c=i(d[p]),!t[s].test(c))throw new TypeError('Expected all "'+l.name+'" to match "'+l.pattern+'", but received `'+JSON.stringify(c)+"`");o+=(0===p?l.prefix:l.delimiter)+c}}else{if(c=l.asterisk?encodeURI(d).replace(/[?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()})):i(d),!t[s].test(c))throw new TypeError('Expected "'+l.name+'" to match "'+l.pattern+'", but received "'+c+'"');o+=l.prefix+c}}else o+=l}return o}}function fa(n){return n.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function ha(n){return n.replace(/([=!:$\/()])/g,"\\$1")}function ga(n,e){return n.keys=e,n}function va(n){return n&&n.sensitive?"":"i"}function ba(n,e,t){oa(e)||(t=e||t,e=[]);for(var r=(t=t||{}).strict,o=!1!==t.end,a="",i=0;i<n.length;i++){var s=n[i];if("string"==typeof s)a+=fa(s);else{var l=fa(s.prefix),c="(?:"+s.pattern+")";e.push(s),s.repeat&&(c+="(?:"+l+c+")*"),a+=c=s.optional?s.partial?l+"("+c+")?":"(?:"+l+"("+c+"))?":l+"("+c+")"}}var d=fa(t.delimiter||"/"),p=a.slice(-d.length)===d;return r||(a=(p?a.slice(0,-d.length):a)+"(?:"+d+"(?=$))?"),a+=o?"$":r&&p?"":"(?="+d+"|$)",ga(new RegExp("^"+a,va(t)),e)}function ya(n,e,t){return oa(e)||(t=e||t,e=[]),t=t||{},n instanceof RegExp?function(n,e){var t=n.source.match(/\((?!\?)/g);if(t)for(var r=0;r<t.length;r++)e.push({name:r,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return ga(n,e)}(n,e):oa(n)?function(n,e,t){for(var r=[],o=0;o<n.length;o++)r.push(ya(n[o],e,t).source);return ga(new RegExp("(?:"+r.join("|")+")",va(t)),e)}(n,e,t):function(n,e,t){return ba(pa(n,t),e,t)}(n,e,t)}aa.parse=ia,aa.compile=sa,aa.tokensToFunction=la,aa.tokensToRegExp=ca;var xa=Object.create(null);function _a(n,e,t){e=e||{};try{var r=xa[n]||(xa[n]=aa.compile(n));return"string"==typeof e.pathMatch&&(e[0]=e.pathMatch),r(e,{pretty:!0})}catch(n){return""}finally{delete e[0]}}function ka(n,e,t,r){var o="string"==typeof n?{path:n}:n;if(o._normalized)return o;if(o.name){var a=(o=zo({},n)).params;return a&&"object"==typeof a&&(o.params=zo({},a)),o}if(!o.path&&o.params&&e){(o=zo({},o))._normalized=!0;var i=zo(zo({},e.params),o.params);if(e.name)o.name=e.name,o.params=i;else if(e.matched.length){var s=e.matched[e.matched.length-1].path;o.path=_a(s,i,e.path)}else 0;return o}var l=function(n){var e="",t="",r=n.indexOf("#");r>=0&&(e=n.slice(r),n=n.slice(0,r));var o=n.indexOf("?");return o>=0&&(t=n.slice(o+1),n=n.slice(0,o)),{path:n,query:t,hash:e}}(o.path||""),c=e&&e.path||"/",d=l.path?ta(l.path,c,t||o.append):c,p=function(n,e,t){void 0===e&&(e={});var r,o=t||Go;try{r=o(n||"")}catch(n){r={}}for(var a in e){var i=e[a];r[a]=Array.isArray(i)?i.map(Bo):Bo(i)}return r}(l.query,o.query,r&&r.options.parseQuery),u=o.hash||l.hash;return u&&"#"!==u.charAt(0)&&(u="#"+u),{_normalized:!0,path:d,query:p,hash:u}}var wa,Ta=function(){},Sa={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(n){var e=this,t=this.$router,r=this.$route,o=t.resolve(this.to,r,this.append),a=o.location,i=o.route,s=o.href,l={},c=t.options.linkActiveClass,d=t.options.linkExactActiveClass,p=null==c?"router-link-active":c,u=null==d?"router-link-exact-active":d,m=null==this.activeClass?p:this.activeClass,f=null==this.exactActiveClass?u:this.exactActiveClass,h=i.redirectedFrom?$o(null,ka(i.redirectedFrom),null,t):i;l[f]=Yo(r,h,this.exactPath),l[m]=this.exact||this.exactPath?l[f]:function(n,e){return 0===n.path.replace(Vo,"/").indexOf(e.path.replace(Vo,"/"))&&(!e.hash||n.hash===e.hash)&&function(n,e){for(var t in e)if(!(t in n))return!1;return!0}(n.query,e.query)}(r,h);var g=l[f]?this.ariaCurrentValue:null,v=function(n){Pa(n)&&(e.replace?t.replace(a,Ta):t.push(a,Ta))},b={click:Pa};Array.isArray(this.event)?this.event.forEach((function(n){b[n]=v})):b[this.event]=v;var y={class:l},x=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:s,route:i,navigate:v,isActive:l[m],isExactActive:l[f]});if(x){if(1===x.length)return x[0];if(x.length>1||!x.length)return 0===x.length?n():n("span",{},x)}if("a"===this.tag)y.on=b,y.attrs={href:s,"aria-current":g};else{var _=function n(e){var t;if(e)for(var r=0;r<e.length;r++){if("a"===(t=e[r]).tag)return t;if(t.children&&(t=n(t.children)))return t}}(this.$slots.default);if(_){_.isStatic=!1;var k=_.data=zo({},_.data);for(var w in k.on=k.on||{},k.on){var T=k.on[w];w in b&&(k.on[w]=Array.isArray(T)?T:[T])}for(var S in b)S in k.on?k.on[S].push(b[S]):k.on[S]=v;var P=_.data.attrs=zo({},_.data.attrs);P.href=s,P["aria-current"]=g}else y.on=b}return n(this.tag,y,this.$slots.default)}};function Pa(n){if(!(n.metaKey||n.altKey||n.ctrlKey||n.shiftKey||n.defaultPrevented||void 0!==n.button&&0!==n.button)){if(n.currentTarget&&n.currentTarget.getAttribute){var e=n.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(e))return}return n.preventDefault&&n.preventDefault(),!0}}var Ca="undefined"!=typeof window;function Ia(n,e,t,r,o){var a=e||[],i=t||Object.create(null),s=r||Object.create(null);n.forEach((function(n){!function n(e,t,r,o,a,i){var s=o.path,l=o.name;0;var c=o.pathToRegexpOptions||{},d=function(n,e,t){t||(n=n.replace(/\/$/,""));if("/"===n[0])return n;if(null==e)return n;return ra(e.path+"/"+n)}(s,a,c.strict);"boolean"==typeof o.caseSensitive&&(c.sensitive=o.caseSensitive);var p={path:d,regex:Ea(d,c),components:o.components||{default:o.component},alias:o.alias?"string"==typeof o.alias?[o.alias]:o.alias:[],instances:{},enteredCbs:{},name:l,parent:a,matchAs:i,redirect:o.redirect,beforeEnter:o.beforeEnter,meta:o.meta||{},props:null==o.props?{}:o.components?o.props:{default:o.props}};o.children&&o.children.forEach((function(o){var a=i?ra(i+"/"+o.path):void 0;n(e,t,r,o,p,a)}));t[p.path]||(e.push(p.path),t[p.path]=p);if(void 0!==o.alias)for(var u=Array.isArray(o.alias)?o.alias:[o.alias],m=0;m<u.length;++m){0;var f={path:u[m],children:o.children};n(e,t,r,f,a,p.path||"/")}l&&(r[l]||(r[l]=p))}(a,i,s,n,o)}));for(var l=0,c=a.length;l<c;l++)"*"===a[l]&&(a.push(a.splice(l,1)[0]),c--,l--);return{pathList:a,pathMap:i,nameMap:s}}function Ea(n,e){return aa(n,[],e)}function Aa(n,e){var t=Ia(n),r=t.pathList,o=t.pathMap,a=t.nameMap;function i(n,t,i){var s=ka(n,t,!1,e),c=s.name;if(c){var d=a[c];if(!d)return l(null,s);var p=d.regex.keys.filter((function(n){return!n.optional})).map((function(n){return n.name}));if("object"!=typeof s.params&&(s.params={}),t&&"object"==typeof t.params)for(var u in t.params)!(u in s.params)&&p.indexOf(u)>-1&&(s.params[u]=t.params[u]);return s.path=_a(d.path,s.params),l(d,s,i)}if(s.path){s.params={};for(var m=0;m<r.length;m++){var f=r[m],h=o[f];if(Da(h.regex,s.path,s.params))return l(h,s,i)}}return l(null,s)}function s(n,t){var r=n.redirect,o="function"==typeof r?r($o(n,t,null,e)):r;if("string"==typeof o&&(o={path:o}),!o||"object"!=typeof o)return l(null,t);var s=o,c=s.name,d=s.path,p=t.query,u=t.hash,m=t.params;if(p=s.hasOwnProperty("query")?s.query:p,u=s.hasOwnProperty("hash")?s.hash:u,m=s.hasOwnProperty("params")?s.params:m,c){a[c];return i({_normalized:!0,name:c,query:p,hash:u,params:m},void 0,t)}if(d){var f=function(n,e){return ta(n,e.parent?e.parent.path:"/",!0)}(d,n);return i({_normalized:!0,path:_a(f,m),query:p,hash:u},void 0,t)}return l(null,t)}function l(n,t,r){return n&&n.redirect?s(n,r||t):n&&n.matchAs?function(n,e,t){var r=i({_normalized:!0,path:_a(t,e.params)});if(r){var o=r.matched,a=o[o.length-1];return e.params=r.params,l(a,e)}return l(null,e)}(0,t,n.matchAs):$o(n,t,r,e)}return{match:i,addRoute:function(n,e){var t="object"!=typeof n?a[n]:void 0;Ia([e||n],r,o,a,t),t&&t.alias.length&&Ia(t.alias.map((function(n){return{path:n,children:[e]}})),r,o,a,t)},getRoutes:function(){return r.map((function(n){return o[n]}))},addRoutes:function(n){Ia(n,r,o,a)}}}function Da(n,e,t){var r=e.match(n);if(!r)return!1;if(!t)return!0;for(var o=1,a=r.length;o<a;++o){var i=n.keys[o-1];i&&(t[i.name||"pathMatch"]="string"==typeof r[o]?Uo(r[o]):r[o])}return!0}var Oa=Ca&&window.performance&&window.performance.now?window.performance:Date;function La(){return Oa.now().toFixed(3)}var ja=La();function Ra(){return ja}function za(n){return ja=n}var Ma=Object.create(null);function Na(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var n=window.location.protocol+"//"+window.location.host,e=window.location.href.replace(n,""),t=zo({},window.history.state);return t.key=Ra(),window.history.replaceState(t,"",e),window.addEventListener("popstate",Ua),function(){window.removeEventListener("popstate",Ua)}}function Fa(n,e,t,r){if(n.app){var o=n.options.scrollBehavior;o&&n.app.$nextTick((function(){var a=function(){var n=Ra();if(n)return Ma[n]}(),i=o.call(n,e,t,r?a:null);i&&("function"==typeof i.then?i.then((function(n){$a(n,a)})).catch((function(n){0})):$a(i,a))}))}}function qa(){var n=Ra();n&&(Ma[n]={x:window.pageXOffset,y:window.pageYOffset})}function Ua(n){qa(),n.state&&n.state.key&&za(n.state.key)}function Ba(n){return Ha(n.x)||Ha(n.y)}function Ga(n){return{x:Ha(n.x)?n.x:window.pageXOffset,y:Ha(n.y)?n.y:window.pageYOffset}}function Ha(n){return"number"==typeof n}var Va=/^#\d/;function $a(n,e){var t,r="object"==typeof n;if(r&&"string"==typeof n.selector){var o=Va.test(n.selector)?document.getElementById(n.selector.slice(1)):document.querySelector(n.selector);if(o){var a=n.offset&&"object"==typeof n.offset?n.offset:{};e=function(n,e){var t=document.documentElement.getBoundingClientRect(),r=n.getBoundingClientRect();return{x:r.left-t.left-e.x,y:r.top-t.top-e.y}}(o,a={x:Ha((t=a).x)?t.x:0,y:Ha(t.y)?t.y:0})}else Ba(n)&&(e=Ga(n))}else r&&Ba(n)&&(e=Ga(n));e&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:e.x,top:e.y,behavior:n.behavior}):window.scrollTo(e.x,e.y))}var Wa,Ka=Ca&&((-1===(Wa=window.navigator.userAgent).indexOf("Android 2.")&&-1===Wa.indexOf("Android 4.0")||-1===Wa.indexOf("Mobile Safari")||-1!==Wa.indexOf("Chrome")||-1!==Wa.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function Xa(n,e){qa();var t=window.history;try{if(e){var r=zo({},t.state);r.key=Ra(),t.replaceState(r,"",n)}else t.pushState({key:za(La())},"",n)}catch(t){window.location[e?"replace":"assign"](n)}}function Qa(n){Xa(n,!0)}function Ya(n,e,t){var r=function(o){o>=n.length?t():n[o]?e(n[o],(function(){r(o+1)})):r(o+1)};r(0)}var Za={redirected:2,aborted:4,cancelled:8,duplicated:16};function Ja(n,e){return ei(n,e,Za.redirected,'Redirected when going from "'+n.fullPath+'" to "'+function(n){if("string"==typeof n)return n;if("path"in n)return n.path;var e={};return ti.forEach((function(t){t in n&&(e[t]=n[t])})),JSON.stringify(e,null,2)}(e)+'" via a navigation guard.')}function ni(n,e){return ei(n,e,Za.cancelled,'Navigation cancelled from "'+n.fullPath+'" to "'+e.fullPath+'" with a new navigation.')}function ei(n,e,t,r){var o=new Error(r);return o._isRouter=!0,o.from=n,o.to=e,o.type=t,o}var ti=["params","query","hash"];function ri(n){return Object.prototype.toString.call(n).indexOf("Error")>-1}function oi(n,e){return ri(n)&&n._isRouter&&(null==e||n.type===e)}function ai(n){return function(e,t,r){var o=!1,a=0,i=null;ii(n,(function(n,e,t,s){if("function"==typeof n&&void 0===n.cid){o=!0,a++;var l,c=ci((function(e){var o;((o=e).__esModule||li&&"Module"===o[Symbol.toStringTag])&&(e=e.default),n.resolved="function"==typeof e?e:wa.extend(e),t.components[s]=e,--a<=0&&r()})),d=ci((function(n){var e="Failed to resolve async component "+s+": "+n;i||(i=ri(n)?n:new Error(e),r(i))}));try{l=n(c,d)}catch(n){d(n)}if(l)if("function"==typeof l.then)l.then(c,d);else{var p=l.component;p&&"function"==typeof p.then&&p.then(c,d)}}})),o||r()}}function ii(n,e){return si(n.map((function(n){return Object.keys(n.components).map((function(t){return e(n.components[t],n.instances[t],n,t)}))})))}function si(n){return Array.prototype.concat.apply([],n)}var li="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function ci(n){var e=!1;return function(){for(var t=[],r=arguments.length;r--;)t[r]=arguments[r];if(!e)return e=!0,n.apply(this,t)}}var di=function(n,e){this.router=n,this.base=function(n){if(!n)if(Ca){var e=document.querySelector("base");n=(n=e&&e.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else n="/";"/"!==n.charAt(0)&&(n="/"+n);return n.replace(/\/$/,"")}(e),this.current=Ko,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function pi(n,e,t,r){var o=ii(n,(function(n,r,o,a){var i=function(n,e){"function"!=typeof n&&(n=wa.extend(n));return n.options[e]}(n,e);if(i)return Array.isArray(i)?i.map((function(n){return t(n,r,o,a)})):t(i,r,o,a)}));return si(r?o.reverse():o)}function ui(n,e){if(e)return function(){return n.apply(e,arguments)}}di.prototype.listen=function(n){this.cb=n},di.prototype.onReady=function(n,e){this.ready?n():(this.readyCbs.push(n),e&&this.readyErrorCbs.push(e))},di.prototype.onError=function(n){this.errorCbs.push(n)},di.prototype.transitionTo=function(n,e,t){var r,o=this;try{r=this.router.match(n,this.current)}catch(n){throw this.errorCbs.forEach((function(e){e(n)})),n}var a=this.current;this.confirmTransition(r,(function(){o.updateRoute(r),e&&e(r),o.ensureURL(),o.router.afterHooks.forEach((function(n){n&&n(r,a)})),o.ready||(o.ready=!0,o.readyCbs.forEach((function(n){n(r)})))}),(function(n){t&&t(n),n&&!o.ready&&(oi(n,Za.redirected)&&a===Ko||(o.ready=!0,o.readyErrorCbs.forEach((function(e){e(n)}))))}))},di.prototype.confirmTransition=function(n,e,t){var r=this,o=this.current;this.pending=n;var a,i,s=function(n){!oi(n)&&ri(n)&&(r.errorCbs.length?r.errorCbs.forEach((function(e){e(n)})):console.error(n)),t&&t(n)},l=n.matched.length-1,c=o.matched.length-1;if(Yo(n,o)&&l===c&&n.matched[l]===o.matched[c])return this.ensureURL(),n.hash&&Fa(this.router,o,n,!1),s(((i=ei(a=o,n,Za.duplicated,'Avoided redundant navigation to current location: "'+a.fullPath+'".')).name="NavigationDuplicated",i));var d=function(n,e){var t,r=Math.max(n.length,e.length);for(t=0;t<r&&n[t]===e[t];t++);return{updated:e.slice(0,t),activated:e.slice(t),deactivated:n.slice(t)}}(this.current.matched,n.matched),p=d.updated,u=d.deactivated,m=d.activated,f=[].concat(function(n){return pi(n,"beforeRouteLeave",ui,!0)}(u),this.router.beforeHooks,function(n){return pi(n,"beforeRouteUpdate",ui)}(p),m.map((function(n){return n.beforeEnter})),ai(m)),h=function(e,t){if(r.pending!==n)return s(ni(o,n));try{e(n,o,(function(e){!1===e?(r.ensureURL(!0),s(function(n,e){return ei(n,e,Za.aborted,'Navigation aborted from "'+n.fullPath+'" to "'+e.fullPath+'" via a navigation guard.')}(o,n))):ri(e)?(r.ensureURL(!0),s(e)):"string"==typeof e||"object"==typeof e&&("string"==typeof e.path||"string"==typeof e.name)?(s(Ja(o,n)),"object"==typeof e&&e.replace?r.replace(e):r.push(e)):t(e)}))}catch(n){s(n)}};Ya(f,h,(function(){Ya(function(n){return pi(n,"beforeRouteEnter",(function(n,e,t,r){return function(n,e,t){return function(r,o,a){return n(r,o,(function(n){"function"==typeof n&&(e.enteredCbs[t]||(e.enteredCbs[t]=[]),e.enteredCbs[t].push(n)),a(n)}))}}(n,t,r)}))}(m).concat(r.router.resolveHooks),h,(function(){if(r.pending!==n)return s(ni(o,n));r.pending=null,e(n),r.router.app&&r.router.app.$nextTick((function(){Jo(n)}))}))}))},di.prototype.updateRoute=function(n){this.current=n,this.cb&&this.cb(n)},di.prototype.setupListeners=function(){},di.prototype.teardown=function(){this.listeners.forEach((function(n){n()})),this.listeners=[],this.current=Ko,this.pending=null};var mi=function(n){function e(e,t){n.call(this,e,t),this._startLocation=fi(this.base)}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router,t=e.options.scrollBehavior,r=Ka&&t;r&&this.listeners.push(Na());var o=function(){var t=n.current,o=fi(n.base);n.current===Ko&&o===n._startLocation||n.transitionTo(o,(function(n){r&&Fa(e,n,t,!0)}))};window.addEventListener("popstate",o),this.listeners.push((function(){window.removeEventListener("popstate",o)}))}},e.prototype.go=function(n){window.history.go(n)},e.prototype.push=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){Xa(ra(r.base+n.fullPath)),Fa(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){Qa(ra(r.base+n.fullPath)),Fa(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.ensureURL=function(n){if(fi(this.base)!==this.current.fullPath){var e=ra(this.base+this.current.fullPath);n?Xa(e):Qa(e)}},e.prototype.getCurrentLocation=function(){return fi(this.base)},e}(di);function fi(n){var e=window.location.pathname,t=e.toLowerCase(),r=n.toLowerCase();return!n||t!==r&&0!==t.indexOf(ra(r+"/"))||(e=e.slice(n.length)),(e||"/")+window.location.search+window.location.hash}var hi=function(n){function e(e,t,r){n.call(this,e,t),r&&function(n){var e=fi(n);if(!/^\/#/.test(e))return window.location.replace(ra(n+"/#"+e)),!0}(this.base)||gi()}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router.options.scrollBehavior,t=Ka&&e;t&&this.listeners.push(Na());var r=function(){var e=n.current;gi()&&n.transitionTo(vi(),(function(r){t&&Fa(n.router,r,e,!0),Ka||xi(r.fullPath)}))},o=Ka?"popstate":"hashchange";window.addEventListener(o,r),this.listeners.push((function(){window.removeEventListener(o,r)}))}},e.prototype.push=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){yi(n.fullPath),Fa(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){xi(n.fullPath),Fa(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.go=function(n){window.history.go(n)},e.prototype.ensureURL=function(n){var e=this.current.fullPath;vi()!==e&&(n?yi(e):xi(e))},e.prototype.getCurrentLocation=function(){return vi()},e}(di);function gi(){var n=vi();return"/"===n.charAt(0)||(xi("/"+n),!1)}function vi(){var n=window.location.href,e=n.indexOf("#");return e<0?"":n=n.slice(e+1)}function bi(n){var e=window.location.href,t=e.indexOf("#");return(t>=0?e.slice(0,t):e)+"#"+n}function yi(n){Ka?Xa(bi(n)):window.location.hash=n}function xi(n){Ka?Qa(bi(n)):window.location.replace(bi(n))}var _i=function(n){function e(e,t){n.call(this,e,t),this.stack=[],this.index=-1}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.push=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index+1).concat(n),r.index++,e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index).concat(n),e&&e(n)}),t)},e.prototype.go=function(n){var e=this,t=this.index+n;if(!(t<0||t>=this.stack.length)){var r=this.stack[t];this.confirmTransition(r,(function(){var n=e.current;e.index=t,e.updateRoute(r),e.router.afterHooks.forEach((function(e){e&&e(r,n)}))}),(function(n){oi(n,Za.duplicated)&&(e.index=t)}))}},e.prototype.getCurrentLocation=function(){var n=this.stack[this.stack.length-1];return n?n.fullPath:"/"},e.prototype.ensureURL=function(){},e}(di),ki=function(n){void 0===n&&(n={}),this.app=null,this.apps=[],this.options=n,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Aa(n.routes||[],this);var e=n.mode||"hash";switch(this.fallback="history"===e&&!Ka&&!1!==n.fallback,this.fallback&&(e="hash"),Ca||(e="abstract"),this.mode=e,e){case"history":this.history=new mi(this,n.base);break;case"hash":this.history=new hi(this,n.base,this.fallback);break;case"abstract":this.history=new _i(this,n.base);break;default:0}},wi={currentRoute:{configurable:!0}};function Ti(n,e){return n.push(e),function(){var t=n.indexOf(e);t>-1&&n.splice(t,1)}}ki.prototype.match=function(n,e,t){return this.matcher.match(n,e,t)},wi.currentRoute.get=function(){return this.history&&this.history.current},ki.prototype.init=function(n){var e=this;if(this.apps.push(n),n.$once("hook:destroyed",(function(){var t=e.apps.indexOf(n);t>-1&&e.apps.splice(t,1),e.app===n&&(e.app=e.apps[0]||null),e.app||e.history.teardown()})),!this.app){this.app=n;var t=this.history;if(t instanceof mi||t instanceof hi){var r=function(n){t.setupListeners(),function(n){var r=t.current,o=e.options.scrollBehavior;Ka&&o&&"fullPath"in n&&Fa(e,n,r,!1)}(n)};t.transitionTo(t.getCurrentLocation(),r,r)}t.listen((function(n){e.apps.forEach((function(e){e._route=n}))}))}},ki.prototype.beforeEach=function(n){return Ti(this.beforeHooks,n)},ki.prototype.beforeResolve=function(n){return Ti(this.resolveHooks,n)},ki.prototype.afterEach=function(n){return Ti(this.afterHooks,n)},ki.prototype.onReady=function(n,e){this.history.onReady(n,e)},ki.prototype.onError=function(n){this.history.onError(n)},ki.prototype.push=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.push(n,e,t)}));this.history.push(n,e,t)},ki.prototype.replace=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.replace(n,e,t)}));this.history.replace(n,e,t)},ki.prototype.go=function(n){this.history.go(n)},ki.prototype.back=function(){this.go(-1)},ki.prototype.forward=function(){this.go(1)},ki.prototype.getMatchedComponents=function(n){var e=n?n.matched?n:this.resolve(n).route:this.currentRoute;return e?[].concat.apply([],e.matched.map((function(n){return Object.keys(n.components).map((function(e){return n.components[e]}))}))):[]},ki.prototype.resolve=function(n,e,t){var r=ka(n,e=e||this.history.current,t,this),o=this.match(r,e),a=o.redirectedFrom||o.fullPath;return{location:r,route:o,href:function(n,e,t){var r="hash"===t?"#"+e:e;return n?ra(n+"/"+r):r}(this.history.base,a,this.mode),normalizedTo:r,resolved:o}},ki.prototype.getRoutes=function(){return this.matcher.getRoutes()},ki.prototype.addRoute=function(n,e){this.matcher.addRoute(n,e),this.history.current!==Ko&&this.history.transitionTo(this.history.getCurrentLocation())},ki.prototype.addRoutes=function(n){this.matcher.addRoutes(n),this.history.current!==Ko&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(ki.prototype,wi),ki.install=function n(e){if(!n.installed||wa!==e){n.installed=!0,wa=e;var t=function(n){return void 0!==n},r=function(n,e){var r=n.$options._parentVnode;t(r)&&t(r=r.data)&&t(r=r.registerRouteInstance)&&r(n,e)};e.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),e.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,r(this,this)},destroyed:function(){r(this)}}),Object.defineProperty(e.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(e.prototype,"$route",{get:function(){return this._routerRoot._route}}),e.component("RouterView",na),e.component("RouterLink",Sa);var o=e.config.optionMergeStrategies;o.beforeRouteEnter=o.beforeRouteLeave=o.beforeRouteUpdate=o.created}},ki.version="3.5.3",ki.isNavigationFailure=oi,ki.NavigationFailureType=Za,ki.START_LOCATION=Ko,Ca&&window.Vue&&window.Vue.use(ki);var Si=ki;t(171),t(172),t(250),t(101),t(173),t(32),t(33),t(252);function Pi(n){n.locales&&Object.keys(n.locales).forEach((function(e){n.locales[e].path=e})),Object.freeze(n)}t(68),t(90),t(120);function Ci(n){return(Ci="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n})(n)}var Ii=t(70),Ei=(t(183),t(21),t(52),t(225),t(226),t(41),t(30),{NotFound:function(){return Promise.all([t.e(0),t.e(13)]).then(t.bind(null,630))},Layout:function(){return Promise.all([t.e(0),t.e(3)]).then(t.bind(null,629))}}),Ai={"v-a395e182":function(){return t.e(29).then(t.bind(null,634))},"v-61e6c4c2":function(){return t.e(30).then(t.bind(null,635))},"v-690ecebf":function(){return t.e(31).then(t.bind(null,636))},"v-0e1d1ba8":function(){return t.e(32).then(t.bind(null,637))},"v-600665ec":function(){return t.e(33).then(t.bind(null,638))},"v-95764dbe":function(){return t.e(34).then(t.bind(null,639))},"v-61aeda36":function(){return t.e(35).then(t.bind(null,640))},"v-f89e89de":function(){return t.e(14).then(t.bind(null,641))},"v-303c02c2":function(){return t.e(15).then(t.bind(null,642))},"v-e117a336":function(){return t.e(36).then(t.bind(null,643))},"v-46965d82":function(){return t.e(37).then(t.bind(null,644))},"v-2c4fb4ae":function(){return t.e(38).then(t.bind(null,645))},"v-742c98c4":function(){return t.e(39).then(t.bind(null,646))},"v-f1ab1866":function(){return t.e(40).then(t.bind(null,647))},"v-5180c0ff":function(){return t.e(41).then(t.bind(null,648))},"v-31e2af82":function(){return t.e(42).then(t.bind(null,649))},"v-92792e82":function(){return t.e(16).then(t.bind(null,650))},"v-53f7dee4":function(){return t.e(43).then(t.bind(null,651))},"v-d7f39702":function(){return t.e(44).then(t.bind(null,652))},"v-3a68b8c2":function(){return t.e(45).then(t.bind(null,653))},"v-16fdda93":function(){return t.e(46).then(t.bind(null,654))},"v-52f58a7d":function(){return t.e(47).then(t.bind(null,655))},"v-65f07e87":function(){return t.e(48).then(t.bind(null,656))},"v-6a7f071f":function(){return t.e(49).then(t.bind(null,657))},"v-2c04e47f":function(){return t.e(50).then(t.bind(null,658))},"v-0c0b8bdf":function(){return t.e(51).then(t.bind(null,659))},"v-95a0b5de":function(){return t.e(52).then(t.bind(null,660))},"v-d3589f42":function(){return t.e(53).then(t.bind(null,661))},"v-90b5b0c2":function(){return t.e(54).then(t.bind(null,662))},"v-50b53767":function(){return t.e(55).then(t.bind(null,663))},"v-718753e8":function(){return t.e(56).then(t.bind(null,664))},"v-570d3d9f":function(){return t.e(57).then(t.bind(null,665))},"v-b9611c0e":function(){return t.e(58).then(t.bind(null,666))},"v-e4b92d82":function(){return t.e(59).then(t.bind(null,667))},"v-75d8bb3f":function(){return t.e(60).then(t.bind(null,668))},"v-32fca817":function(){return t.e(61).then(t.bind(null,669))},"v-398f0321":function(){return t.e(62).then(t.bind(null,670))},"v-319db75f":function(){return t.e(24).then(t.bind(null,671))},"v-5354451a":function(){return t.e(63).then(t.bind(null,672))},"v-48032f1f":function(){return t.e(64).then(t.bind(null,673))},"v-485139ef":function(){return t.e(25).then(t.bind(null,674))},"v-29d661ff":function(){return t.e(65).then(t.bind(null,675))},"v-4976d5df":function(){return t.e(9).then(t.bind(null,676))},"v-6a62161f":function(){return t.e(66).then(t.bind(null,677))},"v-de8bce82":function(){return t.e(67).then(t.bind(null,678))},"v-3682497f":function(){return t.e(68).then(t.bind(null,631))},"v-1d6a5088":function(){return t.e(69).then(t.bind(null,679))},"v-091c8f7f":function(){return t.e(70).then(t.bind(null,680))},"v-7103a3ed":function(){return t.e(71).then(t.bind(null,681))},"v-5240d527":function(){return t.e(72).then(t.bind(null,682))},"v-5e7e6c7d":function(){return t.e(73).then(t.bind(null,683))},"v-633581c2":function(){return t.e(26).then(t.bind(null,684))},"v-4b4d8c9f":function(){return t.e(74).then(t.bind(null,685))},"v-cc5c4542":function(){return t.e(17).then(t.bind(null,686))},"v-386d6b3f":function(){return t.e(75).then(t.bind(null,687))},"v-0e5e6773":function(){return t.e(76).then(t.bind(null,688))},"v-35163721":function(){return t.e(8).then(t.bind(null,689))},"v-75c42f42":function(){return t.e(18).then(t.bind(null,690))},"v-897ab682":function(){return t.e(10).then(t.bind(null,691))},"v-41809442":function(){return t.e(11).then(t.bind(null,692))},"v-66696d37":function(){return t.e(77).then(t.bind(null,693))},"v-71519a9f":function(){return t.e(78).then(t.bind(null,694))},"v-6ca7651f":function(){return t.e(19).then(t.bind(null,695))},"v-15864453":function(){return t.e(79).then(t.bind(null,696))},"v-a254d0c2":function(){return t.e(4).then(t.bind(null,697))},"v-76ece9bf":function(){return t.e(20).then(t.bind(null,698))},"v-34bb950d":function(){return t.e(6).then(t.bind(null,699))},"v-03728847":function(){return t.e(80).then(t.bind(null,700))},"v-cf80e5c2":function(){return t.e(2).then(t.bind(null,701))},"v-7d6afdba":function(){return t.e(21).then(t.bind(null,702))},"v-dde8b282":function(){return t.e(81).then(t.bind(null,703))},"v-6cc2a996":function(){return t.e(82).then(t.bind(null,704))},"v-5f9b1d8c":function(){return t.e(83).then(t.bind(null,705))},"v-0dc92f7f":function(){return t.e(84).then(t.bind(null,706))},"v-25c8ca33":function(){return t.e(85).then(t.bind(null,707))},"v-0b34dfc2":function(){return t.e(86).then(t.bind(null,708))},"v-9af6bf82":function(){return t.e(87).then(t.bind(null,709))},"v-ccf5212a":function(){return t.e(88).then(t.bind(null,710))},"v-c6b25e82":function(){return t.e(89).then(t.bind(null,711))},"v-019d6745":function(){return t.e(90).then(t.bind(null,712))},"v-2fe5090c":function(){return t.e(91).then(t.bind(null,713))},"v-a6752c4a":function(){return t.e(22).then(t.bind(null,632))},"v-0dd9b182":function(){return t.e(92).then(t.bind(null,714))},"v-5d28d3ff":function(){return t.e(27).then(t.bind(null,715))},"v-d5db50c2":function(){return t.e(93).then(t.bind(null,716))},"v-f76e517a":function(){return t.e(23).then(t.bind(null,717))},"v-15f1fc67":function(){return t.e(94).then(t.bind(null,718))},"v-8cf30266":function(){return t.e(95).then(t.bind(null,719))},"v-455450db":function(){return t.e(7).then(t.bind(null,720))},"v-162635f9":function(){return t.e(5).then(t.bind(null,721))},"v-680803e5":function(){return t.e(28).then(t.bind(null,722))},"v-155cc502":function(){return t.e(96).then(t.bind(null,723))},"v-16de7e50":function(){return t.e(97).then(t.bind(null,724))},"v-02e3228c":function(){return t.e(98).then(t.bind(null,725))},"v-4bfbd5e5":function(){return t.e(99).then(t.bind(null,633))},"v-19beb85e":function(){return t.e(100).then(t.bind(null,726))},"v-5b31b7d6":function(){return t.e(101).then(t.bind(null,727))}};function Di(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var Oi=/-(\w)/g,Li=Di((function(n){return n.replace(Oi,(function(n,e){return e?e.toUpperCase():""}))})),ji=/\B([A-Z])/g,Ri=Di((function(n){return n.replace(ji,"-$1").toLowerCase()})),zi=Di((function(n){return n.charAt(0).toUpperCase()+n.slice(1)}));function Mi(n,e){if(e)return n(e)?n(e):e.includes("-")?n(zi(Li(e))):n(zi(e))||n(Ri(e))}var Ni=Object.assign({},Ei,Ai),Fi=function(n){return Ni[n]},qi=function(n){return Ai[n]},Ui=function(n){return Ei[n]},Bi=function(n){return Ro.component(n)};function Gi(n){return Mi(qi,n)}function Hi(n){return Mi(Ui,n)}function Vi(n){return Mi(Fi,n)}function $i(n){return Mi(Bi,n)}function Wi(){for(var n=arguments.length,e=new Array(n),t=0;t<n;t++)e[t]=arguments[t];return Promise.all(e.filter((function(n){return n})).map(function(){var n=o(regeneratorRuntime.mark((function n(e){var t;return regeneratorRuntime.wrap((function(n){for(;;)switch(n.prev=n.next){case 0:if($i(e)||!Vi(e)){n.next=5;break}return n.next=3,Vi(e)();case 3:t=n.sent,Ro.component(e,t.default);case 5:case"end":return n.stop()}}),n)})));return function(e){return n.apply(this,arguments)}}()))}function Ki(n,e){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[n]=e)}t(76);var Xi=t(98);function Qi(n,e){return function(n){if(Array.isArray(n))return n}(n)||function(n,e){var t=null==n?null:"undefined"!=typeof Symbol&&n[Symbol.iterator]||n["@@iterator"];if(null!=t){var r,o,a=[],i=!0,s=!1;try{for(t=t.call(n);!(i=(r=t.next()).done)&&(a.push(r.value),!e||a.length!==e);i=!0);}catch(n){s=!0,o=n}finally{try{i||null==t.return||t.return()}finally{if(s)throw o}}return a}}(n,e)||Object(Xi.a)(n,e)||function(){throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}t(265),t(184),t(72);var Yi=t(213),Zi=t.n(Yi),Ji=t(214),ns=t.n(Ji),es={created:function(){if(this.siteMeta=this.$site.headTags.filter((function(n){return"meta"===Qi(n,1)[0]})).map((function(n){var e=Qi(n,2);e[0];return e[1]})),this.$ssrContext){var n=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(e=n)?e.map((function(n){var e="<meta";return Object.keys(n).forEach((function(t){e+=" ".concat(t,'="').concat(ns()(n[t]),'"')})),e+">"})).join("\n    "):"",this.$ssrContext.canonicalLink=rs(this.$canonicalUrl)}var e},mounted:function(){this.currentMetaTags=Object(Ii.a)(document.querySelectorAll("meta")),this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta:function(){document.title=this.$title,document.documentElement.lang=this.$lang;var n=this.getMergedMetaTags();this.currentMetaTags=os(n,this.currentMetaTags)},getMergedMetaTags:function(){var n=this.$page.frontmatter.meta||[];return Zi()([{name:"description",content:this.$description}],n,this.siteMeta,as)},updateCanonicalLink:function(){ts(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",rs(this.$canonicalUrl))}},watch:{$page:function(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy:function(){os(null,this.currentMetaTags),ts()}};function ts(){var n=document.querySelector("link[rel='canonical']");n&&n.remove()}function rs(){var n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:"";return n?'<link href="'.concat(n,'" rel="canonical" />'):""}function os(n,e){if(e&&Object(Ii.a)(e).filter((function(n){return n.parentNode===document.head})).forEach((function(n){return document.head.removeChild(n)})),n)return n.map((function(n){var e=document.createElement("meta");return Object.keys(n).forEach((function(t){e.setAttribute(t,n[t])})),document.head.appendChild(e),e}))}function as(n){for(var e=0,t=["name","property","itemprop"];e<t.length;e++){var r=t[e];if(n.hasOwnProperty(r))return n[r]+r}return JSON.stringify(n)}t(135);var is=t(143),ss={mounted:function(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(is)()((function(){this.setActiveHash()}),300),setActiveHash:function(){for(var n=this,e=[].slice.call(document.querySelectorAll(".sidebar-link")),t=[].slice.call(document.querySelectorAll(".header-anchor")).filter((function(n){return e.some((function(e){return e.hash===n.hash}))})),r=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),o=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),a=window.innerHeight+r,i=0;i<t.length;i++){var s=t[i],l=t[i+1],c=0===i&&0===r||r>=s.parentElement.offsetTop+10&&(!l||r<l.parentElement.offsetTop-10),d=decodeURIComponent(this.$route.hash);if(c&&d!==decodeURIComponent(s.hash)){var p=s;if(a===o)for(var u=i+1;u<t.length;u++)if(d===decodeURIComponent(t[u].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(p.hash),(function(){n.$nextTick((function(){n.$vuepress.$set("disableScrollBehavior",!1)}))}))}}}},beforeDestroy:function(){window.removeEventListener("scroll",this.onScroll)}},ls=(t(55),t(99)),cs=t.n(ls),ds={mounted:function(){var n=this;cs.a.configure({showSpinner:!1}),this.$router.beforeEach((function(n,e,t){n.path===e.path||Ro.component(n.name)||cs.a.start(),t()})),this.$router.afterEach((function(){cs.a.done(),n.isSidebarOpen=!1}))}};t(74),t(73),t(360);function ps(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}t(97);function us(n,e){for(var t=0;t<e.length;t++){var r=e[t];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(n,r.key,r)}}function ms(n,e,t){return e&&us(n.prototype,e),t&&us(n,t),Object.defineProperty(n,"prototype",{writable:!1}),n}t(361);var fs=function(){function n(){ps(this,n);this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}return ms(n,[{key:"show",value:function(n){var e=this,t=n.text,r=void 0===t?"":t,o=n.duration,a=void 0===o?3e3:o,i=document.createElement("div");i.className="message move-in",i.innerHTML='\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">'.concat(r,"</div>\n    "),this.containerEl.appendChild(i),a>0&&setTimeout((function(){e.close(i)}),a)}},{key:"close",value:function(n){n.className=n.className.replace("move-in",""),n.className+="move-out",n.addEventListener("animationend",(function(){n.remove()}))}}]),n}(),hs={mounted:function(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated:function(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy:function(){var n=this;setTimeout((function(){(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach((function(e){document.querySelectorAll(e).forEach(n.generateCopyButton)}))}),1e3)},generateCopyButton:function(n){var e=this;if(!n.classList.contains("codecopy-enabled")){var t=document.createElement("i");t.className="code-copy",t.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',t.title="Copy to clipboard",t.addEventListener("click",(function(){e.copyToClipboard(n.innerText)})),n.appendChild(t),n.classList.add("codecopy-enabled")}},copyToClipboard:function(n){var e=document.createElement("textarea");e.value=n,e.setAttribute("readonly",""),e.style.position="absolute",e.style.left="-9999px",document.body.appendChild(e);var t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);e.select(),document.execCommand("copy"),(new fs).show({text:"复制成功",duration:1e3}),document.body.removeChild(e),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}},gs=(t(218),"auto"),vs="zoom-in",bs="zoom-out",ys="grab",xs="move";function _s(n,e,t){var r=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],o={passive:!1};r?n.addEventListener(e,t,o):n.removeEventListener(e,t,o)}function ks(n,e){if(n){var t=new Image;t.onload=function(){e&&e(t)},t.src=n}}function ws(n){return n.dataset.original?n.dataset.original:"A"===n.parentNode.tagName?n.parentNode.getAttribute("href"):null}function Ts(n,e,t){!function(n){var e=Ss,t=Ps;if(n.transition){var r=n.transition;delete n.transition,n[e]=r}if(n.transform){var o=n.transform;delete n.transform,n[t]=o}}(e);var r=n.style,o={};for(var a in e)t&&(o[a]=r[a]||""),r[a]=e[a];return o}var Ss="transition",Ps="transform",Cs="transform",Is="transitionend";var Es=function(){},As={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:Es,onClose:Es,onGrab:Es,onMove:Es,onRelease:Es,onBeforeOpen:Es,onBeforeClose:Es,onBeforeGrab:Es,onBeforeRelease:Es,onImageLoading:Es,onImageLoaded:Es},Ds={init:function(n){var e,t;e=this,t=n,Object.getOwnPropertyNames(Object.getPrototypeOf(e)).forEach((function(n){e[n]=e[n].bind(t)}))},click:function(n){if(n.preventDefault(),Ls(n))return window.open(this.target.srcOriginal||n.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(n.currentTarget)},scroll:function(){var n=document.documentElement||document.body.parentNode||document.body,e=window.pageXOffset||n.scrollLeft,t=window.pageYOffset||n.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:e,y:t});var r=this.lastScrollPosition.x-e,o=this.lastScrollPosition.y-t,a=this.options.scrollThreshold;(Math.abs(o)>=a||Math.abs(r)>=a)&&(this.lastScrollPosition=null,this.close())},keydown:function(n){(function(n){return"Escape"===(n.key||n.code)||27===n.keyCode})(n)&&(this.released?this.close():this.release(this.close))},mousedown:function(n){if(Os(n)&&!Ls(n)){n.preventDefault();var e=n.clientX,t=n.clientY;this.pressTimer=setTimeout(function(){this.grab(e,t)}.bind(this),200)}},mousemove:function(n){this.released||this.move(n.clientX,n.clientY)},mouseup:function(n){Os(n)&&!Ls(n)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(n){n.preventDefault();var e=n.touches[0],t=e.clientX,r=e.clientY;this.pressTimer=setTimeout(function(){this.grab(t,r)}.bind(this),200)},touchmove:function(n){if(!this.released){var e=n.touches[0],t=e.clientX,r=e.clientY;this.move(t,r)}},touchend:function(n){(function(n){n.targetTouches.length})(n)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function Os(n){return 0===n.button}function Ls(n){return n.metaKey||n.ctrlKey}var js={init:function(n){this.el=document.createElement("div"),this.instance=n,this.parent=document.body,Ts(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(n.options),_s(this.el,"click",n.handler.clickOverlay.bind(n))},updateStyle:function(n){Ts(this.el,{zIndex:n.zIndex,backgroundColor:n.bgColor,transition:"opacity\n        "+n.transitionDuration+"s\n        "+n.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},Rs="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n},zs=function(){function n(n,e){for(var t=0;t<e.length;t++){var r=e[t];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(n,r.key,r)}}return function(e,t,r){return t&&n(e.prototype,t),r&&n(e,r),e}}(),Ms=Object.assign||function(n){for(var e=1;e<arguments.length;e++){var t=arguments[e];for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(n[r]=t[r])}return n},Ns={init:function(n,e){this.el=n,this.instance=e,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=ws(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var n=this.instance.options,e=n.zIndex,t=n.enableGrab,r=n.transitionDuration,o=n.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:e+1,cursor:t?ys:bs,transition:Cs+"\n        "+r+"s\n        "+o,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=Ts(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,Ts(this.el,{transform:"none"})},grab:function(n,e,t){var r=Fs(),o=r.x-n,a=r.y-e;Ts(this.el,{cursor:xs,transform:"translate3d(\n        "+(this.translate.x+o)+"px, "+(this.translate.y+a)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(n,e,t){var r=Fs(),o=r.x-n,a=r.y-e;Ts(this.el,{transition:Cs,transform:"translate3d(\n        "+(this.translate.x+o)+"px, "+(this.translate.y+a)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){Ts(this.el,this.styleClose)},restoreOpenStyle:function(){Ts(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var n=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var e=this.el.cloneNode(!1);e.setAttribute("src",this.srcOriginal),e.style.position="fixed",e.style.visibility="hidden",n.appendChild(e),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),n.removeChild(e)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var n=Fs(),e=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:n.x-e,y:n.y-t}},calculateScale:function(){var n=this.el.dataset,e=n.zoomingHeight,t=n.zoomingWidth,r=this.instance.options,o=r.customSize,a=r.scaleBase;if(!o&&e&&t)return{x:t/this.rect.width,y:e/this.rect.height};if(o&&"object"===(void 0===o?"undefined":Rs(o)))return{x:o.width/this.rect.width,y:o.height/this.rect.height};var i=this.rect.width/2,s=this.rect.height/2,l=Fs(),c={x:l.x-i,y:l.y-s},d=c.x/i,p=c.y/s,u=a+Math.min(d,p);if(o&&"string"==typeof o){var m=t||this.el.naturalWidth,f=e||this.el.naturalHeight,h=parseFloat(o)*m/(100*this.rect.width),g=parseFloat(o)*f/(100*this.rect.height);if(u>h||u>g)return{x:h,y:g}}return{x:u,y:u}}};function Fs(){var n=document.documentElement;return{x:Math.min(n.clientWidth,window.innerWidth)/2,y:Math.min(n.clientHeight,window.innerHeight)/2}}function qs(n,e,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(r){_s(n,r,e[r],t)}))}var Us=function(){function n(e){!function(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}(this,n),this.target=Object.create(Ns),this.overlay=Object.create(js),this.handler=Object.create(Ds),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=Ms({},As,e),this.overlay.init(this),this.handler.init(this)}return zs(n,[{key:"listen",value:function(n){if("string"==typeof n)for(var e=document.querySelectorAll(n),t=e.length;t--;)this.listen(e[t]);else"IMG"===n.tagName&&(n.style.cursor=vs,_s(n,"click",this.handler.click),this.options.preloadImage&&ks(ws(n)));return this}},{key:"config",value:function(n){return n?(Ms(this.options,n),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(n){var e=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var r="string"==typeof n?document.querySelector(n):n;if("IMG"===r.tagName){if(this.options.onBeforeOpen(r),this.target.init(r,this),!this.options.preloadImage){var o=this.target.srcOriginal;null!=o&&(this.options.onImageLoading(r),ks(o,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),_s(document,"scroll",this.handler.scroll),_s(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&_s(window,"resize",this.handler.resizeWindow);var a=function n(){_s(r,Is,n,!1),e.lock=!1,e.target.upgradeSource(),e.options.enableGrab&&qs(document,e.handler,!0),t(r)};return _s(r,Is,a),this}}}},{key:"close",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=gs,this.overlay.fadeOut(),this.target.zoomOut(),_s(document,"scroll",this.handler.scroll,!1),_s(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&_s(window,"resize",this.handler.resizeWindow,!1);var r=function r(){_s(t,Is,r,!1),n.shown=!1,n.lock=!1,n.target.downgradeSource(),n.options.enableGrab&&qs(document,n.handler,!1),n.target.restoreCloseStyle(),n.overlay.remove(),e(t)};return _s(t,Is,r),this}}},{key:"grab",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var o=this.target.el;this.options.onBeforeGrab(o),this.released=!1,this.target.grab(n,e,t);var a=function n(){_s(o,Is,n,!1),r(o)};return _s(o,Is,a),this}}},{key:"move",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=xs,this.target.move(n,e,t);var o=this.target.el,a=function n(){_s(o,Is,n,!1),r(o)};return _s(o,Is,a),this}}},{key:"release",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=gs,this.target.restoreOpenStyle();var r=function r(){_s(t,Is,r,!1),n.lock=!1,n.released=!0,e(t)};return _s(t,Is,r),this}}}]),n}(),Bs=".theme-vdoing-content img:not(.no-zoom)",Gs=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),Hs=Number("500"),Vs=function(){function n(){ps(this,n),this.instance=new Us(Gs)}return ms(n,[{key:"update",value:function(){var n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:Bs;"undefined"!=typeof window&&this.instance.listen(n)}},{key:"updateDelay",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:Bs,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:Hs;setTimeout((function(){return n.update(e)}),t)}}]),n}(),$s=[es,ss,ds,hs,{watch:{"$page.path":function(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted:function(){this.$vuepress.zooming=new Vs,this.$vuepress.zooming.updateDelay()}}],Ws={name:"GlobalLayout",computed:{layout:function(){var n=this.getLayout();return Ki("layout",n),Ro.component(n)}},methods:{getLayout:function(){if(this.$page.path){var n=this.$page.frontmatter.layout;return n&&(this.$vuepress.getLayoutAsyncComponent(n)||this.$vuepress.getVueComponent(n))?n:"Layout"}return"NotFound"}}},Ks=t(15),Xs=Object(Ks.a)(Ws,(function(){var n=this.$createElement;return(this._self._c||n)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(n,e,t){var r;switch(e){case"components":n[e]||(n[e]={}),Object.assign(n[e],t);break;case"mixins":n[e]||(n[e]=[]),(r=n[e]).push.apply(r,Object(Ii.a)(t));break;default:throw new Error("Unknown option name.")}}(Xs,"mixins",$s);var Qs=[{name:"v-a395e182",path:"/archives/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-a395e182").then(t)}},{path:"/archives/index.html",redirect:"/archives/"},{path:"/@pages/archivesPage.html",redirect:"/archives/"},{name:"v-61e6c4c2",path:"/categories/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-61e6c4c2").then(t)}},{path:"/categories/index.html",redirect:"/categories/"},{path:"/@pages/categoriesPage.html",redirect:"/categories/"},{name:"v-690ecebf",path:"/tags/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-690ecebf").then(t)}},{path:"/tags/index.html",redirect:"/tags/"},{path:"/@pages/tagsPage.html",redirect:"/tags/"},{name:"v-0e1d1ba8",path:"/blog/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-0e1d1ba8").then(t)}},{path:"/blog/index.html",redirect:"/blog/"},{name:"v-600665ec",path:"/blog/database/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-600665ec").then(t)}},{path:"/blog/database/index.html",redirect:"/blog/database/"},{name:"v-95764dbe",path:"/blog/database/common_details.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-95764dbe").then(t)}},{name:"v-61aeda36",path:"/blog/database/dbs_abstract.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-61aeda36").then(t)}},{name:"v-f89e89de",path:"/blog/database/high_performance_mysql.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-f89e89de").then(t)}},{name:"v-303c02c2",path:"/blog/database/mysql_index.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-303c02c2").then(t)}},{name:"v-e117a336",path:"/blog/database/mysql_runin_docker.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-e117a336").then(t)}},{name:"v-46965d82",path:"/blog/database/problem_with_using_myisam.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-46965d82").then(t)}},{name:"v-2c4fb4ae",path:"/blog/database/redis_manual.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-2c4fb4ae").then(t)}},{name:"v-742c98c4",path:"/blog/design/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-742c98c4").then(t)}},{path:"/blog/design/index.html",redirect:"/blog/design/"},{name:"v-f1ab1866",path:"/blog/design/algorithm_common.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-f1ab1866").then(t)}},{name:"v-5180c0ff",path:"/blog/design/algorithm_distributed_consensus_protocols.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-5180c0ff").then(t)}},{name:"v-31e2af82",path:"/blog/design/architecture_7principle_in_software.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-31e2af82").then(t)}},{name:"v-92792e82",path:"/blog/design/architecture_mvc_mvp_mvvm.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-92792e82").then(t)}},{name:"v-53f7dee4",path:"/blog/lang/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-53f7dee4").then(t)}},{path:"/blog/lang/index.html",redirect:"/blog/lang/"},{name:"v-d7f39702",path:"/blog/lang/cxx.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-d7f39702").then(t)}},{name:"v-3a68b8c2",path:"/blog/lang/cxx_traps.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-3a68b8c2").then(t)}},{name:"v-16fdda93",path:"/blog/lang/go.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-16fdda93").then(t)}},{name:"v-52f58a7d",path:"/blog/lang/go/gomod.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-52f58a7d").then(t)}},{name:"v-65f07e87",path:"/blog/lang/go/intrest_blogs.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-65f07e87").then(t)}},{name:"v-6a7f071f",path:"/blog/lang/go/recover&const_desc.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-6a7f071f").then(t)}},{name:"v-2c04e47f",path:"/blog/lang/go/slice_base.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-2c04e47f").then(t)}},{name:"v-0c0b8bdf",path:"/blog/lang/go/somethings_about_nil.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-0c0b8bdf").then(t)}},{name:"v-95a0b5de",path:"/blog/lang/js.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-95a0b5de").then(t)}},{name:"v-d3589f42",path:"/blog/lang/python/py__xx__.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-d3589f42").then(t)}},{name:"v-90b5b0c2",path:"/blog/lang/python/py_env.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-90b5b0c2").then(t)}},{name:"v-50b53767",path:"/blog/lang/python/utils.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-50b53767").then(t)}},{name:"v-718753e8",path:"/blog/network/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-718753e8").then(t)}},{path:"/blog/network/index.html",redirect:"/blog/network/"},{name:"v-570d3d9f",path:"/blog/network/grpc/grpc_connectivity_semantics_and_api.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-570d3d9f").then(t)}},{name:"v-b9611c0e",path:"/blog/network/grpc/grpc_interceptor_with_go.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-b9611c0e").then(t)}},{name:"v-e4b92d82",path:"/blog/network/grpc/grpc_over_http2.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-e4b92d82").then(t)}},{name:"v-75d8bb3f",path:"/blog/network/grpc/grpc_source_notes.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-75d8bb3f").then(t)}},{name:"v-32fca817",path:"/blog/network/http2/http2_in_go.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-32fca817").then(t)}},{name:"v-398f0321",path:"/blog/network/introduce_tcp_udp.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-398f0321").then(t)}},{name:"v-319db75f",path:"/blog/network/tcpip_mind_map.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-319db75f").then(t)}},{name:"v-5354451a",path:"/blog/platform/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-5354451a").then(t)}},{path:"/blog/platform/index.html",redirect:"/blog/platform/"},{name:"v-48032f1f",path:"/blog/platform/android/android_utils.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-48032f1f").then(t)}},{name:"v-485139ef",path:"/blog/platform/linux/linux_cmds.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-485139ef").then(t)}},{name:"v-29d661ff",path:"/blog/platform/linux/linux_mem_grows.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-29d661ff").then(t)}},{name:"v-4976d5df",path:"/blog/platform/windows/certificate.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-4976d5df").then(t)}},{name:"v-6a62161f",path:"/blog/platform/windows/make_cert.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-6a62161f").then(t)}},{name:"v-de8bce82",path:"/blog/platform/windows/pdb_structure.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-de8bce82").then(t)}},{name:"v-3682497f",path:"/blog/platform/windows/runtime_lib.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-3682497f").then(t)}},{name:"v-1d6a5088",path:"/blog/skills/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-1d6a5088").then(t)}},{path:"/blog/skills/index.html",redirect:"/blog/skills/"},{name:"v-091c8f7f",path:"/blog/skills/ai/anime_roam.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-091c8f7f").then(t)}},{name:"v-7103a3ed",path:"/blog/skills/ai/auc_roc.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-7103a3ed").then(t)}},{name:"v-5240d527",path:"/blog/skills/ai/bigdata_arch_theory.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-5240d527").then(t)}},{name:"v-5e7e6c7d",path:"/blog/skills/ai/derivation_of_PCA.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-5e7e6c7d").then(t)}},{name:"v-633581c2",path:"/blog/skills/ai/image_papers.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-633581c2").then(t)}},{name:"v-4b4d8c9f",path:"/blog/skills/ai/imgproc_base.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-4b4d8c9f").then(t)}},{name:"v-cc5c4542",path:"/blog/skills/ai/pytorch_base.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-cc5c4542").then(t)}},{name:"v-386d6b3f",path:"/blog/skills/ai/super_resolution.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-386d6b3f").then(t)}},{name:"v-0e5e6773",path:"/blog/skills/devops/docker-base.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-0e5e6773").then(t)}},{name:"v-35163721",path:"/blog/skills/devops/ipvs_in_k8s.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-35163721").then(t)}},{name:"v-75c42f42",path:"/blog/skills/devops/k8s_base.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-75c42f42").then(t)}},{name:"v-897ab682",path:"/blog/skills/devops/k8s_net_expose.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-897ab682").then(t)}},{name:"v-41809442",path:"/blog/skills/devops/k8s_net_mode.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-41809442").then(t)}},{name:"v-66696d37",path:"/blog/skills/devops/k8s_net_srv.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-66696d37").then(t)}},{name:"v-71519a9f",path:"/blog/skills/devops/k8s_rolling_update.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-71519a9f").then(t)}},{name:"v-6ca7651f",path:"/blog/skills/devops/opentracing_overview.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-6ca7651f").then(t)}},{name:"v-15864453",path:"/blog/skills/office/ms_shellink.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-15864453").then(t)}},{name:"v-a254d0c2",path:"/blog/skills/office/ole_office.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-a254d0c2").then(t)}},{name:"v-76ece9bf",path:"/blog/skills/office/ole_office_msoffcrypto.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-76ece9bf").then(t)}},{name:"v-34bb950d",path:"/blog/skills/pdf/pdf_struct.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-34bb950d").then(t)}},{name:"v-03728847",path:"/blog/skills/ui/inkscape_tutorial.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-03728847").then(t)}},{name:"v-cf80e5c2",path:"/blog/skills/ui/utils.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-cf80e5c2").then(t)}},{name:"v-7d6afdba",path:"/blog/skills/utils/charscter_and_coding.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-7d6afdba").then(t)}},{name:"v-dde8b282",path:"/blog/skills/utils/child_program.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-dde8b282").then(t)}},{name:"v-6cc2a996",path:"/blog/skills/utils/windows_wallpapers.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-6cc2a996").then(t)}},{name:"v-5f9b1d8c",path:"/blog/utilization/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-5f9b1d8c").then(t)}},{path:"/blog/utilization/index.html",redirect:"/blog/utilization/"},{name:"v-0dc92f7f",path:"/blog/utilization/ch_pinyin_tran.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-0dc92f7f").then(t)}},{name:"v-25c8ca33",path:"/blog/utilization/foo_apk_reverse.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-25c8ca33").then(t)}},{name:"v-0b34dfc2",path:"/blog/utilization/foo_batch_pulls.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-0b34dfc2").then(t)}},{name:"v-9af6bf82",path:"/blog/utilization/foo_consul.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-9af6bf82").then(t)}},{name:"v-ccf5212a",path:"/blog/utilization/foo_docker_jenkins_dind.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-ccf5212a").then(t)}},{name:"v-c6b25e82",path:"/blog/utilization/foo_k8s_downward_api.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-c6b25e82").then(t)}},{name:"v-019d6745",path:"/blog/utilization/foo_redis_cluster.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-019d6745").then(t)}},{name:"v-2fe5090c",path:"/blog/utility/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-2fe5090c").then(t)}},{path:"/blog/utility/index.html",redirect:"/blog/utility/"},{path:"/blog/xnote/",redirect:"/blog/utility/"},{name:"v-a6752c4a",path:"/blog/xnote/about_acknowledge.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-a6752c4a").then(t)}},{name:"v-0dd9b182",path:"/blog/xnote/about_heart_and_mind.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-0dd9b182").then(t)}},{name:"v-5d28d3ff",path:"/blog/xnote/about_pm.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-5d28d3ff").then(t)}},{name:"v-d5db50c2",path:"/blog/xnote/about_refactor.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-d5db50c2").then(t)}},{name:"v-f76e517a",path:"/blog/xnote/about_skill_communication.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-f76e517a").then(t)}},{name:"v-15f1fc67",path:"/blog/xnote/about_stock.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-15f1fc67").then(t)}},{name:"v-8cf30266",path:"/blog/xnote/interesting_xxx.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-8cf30266").then(t)}},{name:"v-455450db",path:"/blog/xnote/rnote_deep_mind.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-455450db").then(t)}},{name:"v-162635f9",path:"/blog/xnote/rnote_geekbang_architecture.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-162635f9").then(t)}},{name:"v-680803e5",path:"/blog/xnote/rnote_geekbang_devops.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-680803e5").then(t)}},{name:"v-155cc502",path:"/blog/xnote/rnote_google_skill_level.html",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-155cc502").then(t)}},{name:"v-16de7e50",path:"/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-16de7e50").then(t)}},{path:"/index.html",redirect:"/"},{name:"v-02e3228c",path:"/more/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-02e3228c").then(t)}},{path:"/more/index.html",redirect:"/more/"},{name:"v-4bfbd5e5",path:"/more/about/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-4bfbd5e5").then(t)}},{path:"/more/about/index.html",redirect:"/more/about/"},{path:"/more/about.html",redirect:"/more/about/"},{name:"v-19beb85e",path:"/more/favorites/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-19beb85e").then(t)}},{path:"/more/favorites/index.html",redirect:"/more/favorites/"},{path:"/more/favorites.html",redirect:"/more/favorites/"},{name:"v-5b31b7d6",path:"/more/friends/",component:Xs,beforeEnter:function(n,e,t){Wi("Layout","v-5b31b7d6").then(t)}},{path:"/more/friends/index.html",redirect:"/more/friends/"},{path:"/more/friends.html",redirect:"/more/friends/"},{path:"*",component:Xs}],Ys={title:"",description:"",base:"/blog/",headTags:[["link",{rel:"icon",href:"/blog/img/favicon.ico"}],["meta",{name:"keywords",content:"博客,全栈,技术文档,学习,面试,Go,C/C++,Python,Markdown"}],["meta",{name:"theme-color",content:"#11a8cd"}]],pages:[{title:"归档",frontmatter:{archivesPage:!0,title:"归档",permalink:"/archives/",article:!1},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-a395e182",path:"/archives/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/03/31, 13:54:53",lastUpdatedTimestamp:1648734893e3},{title:"分类",frontmatter:{categoriesPage:!0,title:"分类",permalink:"/categories/",article:!1},regularPath:"/@pages/categoriesPage.html",relativePath:"@pages/categoriesPage.md",key:"v-61e6c4c2",path:"/categories/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/03/31, 13:54:53",lastUpdatedTimestamp:1648734893e3},{title:"标签",frontmatter:{tagsPage:!0,title:"标签",permalink:"/tags/",article:!1},regularPath:"/@pages/tagsPage.html",relativePath:"@pages/tagsPage.md",key:"v-690ecebf",path:"/tags/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/03/31, 13:54:53",lastUpdatedTimestamp:1648734893e3},{title:"blog",frontmatter:{published:!0,title:"blog",description:"jiao's blog",keywords:["jiao's blog"],categories:["blog"],permalink:"/blog/",date:"2020-04-13T00:00:00.000Z",tags:[null]},regularPath:"/blog/",relativePath:"blog/README.md",key:"v-0e1d1ba8",path:"/blog/",headers:[{level:2,title:"Part I -  Design",slug:"part-i-design",normalizedTitle:"part i -  design",charIndex:null},{level:2,title:"Part II -  Skills",slug:"part-ii-skills",normalizedTitle:"part ii -  skills",charIndex:null},{level:2,title:"Part III -  Utilization",slug:"part-iii-utilization",normalizedTitle:"part iii -  utilization",charIndex:null},{level:2,title:"Part IV -  Lang",slug:"part-iv-lang",normalizedTitle:"part iv -  lang",charIndex:null},{level:2,title:"Part V -  Platform",slug:"part-v-platform",normalizedTitle:"part v -  platform",charIndex:null},{level:2,title:"Part VI -  Database",slug:"part-vi-database",normalizedTitle:"part vi -  database",charIndex:null},{level:2,title:"Part VII -  Network",slug:"part-vii-network",normalizedTitle:"part vii -  network",charIndex:null},{level:2,title:"Part VIII -  Xnote",slug:"part-viii-xnote",normalizedTitle:"part viii -  xnote",charIndex:null}],headersStr:"Part I -  Design Part II -  Skills Part III -  Utilization Part IV -  Lang Part V -  Platform Part VI -  Database Part VII -  Network Part VIII -  Xnote",content:"# BLOG\n\n\n# Part I - Design\n\n * 目录\n\n\n# Part II - Skills\n\n * 目录\n * Chapter - Office\n * Chapter - Ui\n * Chapter - Ai\n * Chapter - Utils\n * Chapter - Pdf\n * Chapter - Devops\n\n\n# Part III - Utilization\n\n * 目录\n\n\n# Part IV - Lang\n\n * 目录\n * Chapter - Python\n * Chapter - Go\n\n\n# Part V - Platform\n\n * 目录\n * Chapter - Android\n * Chapter - Linux\n * Chapter - Windows\n\n\n# Part VI - Database\n\n * 目录\n\n\n# Part VII - Network\n\n * 目录\n * Chapter - Http2\n * Chapter - Grpc\n\n\n# Part VIII - Xnote\n\n * 目录",normalizedContent:"# blog\n\n\n# part i - design\n\n * 目录\n\n\n# part ii - skills\n\n * 目录\n * chapter - office\n * chapter - ui\n * chapter - ai\n * chapter - utils\n * chapter - pdf\n * chapter - devops\n\n\n# part iii - utilization\n\n * 目录\n\n\n# part iv - lang\n\n * 目录\n * chapter - python\n * chapter - go\n\n\n# part v - platform\n\n * 目录\n * chapter - android\n * chapter - linux\n * chapter - windows\n\n\n# part vi - database\n\n * 目录\n\n\n# part vii - network\n\n * 目录\n * chapter - http2\n * chapter - grpc\n\n\n# part viii - xnote\n\n * 目录",charsets:{cjk:!0}},{title:"Database",frontmatter:{published:!0,title:"Database",description:"database 相关知识汇总",keywords:[""],categories:["database"],permalink:"/blog/database/",date:"2020-04-14T00:00:00.000Z",tags:[null]},regularPath:"/blog/database/",relativePath:"blog/database/README.md",key:"v-600665ec",path:"/blog/database/",headersStr:null,content:"# DATABASE\n\n * Docker 中运行 Mysql\n * High Performance Mysql, 3Th Edition 阅读\n * 批量写入造成Mysql访问慢问题\n * Mysql 中的索引\n * Db 抽象理解\n * Redis 手册\n * 常见 Db 基础",normalizedContent:"# database\n\n * docker 中运行 mysql\n * high performance mysql, 3th edition 阅读\n * 批量写入造成mysql访问慢问题\n * mysql 中的索引\n * db 抽象理解\n * redis 手册\n * 常见 db 基础",charsets:{cjk:!0}},{title:"常见 DB 基础",frontmatter:{title:"常见 DB 基础",date:"2020-04-21T00:00:00.000Z",description:"常见 DB 基础知识",categories:["blog","database"],tags:[null],permalink:null},regularPath:"/blog/database/common_details.html",relativePath:"blog/database/common_details.md",key:"v-95764dbe",path:"/blog/database/common_details.html",headers:[{level:2,title:"Mongo",slug:"mongo",normalizedTitle:"mongo",charIndex:15},{level:2,title:"Mysql",slug:"mysql",normalizedTitle:"mysql",charIndex:193}],headersStr:"Mongo Mysql",content:"# 常见 DB 基础\n\n\n# Mongo\n\n * cmds\n\n    db.happygame_sdk.test.getIndexes();\n    db.happygame_sdk.test.explain(\"executionStats\").find({'playerid':'ad3e5eb8-a03c-5011-8f2d-ce32c2a7ab31'});\n\n\n1\n2\n\n\n\n# Mysql\n\n * 了解数据库的一些基本理论知识：\n   * 数据的存储格式 (堆组织表 vs 聚簇索引表)\n   * 并发控制协议 (MVCC vs Lock-Based CC)\n   * Two-Phase Locking\n   * 数据库的隔离级别定义 (Isolation Level)\n * 了解SQL本身的执行计划\n   * 主键扫描 vs 唯一键扫描 vs 范围扫描 vs 全表扫描\n   * innodb index types\n * 了解数据库本身的一些实现细节\n   * 过滤条件提取\n     * Index Key/Index Filter/Table Filter\n     * where条件提取与应用浅析\n   * Index Condition Pushdown\n   * Semi-Consistent Read\n * 查看数据库空间占用：\n\n    SELECT CONCAT(table_schema,'.',table_name) AS 'Table Name', \n        CONCAT(ROUND(table_rows/1000000,4),'M') AS 'Number of Rows', \n        CONCAT(ROUND(data_length/(1024*1024*1024),4),'G') AS 'Data Size', \n        CONCAT(ROUND(index_length/(1024*1024*1024),4),'G') AS 'Index Size',\n        CONCAT(ROUND((data_length+index_length)/(1024*1024*1024),4),'G') AS'Total'\n    FROM information_schema.TABLES WHERE table_schema LIKE 'weixin_game' order by Total desc;\n\n\n1\n2\n3\n4\n5\n6\n\n * 锁\n   * 乐观锁、悲观锁(读锁、互斥锁)\n   * mysql 死锁分析\n     * Mysql查询语句使用select.. for update导致的数据库死锁分析",normalizedContent:"# 常见 db 基础\n\n\n# mongo\n\n * cmds\n\n    db.happygame_sdk.test.getindexes();\n    db.happygame_sdk.test.explain(\"executionstats\").find({'playerid':'ad3e5eb8-a03c-5011-8f2d-ce32c2a7ab31'});\n\n\n1\n2\n\n\n\n# mysql\n\n * 了解数据库的一些基本理论知识：\n   * 数据的存储格式 (堆组织表 vs 聚簇索引表)\n   * 并发控制协议 (mvcc vs lock-based cc)\n   * two-phase locking\n   * 数据库的隔离级别定义 (isolation level)\n * 了解sql本身的执行计划\n   * 主键扫描 vs 唯一键扫描 vs 范围扫描 vs 全表扫描\n   * innodb index types\n * 了解数据库本身的一些实现细节\n   * 过滤条件提取\n     * index key/index filter/table filter\n     * where条件提取与应用浅析\n   * index condition pushdown\n   * semi-consistent read\n * 查看数据库空间占用：\n\n    select concat(table_schema,'.',table_name) as 'table name', \n        concat(round(table_rows/1000000,4),'m') as 'number of rows', \n        concat(round(data_length/(1024*1024*1024),4),'g') as 'data size', \n        concat(round(index_length/(1024*1024*1024),4),'g') as 'index size',\n        concat(round((data_length+index_length)/(1024*1024*1024),4),'g') as'total'\n    from information_schema.tables where table_schema like 'weixin_game' order by total desc;\n\n\n1\n2\n3\n4\n5\n6\n\n * 锁\n   * 乐观锁、悲观锁(读锁、互斥锁)\n   * mysql 死锁分析\n     * mysql查询语句使用select.. for update导致的数据库死锁分析",charsets:{cjk:!0}},{title:"DB 抽象理解",frontmatter:{title:"DB 抽象理解",date:"2020-04-21T00:00:00.000Z",description:"常见db的抽象理解",categories:["blog","database"],tags:[null],permalink:null},regularPath:"/blog/database/dbs_abstract.html",relativePath:"blog/database/dbs_abstract.md",key:"v-61aeda36",path:"/blog/database/dbs_abstract.html",headers:[{level:2,title:"db 详解",slug:"db-详解",normalizedTitle:"db 详解",charIndex:2},{level:2,title:"redis 使用",slug:"redis-使用",normalizedTitle:"redis 使用",charIndex:2551},{level:2,title:"mysql",slug:"mysql",normalizedTitle:"mysql",charIndex:1306},{level:2,title:"mongo",slug:"mongo",normalizedTitle:"mongo",charIndex:1335},{level:2,title:"END",slug:"end",normalizedTitle:"end",charIndex:9279}],headersStr:"db 详解 redis 使用 mysql mongo END",content:"# db 详解\n\n * 持久化\n   * 数据镜像(物理备份) 或 修改记录(逻辑备份)\n   * 重点\n     * 自动持久化时，其发生的时机: 一般在在db命令之后, 返回调用方之前\n     * 步骤：buffer ---\x3e 文件 ---\x3e 刷新文件到磁盘\n       * 每个环节都可以有自己的策略选择时机，平衡性能和完整性\n         * 命令执行完成并写入buffer后返回时机的策略控制:\n           * 不保证写入文件\n           * 保证写入文件\n           * 保证文件刷入磁盘\n         * 刷盘策略(linux的fsync命令)\n           * 每次修改命令都刷盘\n           * 每N秒或N个操作刷盘\n           * 不主动刷盘，依赖操作系统的刷盘策略\n     * 注意: 持久化时是否会阻塞数据库操作\n * 高可用\n   * 主从结构\n   * 重点\n     * 作用\n       * 热备\n       * 读写分离，均衡数据库负载\n     * 媒介\n       * 操作记录落盘后再同步(文件)\n       * 操作记录不落盘就同步(内存)\n     * 方式(平衡数据一致性和性能)\n       * 异步复制\n         * 主节点用户命令完成时，只保证数据写入媒介\n         * 高延迟和高性能。需要, 主从通过周期交流复制进度, 来保证主从数据不一致性的幅度\n       * 同步复制\n         * 主节点用户命令完成时，保证数据已经被所有从库同步完成\n       * 半同步复制\n         * 主节点用户命令完成时，保证数据已经被部分从库存储，但不保证从库完成同步\n     * 逻辑\n       * 全量同步、增量同步\n     * 主从切换\n       * 手动\n         * 防止脑裂发生、保证新主节点数据最新\n       * 自动\n         * 通过一致性协议进行决策：主节点当前状态、选主结果\n         * 一般要处理:\n           * 新集群数据最新和一致性保证\n           * 监控节点了解其它所有节点的存活、监控节点之间信息同步、监控节点获取(所有服务节点的)服务状态\n   * 难点\n     * 主从数据一致性\n       * 网络延迟、主节点高流量、从节点性能不足(可以考虑从库并发应用同步到的数据)等等\n * 高性能\n   * 方式\n     * 通过主从结构, 实现读写分离\n     * cluster:\n       * 一致性hash 或 划分slot\n       * sharding 结合数据和控制分离 形成去中心化集群\n   * 问题\n     * 如，redis 集群multi-key操作不支持或者支持不够\n   * 注意\n     * 性能测试(工具)\n     * 数据库锁的问题\n       * redis 单线程, 无锁\n       * mysql 有读写锁, 又分表锁、行锁\n       * mongo 有读写锁, 又分库全局锁、库锁、集合锁\n * 缓存\n   * 缓存穿透: 查询一定不存在的数据时, 查询回源db。流量大(大量的不存在数据请求)时db被压垮\n     * 布隆过滤器、缓存空值(生命周期短)\n   * 缓存击穿：缓存一种非常“热点”的数据，在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，瞬间把后端DB压垮\n     * 互斥锁(mutex key)、不过期(但后台刷新)\n   * 缓存雪崩：设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩\n     * 多副本，并且每个副本设置不同的过期时间(在指定范围内随机)\n * 关系型数据库\n   * 数据库设计三大范式：\n     * 第一范式(1NF)：数据表中的每一列必须是不可拆分的最小单元，也就是确保每一列的原子性\n     * 第二范式(2NF)：满足1NF后，要求表中的所有列都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情\n     * 第三范式(3NF)：必须先满足2NF，要求：表中的每一列只与主键直接相关而不是间接相关，(表中的每一列只能依赖于主键)\n   * 事务(transaction)\n     * ACID ：保证事务是正确可靠的，所必须具备的四个特性：原子性(atomicity，或称不可分割性)、一致性(consistency)、隔离性(isolation，又称独立性)、持久性(durability)。\n     * 事务的隔离级别 : 图解脏读、不可重复读、幻读问题\n       * read uncommitted\n         * 事务A修改数据a, 事务B读取数据a ,,,,,, B 读取到事务 A 已修改但未提交的数据 ,,,,,, 脏读\n       * read committed\n         * 事务A修改数据a, 事务B在A操作之前之后分别读取数据a ,,,,,, B 读到的两次数据不一致 ,,,,,, 不可重复读\n       * repeatable read\n         * 事务A插入(或删除)数据a, 事务B在A操作之前之后分别读取数据a ,,,,,, B 会发现数据a忽在忽不在 ,,,,,, 幻读(虚读)\n       * serializable\n         * 可以避免所有的问题\n     * note\n       * 上述四种隔离级别是由弱到强, 隔离级别越强性能受到的影响越大\n       * 可以在低隔离级别上，配合锁的使用达到几乎避免幻读的效果\n       * 一般的DBMS系统，都使用Read-Comitted作为默认隔离级别，如Oracle、SQL Server等，而MySQL却使用Read-Repeatable\n\n\n# redis 使用\n\n# 持久化\n\n * RDB\n   * 一个非常紧凑(compact)的文件，保存了 Redis 在某个时间点上的数据集。\n   * 父进程在保存RDB时fork一个子进程，然后由子进程来处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。\n * AOF(append-only file)\n   * AOF 文件的体积通常要大于 RDB 文件的体积\n   * 写入AOF文件: aof_buf ---\x3e AOF文件 ---\x3e 刷新到磁盘\n     * 推荐的刷盘策略：每秒 fsync 一次：足够快(和使用 RDB 持久化差不多)，并且在故障时只会丢失 1 秒钟的数据。\n * RDB + AOF\n   * redis5.0之后新增, 需要开启：aof-use-rdb-preamble\n\n# 高可用\n\n * 主从结构(同步使用：slaveof 命令)\n   * Redis使用默认的异步复制\n     * 是绝大多数 Redis 用例的自然复制模式。\n     * 包括：全量同步 和 增量同步\n       * 在Slave启动并连接到Master之后，它将主动发送一个SYNC命令，进行全量复制。后续采用增量同步，只复制最新数据。\n     * 注意，从 Redis 2.8 开始，从服务器会以每秒一次的频率向主服务器报告复制流(replication stream)的处理进度。\n   * 解决数据丢失: (异步复制和脑裂导致)\n     \n         有2个参数：\n         min-slaves-to-write 1\n         min-slaves-max-lag 10\n     \n     \n     1\n     2\n     3\n     \n     * 要求至少有1个slave，数据复制和ACK(同步)的延迟不能超过10秒，如果说一旦所有的slave，数据复制和ACK的延迟都超过了10秒钟，那么master就不会再接收任何请求了，上面两个配置可以减少异步复制和脑裂导致的数据丢失。\n       * 如果主从同步差距过大，则master就停止数据接收，止损\n       * 如果有master处于脑裂状态，则如果它跟任何一个slave丢了连接，在10秒后发现没有slave给自己ACK，那么就拒绝客户端新的写请求，因此在脑裂场景下，最多丢失10秒的数据。\n * 著名实现：sentinel 模式\n   * 实现了自动化的系统监控和故障恢复功能。只能保证redis集群的高可用性, 不会保证数据零丢失。\n   * 选举领头哨兵的过程使用了 Raft算法\n   * 和主库的连接建立完成后，哨兵会定时执行下面3个操作。\n     * 每10秒向主库和从库发送info命令；\n       * 以获得当前数据库的相关信息。从而实现新节点(包括从库)的自动发现。\n     * 每2秒向主库和从库的\"sentinel:hello\"频道发送自己的信息\n       * (就是说哨兵不但订阅了该频道，而且还会向该频道发布信息，以使其他哨兵得到自己的信息)\n     * 每1秒向主库、从库和其他哨兵节点发送ping命令。\n\n * 注意\n   * redis 的代码里是: 先执行命令，再aof + sync，然后再返回客户端\n\n# 高性能\n\n * 客户端\n   * 单线程，所以重点在 rtt\n   * pipeline 和 multi & exec\n * 服务端\n   * 集群：\n     * 一致性hash\n     * 一致性hash+代理\n     * redis-cluster\n       * 问题：redis-cluster对multi-key操作支持不够，其它方式不支持。\n       * redis-cluster 默认并不支持读写分离\n       * 节点之间通过gossip协议交换状态信息\n       * 无中心架构, 数据通过异步复制, 不保证数据的强一致性\n * 测试工具\n   * redis-benchmark\n\n----------------------------------------\n\n----------------------------------------\n\n\n# mysql\n\n# 持久化\n\n * mysqldump\n   * 参数: --lock-tables, 锁表\n   * 注意: 默认情况下，不会阻塞数据库，但是会造成流量突增\n\n# 高可用\n\n * 原则\n   * 我们在考虑MySQL数据库的高可用架构时，主要考虑如下几方面：\n     * 如果数据库发生了宕机或者意外中断等故障，尽可能的减少停机时间，保证业务不会因为数据库的故障而中断。\n     * 用作备份、只读副本等功能的非主节点的数据应该和主节点的数据实时或者最终保持一致。\n     * 当业务发生数据库切换时，切换前后的数据库内容应当一致，不会因为数据缺失或者数据不一致而影响业务。\n   * reference: [https://dbaplus.cn/news-11-1127-1.html]\n * 数据完整性\n   * redo log 和 undo log\n * 主从同步(Master-Slave Replication)\n   * 要求\n     * 主从数据库版本一致\n   * 原理\n     * 主库开启 binlog, 在有数据库修改操作时(只记录更改操作)，更新binlog文件\n       * 写binlog文件：用户commit后同步写入InnoDB Log Buffer ---\x3e binlog文件 ---\x3e 刷新到磁盘\n     * 从库通过start slave开启复制功能：从库异步读取主库的 binlog 写入自己的 relay log, 并另起一线程将其重放到mysql数据库。\n   * 方案\n     * MySQL Replication\n       * MySQL官方提出的主从同步方案。异步复制: 保证binlog写入文件, 不保证binlog传输给从库\n       * 问题\n         * 主库宕机后，数据可能丢失\n         * 主从复制延迟问题\n           * 一个主库的从库太多、从库硬件比主库差、主从库之间的网络延迟，导致复制延迟。\n           * 主从复制的设计问题、主库读写压力大 ：主库数据太多,从库只有一个thread来不及复制\n       * 方案\n         * 半同步复制 : 解决数据丢失的问题\n         * 并行复制 : 解决从库复制延迟的问题\n           * 社区版5.6新增。是指从库多线程并行应用库级别binlog，同一个库数据更改还是串行(5.7版并行复制基于事务组)设置。\n     * mysql semi-sync(半同步复制)\n       * google 提出, 5.5集成到mysql, 以插件的形式存在, 需要单独安装\n       * 确保事务提交后binlog至少传输到一个从库(写入relay log), 但不保证从库应用完这个事务的binlog (应用relay log)\n     * 同步复制\n       * google 提出。不仅要求所有Slave收到binlog数据, 还要求所有Slave将数据commit到数据库中\n   * 主从切换\n     * MySQL Replication的主从切换需要人工介入判断，同时需要Slave的replaylog提交完毕，故障恢复时间会比较长。\n     * MHA(MySQL-master-ha) : 目前广泛使用\n       * 目标\n         * 自动实现主实例宕机后，从机切换为主，并尽量降低切换时延(通常在10-30s内切换完成)。\n       * 特性\n         * MHA对MySQL的主从复制集群非常友好，没有对集群做任何侵入性的修改。\n         * 从机切换为主时，由MHA保证在切换过程中的数据一致性。\n           * 在主实例宕机后，MHA可以自动的判断主从复制集群中哪个从实例的relaylog是最新的，并将其差异log\"应用\"到其余的从实例中，从而保证每个实例的数据一致。\n           * 通常情况下，MHA需要10s左右检测主实例异常，并将主实例关闭从而避免脑裂。然后再用10s左右将差异的log event同步，并启用新的Master。整个MHA的RTO时间大约在30s。\n     * MySQL Cluster : 官方方案\n       * 一个高度可扩展的，兼容ACID事务的实时数据库，基于分布式架构不存在单点故障。支持自动水平扩容，能做自动的读写负载均衡\n       * 控制面和数据面分离\n         * application ---\x3e mysql server(存储表结构) ---\x3e NDB Cluster(数据节点, NDB存储服务器, 通过 ndb_mgmd 管理)\n           * MySQL Cluster的 Cluster 部分(即 NDB Cluster)可独立于MySQL服务器进行配置。\n\n# 高性能\n\n * 锁\n   * 读锁、写锁(表锁、行锁)\n     * 只有在使用索引时才会使用行锁，但当符合条件的数据比较多时会使用表锁\n     * 在select时，都会加上读锁\n * 慢查询\n   * 相关参数\n     \n     参数：(可以通过配置文件或mysql的全局变量设置)\n       mysql> set global slow_query_log='ON'; # slow_query_log  ：是否开启慢查询日志功能(必填)\n       mysql> set global long_query_time=1;   # long_query_time ：超过设定值将被视作慢查询，并记录至慢查询日志文件中(必填)\n       mysql> set global slow_query_log_file='slow.log'; # log-slow-queries ：慢查询日志文件(不可填)，自动在 /data 创建一个 [hostname]-slow.log 文件\n     查看：\n       show variables like 'long%';\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     \n   * 指令: EXPLAIN\n     * 在select语句前加上explain，可以了解SQL执行的详细状态\n   * 慢查询日志分析工具\n     * mysqldumpslow\n     * mysqlsla\n * 测试工具\n   * mysqlslap\n     * 参数：--only-print 打印测试语,不实际执行。\n     * 注意：使用 -a 自动测试时，会drop schema。\n * reference\n   * <高性能MySQL>\n   * 状态查看\n   \n       mysql> set global general_log=on; # 打开general log\n       mysql> show global status;         # 列出MySQL服务器运行各种状态值:\n       mysql> show variables;             # 查询MySQL服务器配置信息语句：\n       mysql> show variables like '%slow%';             # 慢查询情况\n       mysql> show global status like 'table_locks%';   # 表锁情况\n       可以查看设置的最大连接数 和 已经使用的最大连接数, 以调优\n       可以查看参数 table_open_cache, 它控制所有 mysql 执行线程可打开表缓存的数量, 以调优\n       可以查看参数 thread_cache_size, 它控制 mysql 缓存客户端线程的数量, 以调优。可以通过计算线程 cache 的失效率 threads_created / connections 来衡量 thread_cahce_size 的设置是否合适，该值越接近 1，说明线程 cache 命中率越低。\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   \n   * mysql表大时，可以进行分表和表分区、以及分库\n     * 分库分表存在以下问题：\n       * 事务问题\n       * 跨节点Join 和 count,order by,group by以及聚合函数问题\n       * 数据迁移，容量规划，扩容等问题\n\n----------------------------------------\n\n----------------------------------------\n\n\n# mongo\n\n# 持久化\n\n * mongodump & mongorestore\n * mongoexport & mongoimport\n\n# 高可用\n\n * Replica Set\n   * 是mongod的实例集合, 包含三类角色: Primary、Secondary、Arbiter(仲裁者)\n   * 主从同步方式\n     * 两个步骤\n       * intial sync，可以理解为全量同步\n       * replication，追同步源的oplog，可以理解为增量同步, 会不断拉取主上新产生的oplog并重放\n         * 三类线程完成replication工作\n           * producer thread，不断的从同步源上拉取oplog，并加入到一个BlockQueue的队列里。\n           * replBatcher thread，负责逐个从producer thread的队列里取出oplog，并放到自己维护的队列里。要保持顺序性。\n           * sync线程将replBatcher thread的队列分发到默认16个replWriter线程，由replWriter来最终重放每条oplog。\n   * 注意：mongo的oplog具有幂等性\n\n# 高性能\n\n * Cluster\n   * 使用Sharding分片技术: client ---\x3e router(mongos) ---\x3e shard(每个shard节点都是一个replica set)\n * 锁\n   * 在 2.2 版本以前，mongod 只有全局锁；在 2.2 版本开始，库级锁;\n     * 粒度：库 ---\x3e collect ---\x3e document\n     * 建索引就是一个容易引起长时间写锁的问题。如果集合的数据量很大，建索引通常要花比较长时间，特别容易引起问题。\n       * MongoDB 提供了两种建索引的访问\n         * 一种是 background 方式: db.posts.ensureIndex({user_id: 1}, {background: 1})\n         * 一种是非 background 方式: db.posts.ensureIndex({user_id: 1})\n\n# utility\n\n * Schema Explorer\n   * [https://studio3t.com/knowledge-base/articles/schema-explorer/]\n\n----------------------------------------\n\n----------------------------------------\n\n\n# END\n\n * sharding\n   * 当数据量比较大的时候，我们需要把数据分片运行在不同的机器中，以降低CPU、内存和IO的压力，Sharding就是数据库分片技术。\n * ORM(Object-Relational Mapping)\n   * mybatis\n * MYSQL性能优化的最佳20+条经验]\n   * https://www.cnblogs.com/zhouyusheng/p/8038224.html\n     * EXPLAIN、PROCEDURE ANALYSE()\n * MVCC\n   * mysql 的 MVCC ：是一种多版本并发控制机制",normalizedContent:"# db 详解\n\n * 持久化\n   * 数据镜像(物理备份) 或 修改记录(逻辑备份)\n   * 重点\n     * 自动持久化时，其发生的时机: 一般在在db命令之后, 返回调用方之前\n     * 步骤：buffer ---\x3e 文件 ---\x3e 刷新文件到磁盘\n       * 每个环节都可以有自己的策略选择时机，平衡性能和完整性\n         * 命令执行完成并写入buffer后返回时机的策略控制:\n           * 不保证写入文件\n           * 保证写入文件\n           * 保证文件刷入磁盘\n         * 刷盘策略(linux的fsync命令)\n           * 每次修改命令都刷盘\n           * 每n秒或n个操作刷盘\n           * 不主动刷盘，依赖操作系统的刷盘策略\n     * 注意: 持久化时是否会阻塞数据库操作\n * 高可用\n   * 主从结构\n   * 重点\n     * 作用\n       * 热备\n       * 读写分离，均衡数据库负载\n     * 媒介\n       * 操作记录落盘后再同步(文件)\n       * 操作记录不落盘就同步(内存)\n     * 方式(平衡数据一致性和性能)\n       * 异步复制\n         * 主节点用户命令完成时，只保证数据写入媒介\n         * 高延迟和高性能。需要, 主从通过周期交流复制进度, 来保证主从数据不一致性的幅度\n       * 同步复制\n         * 主节点用户命令完成时，保证数据已经被所有从库同步完成\n       * 半同步复制\n         * 主节点用户命令完成时，保证数据已经被部分从库存储，但不保证从库完成同步\n     * 逻辑\n       * 全量同步、增量同步\n     * 主从切换\n       * 手动\n         * 防止脑裂发生、保证新主节点数据最新\n       * 自动\n         * 通过一致性协议进行决策：主节点当前状态、选主结果\n         * 一般要处理:\n           * 新集群数据最新和一致性保证\n           * 监控节点了解其它所有节点的存活、监控节点之间信息同步、监控节点获取(所有服务节点的)服务状态\n   * 难点\n     * 主从数据一致性\n       * 网络延迟、主节点高流量、从节点性能不足(可以考虑从库并发应用同步到的数据)等等\n * 高性能\n   * 方式\n     * 通过主从结构, 实现读写分离\n     * cluster:\n       * 一致性hash 或 划分slot\n       * sharding 结合数据和控制分离 形成去中心化集群\n   * 问题\n     * 如，redis 集群multi-key操作不支持或者支持不够\n   * 注意\n     * 性能测试(工具)\n     * 数据库锁的问题\n       * redis 单线程, 无锁\n       * mysql 有读写锁, 又分表锁、行锁\n       * mongo 有读写锁, 又分库全局锁、库锁、集合锁\n * 缓存\n   * 缓存穿透: 查询一定不存在的数据时, 查询回源db。流量大(大量的不存在数据请求)时db被压垮\n     * 布隆过滤器、缓存空值(生命周期短)\n   * 缓存击穿：缓存一种非常“热点”的数据，在某个时间点过期的时候，恰好在这个时间点对这个key有大量的并发请求过来，瞬间把后端db压垮\n     * 互斥锁(mutex key)、不过期(但后台刷新)\n   * 缓存雪崩：设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到db，db瞬时压力过重雪崩\n     * 多副本，并且每个副本设置不同的过期时间(在指定范围内随机)\n * 关系型数据库\n   * 数据库设计三大范式：\n     * 第一范式(1nf)：数据表中的每一列必须是不可拆分的最小单元，也就是确保每一列的原子性\n     * 第二范式(2nf)：满足1nf后，要求表中的所有列都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情\n     * 第三范式(3nf)：必须先满足2nf，要求：表中的每一列只与主键直接相关而不是间接相关，(表中的每一列只能依赖于主键)\n   * 事务(transaction)\n     * acid ：保证事务是正确可靠的，所必须具备的四个特性：原子性(atomicity，或称不可分割性)、一致性(consistency)、隔离性(isolation，又称独立性)、持久性(durability)。\n     * 事务的隔离级别 : 图解脏读、不可重复读、幻读问题\n       * read uncommitted\n         * 事务a修改数据a, 事务b读取数据a ,,,,,, b 读取到事务 a 已修改但未提交的数据 ,,,,,, 脏读\n       * read committed\n         * 事务a修改数据a, 事务b在a操作之前之后分别读取数据a ,,,,,, b 读到的两次数据不一致 ,,,,,, 不可重复读\n       * repeatable read\n         * 事务a插入(或删除)数据a, 事务b在a操作之前之后分别读取数据a ,,,,,, b 会发现数据a忽在忽不在 ,,,,,, 幻读(虚读)\n       * serializable\n         * 可以避免所有的问题\n     * note\n       * 上述四种隔离级别是由弱到强, 隔离级别越强性能受到的影响越大\n       * 可以在低隔离级别上，配合锁的使用达到几乎避免幻读的效果\n       * 一般的dbms系统，都使用read-comitted作为默认隔离级别，如oracle、sql server等，而mysql却使用read-repeatable\n\n\n# redis 使用\n\n# 持久化\n\n * rdb\n   * 一个非常紧凑(compact)的文件，保存了 redis 在某个时间点上的数据集。\n   * 父进程在保存rdb时fork一个子进程，然后由子进程来处理接下来的所有保存工作，父进程无须执行任何磁盘 i/o 操作。\n * aof(append-only file)\n   * aof 文件的体积通常要大于 rdb 文件的体积\n   * 写入aof文件: aof_buf ---\x3e aof文件 ---\x3e 刷新到磁盘\n     * 推荐的刷盘策略：每秒 fsync 一次：足够快(和使用 rdb 持久化差不多)，并且在故障时只会丢失 1 秒钟的数据。\n * rdb + aof\n   * redis5.0之后新增, 需要开启：aof-use-rdb-preamble\n\n# 高可用\n\n * 主从结构(同步使用：slaveof 命令)\n   * redis使用默认的异步复制\n     * 是绝大多数 redis 用例的自然复制模式。\n     * 包括：全量同步 和 增量同步\n       * 在slave启动并连接到master之后，它将主动发送一个sync命令，进行全量复制。后续采用增量同步，只复制最新数据。\n     * 注意，从 redis 2.8 开始，从服务器会以每秒一次的频率向主服务器报告复制流(replication stream)的处理进度。\n   * 解决数据丢失: (异步复制和脑裂导致)\n     \n         有2个参数：\n         min-slaves-to-write 1\n         min-slaves-max-lag 10\n     \n     \n     1\n     2\n     3\n     \n     * 要求至少有1个slave，数据复制和ack(同步)的延迟不能超过10秒，如果说一旦所有的slave，数据复制和ack的延迟都超过了10秒钟，那么master就不会再接收任何请求了，上面两个配置可以减少异步复制和脑裂导致的数据丢失。\n       * 如果主从同步差距过大，则master就停止数据接收，止损\n       * 如果有master处于脑裂状态，则如果它跟任何一个slave丢了连接，在10秒后发现没有slave给自己ack，那么就拒绝客户端新的写请求，因此在脑裂场景下，最多丢失10秒的数据。\n * 著名实现：sentinel 模式\n   * 实现了自动化的系统监控和故障恢复功能。只能保证redis集群的高可用性, 不会保证数据零丢失。\n   * 选举领头哨兵的过程使用了 raft算法\n   * 和主库的连接建立完成后，哨兵会定时执行下面3个操作。\n     * 每10秒向主库和从库发送info命令；\n       * 以获得当前数据库的相关信息。从而实现新节点(包括从库)的自动发现。\n     * 每2秒向主库和从库的\"sentinel:hello\"频道发送自己的信息\n       * (就是说哨兵不但订阅了该频道，而且还会向该频道发布信息，以使其他哨兵得到自己的信息)\n     * 每1秒向主库、从库和其他哨兵节点发送ping命令。\n\n * 注意\n   * redis 的代码里是: 先执行命令，再aof + sync，然后再返回客户端\n\n# 高性能\n\n * 客户端\n   * 单线程，所以重点在 rtt\n   * pipeline 和 multi & exec\n * 服务端\n   * 集群：\n     * 一致性hash\n     * 一致性hash+代理\n     * redis-cluster\n       * 问题：redis-cluster对multi-key操作支持不够，其它方式不支持。\n       * redis-cluster 默认并不支持读写分离\n       * 节点之间通过gossip协议交换状态信息\n       * 无中心架构, 数据通过异步复制, 不保证数据的强一致性\n * 测试工具\n   * redis-benchmark\n\n----------------------------------------\n\n----------------------------------------\n\n\n# mysql\n\n# 持久化\n\n * mysqldump\n   * 参数: --lock-tables, 锁表\n   * 注意: 默认情况下，不会阻塞数据库，但是会造成流量突增\n\n# 高可用\n\n * 原则\n   * 我们在考虑mysql数据库的高可用架构时，主要考虑如下几方面：\n     * 如果数据库发生了宕机或者意外中断等故障，尽可能的减少停机时间，保证业务不会因为数据库的故障而中断。\n     * 用作备份、只读副本等功能的非主节点的数据应该和主节点的数据实时或者最终保持一致。\n     * 当业务发生数据库切换时，切换前后的数据库内容应当一致，不会因为数据缺失或者数据不一致而影响业务。\n   * reference: [https://dbaplus.cn/news-11-1127-1.html]\n * 数据完整性\n   * redo log 和 undo log\n * 主从同步(master-slave replication)\n   * 要求\n     * 主从数据库版本一致\n   * 原理\n     * 主库开启 binlog, 在有数据库修改操作时(只记录更改操作)，更新binlog文件\n       * 写binlog文件：用户commit后同步写入innodb log buffer ---\x3e binlog文件 ---\x3e 刷新到磁盘\n     * 从库通过start slave开启复制功能：从库异步读取主库的 binlog 写入自己的 relay log, 并另起一线程将其重放到mysql数据库。\n   * 方案\n     * mysql replication\n       * mysql官方提出的主从同步方案。异步复制: 保证binlog写入文件, 不保证binlog传输给从库\n       * 问题\n         * 主库宕机后，数据可能丢失\n         * 主从复制延迟问题\n           * 一个主库的从库太多、从库硬件比主库差、主从库之间的网络延迟，导致复制延迟。\n           * 主从复制的设计问题、主库读写压力大 ：主库数据太多,从库只有一个thread来不及复制\n       * 方案\n         * 半同步复制 : 解决数据丢失的问题\n         * 并行复制 : 解决从库复制延迟的问题\n           * 社区版5.6新增。是指从库多线程并行应用库级别binlog，同一个库数据更改还是串行(5.7版并行复制基于事务组)设置。\n     * mysql semi-sync(半同步复制)\n       * google 提出, 5.5集成到mysql, 以插件的形式存在, 需要单独安装\n       * 确保事务提交后binlog至少传输到一个从库(写入relay log), 但不保证从库应用完这个事务的binlog (应用relay log)\n     * 同步复制\n       * google 提出。不仅要求所有slave收到binlog数据, 还要求所有slave将数据commit到数据库中\n   * 主从切换\n     * mysql replication的主从切换需要人工介入判断，同时需要slave的replaylog提交完毕，故障恢复时间会比较长。\n     * mha(mysql-master-ha) : 目前广泛使用\n       * 目标\n         * 自动实现主实例宕机后，从机切换为主，并尽量降低切换时延(通常在10-30s内切换完成)。\n       * 特性\n         * mha对mysql的主从复制集群非常友好，没有对集群做任何侵入性的修改。\n         * 从机切换为主时，由mha保证在切换过程中的数据一致性。\n           * 在主实例宕机后，mha可以自动的判断主从复制集群中哪个从实例的relaylog是最新的，并将其差异log\"应用\"到其余的从实例中，从而保证每个实例的数据一致。\n           * 通常情况下，mha需要10s左右检测主实例异常，并将主实例关闭从而避免脑裂。然后再用10s左右将差异的log event同步，并启用新的master。整个mha的rto时间大约在30s。\n     * mysql cluster : 官方方案\n       * 一个高度可扩展的，兼容acid事务的实时数据库，基于分布式架构不存在单点故障。支持自动水平扩容，能做自动的读写负载均衡\n       * 控制面和数据面分离\n         * application ---\x3e mysql server(存储表结构) ---\x3e ndb cluster(数据节点, ndb存储服务器, 通过 ndb_mgmd 管理)\n           * mysql cluster的 cluster 部分(即 ndb cluster)可独立于mysql服务器进行配置。\n\n# 高性能\n\n * 锁\n   * 读锁、写锁(表锁、行锁)\n     * 只有在使用索引时才会使用行锁，但当符合条件的数据比较多时会使用表锁\n     * 在select时，都会加上读锁\n * 慢查询\n   * 相关参数\n     \n     参数：(可以通过配置文件或mysql的全局变量设置)\n       mysql> set global slow_query_log='on'; # slow_query_log  ：是否开启慢查询日志功能(必填)\n       mysql> set global long_query_time=1;   # long_query_time ：超过设定值将被视作慢查询，并记录至慢查询日志文件中(必填)\n       mysql> set global slow_query_log_file='slow.log'; # log-slow-queries ：慢查询日志文件(不可填)，自动在 /data 创建一个 [hostname]-slow.log 文件\n     查看：\n       show variables like 'long%';\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     \n   * 指令: explain\n     * 在select语句前加上explain，可以了解sql执行的详细状态\n   * 慢查询日志分析工具\n     * mysqldumpslow\n     * mysqlsla\n * 测试工具\n   * mysqlslap\n     * 参数：--only-print 打印测试语,不实际执行。\n     * 注意：使用 -a 自动测试时，会drop schema。\n * reference\n   * <高性能mysql>\n   * 状态查看\n   \n       mysql> set global general_log=on; # 打开general log\n       mysql> show global status;         # 列出mysql服务器运行各种状态值:\n       mysql> show variables;             # 查询mysql服务器配置信息语句：\n       mysql> show variables like '%slow%';             # 慢查询情况\n       mysql> show global status like 'table_locks%';   # 表锁情况\n       可以查看设置的最大连接数 和 已经使用的最大连接数, 以调优\n       可以查看参数 table_open_cache, 它控制所有 mysql 执行线程可打开表缓存的数量, 以调优\n       可以查看参数 thread_cache_size, 它控制 mysql 缓存客户端线程的数量, 以调优。可以通过计算线程 cache 的失效率 threads_created / connections 来衡量 thread_cahce_size 的设置是否合适，该值越接近 1，说明线程 cache 命中率越低。\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   \n   * mysql表大时，可以进行分表和表分区、以及分库\n     * 分库分表存在以下问题：\n       * 事务问题\n       * 跨节点join 和 count,order by,group by以及聚合函数问题\n       * 数据迁移，容量规划，扩容等问题\n\n----------------------------------------\n\n----------------------------------------\n\n\n# mongo\n\n# 持久化\n\n * mongodump & mongorestore\n * mongoexport & mongoimport\n\n# 高可用\n\n * replica set\n   * 是mongod的实例集合, 包含三类角色: primary、secondary、arbiter(仲裁者)\n   * 主从同步方式\n     * 两个步骤\n       * intial sync，可以理解为全量同步\n       * replication，追同步源的oplog，可以理解为增量同步, 会不断拉取主上新产生的oplog并重放\n         * 三类线程完成replication工作\n           * producer thread，不断的从同步源上拉取oplog，并加入到一个blockqueue的队列里。\n           * replbatcher thread，负责逐个从producer thread的队列里取出oplog，并放到自己维护的队列里。要保持顺序性。\n           * sync线程将replbatcher thread的队列分发到默认16个replwriter线程，由replwriter来最终重放每条oplog。\n   * 注意：mongo的oplog具有幂等性\n\n# 高性能\n\n * cluster\n   * 使用sharding分片技术: client ---\x3e router(mongos) ---\x3e shard(每个shard节点都是一个replica set)\n * 锁\n   * 在 2.2 版本以前，mongod 只有全局锁；在 2.2 版本开始，库级锁;\n     * 粒度：库 ---\x3e collect ---\x3e document\n     * 建索引就是一个容易引起长时间写锁的问题。如果集合的数据量很大，建索引通常要花比较长时间，特别容易引起问题。\n       * mongodb 提供了两种建索引的访问\n         * 一种是 background 方式: db.posts.ensureindex({user_id: 1}, {background: 1})\n         * 一种是非 background 方式: db.posts.ensureindex({user_id: 1})\n\n# utility\n\n * schema explorer\n   * [https://studio3t.com/knowledge-base/articles/schema-explorer/]\n\n----------------------------------------\n\n----------------------------------------\n\n\n# end\n\n * sharding\n   * 当数据量比较大的时候，我们需要把数据分片运行在不同的机器中，以降低cpu、内存和io的压力，sharding就是数据库分片技术。\n * orm(object-relational mapping)\n   * mybatis\n * mysql性能优化的最佳20+条经验]\n   * https://www.cnblogs.com/zhouyusheng/p/8038224.html\n     * explain、procedure analyse()\n * mvcc\n   * mysql 的 mvcc ：是一种多版本并发控制机制",charsets:{cjk:!0}},{title:"High Performance Mysql, 3th Edition 阅读",frontmatter:{title:"High Performance Mysql, 3th Edition 阅读",date:"2020-04-21T00:00:00.000Z",description:"High Performance Mysql, 3th Edition",categories:["blog","database"],tags:[null],permalink:null},regularPath:"/blog/database/high_performance_mysql.html",relativePath:"blog/database/high_performance_mysql.md",key:"v-f89e89de",path:"/blog/database/high_performance_mysql.html",headers:[{level:2,title:"第一章 MySQL架构与历史",slug:"第一章-mysql架构与历史",normalizedTitle:"第一章 mysql架构与历史",charIndex:132},{level:2,title:"第三章",slug:"第三章",normalizedTitle:"第三章",charIndex:898},{level:2,title:"第五章 创建高性能的索引",slug:"第五章-创建高性能的索引",normalizedTitle:"第五章 创建高性能的索引",charIndex:1992},{level:2,title:"第六章 查询性能优化",slug:"第六章-查询性能优化",normalizedTitle:"第六章 查询性能优化",charIndex:3019},{level:2,title:"第七章 MySQL高级特性",slug:"第七章-mysql高级特性",normalizedTitle:"第七章 mysql高级特性",charIndex:3659},{level:2,title:"第八章 优化服务器设置",slug:"第八章-优化服务器设置",normalizedTitle:"第八章 优化服务器设置",charIndex:4148},{level:2,title:"第九章",slug:"第九章",normalizedTitle:"第九章",charIndex:4164},{level:2,title:"第十章 复制",slug:"第十章-复制",normalizedTitle:"第十章 复制",charIndex:4172},{level:2,title:"第十一章 可扩展的MySQL",slug:"第十一章-可扩展的mysql",normalizedTitle:"第十一章 可扩展的mysql",charIndex:4288},{level:2,title:"第十二章 高可用的MySQL",slug:"第十二章-高可用的mysql",normalizedTitle:"第十二章 高可用的mysql",charIndex:4402},{level:2,title:"第十五章 备份与恢复",slug:"第十五章-备份与恢复",normalizedTitle:"第十五章 备份与恢复",charIndex:4446},{level:2,title:"EXPLAIN",slug:"explain",normalizedTitle:"explain",charIndex:4705},{level:2,title:"锁的调试",slug:"锁的调试",normalizedTitle:"锁的调试",charIndex:7348}],headersStr:"第一章 MySQL架构与历史 第三章 第五章 创建高性能的索引 第六章 查询性能优化 第七章 MySQL高级特性 第八章 优化服务器设置 第九章 第十章 复制 第十一章 可扩展的MySQL 第十二章 高可用的MySQL 第十五章 备份与恢复 EXPLAIN 锁的调试",content:'# High Performance Mysql, 3th Edition\n\n知识点：\n    Schema、数据类型、高性能索引、查询性能优化、Mysql高级特性、Mysql配置、\n    复制、可扩展、高可用\n    备份与恢复\n\n\n1\n2\n3\n4\n\n\n\n# 第一章 MySQL架构与历史\n\n共享锁、排他锁\n锁的粒度：row锁，table锁\nACID\n\n\n1\n2\n3\n\n\n每种存储引擎实现的隔离级别都不尽相同。可以根据选择的存储引擎来查阅资料了解对应的隔离级别\n\n * READ UNCOMMITED ---\x3e 脏读\n * READ COMMITED ---\x3e 不可重复度\n * REPEATABLE READ ---\x3e 幻读(写入新记录，phantom row)，多版本并发控制(MVCC)解决幻读问题, mysql默认隔离级别\n * SERIALIZABLE\n\n死锁发生时，目前(mysql5.5中)Innodb的策略是：将持有最少行级锁的事务回滚\n\n事务日志\n\n * 事务日志可以提供事务的效率。使用事务日志时，存储引擎在修改表数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘的事务日志中，而不用每次都将修改的数据本身持久到磁盘。事务日志采用的是顺序追加的方式，所以速度相对会快很多。事务日志持久化后，内存中被修改的数据可以在后台慢慢刷入磁盘。这种方式叫预写式日志(Write-Ahead Logging), 修改数据需要写两次磁盘。\n\nInnoDB的mvcc是通过增加两个隐藏列实现的：一个记录行的过期时间，一个保持行的创建时间。当然，存储的不是实际时间而是一个系统版本号，每开始一个新事物，系统版本号都会递增. InnoDB 通过 间隙锁(next-key lock)解决幻读问题。\n\nMVCC 只对 READ COMMITED 和 REPEATABLE READ 两个事务隔离级别生效，其他两个跟MVCC不兼容，因为：READ UNCOMMITED 总是读取最新的数据行，而不是符合当前事务版本的数据行；而 SERIALIZABLE 则会对所有读取的行都加锁。\n\n\n# 第三章\n\n定义性能最有效的方法是响应时间\n\n准确的性能测量量化，可以很好的帮助发现、解决问题\n\n慢查询日志的记录，对mysql的性能影响很低。\n\n建议诊断问题时先使用以下两种方法： - show (global) status - show processlist 这两种方法的开销很低，可以通过简单的shell脚本(以较高频率，如，次/s 进行)或者反复执行的查询来交互式的收集数据\n\n对收集到的数据进行可视化处理。可视化的数据最具说服力\n\nINFORMATION_SCHEMA.STATISTICS 统计了很多MySQL的统计信息。\n\nSHOW VARIABLES\n\n\n# 第四章 Schema与数据类型优化\n\n数据类型选择原则：\n\n * 更小的通常更好：更小的数据类型通常更快，因为他们张勇更少的磁盘、内存和cpu缓存\n * 简单就好：简单数据类型的操作通常需要更少的cpu周期。\n * 尽量避免NULL：通常情况下最好指定列为NOT NULL, 除非真的需要存储 NULL。\n   * 如果查询中包含可为NULL的列，对于MySQL来说更难优化，因为可为 NULL 的列使得索引、索引统计和值比较都更加复杂。\n   * 可为 NULL 的列使用更多的存储空间，在MySQL里也需要特殊处理。\n   * 当可为 NULL 的列被索引时，每个索引记录需要一个额外的字节。 但是，通常把可为 NULL 的列改为 NOT NULL 带来的性能提升比较小。\n\nDATETIME 和 TIMESTAMP 都可以存储时间，精确到秒。然而，TIMESTAMP 只使用 DATETIME 一半的存储空间，并且会根据时区变化，但是 TIMESTAMP 允许表达的时间范围要小得多。\n\nMySQL 可以为整数类型指定宽度，如 INT(11)，它不会限制值得合法范围，只是规定了MySQL的一些交互工具(如，MySQL命令行客户端)用来显示字符的个数。\n\nFLOAT 和 DOUBLE 使用标准的浮点运算进行近似计算。 DECIMAL 用于存储精确的小数。 因为 CPU 支持原生浮点计算但不支持 DECIMAL 运算，所以浮点运算明显更快。\n\n当存储类型为 CHAR 时，MySQL 会删除所有的末尾空格。\n\nMySQL 的 ALTER TABLE 操作的性能对大表来说是个大问题：MySQL 执行大部分修改表结构操作的方法是用新的表结构创建一个空表，锁旧表，从旧表中查出所有数据插入新表，然后删除旧表。这样的操作可能会花费很长时间，如果内存不足而表又很大，而且还有很多索引的情况下尤其严重。\n\n\n# 第五章 创建高性能的索引\n\n对于非常小的表，大部分情况下简单的全表扫码更高效 对于中到大型的表，索引就非常有效。但对于特大型的表，建立和使用索引的代价将随之增长。\n\n如果表的数量特别多，可以建立一个元数据信息表，用来查询需要用到的某些特性。对于TB级别的数据，定位单条记录的意义不大，所以经常会使用块级别元数据技术来替代索引。\n\n高性能的索引策略\n\n * 如果查询中的列不是独立的，则MySQL就不会使用索引。"独立的列"是指索引列不能是表达式的一部分，也不能是函数的参数。\n\n使用索引的最左匹配原则\n\nInnoDB使用主键来聚集(聚簇)数据。如果没有定义主键，InnoDB会选择一个唯一的非空索引代替。如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引。InnoDB只聚集在同一个页面中的记录，包含相邻键值的页面可能会相距甚远。\n\n聚簇(数据)索引，通过数据存储的连续性，利用磁盘的顺序读取特性，最大限度的提高了IO密集型应用的性能。但是，这也使得 插入新行、主键被更新等导致需要移动行的时候，可能面临“页分裂(page split)”的问题。当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，这就是一次页分裂操作。\n\n二级索引(非聚簇索引)可能比想象的更大，因为二级索引的叶子节点包含了引用行的主键列。二级索引访问需要两次索引查找，而不是一次。因为二级索引叶子节点中保存的不是指向行的物理位置的指针，而是行的主键值。\n\nMySQL 允许在相同列上创建多个索引。但是，需要单独维护重复的索引，并且优化器在优化查询的时候也需要逐个地进行考虑，这会影响性能。应尽量避免重复索引。 表中的索引越多插入速度会越慢。一般来说，增加新索引会导致 INSERT、UPDATE、DELETE 等操作的速度变慢。\n\nMySQL 的索引统计信息： InnoDB 在打开某些 INFORMATION_SCHEMA 表，或者使用 SHOW TABLE STATUS 和 SHOW INDEX 等时，都有可能触发索引统计信息的更新。如果服务器上有大量的数据，这可能是个严重的问题，尤其是当IO比较慢的时候。\n\nInnoDB 引擎通过抽样的方式来计算统计信息：首先随机地读取少量的索引页面，然后以此为样本计算索引的统计信息。可以通过参数 innodb_stats_sample_pages 来设置样本页的数量。\n\n\n\n# 第六章 查询性能优化\n\n1、确认是否向数据库请求了超过实际需要(大量不需要)的数据 2、确认MySQL服务器层是否在分析大量超过需要的数据行 对于MySQL最简单的衡量查询开销的三个指标如下：\n\n * 响应时间\n * 扫描的行数\n * 返回的行数\n\nMySQL 通信协议 半双工。这意味着，在任何一个时刻，要么是由服务器向客户端发送数据，要么是由客户端向服务端发送数据，这两个动作不能同时发生。所以，要特别注意查询语句很长，或者返回结果很大的时候。\n\n有很多方式能查看当前的状态，最简单的是使用 SHOW FULLPROCESSLIST 命令。\n\nSHOW STATUS LIKE \'last_query_cost\';\n\nMySQL 无法利用多核特性来并行执行查询。\n\n优化LIMIT分页 当偏移量非常大时，这种分页方式代价非常高，常见的一种优化方式是：使用索引覆盖扫描，而不是查询所有的列。然后根据需要做一次关联操作再返回所需的列。\n\n一般的，我们要尽量避免使用 SELECT FOR UPDATE。\n\nCOUNT()有两个非常不同的作用：它可以统计某个列值的数量，也可以统计行数。在统计列值时要求列值是非空的（不统计NULL）。 COUNT(1) is only subject to the same optimization if the first column is defined as NOT NULL.\n\nMySQL 的查询执行计划总是左侧深度优先树。\n\n\n# 第七章 MySQL高级特性\n\n分区表、视图、临时表、游标\n\nXA事务\n\n一个常见的误区是认为 innodb_support_xa 只有在需要XA支持的情况下才打开。这是错误的：改参数还会控制 MySQL 内部存储引擎和二进制日志之间的分布式事务。\n\n查询缓存\n\n如果查询语句中包含任何的不确定函数，那么 MySQL 在查询缓存中是不可能找到缓存结果的。 如果查询缓存空间过大，在过期操作的时候可能会导致服务器僵死。一个比较简单的方式就是控制缓存空间(query_cache_size)的大小。\n\n打开查询缓存对读和写操作都会带来额外的消耗：\n\n * 读查询在开始之前必须先检查是否命中缓存\n * 如果这个读查询可以被缓存，那么当完成执行后，会将其结果放入缓存\n * 这对写操作也会有影响，因为当向某个表写入数据的时候，MySQL 必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗。\n\n缓存碎片、内存不足、数据修改等都会造成缓存失效。所以，写密集型的应用，直接禁用查询缓存可能会提高系统性能。\n\n如何分析和配置查询缓存\n\n\n# 第八章 优化服务器设置\n\n\n# 第九章\n\n\n# 第十章 复制\n\n复制解决的基本问题是让一台服务器的数据与其他服务器保持同步。\n\nMySQL支持两种复制方式：基于行的复制和基于语句的复制。这两种方式都是通过在主库行记录二进制日志、在备库重放日志的方式来实现异步的数据复制。\n\n\n# 第十一章 可扩展的MySQL\n\n * 扩展方式：\n   * 数据分片、多实例、集群、数据切分(保持活跃数据独立，将活跃和不活跃数据隔离)\n * 配合以 负载均衡\n   * 可以让客户端多扩展无感，以及其他的一些逻辑操作\n\n\n# 第十二章 高可用的MySQL\n\n * 提升平均失效时间\n * 降低平均恢复时间\n\n\n# 第十五章 备份与恢复\n\n因为 InnoDB 是个 ACID 系统。任何时刻(例如快照时)，每个提交的事务要么在 InnoDB 数据文件中要么在日志文件中。在还原快照后启动MySQL时，InnoDB 将运行恢复进程，就像服务器断过电一样。会查找事务日志中任何提交但没有应用到数据文件中的事务然后应用，因此不会丢失任何事务。这正是要强制 InnoDB 数据文件和日志文件在一起快照的原因。\n\n复制mysql配置，同时观察mysql启动时的错误日志：tail -f /var/log/mysql/mysql.err\n\n\n# EXPLAIN\n\n在查询中每个表在输出中只有一行。如果查询是两个表的联接，那么输出中将有两行。\n\n * EXPLAIN EXTENDED:\n   * 看起来和正常的EXPLAIN行为一样，但是它会告诉服务器\'逆向编译\'执行计划为一个SELECT语句。可以通过紧接气候运行SHOW WARNINGS看到这个生成的语句。这个语句直接来自执行计划，而不是原始SQL语句。\n * EXPLAIN PARTITIONS\n   * 会显示查询将访问的分区，如果查询是基于分区表的话。\n\n认为增加EXPLAIN时MySQL不会执行查询，这是一个常见的错误。实际上，如果查询在FROM子句中包括子查询，那么MySQL实际上会执行子查询，将其结果放在一个临时表中，然后完成外部查询优化。这意味着，如果语句中包含开销较大的子查询或者使用临时表算法的视图，实际上会给服务器带来大量工作。\n\nMySQL EXPLAIN 只能解释 SELECT 查询，并不会对存储程序调用 和 INSERT、UPDATE、DELETE或其他语句做解释。然而，可以重写某些非 SELECT 查询以利用 EXPALIN。为了达到这个目的，只需要将该语句转换成一个等价的访问所有相同列的 SELECT。\n\n * id 列\n   * 标识 SELECT 所属的行。如果在语句中没有子查询或者联合，那么只会有唯一的 SELECT。否则，内层的 SELECT 语句一般会顺序编号。\n * select_type 列\n   * 显示了对应行是简单还是复杂 SELECT。SIMPLE 值意味着查询不包含子查询和UNION，如果查询有任何复杂的子部分，则最外层部分标记为 PRIMARY, 其他部分标记如下：\n     * SUBQUERY\n       * 包含在 SELECT 列表中的子查询中的 SELECT(换句话说，不在FROM子句中)标记为 SUBQUERY\n     * DERIVED\n       * 用来表示包含在 FROM 子句的子查询中的 SELECT，MySQL 会递归执行并将结果放到一个临时表中。服务器内部称其"派生表"，因为该临时表是从子查询中派生来的\n     * UNION\n       * 在 UNION 中的第二个和随后的 SELECT 被标记为 UNION。第一个 SELECT 被标记就好像它以部分外查询来执行。\n     * UNION RESULT\n       * 用来从 UNION 的匿名临时表检索结果的 SELECT 被标记为 UNION RESULT\n     * DEPENDENT\n       * 意味着 SELECT 依赖于外层查询中发现的数据\n     * UNCACHEABLE\n       * 意味着 SELECT 中的某些特性阻止结果被缓存于一个Item_cache\n * table 列\n   * 显示了对应行正在访问哪个表。\n * type 列\n   * 访问类型，换言之就是 MySQL 决定如何查找表中的行\n     * ALL\n       * 全表扫码\n     * index\n       * 跟全表扫描一样，只是 MySQL 扫描表时按索引次序进行而不是行。主要优点是避免了排序，最大的缺点是要承担按索引次序读取整个整个表的开销。这通常意味着若是按随机次序访问行，开销将会非常大。如果在 Extra 列中看到 "Using index" 说明 MySQL 正在使用覆盖索引，它只扫描索引的数据，而不是按索引次序的每一行。\n     * range\n       * 范围扫描就是一个有限制的索引扫描，它开始于索引的某一个点，返回匹配这个值域的行。\n     * ref\n       * 索引访问，它返回所有匹配某个单个值的行。此类索引访问只有当使用非唯一索引或者唯一索引的非唯一性前缀时才会发生。把它叫做 ref 是因为索引要跟某个参考值相比较。\n     * eq_ref\n       * 索引访问，它最多只返回一条符合条件的记录。这种访问方法可以在 MySQL 使用主键或者唯一性索引查找时看到。\n     * const, system\n       * 当 MySQL 能对查询的某部分进行优化并将其转换成一个常量时，它就会使用这些访问类型。\n     * NULL\n       * 意味着 MySQL 能再优化阶段分解查询语句，在执行阶段甚至用不着再访问表或者索引。\n * possible_keys 列\n   * 显示了查询可以使用哪些索引\n * key 列\n   * 显示了 MySQL 决定采用哪个索引来优化对该表的访问。\n * key_len 列\n   * 显示了在索引字段中可能的最大长度，而不是表中数据使用的实际字节数。\n * ref 列\n   * 显示了之前的表在 key 列记录的索引中查找值所使用的列或者常量\n * rows 列\n   * MySQL估计的为了找到所需的行而需要读取的行数。这个数字是内嵌循环关联计划里的循环数目。也就是说它不是 MySQL 认为它最终要从表里读取出来的行数，而是 MySQL 为了找到符合查询的每一点上标准的那些行而必须读取的行的平均数。\n * filtered 列\n   * 在使用 EXPLAIN EXTENDED 时出现，显示的是针对表里符合某个条件(WHERE子句或联接条件)的记录数的百分比所做的一个悲观估算。\n * Extra 列\n   * 包含的是不适合在其它列显示的额外信息。常见的最重要的值如下：\n     * Using index\n       * 表示 MySQL 将使用覆盖索引，以避免访问表\n     * Using where\n       * 意味着 MySQL 服务器将在存储引擎检索行后再进行过滤\n     * Using temporary\n       * 意味着 MySQL 在对查询结果排序时会使用一个临时表\n     * Using filesort\n       * 意味着 MySQL 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行\n     * Range checked for each record(index map:N)\n       * 意味着没有好用的索引，新的索引将在联接的每一行上重新估算\n\n\n# 锁的调试\n\n锁等待可能发生在服务器级别或存储引擎级别。下面是MySQL服务器使用的几种类型的锁：\n\n * 表锁\n   * 表锁可以是显式的也可以是隐式的\n     * 显式：用 LOCK TABLES 创建 (可以使用 SHOW PROCESSLIST 观察到锁状态)\n     * 隐式：服务器在需要时自动创建和释放，并将它们传递给存储引擎\n   * 找出谁持有锁\n     * 指令：mysqladmin debug\n * 全局锁\n   * 可以通过 FLUSH TABLES WITH READ LOCK 或设置 read_only=1 来获取单个全局读锁。\n   \n   一个会话执行：FLUSH TABLES WITH READ LOCK;\n   另一个会话尝试再锁这个表：LOCK TABLES test WRITE;\n   此时，就会看到会话挂起，通过 SHOW PROCESSLIST 可以看到查询状态是：Waiting for release for readlock。这就说明查询正在等待一个全局读锁而不是表级别锁\n   \n   \n   1\n   2\n   3\n   \n   * MySQL 目前没有提供查出谁持有全局读锁的方法\n * 命名锁\n   * 表锁的一种，服务器在重命名或者删除一个表时创建\n * 字符锁\n   * 可以用 GET_LOCK() 及其相关函数在服务器级别内锁住和释放任意一个字符串\n\n存储引擎中的锁 InnoDB 在 SHOW INNODB STATUS 的输出中显露了一些锁信息。如果事务正在等待某个锁，这个锁会显示在 SHOW INNODB STATUS 输出的 TRANSACTIONS 部分。\n\n',normalizedContent:'# high performance mysql, 3th edition\n\n知识点：\n    schema、数据类型、高性能索引、查询性能优化、mysql高级特性、mysql配置、\n    复制、可扩展、高可用\n    备份与恢复\n\n\n1\n2\n3\n4\n\n\n\n# 第一章 mysql架构与历史\n\n共享锁、排他锁\n锁的粒度：row锁，table锁\nacid\n\n\n1\n2\n3\n\n\n每种存储引擎实现的隔离级别都不尽相同。可以根据选择的存储引擎来查阅资料了解对应的隔离级别\n\n * read uncommited ---\x3e 脏读\n * read commited ---\x3e 不可重复度\n * repeatable read ---\x3e 幻读(写入新记录，phantom row)，多版本并发控制(mvcc)解决幻读问题, mysql默认隔离级别\n * serializable\n\n死锁发生时，目前(mysql5.5中)innodb的策略是：将持有最少行级锁的事务回滚\n\n事务日志\n\n * 事务日志可以提供事务的效率。使用事务日志时，存储引擎在修改表数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘的事务日志中，而不用每次都将修改的数据本身持久到磁盘。事务日志采用的是顺序追加的方式，所以速度相对会快很多。事务日志持久化后，内存中被修改的数据可以在后台慢慢刷入磁盘。这种方式叫预写式日志(write-ahead logging), 修改数据需要写两次磁盘。\n\ninnodb的mvcc是通过增加两个隐藏列实现的：一个记录行的过期时间，一个保持行的创建时间。当然，存储的不是实际时间而是一个系统版本号，每开始一个新事物，系统版本号都会递增. innodb 通过 间隙锁(next-key lock)解决幻读问题。\n\nmvcc 只对 read commited 和 repeatable read 两个事务隔离级别生效，其他两个跟mvcc不兼容，因为：read uncommited 总是读取最新的数据行，而不是符合当前事务版本的数据行；而 serializable 则会对所有读取的行都加锁。\n\n\n# 第三章\n\n定义性能最有效的方法是响应时间\n\n准确的性能测量量化，可以很好的帮助发现、解决问题\n\n慢查询日志的记录，对mysql的性能影响很低。\n\n建议诊断问题时先使用以下两种方法： - show (global) status - show processlist 这两种方法的开销很低，可以通过简单的shell脚本(以较高频率，如，次/s 进行)或者反复执行的查询来交互式的收集数据\n\n对收集到的数据进行可视化处理。可视化的数据最具说服力\n\ninformation_schema.statistics 统计了很多mysql的统计信息。\n\nshow variables\n\n\n# 第四章 schema与数据类型优化\n\n数据类型选择原则：\n\n * 更小的通常更好：更小的数据类型通常更快，因为他们张勇更少的磁盘、内存和cpu缓存\n * 简单就好：简单数据类型的操作通常需要更少的cpu周期。\n * 尽量避免null：通常情况下最好指定列为not null, 除非真的需要存储 null。\n   * 如果查询中包含可为null的列，对于mysql来说更难优化，因为可为 null 的列使得索引、索引统计和值比较都更加复杂。\n   * 可为 null 的列使用更多的存储空间，在mysql里也需要特殊处理。\n   * 当可为 null 的列被索引时，每个索引记录需要一个额外的字节。 但是，通常把可为 null 的列改为 not null 带来的性能提升比较小。\n\ndatetime 和 timestamp 都可以存储时间，精确到秒。然而，timestamp 只使用 datetime 一半的存储空间，并且会根据时区变化，但是 timestamp 允许表达的时间范围要小得多。\n\nmysql 可以为整数类型指定宽度，如 int(11)，它不会限制值得合法范围，只是规定了mysql的一些交互工具(如，mysql命令行客户端)用来显示字符的个数。\n\nfloat 和 double 使用标准的浮点运算进行近似计算。 decimal 用于存储精确的小数。 因为 cpu 支持原生浮点计算但不支持 decimal 运算，所以浮点运算明显更快。\n\n当存储类型为 char 时，mysql 会删除所有的末尾空格。\n\nmysql 的 alter table 操作的性能对大表来说是个大问题：mysql 执行大部分修改表结构操作的方法是用新的表结构创建一个空表，锁旧表，从旧表中查出所有数据插入新表，然后删除旧表。这样的操作可能会花费很长时间，如果内存不足而表又很大，而且还有很多索引的情况下尤其严重。\n\n\n# 第五章 创建高性能的索引\n\n对于非常小的表，大部分情况下简单的全表扫码更高效 对于中到大型的表，索引就非常有效。但对于特大型的表，建立和使用索引的代价将随之增长。\n\n如果表的数量特别多，可以建立一个元数据信息表，用来查询需要用到的某些特性。对于tb级别的数据，定位单条记录的意义不大，所以经常会使用块级别元数据技术来替代索引。\n\n高性能的索引策略\n\n * 如果查询中的列不是独立的，则mysql就不会使用索引。"独立的列"是指索引列不能是表达式的一部分，也不能是函数的参数。\n\n使用索引的最左匹配原则\n\ninnodb使用主键来聚集(聚簇)数据。如果没有定义主键，innodb会选择一个唯一的非空索引代替。如果没有这样的索引，innodb会隐式定义一个主键来作为聚簇索引。innodb只聚集在同一个页面中的记录，包含相邻键值的页面可能会相距甚远。\n\n聚簇(数据)索引，通过数据存储的连续性，利用磁盘的顺序读取特性，最大限度的提高了io密集型应用的性能。但是，这也使得 插入新行、主键被更新等导致需要移动行的时候，可能面临“页分裂(page split)”的问题。当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，这就是一次页分裂操作。\n\n二级索引(非聚簇索引)可能比想象的更大，因为二级索引的叶子节点包含了引用行的主键列。二级索引访问需要两次索引查找，而不是一次。因为二级索引叶子节点中保存的不是指向行的物理位置的指针，而是行的主键值。\n\nmysql 允许在相同列上创建多个索引。但是，需要单独维护重复的索引，并且优化器在优化查询的时候也需要逐个地进行考虑，这会影响性能。应尽量避免重复索引。 表中的索引越多插入速度会越慢。一般来说，增加新索引会导致 insert、update、delete 等操作的速度变慢。\n\nmysql 的索引统计信息： innodb 在打开某些 information_schema 表，或者使用 show table status 和 show index 等时，都有可能触发索引统计信息的更新。如果服务器上有大量的数据，这可能是个严重的问题，尤其是当io比较慢的时候。\n\ninnodb 引擎通过抽样的方式来计算统计信息：首先随机地读取少量的索引页面，然后以此为样本计算索引的统计信息。可以通过参数 innodb_stats_sample_pages 来设置样本页的数量。\n\n\n\n# 第六章 查询性能优化\n\n1、确认是否向数据库请求了超过实际需要(大量不需要)的数据 2、确认mysql服务器层是否在分析大量超过需要的数据行 对于mysql最简单的衡量查询开销的三个指标如下：\n\n * 响应时间\n * 扫描的行数\n * 返回的行数\n\nmysql 通信协议 半双工。这意味着，在任何一个时刻，要么是由服务器向客户端发送数据，要么是由客户端向服务端发送数据，这两个动作不能同时发生。所以，要特别注意查询语句很长，或者返回结果很大的时候。\n\n有很多方式能查看当前的状态，最简单的是使用 show fullprocesslist 命令。\n\nshow status like \'last_query_cost\';\n\nmysql 无法利用多核特性来并行执行查询。\n\n优化limit分页 当偏移量非常大时，这种分页方式代价非常高，常见的一种优化方式是：使用索引覆盖扫描，而不是查询所有的列。然后根据需要做一次关联操作再返回所需的列。\n\n一般的，我们要尽量避免使用 select for update。\n\ncount()有两个非常不同的作用：它可以统计某个列值的数量，也可以统计行数。在统计列值时要求列值是非空的（不统计null）。 count(1) is only subject to the same optimization if the first column is defined as not null.\n\nmysql 的查询执行计划总是左侧深度优先树。\n\n\n# 第七章 mysql高级特性\n\n分区表、视图、临时表、游标\n\nxa事务\n\n一个常见的误区是认为 innodb_support_xa 只有在需要xa支持的情况下才打开。这是错误的：改参数还会控制 mysql 内部存储引擎和二进制日志之间的分布式事务。\n\n查询缓存\n\n如果查询语句中包含任何的不确定函数，那么 mysql 在查询缓存中是不可能找到缓存结果的。 如果查询缓存空间过大，在过期操作的时候可能会导致服务器僵死。一个比较简单的方式就是控制缓存空间(query_cache_size)的大小。\n\n打开查询缓存对读和写操作都会带来额外的消耗：\n\n * 读查询在开始之前必须先检查是否命中缓存\n * 如果这个读查询可以被缓存，那么当完成执行后，会将其结果放入缓存\n * 这对写操作也会有影响，因为当向某个表写入数据的时候，mysql 必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗。\n\n缓存碎片、内存不足、数据修改等都会造成缓存失效。所以，写密集型的应用，直接禁用查询缓存可能会提高系统性能。\n\n如何分析和配置查询缓存\n\n\n# 第八章 优化服务器设置\n\n\n# 第九章\n\n\n# 第十章 复制\n\n复制解决的基本问题是让一台服务器的数据与其他服务器保持同步。\n\nmysql支持两种复制方式：基于行的复制和基于语句的复制。这两种方式都是通过在主库行记录二进制日志、在备库重放日志的方式来实现异步的数据复制。\n\n\n# 第十一章 可扩展的mysql\n\n * 扩展方式：\n   * 数据分片、多实例、集群、数据切分(保持活跃数据独立，将活跃和不活跃数据隔离)\n * 配合以 负载均衡\n   * 可以让客户端多扩展无感，以及其他的一些逻辑操作\n\n\n# 第十二章 高可用的mysql\n\n * 提升平均失效时间\n * 降低平均恢复时间\n\n\n# 第十五章 备份与恢复\n\n因为 innodb 是个 acid 系统。任何时刻(例如快照时)，每个提交的事务要么在 innodb 数据文件中要么在日志文件中。在还原快照后启动mysql时，innodb 将运行恢复进程，就像服务器断过电一样。会查找事务日志中任何提交但没有应用到数据文件中的事务然后应用，因此不会丢失任何事务。这正是要强制 innodb 数据文件和日志文件在一起快照的原因。\n\n复制mysql配置，同时观察mysql启动时的错误日志：tail -f /var/log/mysql/mysql.err\n\n\n# explain\n\n在查询中每个表在输出中只有一行。如果查询是两个表的联接，那么输出中将有两行。\n\n * explain extended:\n   * 看起来和正常的explain行为一样，但是它会告诉服务器\'逆向编译\'执行计划为一个select语句。可以通过紧接气候运行show warnings看到这个生成的语句。这个语句直接来自执行计划，而不是原始sql语句。\n * explain partitions\n   * 会显示查询将访问的分区，如果查询是基于分区表的话。\n\n认为增加explain时mysql不会执行查询，这是一个常见的错误。实际上，如果查询在from子句中包括子查询，那么mysql实际上会执行子查询，将其结果放在一个临时表中，然后完成外部查询优化。这意味着，如果语句中包含开销较大的子查询或者使用临时表算法的视图，实际上会给服务器带来大量工作。\n\nmysql explain 只能解释 select 查询，并不会对存储程序调用 和 insert、update、delete或其他语句做解释。然而，可以重写某些非 select 查询以利用 expalin。为了达到这个目的，只需要将该语句转换成一个等价的访问所有相同列的 select。\n\n * id 列\n   * 标识 select 所属的行。如果在语句中没有子查询或者联合，那么只会有唯一的 select。否则，内层的 select 语句一般会顺序编号。\n * select_type 列\n   * 显示了对应行是简单还是复杂 select。simple 值意味着查询不包含子查询和union，如果查询有任何复杂的子部分，则最外层部分标记为 primary, 其他部分标记如下：\n     * subquery\n       * 包含在 select 列表中的子查询中的 select(换句话说，不在from子句中)标记为 subquery\n     * derived\n       * 用来表示包含在 from 子句的子查询中的 select，mysql 会递归执行并将结果放到一个临时表中。服务器内部称其"派生表"，因为该临时表是从子查询中派生来的\n     * union\n       * 在 union 中的第二个和随后的 select 被标记为 union。第一个 select 被标记就好像它以部分外查询来执行。\n     * union result\n       * 用来从 union 的匿名临时表检索结果的 select 被标记为 union result\n     * dependent\n       * 意味着 select 依赖于外层查询中发现的数据\n     * uncacheable\n       * 意味着 select 中的某些特性阻止结果被缓存于一个item_cache\n * table 列\n   * 显示了对应行正在访问哪个表。\n * type 列\n   * 访问类型，换言之就是 mysql 决定如何查找表中的行\n     * all\n       * 全表扫码\n     * index\n       * 跟全表扫描一样，只是 mysql 扫描表时按索引次序进行而不是行。主要优点是避免了排序，最大的缺点是要承担按索引次序读取整个整个表的开销。这通常意味着若是按随机次序访问行，开销将会非常大。如果在 extra 列中看到 "using index" 说明 mysql 正在使用覆盖索引，它只扫描索引的数据，而不是按索引次序的每一行。\n     * range\n       * 范围扫描就是一个有限制的索引扫描，它开始于索引的某一个点，返回匹配这个值域的行。\n     * ref\n       * 索引访问，它返回所有匹配某个单个值的行。此类索引访问只有当使用非唯一索引或者唯一索引的非唯一性前缀时才会发生。把它叫做 ref 是因为索引要跟某个参考值相比较。\n     * eq_ref\n       * 索引访问，它最多只返回一条符合条件的记录。这种访问方法可以在 mysql 使用主键或者唯一性索引查找时看到。\n     * const, system\n       * 当 mysql 能对查询的某部分进行优化并将其转换成一个常量时，它就会使用这些访问类型。\n     * null\n       * 意味着 mysql 能再优化阶段分解查询语句，在执行阶段甚至用不着再访问表或者索引。\n * possible_keys 列\n   * 显示了查询可以使用哪些索引\n * key 列\n   * 显示了 mysql 决定采用哪个索引来优化对该表的访问。\n * key_len 列\n   * 显示了在索引字段中可能的最大长度，而不是表中数据使用的实际字节数。\n * ref 列\n   * 显示了之前的表在 key 列记录的索引中查找值所使用的列或者常量\n * rows 列\n   * mysql估计的为了找到所需的行而需要读取的行数。这个数字是内嵌循环关联计划里的循环数目。也就是说它不是 mysql 认为它最终要从表里读取出来的行数，而是 mysql 为了找到符合查询的每一点上标准的那些行而必须读取的行的平均数。\n * filtered 列\n   * 在使用 explain extended 时出现，显示的是针对表里符合某个条件(where子句或联接条件)的记录数的百分比所做的一个悲观估算。\n * extra 列\n   * 包含的是不适合在其它列显示的额外信息。常见的最重要的值如下：\n     * using index\n       * 表示 mysql 将使用覆盖索引，以避免访问表\n     * using where\n       * 意味着 mysql 服务器将在存储引擎检索行后再进行过滤\n     * using temporary\n       * 意味着 mysql 在对查询结果排序时会使用一个临时表\n     * using filesort\n       * 意味着 mysql 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行\n     * range checked for each record(index map:n)\n       * 意味着没有好用的索引，新的索引将在联接的每一行上重新估算\n\n\n# 锁的调试\n\n锁等待可能发生在服务器级别或存储引擎级别。下面是mysql服务器使用的几种类型的锁：\n\n * 表锁\n   * 表锁可以是显式的也可以是隐式的\n     * 显式：用 lock tables 创建 (可以使用 show processlist 观察到锁状态)\n     * 隐式：服务器在需要时自动创建和释放，并将它们传递给存储引擎\n   * 找出谁持有锁\n     * 指令：mysqladmin debug\n * 全局锁\n   * 可以通过 flush tables with read lock 或设置 read_only=1 来获取单个全局读锁。\n   \n   一个会话执行：flush tables with read lock;\n   另一个会话尝试再锁这个表：lock tables test write;\n   此时，就会看到会话挂起，通过 show processlist 可以看到查询状态是：waiting for release for readlock。这就说明查询正在等待一个全局读锁而不是表级别锁\n   \n   \n   1\n   2\n   3\n   \n   * mysql 目前没有提供查出谁持有全局读锁的方法\n * 命名锁\n   * 表锁的一种，服务器在重命名或者删除一个表时创建\n * 字符锁\n   * 可以用 get_lock() 及其相关函数在服务器级别内锁住和释放任意一个字符串\n\n存储引擎中的锁 innodb 在 show innodb status 的输出中显露了一些锁信息。如果事务正在等待某个锁，这个锁会显示在 show innodb status 输出的 transactions 部分。\n\n',charsets:{cjk:!0}},{title:"mysql 中的索引",frontmatter:{title:"mysql 中的索引",date:"2020-04-21T00:00:00.000Z",lastmod:null,description:"关于 mysql 中的引擎 以及 索引类型，以帮助更好的了解 mysql",categories:["blog","database"],tags:[null],permalink:null},regularPath:"/blog/database/mysql_index.html",relativePath:"blog/database/mysql_index.md",key:"v-303c02c2",path:"/blog/database/mysql_index.html",headers:[{level:2,title:"B+Tree",slug:"b-tree",normalizedTitle:"b+tree",charIndex:321},{level:2,title:"聚簇索引",slug:"聚簇索引",normalizedTitle:"聚簇索引",charIndex:32},{level:2,title:"非聚簇索",slug:"非聚簇索",normalizedTitle:"非聚簇索",charIndex:50}],headersStr:"B+Tree 聚簇索引 非聚簇索",content:"# mysql 中的索引类型\n\n在 mysql 中，有两类索引：聚簇索引(clustered) 和 非聚簇索引(nonclustered)。正常情况下，InnoDB 的主键使用 聚簇索引，MyISAM 使用的是 非聚簇索引。这个差异也给两个引擎的最优使用场景带来了不同，使用时注意测试、考察。\n\n先说下 聚簇索引 和 非聚簇索引 的差异：\n\n * 聚簇索引\n   * 主键和表数据一起存储：主键索引的叶结点存储主键值的同时也包含了行数据。二级索引的叶结点存储行的主键值\n * 非聚簇索引\n   * 索引和表数据分开存储：所有的节点都是索引，叶子节点存储的是 索引 和 索引对应的数据记录地址。主键索引和二级索引在存储上没有任何区别。\n\n\n# B+Tree\n\n这里，我们需要说一下，常用的索引结构 B+ tree,\n\n从图中也可以看到，B+树与B树的不同在于：\n\n 1. 所有数据都存储在叶子节点，非叶子节点不存储真正的data\n 2. 为所有叶子节点增加了一个链指针\n\n\n# 聚簇索引\n\n根据上述信息，我们可以想象，对于聚簇索引来说:\n\n 1. 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。\n\n同时, 由于主键发生变更的话, 索引结构需要再平衡、以及相关数据的移动, 这个代价相对较大, 所以一般设置主键为不可更新的.\n\n因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键。\n\n页分裂是指，当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，这就是一次分裂操作。页分裂会导致表占用更多的磁盘空间。\n\n 2. 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。而非聚簇索引，主键索引和非主键索引，都可以直接定位数据的具体位置，然后进行访问即可。\n 3. 当通过聚簇索引查找目标数据时理论上比非聚簇索引要快，因为非聚簇索引定位到对应主键时还要多一次目标记录寻址,即多一次I/O。\n 4. 当需要取出一定范围内的数据时，用聚簇索引要比用非聚簇索引好\n\n对于聚簇索引的存储引擎，因为数据是根据主键顺序连续存储的，数据的物理存放顺序与索引顺序是一致的，所以只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的，索引结构相对紧凑，磁盘碎片少，效率也高。可以很方便的取出一定范围内的数据。\n\n对于聚簇索引也有一些不足之处，如：\n\n 1. 聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候。\n 2. 顺序主键在高并发工作负载下，在InnoDB中按主键顺序插入可能会造成明显的争用。\n\n主键的上界会成为“热点”。因为所有的插入都发生在这里，所以并发插入可能导致间隙锁竞争。\n\n另一个热点可能是auto_increment锁机制；如果遇到这个问题，则可能需要考虑重新设计表或者应用，比如应用层面生成单调递增的主键ID，插表不使用auto_increment机制，或者更改innodb_autonc_lock_mode配置。\n\n\n# 非聚簇索\n\n对于非聚簇索引而言，\n\n 1. 二级索引可能比想象的要更大，因为在二给索引的叶子节点包含了引用行的主键列。\n 2. 由于插入的数据，是顺序写入的，与索引顺序无关，所以可以不必用单调递增ID。\n 3. 但是 MyISAM 的锁是表级：写入数据，会使用全局(独占)表锁，读取数据也会使用全局(非独占)表锁。而 Innodb 使用行级锁，同时有 MVCC 加持读性能。",normalizedContent:"# mysql 中的索引类型\n\n在 mysql 中，有两类索引：聚簇索引(clustered) 和 非聚簇索引(nonclustered)。正常情况下，innodb 的主键使用 聚簇索引，myisam 使用的是 非聚簇索引。这个差异也给两个引擎的最优使用场景带来了不同，使用时注意测试、考察。\n\n先说下 聚簇索引 和 非聚簇索引 的差异：\n\n * 聚簇索引\n   * 主键和表数据一起存储：主键索引的叶结点存储主键值的同时也包含了行数据。二级索引的叶结点存储行的主键值\n * 非聚簇索引\n   * 索引和表数据分开存储：所有的节点都是索引，叶子节点存储的是 索引 和 索引对应的数据记录地址。主键索引和二级索引在存储上没有任何区别。\n\n\n# b+tree\n\n这里，我们需要说一下，常用的索引结构 b+ tree,\n\n从图中也可以看到，b+树与b树的不同在于：\n\n 1. 所有数据都存储在叶子节点，非叶子节点不存储真正的data\n 2. 为所有叶子节点增加了一个链指针\n\n\n# 聚簇索引\n\n根据上述信息，我们可以想象，对于聚簇索引来说:\n\n 1. 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。\n\n同时, 由于主键发生变更的话, 索引结构需要再平衡、以及相关数据的移动, 这个代价相对较大, 所以一般设置主键为不可更新的.\n\n因此，对于innodb表，我们一般都会定义一个自增的id列为主键。\n\n页分裂是指，当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，这就是一次分裂操作。页分裂会导致表占用更多的磁盘空间。\n\n 2. 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。而非聚簇索引，主键索引和非主键索引，都可以直接定位数据的具体位置，然后进行访问即可。\n 3. 当通过聚簇索引查找目标数据时理论上比非聚簇索引要快，因为非聚簇索引定位到对应主键时还要多一次目标记录寻址,即多一次i/o。\n 4. 当需要取出一定范围内的数据时，用聚簇索引要比用非聚簇索引好\n\n对于聚簇索引的存储引擎，因为数据是根据主键顺序连续存储的，数据的物理存放顺序与索引顺序是一致的，所以只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的，索引结构相对紧凑，磁盘碎片少，效率也高。可以很方便的取出一定范围内的数据。\n\n对于聚簇索引也有一些不足之处，如：\n\n 1. 聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候。\n 2. 顺序主键在高并发工作负载下，在innodb中按主键顺序插入可能会造成明显的争用。\n\n主键的上界会成为“热点”。因为所有的插入都发生在这里，所以并发插入可能导致间隙锁竞争。\n\n另一个热点可能是auto_increment锁机制；如果遇到这个问题，则可能需要考虑重新设计表或者应用，比如应用层面生成单调递增的主键id，插表不使用auto_increment机制，或者更改innodb_autonc_lock_mode配置。\n\n\n# 非聚簇索\n\n对于非聚簇索引而言，\n\n 1. 二级索引可能比想象的要更大，因为在二给索引的叶子节点包含了引用行的主键列。\n 2. 由于插入的数据，是顺序写入的，与索引顺序无关，所以可以不必用单调递增id。\n 3. 但是 myisam 的锁是表级：写入数据，会使用全局(独占)表锁，读取数据也会使用全局(非独占)表锁。而 innodb 使用行级锁，同时有 mvcc 加持读性能。",charsets:{cjk:!0}},{title:"docker 中运行 mysql",frontmatter:{title:"docker 中运行 mysql",date:"2020-04-21T00:00:00.000Z",description:"在 docker 中运行 mysql 遇到的问题以及步骤",categories:["database"],tags:["database、mysql、docker"],permalink:null},regularPath:"/blog/database/mysql_runin_docker.html",relativePath:"blog/database/mysql_runin_docker.md",key:"v-e117a336",path:"/blog/database/mysql_runin_docker.html",headers:[{level:2,title:"运行:",slug:"运行",normalizedTitle:"运行:",charIndex:23},{level:3,title:"dump & restore",slug:"dump-restore",normalizedTitle:"dump &amp; restore",charIndex:null},{level:2,title:"问题",slug:"问题",normalizedTitle:"问题",charIndex:475}],headersStr:"运行: dump & restore 问题",content:"# docker 中运行 mysql\n\n\n# 运行:\n\ndocker run --name mysql -v /data/mysql:/var/lib/mysql -p 33061:3306 -e MYSQL_ROOT_PASSWORD=xxx -d mysql:5.7 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci\n\n\n# dump & restore\n\n * dump:\n   * docker exec some-mysql sh -c 'exec mysqldump --all-databases -uroot -p\"$MYSQL_ROOT_PASSWORD\"' > ~/all-databases.sql\n * restore:\n   * docker exec -i some-mysql sh -c 'exec mysql -uroot -p\"$MYSQL_ROOT_PASSWORD\"' < ~/all-databases.sql\n\n\n# 问题\n\n * host 无法连接 docker 中的mysql ：\"Unable to load plugin 'caching_sha2_password'\"\n   \n   进入容器：\n       docker exec -it CONTAINER_ID bash\n   登录mysql：\n       mysql --user=root --password\n   修改密码加密方式：\n       ALTER USER 'username' IDENTIFIED WITH mysql_native_password BY 'password';\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   \n * 用户以及授权\n   \n       create user 'miniuser'@'%' identified by '0sgckpIvpH5s3vmb';\n       grant all privileges on miniprogram.* to miniuser@'%';\n       flush privileges; \n       DROP USER 'miniprogram'@'%';\n   \n   \n   1\n   2\n   3\n   4\n   ",normalizedContent:"# docker 中运行 mysql\n\n\n# 运行:\n\ndocker run --name mysql -v /data/mysql:/var/lib/mysql -p 33061:3306 -e mysql_root_password=xxx -d mysql:5.7 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci\n\n\n# dump & restore\n\n * dump:\n   * docker exec some-mysql sh -c 'exec mysqldump --all-databases -uroot -p\"$mysql_root_password\"' > ~/all-databases.sql\n * restore:\n   * docker exec -i some-mysql sh -c 'exec mysql -uroot -p\"$mysql_root_password\"' < ~/all-databases.sql\n\n\n# 问题\n\n * host 无法连接 docker 中的mysql ：\"unable to load plugin 'caching_sha2_password'\"\n   \n   进入容器：\n       docker exec -it container_id bash\n   登录mysql：\n       mysql --user=root --password\n   修改密码加密方式：\n       alter user 'username' identified with mysql_native_password by 'password';\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   \n * 用户以及授权\n   \n       create user 'miniuser'@'%' identified by '0sgckpivph5s3vmb';\n       grant all privileges on miniprogram.* to miniuser@'%';\n       flush privileges; \n       drop user 'miniprogram'@'%';\n   \n   \n   1\n   2\n   3\n   4\n   ",charsets:{cjk:!0}},{title:"批量写入造成mysql访问慢问题",frontmatter:{title:"批量写入造成mysql访问慢问题",date:"2020-04-14T00:00:00.000Z",description:"批量写入造成mysql访问慢问题",categories:["blog","database"],tags:[null],permalink:null},regularPath:"/blog/database/problem_with_using_myisam.html",relativePath:"blog/database/problem_with_using_myisam.md",key:"v-46965d82",path:"/blog/database/problem_with_using_myisam.html",headers:[{level:2,title:"现象",slug:"现象",normalizedTitle:"现象",charIndex:23},{level:2,title:"跟进",slug:"跟进",normalizedTitle:"跟进",charIndex:72},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:1247},{level:2,title:"MYSQL 知识",slug:"mysql-知识",normalizedTitle:"mysql 知识",charIndex:1654}],headersStr:"现象 跟进 总结 MYSQL 知识",content:"# 批量写入造成mysql访问慢问题\n\n\n# 现象\n\n2020.03的某天下午，突然收到同事反馈，产品的某个页面出现'服务无响应'问题\n\n\n# 跟进\n\n * 由于服务器是分线路访问，可以通过 ping 指令，找到具体的服务器ip，然后本地绑定域名，进行模拟请求，确认问题并查看日志。\n * 发现是mysql数据库响应慢，造成接口响应速度下降 20+ 倍\n * 进行以下操作：\n   1. 通过以下指令打开、设置并查看慢查询日志\n      \n      // 查看\n      show variables like 'slow_query%';\n      show variables like 'long_query_time';\n      // 设置\n      set global [variablesName]=[Value]\n      // 日志输出方式：TABLE,FILE\n      show variables like '%log_output%'\n      \n      \n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      \n   2. 查看mysql的连接数等状态\n      \n      // 如果是root帐号，你能看到所有用户的当前连接。如果是其它普通帐号，只能看到自己占用的连接。\n      show full processlist;\n      // 状态\n      show status [like '%variables%'];\n      // 参数\n      show variables [like '%variables%']\n      \n      \n      1\n      2\n      3\n      4\n      5\n      6\n      \n   3. 查看mysql使用的内存、cpu、磁盘、网络状况\n * 分析\n   1. 数据库连接数已满(max=1000)\n   2. 磁盘、网络、cpu、内存 都不高，特别是内存低的很奇怪，只占总内存的 8% 左右，不能有效利用机器性能\n   3. 慢查询日志：发现发生慢查询的语句，都是使用到了索引、并且索引有效的查询语句\n * 猜测是：服务器配置 + 用户流量激增造成\n   1. 看域名流量，没有异常\n   2. mysql配置有异常：key_buffer_size 设置的很小。调整后，问题没有好转\n * 查看锁状况\n   1. 由于相关表使用的是MyISAM引擎，所以通过 show status like 'table%' 查看锁状态，发现：Table_locks_immediate / Table_locks_waited ~= 2\n   2. 因为这个库只能通过主从同步进行修改，这时想起相关的运营组最近在进行自动入库操作。\n   3. 停止后，问题缓解\n\n\n# 总结\n\n * 问题复盘\n   1. 这个数据库采用主从结构(一主多从)，异步同步，落盘策略为：sync_binlog=0\n   2. 自动入库：最近才开始，采用 while do { 写入数据(标记无效),校验文件md5,修改标记(有效) }\n      * 问题：相关人员说，前两天同样的操作没有出问题啊\n      * 确认：当天加上了文件md5校验\n      * 猜测：文件校验操作，造成mysql数据被分隔成更多次数刷新到磁盘并触发主从同步动作，造成更加密集的MyISAM表锁。由于，写锁优先级高，造成客户端请求近乎饿死，进而造成连接数打满。\n   3. 处理\n      * 考虑到这是个多年轻的项目，这次需要切换 MyISAM 到 innodb\n      * 调整Mysql相关参数，尽可能的发挥机器性能\n\n----------------------------------------\n\n\n# MYSQL 知识\n\n# 1. 相关命令、参数\n\n * 落盘策略: innodb_flush_log_at_trx_commit 和 sync_binlog\n * 查看主从同步状态：\n   \n   show slave status\n   show master status\n   \n   \n   1\n   2\n   \n\n# 2. mysql 的 sql_mode:\n\n * 查看当前sql-mode\n   \n   SELECT @@GLOBAL.sql_mode;\n   SELECT @@SESSION.sql_mode;\n   \n   \n   1\n   2\n   \n * 设置当前sql-mode\n   \n   // 命令\n   SET GLOBAL sql_mode = 'modes...';\n   SET SESSION sql_mode = 'modes...';\n   // my.cnf中配置sql-mode\n   [mysqld]\n   #set the SQL mode to strict\n   #sql-mode=\"modes...\" \n   sql-mode = \"STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\"\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   \n\n# 3. 查看引擎的锁定状态\n\n * Myisam : show status like 'table%'\n   * 通过检查 table_locks_waited 和 table_locks_immediate 状态变量分析系统上表锁争夺情况\n   * 表级锁是MyISAM不适合含有大量更新操作和查询操作应用的原因。\n   \n   •Table_locks_immediate \n       The number of times that a request for a table lock could be granted immediately. \n   •Table_locks_waited \n       The number of times that a request for a table lock could not be granted immediately and a wait was needed. If this is high and you have performance problems, you should first optimize your queries, and then either split your table or tables or use replication. \n   \n   \n   1\n   2\n   3\n   4\n   \n * Innodb : show status like 'innodb_row_lock%'\n   * 查看InnoDB行锁争用情况\n\n在学习锁的过程中，常用：set autocommit = 0; 来关闭自动提交，进而观察的状态。\n\n\n1\n\n\n# 4. MyISAM & InnoDB\n\n引擎       事务    锁机制   外键    并发性能   缓存      备份                        系统表是否使用   引入GTID后的影响\nMyISAM   不支持   表锁    不支持   低      索引      为了保持数据一致性，必须对表加读锁，影响业务写   使用        有问题(一个事务中同时使用事务引擎和非事务引擎)\nInnoDB   支持    行锁    支持    高      索引和数据   不需要锁表，不影响业务读写             使用        无问题\n\n从MySQL5.5开始，默认存储引擎变为了InnoDB，在此之前默认引擎使用的是MyISAM.\n从MySQL8.0开始，系统表也将采用InnoDB，完全放弃MyISAM。\n\n\n1\n2\n\n\n * MyISAM\n   \n   * MyISAM面临的主要问题\n     * 问题1：主从复制中断、主从数据不一致 ：由于MyISAM不支持事务，导致特别容易出现主备复制异常、主备数据不一致的情况\n     * 问题2: 进行备份时，无论是采用mysqldump进行的逻辑备份还是使用extrabackup进行的物理备份，为了保证MyISAM表的数据一致性，必须对表进行加锁，导致阻塞写入。这对于重建主从是经常出现的问题。\n   * MyISAM表级锁:\n     * 模式：表共享读锁(Table Read Lock)、表独占写锁(Table Write Lock)\n     * 默认情况下，写锁比读锁具有更高的优先级，这正是 MyISAM 表不太适合于有大量更新操作和查询操作应用的原因。因为，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。\n     * 在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，所以 MyISAM 表不会出现死锁。\n\n * InnoDB\n   \n   * 与 MyISAM 最大不同有两点：\n     1. 支持事务\n     2. 采用行级锁\n\n * 索引\n   \n   * MyISAM\n     * MyISAM索引实现：MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址.\n     * 在MyISAM中，主索引和辅助索引辅助索引(Secondary Index, 即非主键索引)在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。\n   * InnoDB\n     * InnoDB 表是基于聚簇索引建立的。因此InnoDB 的索引能提供一种非常快速的主键查找性能。InnoDB 不会压缩索引。\n       * 聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。\n       * 因为所有辅助索引都引用主索引(即，辅助索引也会包含主键列)，如果主键定义的比较大，其他索引也将很大，所以不建议使用过长的字段作为主键。另外，如果想在表上定义很多索引，则争取尽量把主键定义得小一些。\n     * 行锁\n       * InnoDB的行锁是针对索引加的锁，不是针对记录加的锁。\n         * 这一点MySQL与Oracle不同，它们是通过在数据块中，对相应数据行加锁来实现的\n       * InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，innoDB才使用行级锁，否则InnoDB将使用表锁。\n     * 主键\n       * 用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。\n\n# Mysql 内存优化\n\n注意：以下都是在MySQL目录下的my.ini文件中改写\n\n * InnoDB内存优化\n   * InnoDB用一块内存区域做I/O缓存池，该缓存池不仅用来缓存InnoDB的索引块，而且也用来缓存InnoDB的数据块。\n   1. innodb_log_buffer_size\n      * 决定了InnoDB重做日志缓存的大小，可以避免InnoDB在事务提交前就执行不必要的日志写入磁盘操作。\n   2. Innodb_buffer_pool_size\n      * 决定了InnoDB存储引擎表数据和索引数据的最大缓存区大小。\n * MyISAM内存优化\n   * MyISAM存储引擎使用key_buffer缓存索引模块，加速索引的读写速度。对于MyISAM表的数据块，mysql没有特别的缓存机制，完全依赖于操作系统的IO缓存。\n   1. read_rnd_buffer_size\n      * 对于需要做排序的MyISAM表查询，如带有order by子句的sql，适当增加read_rnd_buffer_size的值，可以改善此类的sql性能。但需要注意的是read_rnd_buffer_size独占的，如果默认设置值太大，就会造成内存浪费。\n   2. key_buffer_size\n      * key_buffer_size决定MyISAM索引块缓存分区的大小。直接影响到MyISAM表的存取效率。对于一般MyISAM数据库，建议1/4可用内存分配给key_buffer_size:\n   3. read_buffer_size\n      * 如果需要经常顺序扫描MyISAM表，可以通过增大read_buffer_size的值来改善性能。但需要注意的是read_buffer_size是每个seesion独占的，如果默认值设置太大，就会造成内存浪费。\n * 调整MySQL参数并发相关的参数\n   1. 调整max_connections: 提高并发连接\n   2. 调整thread_cache_size\n      * 加快连接数据库的速度，MySQL会缓存一定数量的客户服务线程以备重用，通过参数thread_cache_size可控制mysql缓存客户端线程的数量。\n   3. innodb_lock_wait_timeout\n      * 控制InnoDB事务等待行锁的时间，对于快速处理的SQL语句，可以将行锁等待超时时间调大，以避免发生大的回滚操作。（技术文）",normalizedContent:"# 批量写入造成mysql访问慢问题\n\n\n# 现象\n\n2020.03的某天下午，突然收到同事反馈，产品的某个页面出现'服务无响应'问题\n\n\n# 跟进\n\n * 由于服务器是分线路访问，可以通过 ping 指令，找到具体的服务器ip，然后本地绑定域名，进行模拟请求，确认问题并查看日志。\n * 发现是mysql数据库响应慢，造成接口响应速度下降 20+ 倍\n * 进行以下操作：\n   1. 通过以下指令打开、设置并查看慢查询日志\n      \n      // 查看\n      show variables like 'slow_query%';\n      show variables like 'long_query_time';\n      // 设置\n      set global [variablesname]=[value]\n      // 日志输出方式：table,file\n      show variables like '%log_output%'\n      \n      \n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      \n   2. 查看mysql的连接数等状态\n      \n      // 如果是root帐号，你能看到所有用户的当前连接。如果是其它普通帐号，只能看到自己占用的连接。\n      show full processlist;\n      // 状态\n      show status [like '%variables%'];\n      // 参数\n      show variables [like '%variables%']\n      \n      \n      1\n      2\n      3\n      4\n      5\n      6\n      \n   3. 查看mysql使用的内存、cpu、磁盘、网络状况\n * 分析\n   1. 数据库连接数已满(max=1000)\n   2. 磁盘、网络、cpu、内存 都不高，特别是内存低的很奇怪，只占总内存的 8% 左右，不能有效利用机器性能\n   3. 慢查询日志：发现发生慢查询的语句，都是使用到了索引、并且索引有效的查询语句\n * 猜测是：服务器配置 + 用户流量激增造成\n   1. 看域名流量，没有异常\n   2. mysql配置有异常：key_buffer_size 设置的很小。调整后，问题没有好转\n * 查看锁状况\n   1. 由于相关表使用的是myisam引擎，所以通过 show status like 'table%' 查看锁状态，发现：table_locks_immediate / table_locks_waited ~= 2\n   2. 因为这个库只能通过主从同步进行修改，这时想起相关的运营组最近在进行自动入库操作。\n   3. 停止后，问题缓解\n\n\n# 总结\n\n * 问题复盘\n   1. 这个数据库采用主从结构(一主多从)，异步同步，落盘策略为：sync_binlog=0\n   2. 自动入库：最近才开始，采用 while do { 写入数据(标记无效),校验文件md5,修改标记(有效) }\n      * 问题：相关人员说，前两天同样的操作没有出问题啊\n      * 确认：当天加上了文件md5校验\n      * 猜测：文件校验操作，造成mysql数据被分隔成更多次数刷新到磁盘并触发主从同步动作，造成更加密集的myisam表锁。由于，写锁优先级高，造成客户端请求近乎饿死，进而造成连接数打满。\n   3. 处理\n      * 考虑到这是个多年轻的项目，这次需要切换 myisam 到 innodb\n      * 调整mysql相关参数，尽可能的发挥机器性能\n\n----------------------------------------\n\n\n# mysql 知识\n\n# 1. 相关命令、参数\n\n * 落盘策略: innodb_flush_log_at_trx_commit 和 sync_binlog\n * 查看主从同步状态：\n   \n   show slave status\n   show master status\n   \n   \n   1\n   2\n   \n\n# 2. mysql 的 sql_mode:\n\n * 查看当前sql-mode\n   \n   select @@global.sql_mode;\n   select @@session.sql_mode;\n   \n   \n   1\n   2\n   \n * 设置当前sql-mode\n   \n   // 命令\n   set global sql_mode = 'modes...';\n   set session sql_mode = 'modes...';\n   // my.cnf中配置sql-mode\n   [mysqld]\n   #set the sql mode to strict\n   #sql-mode=\"modes...\" \n   sql-mode = \"strict_trans_tables,no_auto_create_user,no_engine_substitution\"\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   \n\n# 3. 查看引擎的锁定状态\n\n * myisam : show status like 'table%'\n   * 通过检查 table_locks_waited 和 table_locks_immediate 状态变量分析系统上表锁争夺情况\n   * 表级锁是myisam不适合含有大量更新操作和查询操作应用的原因。\n   \n   •table_locks_immediate \n       the number of times that a request for a table lock could be granted immediately. \n   •table_locks_waited \n       the number of times that a request for a table lock could not be granted immediately and a wait was needed. if this is high and you have performance problems, you should first optimize your queries, and then either split your table or tables or use replication. \n   \n   \n   1\n   2\n   3\n   4\n   \n * innodb : show status like 'innodb_row_lock%'\n   * 查看innodb行锁争用情况\n\n在学习锁的过程中，常用：set autocommit = 0; 来关闭自动提交，进而观察的状态。\n\n\n1\n\n\n# 4. myisam & innodb\n\n引擎       事务    锁机制   外键    并发性能   缓存      备份                        系统表是否使用   引入gtid后的影响\nmyisam   不支持   表锁    不支持   低      索引      为了保持数据一致性，必须对表加读锁，影响业务写   使用        有问题(一个事务中同时使用事务引擎和非事务引擎)\ninnodb   支持    行锁    支持    高      索引和数据   不需要锁表，不影响业务读写             使用        无问题\n\n从mysql5.5开始，默认存储引擎变为了innodb，在此之前默认引擎使用的是myisam.\n从mysql8.0开始，系统表也将采用innodb，完全放弃myisam。\n\n\n1\n2\n\n\n * myisam\n   \n   * myisam面临的主要问题\n     * 问题1：主从复制中断、主从数据不一致 ：由于myisam不支持事务，导致特别容易出现主备复制异常、主备数据不一致的情况\n     * 问题2: 进行备份时，无论是采用mysqldump进行的逻辑备份还是使用extrabackup进行的物理备份，为了保证myisam表的数据一致性，必须对表进行加锁，导致阻塞写入。这对于重建主从是经常出现的问题。\n   * myisam表级锁:\n     * 模式：表共享读锁(table read lock)、表独占写锁(table write lock)\n     * 默认情况下，写锁比读锁具有更高的优先级，这正是 myisam 表不太适合于有大量更新操作和查询操作应用的原因。因为，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。\n     * 在自动加锁的情况下，myisam 总是一次获得 sql 语句所需要的全部锁，所以 myisam 表不会出现死锁。\n\n * innodb\n   \n   * 与 myisam 最大不同有两点：\n     1. 支持事务\n     2. 采用行级锁\n\n * 索引\n   \n   * myisam\n     * myisam索引实现：myisam索引文件和数据文件是分离的，索引文件仅保存数据记录的地址.\n     * 在myisam中，主索引和辅助索引辅助索引(secondary index, 即非主键索引)在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。\n   * innodb\n     * innodb 表是基于聚簇索引建立的。因此innodb 的索引能提供一种非常快速的主键查找性能。innodb 不会压缩索引。\n       * 聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。\n       * 因为所有辅助索引都引用主索引(即，辅助索引也会包含主键列)，如果主键定义的比较大，其他索引也将很大，所以不建议使用过长的字段作为主键。另外，如果想在表上定义很多索引，则争取尽量把主键定义得小一些。\n     * 行锁\n       * innodb的行锁是针对索引加的锁，不是针对记录加的锁。\n         * 这一点mysql与oracle不同，它们是通过在数据块中，对相应数据行加锁来实现的\n       * innodb这种行锁实现特点意味着：只有通过索引条件检索数据，innodb才使用行级锁，否则innodb将使用表锁。\n     * 主键\n       * 用非单调的字段作为主键在innodb中不是个好主意，因为innodb数据文件本身是一颗b+tree，非单调的主键会造成在插入新记录时数据文件为了维持b+tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。\n\n# mysql 内存优化\n\n注意：以下都是在mysql目录下的my.ini文件中改写\n\n * innodb内存优化\n   * innodb用一块内存区域做i/o缓存池，该缓存池不仅用来缓存innodb的索引块，而且也用来缓存innodb的数据块。\n   1. innodb_log_buffer_size\n      * 决定了innodb重做日志缓存的大小，可以避免innodb在事务提交前就执行不必要的日志写入磁盘操作。\n   2. innodb_buffer_pool_size\n      * 决定了innodb存储引擎表数据和索引数据的最大缓存区大小。\n * myisam内存优化\n   * myisam存储引擎使用key_buffer缓存索引模块，加速索引的读写速度。对于myisam表的数据块，mysql没有特别的缓存机制，完全依赖于操作系统的io缓存。\n   1. read_rnd_buffer_size\n      * 对于需要做排序的myisam表查询，如带有order by子句的sql，适当增加read_rnd_buffer_size的值，可以改善此类的sql性能。但需要注意的是read_rnd_buffer_size独占的，如果默认设置值太大，就会造成内存浪费。\n   2. key_buffer_size\n      * key_buffer_size决定myisam索引块缓存分区的大小。直接影响到myisam表的存取效率。对于一般myisam数据库，建议1/4可用内存分配给key_buffer_size:\n   3. read_buffer_size\n      * 如果需要经常顺序扫描myisam表，可以通过增大read_buffer_size的值来改善性能。但需要注意的是read_buffer_size是每个seesion独占的，如果默认值设置太大，就会造成内存浪费。\n * 调整mysql参数并发相关的参数\n   1. 调整max_connections: 提高并发连接\n   2. 调整thread_cache_size\n      * 加快连接数据库的速度，mysql会缓存一定数量的客户服务线程以备重用，通过参数thread_cache_size可控制mysql缓存客户端线程的数量。\n   3. innodb_lock_wait_timeout\n      * 控制innodb事务等待行锁的时间，对于快速处理的sql语句，可以将行锁等待超时时间调大，以避免发生大的回滚操作。（技术文）",charsets:{cjk:!0}},{title:"Redis 手册",frontmatter:{title:"Redis 手册",date:"2020-04-21T00:00:00.000Z",description:"Redis 基础",categories:["blog","database"],tags:[null],permalink:null},regularPath:"/blog/database/redis_manual.html",relativePath:"blog/database/redis_manual.md",key:"v-2c4fb4ae",path:"/blog/database/redis_manual.html",headers:[{level:2,title:"Redis 基础类型",slug:"redis-基础类型",normalizedTitle:"redis 基础类型",charIndex:15},{level:3,title:"Stream 使用简介",slug:"stream-使用简介",normalizedTitle:"stream 使用简介",charIndex:250},{level:3,title:"Benchmark",slug:"benchmark",normalizedTitle:"benchmark",charIndex:1394},{level:2,title:"redis 的各种使用场景",slug:"redis-的各种使用场景",normalizedTitle:"redis 的各种使用场景",charIndex:1876},{level:2,title:"Redis 原理",slug:"redis-原理",normalizedTitle:"redis 原理",charIndex:1952},{level:2,title:"高可用",slug:"高可用",normalizedTitle:"高可用",charIndex:2104},{level:2,title:"指标、监控、安全",slug:"指标、监控、安全",normalizedTitle:"指标、监控、安全",charIndex:2145},{level:2,title:"新版本特征追踪",slug:"新版本特征追踪",normalizedTitle:"新版本特征追踪",charIndex:2191}],headersStr:"Redis 基础类型 Stream 使用简介 Benchmark redis 的各种使用场景 Redis 原理 高可用 指标、监控、安全 新版本特征追踪",content:"# Redis 手册\n\n\n# Redis 基础类型\n\nRedis 常用的数据类型有:\n\n    string list set hash zset \n    pub/sub \n    stream(5.0) \n\n\n1\n2\n3\n\n * 常用指令:\n * 原理:\n   * 基础数据结构:\n     * hashtable\n     * quicklist ---\x3e node: ziplist\n     * radixtree ---\x3e node: listpack(ziplist的升级版)\n\n\n# Stream 使用简介\n\nstream 的每个消息都有 steam id:\n\n * 由 '-' 连接一个精确到毫秒的时间戳 和 自增的整数这两部分组成。\n * 两个部分都由一个无符号64位整数表示。因此, 不用担心id重复: 要用完这两部分，一毫秒内得发送 2 ** 64 = 18446744073709551616 条数据，目前应该没有哪个高并发系统能高到这个程度。\n\n对于消费组来说，stream 提供如下保障：\n\n * 组内消费者消费的消息不重复;\n * 组内消费者名称必须唯一;\n * 消费者拿到的消息肯定是没有被组内其他消费者消费过的消息，消费者成功消费消息之后要求发送ACK，然后这条消息才会从消费者组中移除，也就是说消息至少被消费一次，和kafka一样;\n * 消费者组会跟踪所有待处理的消息;\n\n关于 stream 的使用 和 原理 可以参考：\n\n * 基于Redis的Stream类型的完美消息队列解决方案\n * radix tree，基数树\n\n另外，我们来看看依赖 redis 特效实现消息队列的几种方式对比：\n\nLIST, ZSET, PUB/SUB                                        STREAM\nList 不能高效的从中间获取数据, O(N)                                    可以, 即使是亿级别, O(logN)\nList 没有offset概念, 如果成员发生evit, 无法确认最新的成员, 也无法rewind到某个指定成员   每条msg都有唯一id, 老的成员被淘汰, id不变\nPub/Sub 不能持久化消息                                            可以保存在 RDB 和 AOF\nPub/Sub 没有consumer group的概念                                有, 更贴近真实的业务场景\nPub/Sub 的性能和订阅某个频道的client数量正相关                             不存在\nZset 不允许添加重复成员, 不支持成员淘汰和block操作, 内存开销大                     允许, 支持按时间线来淘汰历史数据, 支持block操作, 基于radix tree和listpack, 内存开销低\nZset 需要支持删除任意元素                                            不支持从中间删除元素(log属性), more compact and memory efficient\n\n\n# Benchmark\n\n一般来说，redis 作为内存存储的 nosql，提供了多种数据类型，且效率之高，能满足大多数场景的需要。\n\n但，它依然有瓶颈存在，常见的瓶颈有：QPS CPU 流量. 其中，QPS 和 CPU 我们很容易想的到，流量这个瓶颈点很容易被忽略，在较大的 key或value 较多的时候，要非常注意。\n\n在使用 redis 前，大多会针对使用场景进行压测，所以一种高效的 benchmark 工具是必须的，而 redis 自带的 redis-benchmark 就提供了非常完善的功能，完美~\n\n使用示例：\n    redis-benchmark -h 10.46.35.1 -p 6379 -a 'passwd' -r 80 -d 1500 -c 1000 -l -k 0 -n 1000000 -t set,mget\n    redis-benchmark -h 10.46.35.1 -p 6379 -a 'passwd' -t set -c 3500 -d 128 -n 25000000 -r 5000000\n\n\n1\n2\n3\n\n\n\n# redis 的各种使用场景\n\nboomfilter、限流、GeoHash、分布式锁 Scan、管道、事务、pubsub Sort Lua 脚本\n\n\n# Redis 原理\n\n单线程模型 过期策略 以及 原理 内存回收 基础类型实现原理：string: SDS, dict: hashtable, list: ziplist、linkedlist、listpack(5.0, 目前只stream), zset: skiplist 渐进式 rehash\n\n\n# 高可用\n\nAOF、RDB, PSYNC sentinel、cluster\n\n\n# 指标、监控、安全\n\ninfo 慢查询、热点数据 rename-command 指令\n\n\n# 新版本特征追踪",normalizedContent:"# redis 手册\n\n\n# redis 基础类型\n\nredis 常用的数据类型有:\n\n    string list set hash zset \n    pub/sub \n    stream(5.0) \n\n\n1\n2\n3\n\n * 常用指令:\n * 原理:\n   * 基础数据结构:\n     * hashtable\n     * quicklist ---\x3e node: ziplist\n     * radixtree ---\x3e node: listpack(ziplist的升级版)\n\n\n# stream 使用简介\n\nstream 的每个消息都有 steam id:\n\n * 由 '-' 连接一个精确到毫秒的时间戳 和 自增的整数这两部分组成。\n * 两个部分都由一个无符号64位整数表示。因此, 不用担心id重复: 要用完这两部分，一毫秒内得发送 2 ** 64 = 18446744073709551616 条数据，目前应该没有哪个高并发系统能高到这个程度。\n\n对于消费组来说，stream 提供如下保障：\n\n * 组内消费者消费的消息不重复;\n * 组内消费者名称必须唯一;\n * 消费者拿到的消息肯定是没有被组内其他消费者消费过的消息，消费者成功消费消息之后要求发送ack，然后这条消息才会从消费者组中移除，也就是说消息至少被消费一次，和kafka一样;\n * 消费者组会跟踪所有待处理的消息;\n\n关于 stream 的使用 和 原理 可以参考：\n\n * 基于redis的stream类型的完美消息队列解决方案\n * radix tree，基数树\n\n另外，我们来看看依赖 redis 特效实现消息队列的几种方式对比：\n\nlist, zset, pub/sub                                        stream\nlist 不能高效的从中间获取数据, o(n)                                    可以, 即使是亿级别, o(logn)\nlist 没有offset概念, 如果成员发生evit, 无法确认最新的成员, 也无法rewind到某个指定成员   每条msg都有唯一id, 老的成员被淘汰, id不变\npub/sub 不能持久化消息                                            可以保存在 rdb 和 aof\npub/sub 没有consumer group的概念                                有, 更贴近真实的业务场景\npub/sub 的性能和订阅某个频道的client数量正相关                             不存在\nzset 不允许添加重复成员, 不支持成员淘汰和block操作, 内存开销大                     允许, 支持按时间线来淘汰历史数据, 支持block操作, 基于radix tree和listpack, 内存开销低\nzset 需要支持删除任意元素                                            不支持从中间删除元素(log属性), more compact and memory efficient\n\n\n# benchmark\n\n一般来说，redis 作为内存存储的 nosql，提供了多种数据类型，且效率之高，能满足大多数场景的需要。\n\n但，它依然有瓶颈存在，常见的瓶颈有：qps cpu 流量. 其中，qps 和 cpu 我们很容易想的到，流量这个瓶颈点很容易被忽略，在较大的 key或value 较多的时候，要非常注意。\n\n在使用 redis 前，大多会针对使用场景进行压测，所以一种高效的 benchmark 工具是必须的，而 redis 自带的 redis-benchmark 就提供了非常完善的功能，完美~\n\n使用示例：\n    redis-benchmark -h 10.46.35.1 -p 6379 -a 'passwd' -r 80 -d 1500 -c 1000 -l -k 0 -n 1000000 -t set,mget\n    redis-benchmark -h 10.46.35.1 -p 6379 -a 'passwd' -t set -c 3500 -d 128 -n 25000000 -r 5000000\n\n\n1\n2\n3\n\n\n\n# redis 的各种使用场景\n\nboomfilter、限流、geohash、分布式锁 scan、管道、事务、pubsub sort lua 脚本\n\n\n# redis 原理\n\n单线程模型 过期策略 以及 原理 内存回收 基础类型实现原理：string: sds, dict: hashtable, list: ziplist、linkedlist、listpack(5.0, 目前只stream), zset: skiplist 渐进式 rehash\n\n\n# 高可用\n\naof、rdb, psync sentinel、cluster\n\n\n# 指标、监控、安全\n\ninfo 慢查询、热点数据 rename-command 指令\n\n\n# 新版本特征追踪",charsets:{cjk:!0}},{title:"Design",frontmatter:{published:!0,title:"Design",description:"algorithm、design 相关知识汇总",keywords:[""],categories:["blog","design","algorithm"],permalink:"/blog/design/",date:"2020-04-13T00:00:00.000Z",tags:[null]},regularPath:"/blog/design/",relativePath:"blog/design/README.md",key:"v-742c98c4",path:"/blog/design/",headersStr:null,content:"# DESIGN\n\n * Mvp Mvp Mvvm\n * 常见算法集\n * 分布式一致性协议简介\n * 软件设计的7大原则",normalizedContent:"# design\n\n * mvp mvp mvvm\n * 常见算法集\n * 分布式一致性协议简介\n * 软件设计的7大原则",charsets:{cjk:!0}},{title:"常见算法集",frontmatter:{title:"常见算法集",date:"2021-01-16T23:29:06.000Z",categories:["blog","design","algorithm"],tags:[null],permalink:null},regularPath:"/blog/design/algorithm_common.html",relativePath:"blog/design/algorithm_common.md",key:"v-f1ab1866",path:"/blog/design/algorithm_common.html",headers:[{level:2,title:"Floyd算法",slug:"floyd算法",normalizedTitle:"floyd算法",charIndex:16},{level:2,title:"Dynamic Programming",slug:"dynamic-programming",normalizedTitle:"dynamic programming",charIndex:184},{level:2,title:"α-β剪枝算法",slug:"α-β剪枝算法",normalizedTitle:"α-β剪枝算法",charIndex:398},{level:2,title:"朴素贝叶斯",slug:"朴素贝叶斯",normalizedTitle:"朴素贝叶斯",charIndex:410},{level:2,title:"推荐算法",slug:"推荐算法",normalizedTitle:"推荐算法",charIndex:420},{level:2,title:"树",slug:"树",normalizedTitle:"树",charIndex:446},{level:2,title:"LRU (Least recently used)",slug:"lru-least-recently-used",normalizedTitle:"lru (least recently used)",charIndex:609},{level:2,title:"LFU (Least-frequently used)",slug:"lfu-least-frequently-used",normalizedTitle:"lfu (least-frequently used)",charIndex:779},{level:2,title:"ARC",slug:"arc",normalizedTitle:"arc",charIndex:959}],headersStr:"Floyd算法 Dynamic Programming α-β剪枝算法 朴素贝叶斯 推荐算法 树 LRU (Least recently used) LFU (Least-frequently used) ARC",content:'# Algorithm\n\n\n# Floyd算法\n\n * Dis(AB) = min(Dis(AB), Dis(AK) + Dis(KB))\n * 注意循环的嵌套顺序:\n   * 如果把检查所有节点K放在最内层(应该放在最外层)，那么结果将是不正确的\n   * 为什么呢？因为这样便过早的把A到B的最短路径确定下来了，而当后面存在更短的路径时，已经不再会更新了\n\n\n# Dynamic Programming\n\n * 使用条件：无后效性\n   * 某阶段的状态一旦确定，则此后过程的演变不再受此前各种状态及决策的影响。简单的说，就是"未来与过去无关"，当前的状态是此前历史的一个完整总结，此前的历史只能通过当前状态去影响未来过程的演变。\n * 常见问题\n   * 01背包问题、最长非降子序列\n   * 带权重的单源最短路\n   * 带权重、每步都有一定资源消耗(如:过路费)的单源最短路\n\n\n# α-β剪枝算法\n\n\n# 朴素贝叶斯\n\n\n# 推荐算法\n\n * 协同过滤、LR、GBDT\n\n\n# 树\n\n * 二叉树、完全二叉树、平衡二叉树、二叉查找树（BST）\n   * \n * 红黑树\n * B，B+，B*树\n * LSM 树\n * 最小生成树算法\n   * https://blog.csdn.net/luoshixian099/article/details/51908175\n\nTOP\n\n\n# Cache\n\n\n# LRU (Least recently used)\n\n其核心思想是:假设刚visit的item,很有可能在未来被revisit,丢弃最近最少访问的items\n\n * 通常用双链表实现\n * 缺点:忽略了frequency, 不适合大规模扫描等情况\n * LRU有一系列变种，比如LRU-N(如，LRU-2), 2Q, LIRS等。\n\n\n# LFU (Least-frequently used)\n\n其核心思想是:假设visit次数越多的item,很有可能在未来被revisit\n\n * 适应大规模扫描\n * 对热点友好\n * 缺点:忽略了recency, 可能会积累不再使用的数据 tips: redis4.0开始支持了LFU,例如volatile-lfu, allkeys-lfu配置选项\n\n\n# ARC\n\nARC（Adaptive Replacement Cache）是一种适应性Cache算法, 它结合了LRU与LFU的特点。\n\nARC 论文，将整个Cache分成两部分，起始LRU和LFU各占一半，后续会动态适应调整partion的位置(记为p), 除此，LRU和LFU各自有一个ghost list(因此，一共4个list)。每次，被淘汰的item放到对应的ghost list中（ghost list只存key）, 例如：如果被evicted的item来自LRU的部分， 则该item对应的key会被放入LRU对应的ghost list\n\n * 第一次cache miss, 则会放入LRU\n * 如果cache hit, 如果LFU中没有，则放入LFU\n * 如果cache miss, 但在ghost list中命中，这说明对应的cache如果再大一丁点儿就好了： 如果存在于LRU ghost list, 则p=p+1；否则存在于LFU ghost list, p=p-1.\n * 也就是说，利用这种适应机制，当系统趋向于访问最近的内容，会更多地命中LRU ghost list，这样会增大LRU的空间； 当系统趋向于访问最频繁的内容，会更多地命中LFU ghost list，这样会增加LFU的空间.',normalizedContent:'# algorithm\n\n\n# floyd算法\n\n * dis(ab) = min(dis(ab), dis(ak) + dis(kb))\n * 注意循环的嵌套顺序:\n   * 如果把检查所有节点k放在最内层(应该放在最外层)，那么结果将是不正确的\n   * 为什么呢？因为这样便过早的把a到b的最短路径确定下来了，而当后面存在更短的路径时，已经不再会更新了\n\n\n# dynamic programming\n\n * 使用条件：无后效性\n   * 某阶段的状态一旦确定，则此后过程的演变不再受此前各种状态及决策的影响。简单的说，就是"未来与过去无关"，当前的状态是此前历史的一个完整总结，此前的历史只能通过当前状态去影响未来过程的演变。\n * 常见问题\n   * 01背包问题、最长非降子序列\n   * 带权重的单源最短路\n   * 带权重、每步都有一定资源消耗(如:过路费)的单源最短路\n\n\n# α-β剪枝算法\n\n\n# 朴素贝叶斯\n\n\n# 推荐算法\n\n * 协同过滤、lr、gbdt\n\n\n# 树\n\n * 二叉树、完全二叉树、平衡二叉树、二叉查找树（bst）\n   * \n * 红黑树\n * b，b+，b*树\n * lsm 树\n * 最小生成树算法\n   * https://blog.csdn.net/luoshixian099/article/details/51908175\n\ntop\n\n\n# cache\n\n\n# lru (least recently used)\n\n其核心思想是:假设刚visit的item,很有可能在未来被revisit,丢弃最近最少访问的items\n\n * 通常用双链表实现\n * 缺点:忽略了frequency, 不适合大规模扫描等情况\n * lru有一系列变种，比如lru-n(如，lru-2), 2q, lirs等。\n\n\n# lfu (least-frequently used)\n\n其核心思想是:假设visit次数越多的item,很有可能在未来被revisit\n\n * 适应大规模扫描\n * 对热点友好\n * 缺点:忽略了recency, 可能会积累不再使用的数据 tips: redis4.0开始支持了lfu,例如volatile-lfu, allkeys-lfu配置选项\n\n\n# arc\n\narc（adaptive replacement cache）是一种适应性cache算法, 它结合了lru与lfu的特点。\n\narc 论文，将整个cache分成两部分，起始lru和lfu各占一半，后续会动态适应调整partion的位置(记为p), 除此，lru和lfu各自有一个ghost list(因此，一共4个list)。每次，被淘汰的item放到对应的ghost list中（ghost list只存key）, 例如：如果被evicted的item来自lru的部分， 则该item对应的key会被放入lru对应的ghost list\n\n * 第一次cache miss, 则会放入lru\n * 如果cache hit, 如果lfu中没有，则放入lfu\n * 如果cache miss, 但在ghost list中命中，这说明对应的cache如果再大一丁点儿就好了： 如果存在于lru ghost list, 则p=p+1；否则存在于lfu ghost list, p=p-1.\n * 也就是说，利用这种适应机制，当系统趋向于访问最近的内容，会更多地命中lru ghost list，这样会增大lru的空间； 当系统趋向于访问最频繁的内容，会更多地命中lfu ghost list，这样会增加lfu的空间.',charsets:{cjk:!0}},{title:"分布式一致性协议简介",frontmatter:{title:"分布式一致性协议简介",date:"2021-01-16T23:29:06.000Z",categories:["blog","design","algorithm"],tags:[null],permalink:null},regularPath:"/blog/design/algorithm_distributed_consensus_protocols.html",relativePath:"blog/design/algorithm_distributed_consensus_protocols.md",key:"v-5180c0ff",path:"/blog/design/algorithm_distributed_consensus_protocols.html",headers:[{level:2,title:"Raft：",slug:"raft",normalizedTitle:"raft：",charIndex:17},{level:2,title:"Paxos：",slug:"paxos",normalizedTitle:"paxos：",charIndex:752},{level:2,title:"Gossip:",slug:"gossip",normalizedTitle:"gossip:",charIndex:1746},{level:2,title:"Totem：",slug:"totem",normalizedTitle:"totem：",charIndex:2002}],headersStr:"Raft： Paxos： Gossip: Totem：",content:"# 分布式一致性协议简介\n\n\n# Raft：\n\n * leader election\n   * two timeouts\n     * eletction timeout\n       * randomized to be between 150ms and 300ms\n     * heartbeat timeout:\n       * usage: Append Entries messages\n * log replication\n   * client make request to leader\n   * leader make log entry and log replication, expecting major votes from all clients\n   * leader respone to client and accept client's request\n   * leader make log replication that commit client's request\n * status\n   * follower ---\x3e candidate ---\x3e leader\n     * follower become candidate when eletction timeout\n     * candidate become leader when major votes\n * infomations:\n   * url : http://thesecretlivesofdata.com/raft/\n   * github: https://github.com/benbjohnson/thesecretlivesofdata\n\n\n# Paxos：\n\n# Basic Paxos：\n\n * abstract\n   * 强一致性\n   * Proposer、Acceptor、ProposalID(以高位时间戳 + 低位机器 IP 可以保证唯一性和递增性)\n * steps:\n   \n   * prepare\n     \n     * Proposer 发送 Prepare\n       * 生成新的ProposalID\n     * Acceptor 应答 Prepare\n       * response：\n         * 返回自己已经 Accept 过的提案中 ProposalID 最大的那个提案的内容，如果没有则返回空值;\n         * 应答前要在本地持久化当前 Propsalid\n       * promise：\n         * 不再应答 Proposalid 小于等于（注意：这里是 <= ）当前请求的 PrepareRequest\n         * 不再应答 Proposalid 小于（注意：这里是 < ）当前请求的 AcceptRequest\n   \n   * accept\n     \n     * Proposer 发送 Accept\n       * “提案生成规则”：\n         * Proposer 收集到多数派应答的 PrepareResponse 后，从中选择proposalid最大的提案内容，作为要发起 Accept 的提案，如果这个提案为空值，则可以自己随意决定提案内容。然后携带上当前 Proposalid，向 Paxos 集群的所有机器发送 AccpetRequest。\n     * Acceptor 应答 Accept\n       * 检查AccpetRequest不违背自己之前作出的“两个承诺”情况下，持久化当前 Proposalid 和提案内容。最后 Proposer 收集到多数派应答的 AcceptResponse 后，形成决议。\n * infomations\n   * http://chuansong.me/n/2189245\n   * https://blog.csdn.net/heiyeshuwu/article/details/42426811\n\n# Fast Paxos\n\n# Multi Paxos\n\n\n# Gossip:\n\n * abstract\n   * 反熵（Anti-Entropy）\n   * 种子节点\n   * 去中心化\n   * 最终一致性（现实中存在，理论无法证明的时间点）\n * weakness\n   * 冗余通信\n * kernel\n   * 信息同步\n   * Merkle tree(MT)是一个非常适合同步的数据结构\n * paper\n   * Efficient Reconciliation and Flow Control for Anti-Entropy Protocols\n\n\n# Totem：\n\n * abstract\n   * 强一致性\n * steps：\n   * 通信方式\n     * 当集群有节点要发起通信时，需要等待token。当拿到token后，先广播这次需要发送的数据，然后传递token来确认所有人都接收到消息。 如果确认成功，释放token\n   * 节点的加入和退出\n     1. 当集群中有节点加入时，加入的节点广播一个加入信息，所有人都开始广播自己的信息，当所有人都获得同伴信息，开始由id最小的人提交一个token，交由所有节点确认。\n     2. 如果都确认后，则节点正式加入，开始正常运行。\n     3. 当集群有节点退出时，由于令牌环断链，触发token超时，则同样开始广播信息，然后由最小id提交token，经过确认后恢复正常。",normalizedContent:"# 分布式一致性协议简介\n\n\n# raft：\n\n * leader election\n   * two timeouts\n     * eletction timeout\n       * randomized to be between 150ms and 300ms\n     * heartbeat timeout:\n       * usage: append entries messages\n * log replication\n   * client make request to leader\n   * leader make log entry and log replication, expecting major votes from all clients\n   * leader respone to client and accept client's request\n   * leader make log replication that commit client's request\n * status\n   * follower ---\x3e candidate ---\x3e leader\n     * follower become candidate when eletction timeout\n     * candidate become leader when major votes\n * infomations:\n   * url : http://thesecretlivesofdata.com/raft/\n   * github: https://github.com/benbjohnson/thesecretlivesofdata\n\n\n# paxos：\n\n# basic paxos：\n\n * abstract\n   * 强一致性\n   * proposer、acceptor、proposalid(以高位时间戳 + 低位机器 ip 可以保证唯一性和递增性)\n * steps:\n   \n   * prepare\n     \n     * proposer 发送 prepare\n       * 生成新的proposalid\n     * acceptor 应答 prepare\n       * response：\n         * 返回自己已经 accept 过的提案中 proposalid 最大的那个提案的内容，如果没有则返回空值;\n         * 应答前要在本地持久化当前 propsalid\n       * promise：\n         * 不再应答 proposalid 小于等于（注意：这里是 <= ）当前请求的 preparerequest\n         * 不再应答 proposalid 小于（注意：这里是 < ）当前请求的 acceptrequest\n   \n   * accept\n     \n     * proposer 发送 accept\n       * “提案生成规则”：\n         * proposer 收集到多数派应答的 prepareresponse 后，从中选择proposalid最大的提案内容，作为要发起 accept 的提案，如果这个提案为空值，则可以自己随意决定提案内容。然后携带上当前 proposalid，向 paxos 集群的所有机器发送 accpetrequest。\n     * acceptor 应答 accept\n       * 检查accpetrequest不违背自己之前作出的“两个承诺”情况下，持久化当前 proposalid 和提案内容。最后 proposer 收集到多数派应答的 acceptresponse 后，形成决议。\n * infomations\n   * http://chuansong.me/n/2189245\n   * https://blog.csdn.net/heiyeshuwu/article/details/42426811\n\n# fast paxos\n\n# multi paxos\n\n\n# gossip:\n\n * abstract\n   * 反熵（anti-entropy）\n   * 种子节点\n   * 去中心化\n   * 最终一致性（现实中存在，理论无法证明的时间点）\n * weakness\n   * 冗余通信\n * kernel\n   * 信息同步\n   * merkle tree(mt)是一个非常适合同步的数据结构\n * paper\n   * efficient reconciliation and flow control for anti-entropy protocols\n\n\n# totem：\n\n * abstract\n   * 强一致性\n * steps：\n   * 通信方式\n     * 当集群有节点要发起通信时，需要等待token。当拿到token后，先广播这次需要发送的数据，然后传递token来确认所有人都接收到消息。 如果确认成功，释放token\n   * 节点的加入和退出\n     1. 当集群中有节点加入时，加入的节点广播一个加入信息，所有人都开始广播自己的信息，当所有人都获得同伴信息，开始由id最小的人提交一个token，交由所有节点确认。\n     2. 如果都确认后，则节点正式加入，开始正常运行。\n     3. 当集群有节点退出时，由于令牌环断链，触发token超时，则同样开始广播信息，然后由最小id提交token，经过确认后恢复正常。",charsets:{cjk:!0}},{title:"软件设计的7大原则",frontmatter:{title:"软件设计的7大原则",date:"2020-04-13T00:00:00.000Z",description:"软件设计的7大原则",permalink:null,categories:["blog","design"],tags:[null]},regularPath:"/blog/design/architecture_7principle_in_software.html",relativePath:"blog/design/architecture_7principle_in_software.md",key:"v-31e2af82",path:"/blog/design/architecture_7principle_in_software.html",headersStr:null,content:'# 软件设计的7大原则\n\n# 开-闭原则(Open-Closed Principle, OCP)\n\n * 对扩展开发,对修改关闭\n * 是面向对象设计（OOD）的基石，也是最重要的原则\n\n# 里氏代换原则(Liskov Substitution Principle)\n\n * 是继承复用的基石\n * 严格表达:如果每一个类型为T1的对象o1,都有类型为T2的对象o2,使得以T1定义的所有程序P在所有的对象o1都代换称o2时,程序P的行为没有变化,那么类型T2是类型T1的子类型\n * 换言之,一个软件实体如果使用的是一个基类的话,那么一定适用于其子类,而且它根本不能察觉出基类对象和子类对象的区别.只有衍生类可以替换基类，软件单位的功能才能不受影响，基类才能真正被复用，而衍生类也能够在基类的基础上增加新功能。\n * 反过来的代换不成立\n * 该类著名的例程为:正方形是否是长方形的子类(答案是"否")\n * 应当尽量从抽象类继承,而不从具体类继承\n * my note：描述了继承关系应该满足的条件：子类可以替换父类，并保证程序行为没有变化\n\n# 依赖倒置原则(Dependence Inversion Principle)\n\n * 抽象不应当依赖于细节,细节应当依赖于抽象.(Program to an interface, not an implementaction)\n * 不应当使用具体类进行变量的类型声明,参量类型声明,方法的返还类型声明,以及数据类型的转换等。而应该使用接口和抽象类。\n\n> ==接口与抽象类==\n\n * 接口与抽象的区别：抽象类可以提供某些方法的部分实现,而接口则不可以,如果向一个抽象类加入一个新的具体方法,那么所有的子类型就都得到得到了这个新的具体方法,而接口做不到这一点.\n * 一个抽象类的实现只能由这个抽象类的子类给出,而由于一般语言都限制一个类只能从最多一个超类继承,因此将抽象作为类型定义工具的效能大打折扣.反过来,一个类可以实现任意多个接口.\n * 从代码重构的角度,将一个单独的具体类重构成一个接口的实现是很容易的,只需要声明一个接口,并将重要的方法添加到接口声明中,然后在具体类定义语句中加上保留字以继承于该接口就行了.而对具体类重构成一个抽象类的实现，就不那么容易了,因为这个具体类有可能已经有一个超类.这样一来,这个新定义的抽象类只好继续向上移动,变成这个超类的超类,如此循环,最后这个新的抽象类必定处于整个类型等级结构的最上端,从而使登记结构中的所有成员都会受到影响.\n * 接口是定义混合类型的理想工具,所为混合类型,就是在一个类的主类型之外的次要类型.一个混合类型表明一个类不仅仅具有某个主类型的行为,而且具有其他的次要行为.\n * 联合使用接口和抽象类: 由于抽象类具有提供缺省实现的优点,而接口具有其他所有优点,所以联合使用两者就是一个很好的选择. 首先,声明类型的工作仍然接口承担的,但是同时给出的还有一个抽象类,为这个接口给出一个缺省实现.其他同属于这个抽象类型的具体类可以选择实现这个接口,也可以选择继承自这个抽象类.如果一个具体类直接实现这个接口的话,它就必须自行实现所有的接口;相反,如果它继承自抽象类的话,它可以省去一些不必要的的方法,因为它可以从抽象类中自动得到这些方法的缺省实现;如果需要向接口加入一个新的方法的话,那么只要同时向这个抽象类加入这个方法的一个具体实现就可以了,因为所有继承自这个抽象类的子类都会从这个抽象类得到这个具体方法.这其实就是缺省适配器模式(Defaule Adapter).\n\n# 接口隔离原则(Interface Segregation Principle, ISP)\n\n * 一个类对另外一个类的依赖是建立在最小的接口上\n * 使用多个专门的接口比使用单一的总接口要好\n * 胖接口会导致他们的客户程序之间产生不正常的耦合.当一个客户程序要求该胖接口进行一个改动时,会影响到所有其他的客户程序.因此客户程序应该仅仅依赖他们实际需要调用的方法.\n\n# 合成/聚合复用原则(Composite/Aggregate Reuse Principle,CARP)\n\n * 要尽量使用合成/聚合,尽量不要使用继承\n\n# 迪米特法则(Law of Demeter LoD)\n\n * 又叫做最少知识原则(Least Knowledge Principle,LKP),就是说,一个对象应当对其他对象有尽可能少的了了解\n\n# 单一职责原则(Simple responsibility pinciple SRP)\n\n * 包括函数 和 类的实现，建议接口一定要单一职责，类的设计尽量做到只有一个原因会引起变化',normalizedContent:'# 软件设计的7大原则\n\n# 开-闭原则(open-closed principle, ocp)\n\n * 对扩展开发,对修改关闭\n * 是面向对象设计（ood）的基石，也是最重要的原则\n\n# 里氏代换原则(liskov substitution principle)\n\n * 是继承复用的基石\n * 严格表达:如果每一个类型为t1的对象o1,都有类型为t2的对象o2,使得以t1定义的所有程序p在所有的对象o1都代换称o2时,程序p的行为没有变化,那么类型t2是类型t1的子类型\n * 换言之,一个软件实体如果使用的是一个基类的话,那么一定适用于其子类,而且它根本不能察觉出基类对象和子类对象的区别.只有衍生类可以替换基类，软件单位的功能才能不受影响，基类才能真正被复用，而衍生类也能够在基类的基础上增加新功能。\n * 反过来的代换不成立\n * 该类著名的例程为:正方形是否是长方形的子类(答案是"否")\n * 应当尽量从抽象类继承,而不从具体类继承\n * my note：描述了继承关系应该满足的条件：子类可以替换父类，并保证程序行为没有变化\n\n# 依赖倒置原则(dependence inversion principle)\n\n * 抽象不应当依赖于细节,细节应当依赖于抽象.(program to an interface, not an implementaction)\n * 不应当使用具体类进行变量的类型声明,参量类型声明,方法的返还类型声明,以及数据类型的转换等。而应该使用接口和抽象类。\n\n> ==接口与抽象类==\n\n * 接口与抽象的区别：抽象类可以提供某些方法的部分实现,而接口则不可以,如果向一个抽象类加入一个新的具体方法,那么所有的子类型就都得到得到了这个新的具体方法,而接口做不到这一点.\n * 一个抽象类的实现只能由这个抽象类的子类给出,而由于一般语言都限制一个类只能从最多一个超类继承,因此将抽象作为类型定义工具的效能大打折扣.反过来,一个类可以实现任意多个接口.\n * 从代码重构的角度,将一个单独的具体类重构成一个接口的实现是很容易的,只需要声明一个接口,并将重要的方法添加到接口声明中,然后在具体类定义语句中加上保留字以继承于该接口就行了.而对具体类重构成一个抽象类的实现，就不那么容易了,因为这个具体类有可能已经有一个超类.这样一来,这个新定义的抽象类只好继续向上移动,变成这个超类的超类,如此循环,最后这个新的抽象类必定处于整个类型等级结构的最上端,从而使登记结构中的所有成员都会受到影响.\n * 接口是定义混合类型的理想工具,所为混合类型,就是在一个类的主类型之外的次要类型.一个混合类型表明一个类不仅仅具有某个主类型的行为,而且具有其他的次要行为.\n * 联合使用接口和抽象类: 由于抽象类具有提供缺省实现的优点,而接口具有其他所有优点,所以联合使用两者就是一个很好的选择. 首先,声明类型的工作仍然接口承担的,但是同时给出的还有一个抽象类,为这个接口给出一个缺省实现.其他同属于这个抽象类型的具体类可以选择实现这个接口,也可以选择继承自这个抽象类.如果一个具体类直接实现这个接口的话,它就必须自行实现所有的接口;相反,如果它继承自抽象类的话,它可以省去一些不必要的的方法,因为它可以从抽象类中自动得到这些方法的缺省实现;如果需要向接口加入一个新的方法的话,那么只要同时向这个抽象类加入这个方法的一个具体实现就可以了,因为所有继承自这个抽象类的子类都会从这个抽象类得到这个具体方法.这其实就是缺省适配器模式(defaule adapter).\n\n# 接口隔离原则(interface segregation principle, isp)\n\n * 一个类对另外一个类的依赖是建立在最小的接口上\n * 使用多个专门的接口比使用单一的总接口要好\n * 胖接口会导致他们的客户程序之间产生不正常的耦合.当一个客户程序要求该胖接口进行一个改动时,会影响到所有其他的客户程序.因此客户程序应该仅仅依赖他们实际需要调用的方法.\n\n# 合成/聚合复用原则(composite/aggregate reuse principle,carp)\n\n * 要尽量使用合成/聚合,尽量不要使用继承\n\n# 迪米特法则(law of demeter lod)\n\n * 又叫做最少知识原则(least knowledge principle,lkp),就是说,一个对象应当对其他对象有尽可能少的了了解\n\n# 单一职责原则(simple responsibility pinciple srp)\n\n * 包括函数 和 类的实现，建议接口一定要单一职责，类的设计尽量做到只有一个原因会引起变化',charsets:{cjk:!0}},{title:"MVP MVP MVVM",frontmatter:{title:"MVP MVP MVVM",date:"2020-04-13T00:00:00.000Z",description:"MVP MVP MVVM",permalink:null,categories:["blog","design"],tags:[null]},regularPath:"/blog/design/architecture_mvc_mvp_mvvm.html",relativePath:"blog/design/architecture_mvc_mvp_mvvm.md",key:"v-92792e82",path:"/blog/design/architecture_mvc_mvp_mvvm.html",headers:[{level:2,title:"MVC (Model-View-Controller)",slug:"mvc-model-view-controller",normalizedTitle:"mvc (model-view-controller)",charIndex:19},{level:2,title:"MVP (Model-View-Presenter)",slug:"mvp-model-view-presenter",normalizedTitle:"mvp (model-view-presenter)",charIndex:899},{level:2,title:"MVVM (Model-View-ViewModel)",slug:"mvvm-model-view-viewmodel",normalizedTitle:"mvvm (model-view-viewmodel)",charIndex:2337},{level:2,title:"备注",slug:"备注",normalizedTitle:"备注",charIndex:2677}],headersStr:"MVC (Model-View-Controller) MVP (Model-View-Presenter) MVVM (Model-View-ViewModel) 备注",content:"# MVP MVP MVVM\n\n\n# MVC (Model-View-Controller)\n\n\n\n * 分层：\n   * 当有用户的行为触发操作时，会有控制器更新模型，并通知视图进行更新，在这时视图向模型请求新的数据\n     * Model: 管理应用的行为和数据，响应数据请求(经常来自视图)和更新状态的指令(经常来自控制器)\n     * View: 管理作为位图展示到屏幕上的图形和文字输出\n     * Controller: 翻译用户的输入并依照用户的输入操作模型和视图\n * 问题\n   * 很容易将 VC 层写到一起，造成 V或C 层臃肿\n   * Controller更多时候承担一种转发的作用\n * 说明\n   * MVC 最重要的目的并不是规定各个模块应该如何交互和联系，而是将原有的混乱的应用程序划分出合理的层级，把一团混乱的代码，按照展示层和领域层分成两个部分。\n   * 分离展示层\n     * GUI 应用程序由于其需要展示内容的特点，分为两个部分：一部分是用于展示内容的展示层(Presentation Layer)，另一部分包含领域和数据逻辑的领域层(Domain Layer)\n     * 展示层依赖于领域层中存储的数据，而领域层对于展示层一无所知，领域层其实也是 MVC 模式中的模型层，而展示层可以理解为 VC 部分\n   * 观察者同步(观察者模式)\n     * 因为在 MVC 模式中，模型可以单独工作，同时它对使用模型中数据的视图和控制器一无所知，为了保持模型的独立性，我们需要一种机制，当模型发生改变时，能够同时更新多个视图和控制器的内容；在这时，就需要以观察者同步的方式解决这个问题。\n   * 占主导地位的控制器\n     * 控制器承担了MVC架构中的大部分业务逻辑，在用户请求到达或者事件发生时都会首先通知控制器并由它来决定如何响应这次请求或者事件。\n   * 被动的模型\n     * 模型都不会主动向视图或者控制器推送消息。它对于视图和控制器的存在并不知情，只是向外部提供接口并响应视图和控制器对于数据的请求和更新操作。\n\n\n# MVP (Model-View-Presenter)\n\n\n\n * 分层\n   * Model负责数据(的存储、以及增删改查等动作)。一般会使用 Model interface 用来降低耦合\n   * View负责显示(绘制UI元素)以及与用户进行交互(在Android中体现为Activity)\n     * 一般会使用 View interface : 需要View实现的接口\n     * View通过View interface与Presenter进行交互，降低耦合，方便进行单元测试\n   * Presenter负责(与用户交互的)业务逻辑\n * 实现\n   * 根据Presenter和View对逻辑代码分担的程度不同，这种模式又有两种情况：\n     * Passive View(常用)\n       * 交互流程\n         \n             1、当视图接收到来自用户的事件时，会将事件转交给 Presenter 进行处理\n             2、被动的视图向外界暴露接口，当需要更新视图时 Presenter 通过视图暴露的接口更新视图的内容\n             3、Presenter 负责对模型进行操作和更新，在需要时取出其中存储的信息\n             4、当模型层改变时，可以将改变的信息发送给观察者 Presenter\n         \n         \n         1\n         2\n         3\n         4\n         \n       * 说明\n         * View向Presenter发送用户交互请求:\n           * 应该采用这样的口吻：“我现在将用户交互请求发送给你，你看着办，需要我的时候我会协助你”\n           * 不应该是这样：“我现在处理用户交互请求了，我知道该怎么办，但是我需要你的支持，因为实现业务逻辑的Model只信任你”；\n         * 对于绑定到View上的数据，不应该是View从Presenter上“拉”回来的，应该是Presenter主动“推”给View的；\n         * View 尽可能不维护数据状态, 因为它仅仅是用户交互请求的汇报者，不参与响应用户交互相关的逻辑和流程\n     * Supervisor Controller\n       * 视图和模型之间新增的依赖就是数据绑定的产物；视图通过声明式的语法与模型中的简单属性进行绑定，当模型发生改变时，会通知其观察者视图作出相应的更新。\n       * 这种方式能够减轻监督控制器的负担，减少其中简单的代码，将一部分逻辑交由视图进行处理；这样也就导致了视图同时可以被 Presenter 和数据绑定两种方式更新，相比于被动视图，监督控制器的方式也降低了视图的可测试性和封装性。\n * 说明\n   * MVP 与 MVC 对比\n     * MVP 与 MVC 之间的重大区别就是，MVP(Passive View)中的视图和模型是完全解耦的，它们对于对方的存在完全不知情\n   * 占主导地位的视图\n     * 视图层在整个架构中都是占主导地位的\n     * 在 MVC 中，控制器负责以不同的视图响应客户端请求的不同动作；然而 MVP 中视图层选择好要渲染的图层后将所有的动作交给 Presenter 进行处理\n\n\n# MVVM (Model-View-ViewModel)\n\n * 分层\n   * ViewModel可以理解成是View的数据模型和Presenter的合体，说白了就是包含View的一些数据属性和操作的东东\n   * ViewModel和View之间的交互通过Data Binding完成，而Data Binding可以实现双向的交互，这就使得视图和控制层之间的耦合程度进一步降低。\n * 说明\n   * 这种模式的关键技术就是数据绑定(data binding)\n   * View的变化会直接影响ViewModel，ViewModel的变化或者内容也会直接体现在View上\n   * 它实际上是框架替应用开发者做了一些工作，开发者只需要较少的代码就能实现比较复杂的交互\n\n\n# 备注\n\n * 这些模式，只是对数据、逻辑、视图这三层的不同划分方式，整体目的还是三层解耦\n * MVP和MVVM完全隔离了Model和View，但是在有些情况下，数据从Model到ViewModel或者Presenter的拷贝开销很大，可能也会结合MVC的方式，Model直接通知View进行变更。\n * 在实际的应用中很有可能你已经在不知不觉中将几种模式融合在一起，但是为了代码的可扩展、可测试性，必须做到模块的解耦，不相关的代码不要放在一起。",normalizedContent:"# mvp mvp mvvm\n\n\n# mvc (model-view-controller)\n\n\n\n * 分层：\n   * 当有用户的行为触发操作时，会有控制器更新模型，并通知视图进行更新，在这时视图向模型请求新的数据\n     * model: 管理应用的行为和数据，响应数据请求(经常来自视图)和更新状态的指令(经常来自控制器)\n     * view: 管理作为位图展示到屏幕上的图形和文字输出\n     * controller: 翻译用户的输入并依照用户的输入操作模型和视图\n * 问题\n   * 很容易将 vc 层写到一起，造成 v或c 层臃肿\n   * controller更多时候承担一种转发的作用\n * 说明\n   * mvc 最重要的目的并不是规定各个模块应该如何交互和联系，而是将原有的混乱的应用程序划分出合理的层级，把一团混乱的代码，按照展示层和领域层分成两个部分。\n   * 分离展示层\n     * gui 应用程序由于其需要展示内容的特点，分为两个部分：一部分是用于展示内容的展示层(presentation layer)，另一部分包含领域和数据逻辑的领域层(domain layer)\n     * 展示层依赖于领域层中存储的数据，而领域层对于展示层一无所知，领域层其实也是 mvc 模式中的模型层，而展示层可以理解为 vc 部分\n   * 观察者同步(观察者模式)\n     * 因为在 mvc 模式中，模型可以单独工作，同时它对使用模型中数据的视图和控制器一无所知，为了保持模型的独立性，我们需要一种机制，当模型发生改变时，能够同时更新多个视图和控制器的内容；在这时，就需要以观察者同步的方式解决这个问题。\n   * 占主导地位的控制器\n     * 控制器承担了mvc架构中的大部分业务逻辑，在用户请求到达或者事件发生时都会首先通知控制器并由它来决定如何响应这次请求或者事件。\n   * 被动的模型\n     * 模型都不会主动向视图或者控制器推送消息。它对于视图和控制器的存在并不知情，只是向外部提供接口并响应视图和控制器对于数据的请求和更新操作。\n\n\n# mvp (model-view-presenter)\n\n\n\n * 分层\n   * model负责数据(的存储、以及增删改查等动作)。一般会使用 model interface 用来降低耦合\n   * view负责显示(绘制ui元素)以及与用户进行交互(在android中体现为activity)\n     * 一般会使用 view interface : 需要view实现的接口\n     * view通过view interface与presenter进行交互，降低耦合，方便进行单元测试\n   * presenter负责(与用户交互的)业务逻辑\n * 实现\n   * 根据presenter和view对逻辑代码分担的程度不同，这种模式又有两种情况：\n     * passive view(常用)\n       * 交互流程\n         \n             1、当视图接收到来自用户的事件时，会将事件转交给 presenter 进行处理\n             2、被动的视图向外界暴露接口，当需要更新视图时 presenter 通过视图暴露的接口更新视图的内容\n             3、presenter 负责对模型进行操作和更新，在需要时取出其中存储的信息\n             4、当模型层改变时，可以将改变的信息发送给观察者 presenter\n         \n         \n         1\n         2\n         3\n         4\n         \n       * 说明\n         * view向presenter发送用户交互请求:\n           * 应该采用这样的口吻：“我现在将用户交互请求发送给你，你看着办，需要我的时候我会协助你”\n           * 不应该是这样：“我现在处理用户交互请求了，我知道该怎么办，但是我需要你的支持，因为实现业务逻辑的model只信任你”；\n         * 对于绑定到view上的数据，不应该是view从presenter上“拉”回来的，应该是presenter主动“推”给view的；\n         * view 尽可能不维护数据状态, 因为它仅仅是用户交互请求的汇报者，不参与响应用户交互相关的逻辑和流程\n     * supervisor controller\n       * 视图和模型之间新增的依赖就是数据绑定的产物；视图通过声明式的语法与模型中的简单属性进行绑定，当模型发生改变时，会通知其观察者视图作出相应的更新。\n       * 这种方式能够减轻监督控制器的负担，减少其中简单的代码，将一部分逻辑交由视图进行处理；这样也就导致了视图同时可以被 presenter 和数据绑定两种方式更新，相比于被动视图，监督控制器的方式也降低了视图的可测试性和封装性。\n * 说明\n   * mvp 与 mvc 对比\n     * mvp 与 mvc 之间的重大区别就是，mvp(passive view)中的视图和模型是完全解耦的，它们对于对方的存在完全不知情\n   * 占主导地位的视图\n     * 视图层在整个架构中都是占主导地位的\n     * 在 mvc 中，控制器负责以不同的视图响应客户端请求的不同动作；然而 mvp 中视图层选择好要渲染的图层后将所有的动作交给 presenter 进行处理\n\n\n# mvvm (model-view-viewmodel)\n\n * 分层\n   * viewmodel可以理解成是view的数据模型和presenter的合体，说白了就是包含view的一些数据属性和操作的东东\n   * viewmodel和view之间的交互通过data binding完成，而data binding可以实现双向的交互，这就使得视图和控制层之间的耦合程度进一步降低。\n * 说明\n   * 这种模式的关键技术就是数据绑定(data binding)\n   * view的变化会直接影响viewmodel，viewmodel的变化或者内容也会直接体现在view上\n   * 它实际上是框架替应用开发者做了一些工作，开发者只需要较少的代码就能实现比较复杂的交互\n\n\n# 备注\n\n * 这些模式，只是对数据、逻辑、视图这三层的不同划分方式，整体目的还是三层解耦\n * mvp和mvvm完全隔离了model和view，但是在有些情况下，数据从model到viewmodel或者presenter的拷贝开销很大，可能也会结合mvc的方式，model直接通知view进行变更。\n * 在实际的应用中很有可能你已经在不知不觉中将几种模式融合在一起，但是为了代码的可扩展、可测试性，必须做到模块的解耦，不相关的代码不要放在一起。",charsets:{cjk:!0}},{title:"Language 目录",frontmatter:{published:!0,title:"Language 目录",description:"编程语言相关知识汇总",keywords:["lang"],categories:["lang"],permalink:"/blog/lang/",date:"2020-04-13T00:00:00.000Z",tags:[null]},regularPath:"/blog/lang/",relativePath:"blog/lang/README.md",key:"v-53f7dee4",path:"/blog/lang/",headers:[{level:2,title:"一、 Python",slug:"一、-python",normalizedTitle:"一、 python",charIndex:18},{level:2,title:"三、 Go",slug:"三、-go",normalizedTitle:"三、 go",charIndex:115}],headersStr:"一、 Python 三、 Go",content:'# LANGUAGE 目录\n\n\n# 一、 Python\n\n * Python 中 "_"、"__" 和 "__Xx__" 的区别\n\n * Python 环境问题记录\n\n * Python 基础\n\n * Cxx Traps\n\n\n# 三、 Go\n\n * Recover & Const 简述\n\n * Slice 底层结构\n\n * 关于 Nil 判定的一些事情\n\n * Go Mod 简介\n\n * 优秀的 Go 文档\n\n * Js 零基础起步\n\n * Go\n\n * Cxx',normalizedContent:'# language 目录\n\n\n# 一、 python\n\n * python 中 "_"、"__" 和 "__xx__" 的区别\n\n * python 环境问题记录\n\n * python 基础\n\n * cxx traps\n\n\n# 三、 go\n\n * recover & const 简述\n\n * slice 底层结构\n\n * 关于 nil 判定的一些事情\n\n * go mod 简介\n\n * 优秀的 go 文档\n\n * js 零基础起步\n\n * go\n\n * cxx',charsets:{cjk:!0}},{title:"CXX",frontmatter:{title:"CXX",date:"2021-11-24T11:50:00.000Z",lastmod:null,publish:!0,categories:null,keywords:null,description:null,tags:null,permalink:null},regularPath:"/blog/lang/cxx.html",relativePath:"blog/lang/cxx.md",key:"v-d7f39702",path:"/blog/lang/cxx.html",headers:[{level:2,title:"基础",slug:"基础",normalizedTitle:"基础",charIndex:15},{level:2,title:"多态",slug:"多态",normalizedTitle:"多态",charIndex:175},{level:3,title:"1. 虚函数表内存模型",slug:"_1-虚函数表内存模型",normalizedTitle:"1. 虚函数表内存模型",charIndex:531},{level:3,title:"2. 方法派发(dispatch)流程(选择正确方法调用的过程)",slug:"_2-方法派发-dispatch-流程-选择正确方法调用的过程",normalizedTitle:"2. 方法派发(dispatch)流程(选择正确方法调用的过程)",charIndex:547},{level:2,title:"模版",slug:"模版",normalizedTitle:"模版",charIndex:178},{level:2,title:"导入(import)导出(export)",slug:"导入-import-导出-export",normalizedTitle:"导入(import)导出(export)",charIndex:1877},{level:3,title:"1. 对象",slug:"_1-对象",normalizedTitle:"1. 对象",charIndex:1902},{level:3,title:"2. 使用",slug:"_2-使用",normalizedTitle:"2. 使用",charIndex:1934},{level:3,title:"3. 名称修饰(符号名)",slug:"_3-名称修饰-符号名",normalizedTitle:"3. 名称修饰(符号名)",charIndex:3952},{level:2,title:"特性",slug:"特性",normalizedTitle:"特性",charIndex:38}],headersStr:"基础 多态 1. 虚函数表内存模型 2. 方法派发(dispatch)流程(选择正确方法调用的过程) 模版 导入(import)导出(export) 1. 对象 2. 使用 3. 名称修饰(符号名) 特性",content:'# C && C++\n\n\n# 基础\n\nc && c++ 标准定义了语法、语言特性 以及 C++ 内置库(也就是C++标准库)的实现规范, 但不同的编译器对标准库的实现方法各不一致\n\nSUBJECT   CONTENT                                  STATUS\n语言特性      C++ 11/14/17 标准、多态、模版                    ☑\n异常        标准异常、VEH、SEH、TopLevelEH...               ☐\n调优        内存、性能                                    ☐\n编译运行      编译、运行期的 action 和 mechanism               ☐\nDesign    is-a(Inheritance) 和 has-a(Composition)   ☑\n平台特性      window、linux                             ☐\n技巧        Tricks and Traps                         ☐\n\n\n# 多态\n\n\n# 1. 虚函数表内存模型\n\n\n# 2. 方法派发(dispatch)流程(选择正确方法调用的过程)\n\n * 派发机制按照选择正确方法的时期(编译期和运行期)，可以分为: static dispatch 和 dynamic dispatch\n   * static dispatch\n     * 在编译期就完全确定调用方法的分派方式。也就是说，编译期直接决定函数地址(方法指针)，运行时可以直接通过函数地址调用方法。\n       * static dispatch 的进行进一步优化的一种实现方式叫做内联(inline), 是指编译期从指定被调用的方法指针，改为将方法的实现平铺在调用方的可执行文件内，从而节省了指针到方法实现体的调用的消耗。\n         * 内联展开和宏展开的区别在于,内联发生在编译期,并且不会改变源文件.但是宏展开是在编译前就完成的,会改变源码本身,之后再对此进行编译.\n         * inline 关键字是一个 desire 声明而非 require. 只能告诉编译器倾向使用内联方式, 但是最终实现是编译器决定的.\n           * 如果一个方法被内联10次,那么会出现10份方法的副本.所以内联适用于会被频繁调用的比较小的方法.但是如果一个方法特别大,被inline关键字修饰的话,编译器也可能会选择不使用内联实现.\n   * dynamic dispatch\n     * 在运行期选择调用方法的实现的流程\n     * 虚函数表(动态分派的一种实现机制)\n       * 常见语言如 C++、Java 都是通过虚函数表来实现的(Java所有的实例方法都默认使用虚函数表实现)。\n       * 虚函数表\n         * 编译器会为每个类创建单独的虚函数表。编译器也会生成包含了虚函数表指针的代码。\n         * 多继承和指针修正(thunks)\n           * 菱形继承\n             * 虚基类\n     * 和 late binding 不同：\n       * late binding (也叫dynamic binding或dynamic linkage)是一种用于处理在运行时通过对象调用方法或者通过函数名去调用包含参数的方法的一种编程机制.\n         * 简单的说，就是在编译期并不会解读足够的信息去确定方法是否存在\n       * 在组件对象模型编程中,使用late binding的最大优势在于,不要求编译器在编译期间去引用包含对象的库.这使得编译过程可以更有效的去避免类的虚函数表突然更改带来的冲突.\n       * 大部分的动态类型语言都可以在运行时去修改对象的方法列表, 因此他们就需要late binding.\n\n\n# 模版\n\n * C++ 模板是图灵完备的\n   * 具备以下能力：编译期数值计算、类型计算、代码计算（如循环展开）\n * 模版实例化、偏特化、偏特化(与函数的柯里化不同)...\n * 可变模版参数（variadic templates）: C++11新增的最强大的特性之一\n * 元编程\n * 类型萃取\n   * 依赖模板的特化来实现\n\n\n# 导入(import)导出(export)\n\n\n# 1. 对象\n\n * 函数、接口、类、成员函数、成员变量\n\n\n# 2. 使用\n\n * 导出\n   * 模块定义文件(.def)\n   * __declspec(export)、__declspec(import)\n   * visibility\n     * 代码修饰：__attribute((visibility("default")))、__attribute((visibility("hidden")))\n     * 链接选项：-fvisibility=default、-fvisibility=hidden\n       * gcc 默认设置为 default 即全部可见(导出)\n * 加载\n   * 显式加载：从导出表获取函数地址(通过函数名、函数编号)，进行使用\n   * 隐式加载：依赖生成dll时生成的 lib 文件，直接引用头文件\n     * lib 文件包含了导出的符号信息，会在模块被加载时主动寻找 dll或so 文件并关联其中对应的符号\n     * 宏定义(You can use the same header file for both the DLL and the client application)：\n       \n       #ifdef _EXPORTING\n         #define API_DECLSPEC    __declspec(dllexport)\n       #else\n         #define API_DECLSPEC    __declspec(dllimport)\n       #endif\n       \n       \n       1\n       2\n       3\n       4\n       5\n       \n     * MSDN关于__declspec(dllimport)的解释\n       * The keyword __declspec(dllimport) works whether you export with .def files or with the __declspec(dllexport) keyword.\n       * Using __declspec(dllimport) is optional on function declarations, but the compiler produces more efficient code if you use this keyword.\n       * However, you must use __declspec(dllimport) for the importing executable to access the DLL\'s public data symbols and objects.\n     * 示例：假设 func 是 DLL 中的一个函数，在另一个程序的 main 函数中尝试调用 DLL 中的的这个函数\n       * 如果导入的头文件中函数没有__declspec(dllimport)的修饰\n         \n         编译器将产生类似这样的调用:\n           call func\n         然后，链接器把该调用翻译为类似这样的代码：\n           call 0x40000001       // 0x40000001是 func 的地址\n         并且，链接器将产生一个 Thunk，形如：\n           0x40000001: jmp DWORD PTR __imp_func\n         \n         这里的 imp_func 是 func 函数在 exe 的导入地址表中的函数槽的地址。然后，加载器只需要在加载时更新 exe 的导入地址表(导入表修复)即可\n         \n         \n         1\n         2\n         3\n         4\n         5\n         6\n         7\n         8\n         \n       * 如果使用了__declspec(dllimport)显示地导入函数\n         \n         链接器将不会产生 Thunk(如果不被要求的话)，而直接产生一个间接调用。形如：\n           call DWORD PTR __imp_func1\n         因此，显示地导入函数能有效减少目标代码、增加执行效率(因为不产生Thunk)。\n         \n         \n         1\n         2\n         3\n         \n * 注意\n   * 类、成员函数、成员变量 导出时的对象归属问题\n\n\n# 3. 名称修饰(符号名)\n\n * 查看方法：\n   * Linux\n     * gcc 编译，而后以 nm 命令查看动态、静态库以及.o中的符号\n   * Window\n     * cl 编译(参数-c)，而后以 dumpbin 命令查看符号(参数/SYMBOLS)\n * 注意\n   * 不同的编译器的名称修饰方法可能不同，所以不同的编译器对于同一个函数签名可能对应不同的修饰后名称\n   * 模块定义文件(.def) 定义的函数，不会使用名称修饰，而是保持函数名不变\n   * Microsoft 提供了一个 UnDecorateSymbolName() 的API，可以将修饰后名称转换成函数签名\n   * VC 提供了一个预处理指示符 "#pragma" 来指定连接选项, 其中有：\n     * /EXPORT:entryname[,@ordinal[,NONAME]][,DATA]，@ordinal 指定顺序；NONAME 指定只将函数导出为序号；DATA 关键字指定导出项为数据项\n       * 用于修改导出的名称，如：#pragma comment(linker,"/EXPORT:MyExportFunction=_MyExportFunction@4")\n * C 编译器的函数名修饰规则\n   * Visual C++ 的基本C名称修饰方法：\n   * __stdcall x86 调用约定，编译器会在输出函数名前加上一个下划线前缀，函数名后面加上一个“@”符号和其參数的字节数。比如 _functionname@argbytes\n   * __fastcall x86 调用约定，在输出函数名前加上一个"@"符号，后面也是一个"@"符号和其參数的字节数，比如 @functionname@argbytes\n   * __stdcall x64 和 __fastcall x64 调用约定，保持输出函数名不变，比如functionname\n   * __cdecl 同 GCC\n   * GCC 的基本C名称修饰方法：\n     * __cdecl x86 调用约定，仅在输出函数名前加上一个下划线前缀。比如_functionname\n     * __cdecl x64 调用约定，保持输出函数名不变。比如functionname\n * C++ 编译器的名称修饰规则\n   * Visual C++ 的基本C++名称修饰方法：\n     * 形如：?func_name@class_name@namespace@@flags_and_args_and_return@Z, 修饰后名字由"?"开头，接着是函数名由"@"符号结尾的函数名；后面跟着由"@"结尾的类名和名称空间，再一个"@"表示函数的名称空间结束；其后可能有，函数调用类型(__cdecl或__stdcall等)、函数保护属性(public、private...) 以及 参数列表等信息，由"@"结束，最后由"Z"结尾。\n       * 比如 int C::C2::func(int) 经过名称修饰以后就是 ?func@C2@C@@AAEHH@Z\n   * GCC 的基本C++名称修饰方法：\n     * 所有的符号都以"_Z"开头，对于嵌套的名字（在名称空间或在类里面的），后面紧跟"N"，然后是各个名称空间和类的名字，每个名字前是名字字符串长度，再以"E"结尾。对于一个函数来说，它的参数列表紧跟在"E"后面。\n       * 比如 N::C::func 经过名称修饰以后就是 _ZN1N1C4funcE。N::C::func(int) 函数签名经过修饰为 _ZN1N1C4funcEi, 对于int类型来说，就是字母"i"。\n\n\n# 特性\n\n * 右值引用\n   * std::move、std::forward\n * using、typedef、typename\n   * using 可读性更高，并且可以用于模板别名\n   * The "typename" keyword\n * const\n   * 指针：位于*的左侧 或 右侧\n   * 成员变量\n   * 成员函数\n     * 不被允许修改它所在对象的任何一个数据成员(但可以访问)\n     * const成员函数，可以访问const成员函数\n   * 对象\n     * 该对象的任何非const成员函数都不能被调用，因为任何非const成员函数会有修改成员变量的企图\n   * const_cast<type_id> (expression)\n * attribute\n   \n     #if defined(__GCC__)\n     /*\n     * __attribute__ 是 GCC 编译器特有的机制\n     * 如，__attribute__((packed)) 和 __attribute__(aligned(4))\n     * \n     * 使用：\n     *   typedef struct {\n     *   } __attribute__((packed)) position_t;\n     * \n     *   struct test {\n     *   } __attribute__((packed));\n     */\n     #endif\n     对齐方式还有：\n     #if ( _MSC_VER >= 800 && !defined(_M_I86)) || defined(_PUSHPOP_SUPPORTED)\n       #pragma pack(push,1)\n     #else\n       #pragma pack(1)\n     #endif\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   19\n   \n * HeapOnly 和 StackOnly\n   \n       #include <iostream>\n       class HeapOnly {\n       public:  \n           HeapOnly() { }\n           void destroy() const { delete this; }\n       private:  \n           ~HeapOnly() { }\n       };\n       class StackOnly {\n       public:\n           StackOnly() { }\n           ~StackOnly() { }\n       private:\n           void* operator new(size_t);\n       };\n       int main() {  \n           StackOnly s; // ok\n           StackOnly *p = new StackOnly; // wrong\n           HeapOnly *p = new HeapOnly; // ok\n           p->destroy();\n           HeapOnly h;  // wrong\n           return 0;\n       }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   19\n   20\n   21\n   22\n   23\n   ',normalizedContent:'# c && c++\n\n\n# 基础\n\nc && c++ 标准定义了语法、语言特性 以及 c++ 内置库(也就是c++标准库)的实现规范, 但不同的编译器对标准库的实现方法各不一致\n\nsubject   content                                  status\n语言特性      c++ 11/14/17 标准、多态、模版                    ☑\n异常        标准异常、veh、seh、topleveleh...               ☐\n调优        内存、性能                                    ☐\n编译运行      编译、运行期的 action 和 mechanism               ☐\ndesign    is-a(inheritance) 和 has-a(composition)   ☑\n平台特性      window、linux                             ☐\n技巧        tricks and traps                         ☐\n\n\n# 多态\n\n\n# 1. 虚函数表内存模型\n\n\n# 2. 方法派发(dispatch)流程(选择正确方法调用的过程)\n\n * 派发机制按照选择正确方法的时期(编译期和运行期)，可以分为: static dispatch 和 dynamic dispatch\n   * static dispatch\n     * 在编译期就完全确定调用方法的分派方式。也就是说，编译期直接决定函数地址(方法指针)，运行时可以直接通过函数地址调用方法。\n       * static dispatch 的进行进一步优化的一种实现方式叫做内联(inline), 是指编译期从指定被调用的方法指针，改为将方法的实现平铺在调用方的可执行文件内，从而节省了指针到方法实现体的调用的消耗。\n         * 内联展开和宏展开的区别在于,内联发生在编译期,并且不会改变源文件.但是宏展开是在编译前就完成的,会改变源码本身,之后再对此进行编译.\n         * inline 关键字是一个 desire 声明而非 require. 只能告诉编译器倾向使用内联方式, 但是最终实现是编译器决定的.\n           * 如果一个方法被内联10次,那么会出现10份方法的副本.所以内联适用于会被频繁调用的比较小的方法.但是如果一个方法特别大,被inline关键字修饰的话,编译器也可能会选择不使用内联实现.\n   * dynamic dispatch\n     * 在运行期选择调用方法的实现的流程\n     * 虚函数表(动态分派的一种实现机制)\n       * 常见语言如 c++、java 都是通过虚函数表来实现的(java所有的实例方法都默认使用虚函数表实现)。\n       * 虚函数表\n         * 编译器会为每个类创建单独的虚函数表。编译器也会生成包含了虚函数表指针的代码。\n         * 多继承和指针修正(thunks)\n           * 菱形继承\n             * 虚基类\n     * 和 late binding 不同：\n       * late binding (也叫dynamic binding或dynamic linkage)是一种用于处理在运行时通过对象调用方法或者通过函数名去调用包含参数的方法的一种编程机制.\n         * 简单的说，就是在编译期并不会解读足够的信息去确定方法是否存在\n       * 在组件对象模型编程中,使用late binding的最大优势在于,不要求编译器在编译期间去引用包含对象的库.这使得编译过程可以更有效的去避免类的虚函数表突然更改带来的冲突.\n       * 大部分的动态类型语言都可以在运行时去修改对象的方法列表, 因此他们就需要late binding.\n\n\n# 模版\n\n * c++ 模板是图灵完备的\n   * 具备以下能力：编译期数值计算、类型计算、代码计算（如循环展开）\n * 模版实例化、偏特化、偏特化(与函数的柯里化不同)...\n * 可变模版参数（variadic templates）: c++11新增的最强大的特性之一\n * 元编程\n * 类型萃取\n   * 依赖模板的特化来实现\n\n\n# 导入(import)导出(export)\n\n\n# 1. 对象\n\n * 函数、接口、类、成员函数、成员变量\n\n\n# 2. 使用\n\n * 导出\n   * 模块定义文件(.def)\n   * __declspec(export)、__declspec(import)\n   * visibility\n     * 代码修饰：__attribute((visibility("default")))、__attribute((visibility("hidden")))\n     * 链接选项：-fvisibility=default、-fvisibility=hidden\n       * gcc 默认设置为 default 即全部可见(导出)\n * 加载\n   * 显式加载：从导出表获取函数地址(通过函数名、函数编号)，进行使用\n   * 隐式加载：依赖生成dll时生成的 lib 文件，直接引用头文件\n     * lib 文件包含了导出的符号信息，会在模块被加载时主动寻找 dll或so 文件并关联其中对应的符号\n     * 宏定义(you can use the same header file for both the dll and the client application)：\n       \n       #ifdef _exporting\n         #define api_declspec    __declspec(dllexport)\n       #else\n         #define api_declspec    __declspec(dllimport)\n       #endif\n       \n       \n       1\n       2\n       3\n       4\n       5\n       \n     * msdn关于__declspec(dllimport)的解释\n       * the keyword __declspec(dllimport) works whether you export with .def files or with the __declspec(dllexport) keyword.\n       * using __declspec(dllimport) is optional on function declarations, but the compiler produces more efficient code if you use this keyword.\n       * however, you must use __declspec(dllimport) for the importing executable to access the dll\'s public data symbols and objects.\n     * 示例：假设 func 是 dll 中的一个函数，在另一个程序的 main 函数中尝试调用 dll 中的的这个函数\n       * 如果导入的头文件中函数没有__declspec(dllimport)的修饰\n         \n         编译器将产生类似这样的调用:\n           call func\n         然后，链接器把该调用翻译为类似这样的代码：\n           call 0x40000001       // 0x40000001是 func 的地址\n         并且，链接器将产生一个 thunk，形如：\n           0x40000001: jmp dword ptr __imp_func\n         \n         这里的 imp_func 是 func 函数在 exe 的导入地址表中的函数槽的地址。然后，加载器只需要在加载时更新 exe 的导入地址表(导入表修复)即可\n         \n         \n         1\n         2\n         3\n         4\n         5\n         6\n         7\n         8\n         \n       * 如果使用了__declspec(dllimport)显示地导入函数\n         \n         链接器将不会产生 thunk(如果不被要求的话)，而直接产生一个间接调用。形如：\n           call dword ptr __imp_func1\n         因此，显示地导入函数能有效减少目标代码、增加执行效率(因为不产生thunk)。\n         \n         \n         1\n         2\n         3\n         \n * 注意\n   * 类、成员函数、成员变量 导出时的对象归属问题\n\n\n# 3. 名称修饰(符号名)\n\n * 查看方法：\n   * linux\n     * gcc 编译，而后以 nm 命令查看动态、静态库以及.o中的符号\n   * window\n     * cl 编译(参数-c)，而后以 dumpbin 命令查看符号(参数/symbols)\n * 注意\n   * 不同的编译器的名称修饰方法可能不同，所以不同的编译器对于同一个函数签名可能对应不同的修饰后名称\n   * 模块定义文件(.def) 定义的函数，不会使用名称修饰，而是保持函数名不变\n   * microsoft 提供了一个 undecoratesymbolname() 的api，可以将修饰后名称转换成函数签名\n   * vc 提供了一个预处理指示符 "#pragma" 来指定连接选项, 其中有：\n     * /export:entryname[,@ordinal[,noname]][,data]，@ordinal 指定顺序；noname 指定只将函数导出为序号；data 关键字指定导出项为数据项\n       * 用于修改导出的名称，如：#pragma comment(linker,"/export:myexportfunction=_myexportfunction@4")\n * c 编译器的函数名修饰规则\n   * visual c++ 的基本c名称修饰方法：\n   * __stdcall x86 调用约定，编译器会在输出函数名前加上一个下划线前缀，函数名后面加上一个“@”符号和其參数的字节数。比如 _functionname@argbytes\n   * __fastcall x86 调用约定，在输出函数名前加上一个"@"符号，后面也是一个"@"符号和其參数的字节数，比如 @functionname@argbytes\n   * __stdcall x64 和 __fastcall x64 调用约定，保持输出函数名不变，比如functionname\n   * __cdecl 同 gcc\n   * gcc 的基本c名称修饰方法：\n     * __cdecl x86 调用约定，仅在输出函数名前加上一个下划线前缀。比如_functionname\n     * __cdecl x64 调用约定，保持输出函数名不变。比如functionname\n * c++ 编译器的名称修饰规则\n   * visual c++ 的基本c++名称修饰方法：\n     * 形如：?func_name@class_name@namespace@@flags_and_args_and_return@z, 修饰后名字由"?"开头，接着是函数名由"@"符号结尾的函数名；后面跟着由"@"结尾的类名和名称空间，再一个"@"表示函数的名称空间结束；其后可能有，函数调用类型(__cdecl或__stdcall等)、函数保护属性(public、private...) 以及 参数列表等信息，由"@"结束，最后由"z"结尾。\n       * 比如 int c::c2::func(int) 经过名称修饰以后就是 ?func@c2@c@@aaehh@z\n   * gcc 的基本c++名称修饰方法：\n     * 所有的符号都以"_z"开头，对于嵌套的名字（在名称空间或在类里面的），后面紧跟"n"，然后是各个名称空间和类的名字，每个名字前是名字字符串长度，再以"e"结尾。对于一个函数来说，它的参数列表紧跟在"e"后面。\n       * 比如 n::c::func 经过名称修饰以后就是 _zn1n1c4funce。n::c::func(int) 函数签名经过修饰为 _zn1n1c4funcei, 对于int类型来说，就是字母"i"。\n\n\n# 特性\n\n * 右值引用\n   * std::move、std::forward\n * using、typedef、typename\n   * using 可读性更高，并且可以用于模板别名\n   * the "typename" keyword\n * const\n   * 指针：位于*的左侧 或 右侧\n   * 成员变量\n   * 成员函数\n     * 不被允许修改它所在对象的任何一个数据成员(但可以访问)\n     * const成员函数，可以访问const成员函数\n   * 对象\n     * 该对象的任何非const成员函数都不能被调用，因为任何非const成员函数会有修改成员变量的企图\n   * const_cast<type_id> (expression)\n * attribute\n   \n     #if defined(__gcc__)\n     /*\n     * __attribute__ 是 gcc 编译器特有的机制\n     * 如，__attribute__((packed)) 和 __attribute__(aligned(4))\n     * \n     * 使用：\n     *   typedef struct {\n     *   } __attribute__((packed)) position_t;\n     * \n     *   struct test {\n     *   } __attribute__((packed));\n     */\n     #endif\n     对齐方式还有：\n     #if ( _msc_ver >= 800 && !defined(_m_i86)) || defined(_pushpop_supported)\n       #pragma pack(push,1)\n     #else\n       #pragma pack(1)\n     #endif\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   19\n   \n * heaponly 和 stackonly\n   \n       #include <iostream>\n       class heaponly {\n       public:  \n           heaponly() { }\n           void destroy() const { delete this; }\n       private:  \n           ~heaponly() { }\n       };\n       class stackonly {\n       public:\n           stackonly() { }\n           ~stackonly() { }\n       private:\n           void* operator new(size_t);\n       };\n       int main() {  \n           stackonly s; // ok\n           stackonly *p = new stackonly; // wrong\n           heaponly *p = new heaponly; // ok\n           p->destroy();\n           heaponly h;  // wrong\n           return 0;\n       }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   19\n   20\n   21\n   22\n   23\n   ',charsets:{cjk:!0}},{title:"Cxx Traps",frontmatter:{title:"Cxx Traps",date:"2021-12-22T10:30:00.000Z",lastmod:null,publish:!0,categories:null,keywords:null,description:null,tags:null,permalink:null},regularPath:"/blog/lang/cxx_traps.html",relativePath:"blog/lang/cxx_traps.md",key:"v-3a68b8c2",path:"/blog/lang/cxx_traps.html",headers:[{level:2,title:"1. Enum",slug:"_1-enum",normalizedTitle:"1. enum",charIndex:278},{level:3,title:"1.1 疑问",slug:"_1-1-疑问",normalizedTitle:"1.1 疑问",charIndex:290},{level:3,title:"1.2 背景",slug:"_1-2-背景",normalizedTitle:"1.2 背景",charIndex:834},{level:3,title:"1.3 解答",slug:"_1-3-解答",normalizedTitle:"1.3 解答",charIndex:1073},{level:2,title:"2. Array & Pointer",slug:"_2-array-pointer",normalizedTitle:"2. array &amp; pointer",charIndex:null},{level:3,title:"2.1 疑问",slug:"_2-1-疑问",normalizedTitle:"2.1 疑问",charIndex:1303},{level:3,title:"2.2 解答",slug:"_2-2-解答",normalizedTitle:"2.2 解答",charIndex:1591},{level:2,title:"3. TODO",slug:"_3-todo",normalizedTitle:"3. todo",charIndex:3798}],headersStr:"1. Enum 1.1 疑问 1.2 背景 1.3 解答 2. Array & Pointer 2.1 疑问 2.2 解答 3. TODO",content:'# Cxx Traps\n\nc/c++ 源代码一般会通过以下步骤，被编译、链接成可执行文件：\n\n 1. 预处理(Preprocess) : gcc -E test.cpp -o test.i\n 2. 编译为汇编(Compilation): gcc -S test.i -o test.s\n 3. 汇编(Assembly): gcc -c test.s -o test.o\n 4. 连接(Linking): gcc test.o -o test\n\n当然，上述步骤可以直接通过 gcc define.cpp test.cpp -o test 一步到位.\n\n\n# 1. Enum\n\n\n# 1.1 疑问\n\nclass Test {\npublic:\n    enum Result {\n        Result_OK = 0x1000,\n    };\n\n    Test(enum Result emRst) {\n        m_nRst = emRst;\n    }\n\n    static int m_nRst;\n};\n\nint Test::m_nRst = 0; /* OK */\n// Test::m_nRst = 0; /* ERROR, 此声明没有存储类或类型说明符 */\n\nint main() { \n    Test(Test::Result(Test::Result_OK)); /* OK */\n    Test((Test::Result)Test::Result_OK); /* OK */\n    // Test(Test::Result_OK); /* ERROR, 当前范围内无法定义 constant "Test::Result_OK" */\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n为什么上述代码在去掉注释"//"后，vs2019编译器会提示错误？\n\n\n# 1.2 背景\n\n我们需要明白，enum 关键字会定义一个类型，同时，其内定义的项目会被展开为int型常量到定义 enum 的作用域。\n\n这会造成，在全局位置定义的 enum 类型中的项目名需要是全局唯一的, 如下述定义会编译出错(error C2365: “a”: 重定义)：\n\nenum X { a };\nenum Y { a };\n\n\n1\n2\n\n\n由此，为了解决作用域 以及 强类型限定问题，C++11 中引入了 enum class 或 enum struct。\n\n\n# 1.3 解答\n\n 1. 全局位置的 ERROR, 此声明没有存储类或类型说明符：\n    * c/c++ 没有全局代码块，在全局位置的是 声明或定义\n 2. 传递枚举值到枚举类型参数时 ERROR, 当前范围内无法定义 constant：\n    * ？\n    * vs2019 会报错，但，g++ 在 linux 下编译正常\n      * 可能是：强类型限定造成现在拒绝枚举量与int之间的隐式转换\n\n\n# 2. Array & Pointer\n\n\n# 2.1 疑问\n\n// define.c\nint arr[] = { 1,2,3 };\nint* ard = &arr[0];\n\n// test.c\nint art[] = { 5,6,7,8,9 };\nextern int* arr;\n\nvoid test() {\n    int* x = arr + 1;\n    int* m = arrx + 1;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n请问 test 函数中的 x 和 m 分别是多少？(int)x = 5, *m = 6\n\n同我们的认知：数组可以当成指针使用 不一样，对吧...\n\n\n# 2.2 解答\n\n将上述代码编译成汇编后的代码如下：\n\n * define.cpp\n\n        .file   "define.cpp"\n        .text\n        .globl  arr\n        .data\n        .align 8\n        .type   arr, @object\n        .size   arr, 12\narr:\n        .long   1\n        .long   2\n        .long   3\n        .globl  arm\n        .section        .data.rel.local,"aw"\n        .align 8\n        .type   arm, @object\n        .size   arm, 8\narm:\n        .quad   arr\n        .ident  "GCC: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0"\n        .section        .note.GNU-stack,"",@progbits\n        .section        .note.gnu.property,"a"\n        .align 8\n        .long    1f - 0f\n        .long    4f - 1f\n        .long    5\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n * test.cpp\n\n        .file   "test.cpp"\n        .text\n        .globl  art\n        .data\n        .align 16\n        .type   art, @object\n        .size   art, 20\nart:\n        .long   5\n        .long   6\n        .long   7\n        .long   8\n        .long   9\n        .text\n        .globl  test\n        .type   test, @function\ntest:\n.LFB0:\n        .cfi_startproc\n        endbr64\n        pushq   %rbp\n        .cfi_def_cfa_offset 16\n        .cfi_offset 6, -16\n        movq    %rsp, %rbp\n        .cfi_def_cfa_register 6\n        movq    arr(%rip), %rax\n        addq    $4, %rax\n        movq    %rax, -16(%rbp)\n        leaq    4+art(%rip), %rax\n        movq    %rax, -8(%rbp)\n        movq    -8(%rbp), %rax\n        movl    (%rax), %eax\n        movl    %eax, -20(%rbp)\n        nop\n        popq    %rbp\n        .cfi_def_cfa 7, 8\n        ret\n        .cfi_endproc\n.LFE0:\n        .size   test, .-test\n        .ident  "GCC: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0"\n        .section        .note.GNU-stack,"",@progbits\n        .section        .note.gnu.property,"a"\n        .align 8\n        .long    1f - 0f\n        .long    4f - 1f\n        .long    5\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n\n\n观察：\n\n * define.cpp中 arr 和 arm 的定义\n * test.cpp中 arr(%rip) 和 art(%rip) 的操作\n\n可以发现：\n\n 1. 数组可以当成指针使用，的原因是：编译器帮忙做了取地址操作\n 2. 因为 extern int* arr 在使用时缺少了编译器帮忙做取地址操作这一动作，直接被把 arr 当成了 指针使用：具体的方式可以参考 arm 的定义：直接把 arm 的值当成了地址使用\n\n\n# 3. TODO',normalizedContent:'# cxx traps\n\nc/c++ 源代码一般会通过以下步骤，被编译、链接成可执行文件：\n\n 1. 预处理(preprocess) : gcc -e test.cpp -o test.i\n 2. 编译为汇编(compilation): gcc -s test.i -o test.s\n 3. 汇编(assembly): gcc -c test.s -o test.o\n 4. 连接(linking): gcc test.o -o test\n\n当然，上述步骤可以直接通过 gcc define.cpp test.cpp -o test 一步到位.\n\n\n# 1. enum\n\n\n# 1.1 疑问\n\nclass test {\npublic:\n    enum result {\n        result_ok = 0x1000,\n    };\n\n    test(enum result emrst) {\n        m_nrst = emrst;\n    }\n\n    static int m_nrst;\n};\n\nint test::m_nrst = 0; /* ok */\n// test::m_nrst = 0; /* error, 此声明没有存储类或类型说明符 */\n\nint main() { \n    test(test::result(test::result_ok)); /* ok */\n    test((test::result)test::result_ok); /* ok */\n    // test(test::result_ok); /* error, 当前范围内无法定义 constant "test::result_ok" */\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n为什么上述代码在去掉注释"//"后，vs2019编译器会提示错误？\n\n\n# 1.2 背景\n\n我们需要明白，enum 关键字会定义一个类型，同时，其内定义的项目会被展开为int型常量到定义 enum 的作用域。\n\n这会造成，在全局位置定义的 enum 类型中的项目名需要是全局唯一的, 如下述定义会编译出错(error c2365: “a”: 重定义)：\n\nenum x { a };\nenum y { a };\n\n\n1\n2\n\n\n由此，为了解决作用域 以及 强类型限定问题，c++11 中引入了 enum class 或 enum struct。\n\n\n# 1.3 解答\n\n 1. 全局位置的 error, 此声明没有存储类或类型说明符：\n    * c/c++ 没有全局代码块，在全局位置的是 声明或定义\n 2. 传递枚举值到枚举类型参数时 error, 当前范围内无法定义 constant：\n    * ？\n    * vs2019 会报错，但，g++ 在 linux 下编译正常\n      * 可能是：强类型限定造成现在拒绝枚举量与int之间的隐式转换\n\n\n# 2. array & pointer\n\n\n# 2.1 疑问\n\n// define.c\nint arr[] = { 1,2,3 };\nint* ard = &arr[0];\n\n// test.c\nint art[] = { 5,6,7,8,9 };\nextern int* arr;\n\nvoid test() {\n    int* x = arr + 1;\n    int* m = arrx + 1;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n请问 test 函数中的 x 和 m 分别是多少？(int)x = 5, *m = 6\n\n同我们的认知：数组可以当成指针使用 不一样，对吧...\n\n\n# 2.2 解答\n\n将上述代码编译成汇编后的代码如下：\n\n * define.cpp\n\n        .file   "define.cpp"\n        .text\n        .globl  arr\n        .data\n        .align 8\n        .type   arr, @object\n        .size   arr, 12\narr:\n        .long   1\n        .long   2\n        .long   3\n        .globl  arm\n        .section        .data.rel.local,"aw"\n        .align 8\n        .type   arm, @object\n        .size   arm, 8\narm:\n        .quad   arr\n        .ident  "gcc: (ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0"\n        .section        .note.gnu-stack,"",@progbits\n        .section        .note.gnu.property,"a"\n        .align 8\n        .long    1f - 0f\n        .long    4f - 1f\n        .long    5\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n * test.cpp\n\n        .file   "test.cpp"\n        .text\n        .globl  art\n        .data\n        .align 16\n        .type   art, @object\n        .size   art, 20\nart:\n        .long   5\n        .long   6\n        .long   7\n        .long   8\n        .long   9\n        .text\n        .globl  test\n        .type   test, @function\ntest:\n.lfb0:\n        .cfi_startproc\n        endbr64\n        pushq   %rbp\n        .cfi_def_cfa_offset 16\n        .cfi_offset 6, -16\n        movq    %rsp, %rbp\n        .cfi_def_cfa_register 6\n        movq    arr(%rip), %rax\n        addq    $4, %rax\n        movq    %rax, -16(%rbp)\n        leaq    4+art(%rip), %rax\n        movq    %rax, -8(%rbp)\n        movq    -8(%rbp), %rax\n        movl    (%rax), %eax\n        movl    %eax, -20(%rbp)\n        nop\n        popq    %rbp\n        .cfi_def_cfa 7, 8\n        ret\n        .cfi_endproc\n.lfe0:\n        .size   test, .-test\n        .ident  "gcc: (ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0"\n        .section        .note.gnu-stack,"",@progbits\n        .section        .note.gnu.property,"a"\n        .align 8\n        .long    1f - 0f\n        .long    4f - 1f\n        .long    5\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n\n\n观察：\n\n * define.cpp中 arr 和 arm 的定义\n * test.cpp中 arr(%rip) 和 art(%rip) 的操作\n\n可以发现：\n\n 1. 数组可以当成指针使用，的原因是：编译器帮忙做了取地址操作\n 2. 因为 extern int* arr 在使用时缺少了编译器帮忙做取地址操作这一动作，直接被把 arr 当成了 指针使用：具体的方式可以参考 arm 的定义：直接把 arm 的值当成了地址使用\n\n\n# 3. todo',charsets:{cjk:!0}},{title:"GO",frontmatter:{title:"GO",date:"2021-11-24T11:50:00.000Z",lastmod:null,publish:!0,categories:null,keywords:null,description:null,tags:null,permalink:null},regularPath:"/blog/lang/go.html",relativePath:"blog/lang/go.md",key:"v-16fdda93",path:"/blog/lang/go.html",headers:[{level:2,title:"Go",slug:"go",normalizedTitle:"go",charIndex:2}],headersStr:"Go",content:'# Go\n\n * 类型\n   \n   * (u)int(8|16|32|64)、bool、string、uintptr、byte(=uint8)、rune(=uint32)、float[32|64]、complex[64|128]\n   * chan、interface、func\n   * array、slice、map\n\n * 关键字\n   \n   * 概览\n     \n     reserved-keywords:25\n         package\timport\tstruct\tinterface\tconst\tmap\ttype\tfunc\t\n         if\telse\tfor\tswitch\tselect\tbreak\tcontinue\tgoto\n         return\tfallthrough\tcase\tdefault\tdefer\trange\tgo\tchan\tvar\n     预定义标识符：内嵌函数和数据类型等\n         append\tiota\tlen\tcap\tmake\tnew\tcopy\ttrue\tfalse nil\n         close\timag\tprint\tprintln\tpanic\treal\trecover\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     \n   * range\n     * 作用于 string or map，可以返回系列 (key, value)\n   * fallthrough\n     * 在 switch case 中强制执行后面的 case 代码\n   * chan\n     \n     chonlyread := make(<-chan int) //创建只读channel \n     chonlywrite := make(chan<- int) //创建只写channel    \n     \n     \n     1\n     2\n     \n   * defer\n     * 当函数返回时，会执行defer语句，即使触发异常也会走defer语句；如果有多个defer语句，则按 first-in-last-out 的顺序依次执行；\n     * defer语句中的变量，在defer声明时确定变量\n   * func\n     * 不支持重载，一个包不能有两个名字一样的函数\n     * 命名返回值的名字（return可以不指定变量名）\n       \n       func add(a, b int) (c int) {\n               c = a + b\n               return\n       }\n       \n       \n       1\n       2\n       3\n       4\n       \n\n * 值传递 & 引用传递\n   \n   * map、slice、chan、指针、interface默认以引用的方式传递\n   * 分配内存\n     * new 主要用来分配值类型，比如 int、struct、array，返回的是指针\n     * make 主要用来分配引用类型，比如 chan、map、slice\n   * array : 值类型, 当作为方法的入参传入时将复制一份数组而不是引用同一指针\n   * slice : 引用类型, 在传递切片时，等同于传递了一指针\n\n * 可变参数\n   \n   * 可变参数实际上是一个slice，可以通过arg[index]依次访问所有参数；通过len(arg)来判断变参的个数\n     \n     func concat(s string, arg ...string) string {\n         str := s\n         for i := 0; i < len(arg); i++ { str += arg[i] }\n         return str\n     }\n     \n     \n     1\n     2\n     3\n     4\n     5\n     \n\n * closure\n   \n   * 闭包是一个函数和与其相关的引用环境组合而成的实体\n   * 函数可以存储到变量中作为参数传递给其它函数，能够被函数动态的创建和返回\n     \n     func Adder() func(int) int {\n         var x int\n         return func(d int) int {\n             x += d\n             return x\n         }\n     }\n     f := Adder()\n     fmt.Println(f(1))    //1\n     fmt.Println(f(10))   //11\n     fmt.Println(f(100))  //111\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     11\n     \n\n * 程序初始化与执行过程\n   \n   * 程序的初始化和执行都起于main包, 编译时将依赖的包依次导入\n   * 流程：\n     * 包初始化时，会先逐层递归的将它依赖的包导入进来，直到顶层包。\n     * 然后对顶层包中的包级常量和变量进行初始化，接着执行init函数（如果有的话），依次类推，直到最外层包被初始化。\n     * 等所有被导入的包加载完毕，就开始对main包中的包级常量和变量进行初始化，然后执行main包中的init函数（如果存在的话），最后执行main函数。\n   * 注意\n     * init()可以在任何package中出现(可选); main()只能用在package main 中(必需)\n     * 如果一个包会被多个包同时导入，那么它只会被导入一次\n\n * reflect\n   \n   * reflect.Value.NumField()，获取结构体中字段的个数\n   * reflect.Value.Method(n).Call(nil)，调用结构体中的方法\n   * reflect.TypeOf，返回一个Type类型值\n   * reflect.Value.Kind，返回一个常量，表示变量的类别\n   * reflect.ValueOf，返回一个Value类型值，该值代表运行时的数据\n     * SetXX(x) 因为传递的是x的副本，所以SetXX不能够改x，要改动x必须向函数传递x的指针\n     \n     //> SetInt、SetFloat、SetString\n     \n     //错误代码！！！\n     //panic: reflect: reflect.Value.SetFloat using unaddressable value\n     func main() {\n         var a float64\n         fv := reflect.ValueOf(&a)\n         fv.SetFloat(520.00)\n     }\n     //正确的，传指针\n     func main() {\n         var a2 float64\n         fv2 := reflect.ValueOf(&a2)\n         fv2.Elem().SetFloat(520.00)\n         fmt.Printf("%v\\n", a2)    //520\n     }\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     11\n     12\n     13\n     14\n     15\n     16\n     ',normalizedContent:'# go\n\n * 类型\n   \n   * (u)int(8|16|32|64)、bool、string、uintptr、byte(=uint8)、rune(=uint32)、float[32|64]、complex[64|128]\n   * chan、interface、func\n   * array、slice、map\n\n * 关键字\n   \n   * 概览\n     \n     reserved-keywords:25\n         package\timport\tstruct\tinterface\tconst\tmap\ttype\tfunc\t\n         if\telse\tfor\tswitch\tselect\tbreak\tcontinue\tgoto\n         return\tfallthrough\tcase\tdefault\tdefer\trange\tgo\tchan\tvar\n     预定义标识符：内嵌函数和数据类型等\n         append\tiota\tlen\tcap\tmake\tnew\tcopy\ttrue\tfalse nil\n         close\timag\tprint\tprintln\tpanic\treal\trecover\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     \n   * range\n     * 作用于 string or map，可以返回系列 (key, value)\n   * fallthrough\n     * 在 switch case 中强制执行后面的 case 代码\n   * chan\n     \n     chonlyread := make(<-chan int) //创建只读channel \n     chonlywrite := make(chan<- int) //创建只写channel    \n     \n     \n     1\n     2\n     \n   * defer\n     * 当函数返回时，会执行defer语句，即使触发异常也会走defer语句；如果有多个defer语句，则按 first-in-last-out 的顺序依次执行；\n     * defer语句中的变量，在defer声明时确定变量\n   * func\n     * 不支持重载，一个包不能有两个名字一样的函数\n     * 命名返回值的名字（return可以不指定变量名）\n       \n       func add(a, b int) (c int) {\n               c = a + b\n               return\n       }\n       \n       \n       1\n       2\n       3\n       4\n       \n\n * 值传递 & 引用传递\n   \n   * map、slice、chan、指针、interface默认以引用的方式传递\n   * 分配内存\n     * new 主要用来分配值类型，比如 int、struct、array，返回的是指针\n     * make 主要用来分配引用类型，比如 chan、map、slice\n   * array : 值类型, 当作为方法的入参传入时将复制一份数组而不是引用同一指针\n   * slice : 引用类型, 在传递切片时，等同于传递了一指针\n\n * 可变参数\n   \n   * 可变参数实际上是一个slice，可以通过arg[index]依次访问所有参数；通过len(arg)来判断变参的个数\n     \n     func concat(s string, arg ...string) string {\n         str := s\n         for i := 0; i < len(arg); i++ { str += arg[i] }\n         return str\n     }\n     \n     \n     1\n     2\n     3\n     4\n     5\n     \n\n * closure\n   \n   * 闭包是一个函数和与其相关的引用环境组合而成的实体\n   * 函数可以存储到变量中作为参数传递给其它函数，能够被函数动态的创建和返回\n     \n     func adder() func(int) int {\n         var x int\n         return func(d int) int {\n             x += d\n             return x\n         }\n     }\n     f := adder()\n     fmt.println(f(1))    //1\n     fmt.println(f(10))   //11\n     fmt.println(f(100))  //111\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     11\n     \n\n * 程序初始化与执行过程\n   \n   * 程序的初始化和执行都起于main包, 编译时将依赖的包依次导入\n   * 流程：\n     * 包初始化时，会先逐层递归的将它依赖的包导入进来，直到顶层包。\n     * 然后对顶层包中的包级常量和变量进行初始化，接着执行init函数（如果有的话），依次类推，直到最外层包被初始化。\n     * 等所有被导入的包加载完毕，就开始对main包中的包级常量和变量进行初始化，然后执行main包中的init函数（如果存在的话），最后执行main函数。\n   * 注意\n     * init()可以在任何package中出现(可选); main()只能用在package main 中(必需)\n     * 如果一个包会被多个包同时导入，那么它只会被导入一次\n\n * reflect\n   \n   * reflect.value.numfield()，获取结构体中字段的个数\n   * reflect.value.method(n).call(nil)，调用结构体中的方法\n   * reflect.typeof，返回一个type类型值\n   * reflect.value.kind，返回一个常量，表示变量的类别\n   * reflect.valueof，返回一个value类型值，该值代表运行时的数据\n     * setxx(x) 因为传递的是x的副本，所以setxx不能够改x，要改动x必须向函数传递x的指针\n     \n     //> setint、setfloat、setstring\n     \n     //错误代码！！！\n     //panic: reflect: reflect.value.setfloat using unaddressable value\n     func main() {\n         var a float64\n         fv := reflect.valueof(&a)\n         fv.setfloat(520.00)\n     }\n     //正确的，传指针\n     func main() {\n         var a2 float64\n         fv2 := reflect.valueof(&a2)\n         fv2.elem().setfloat(520.00)\n         fmt.printf("%v\\n", a2)    //520\n     }\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     11\n     12\n     13\n     14\n     15\n     16\n     ',charsets:{cjk:!0}},{title:"Go Mod 简介",frontmatter:{title:"Go Mod 简介",date:"2020-03-23T00:00:00.000Z",lastmod:null,publish:!0,categories:["golang"],keywords:["go","mod"],description:"golang 中 mod 的简介以及使用",tags:[null],permalink:null},regularPath:"/blog/lang/go/gomod.html",relativePath:"blog/lang/go/gomod.md",key:"v-52f58a7d",path:"/blog/lang/go/gomod.html",headers:[{level:2,title:"GOMOD",slug:"gomod",normalizedTitle:"gomod",charIndex:16},{level:2,title:"reference",slug:"reference",normalizedTitle:"reference",charIndex:1649}],headersStr:"GOMOD reference",content:"# Go Mod 简介\n\n\n# GOMOD\n\n * GOROOT & GOPATH\n   * 如果没有自行设置的话，GOROOT 会取 /usr/lib/go 作为默认值，而 GOPATH 则会取 $HOME/go。\n * 依赖管理目标：\n   * API 稳定性和可重现构建\n * go_version < 1.12\n   * go get位置：$GOPATH/src\n * go_version >= 1.13\n   * go mod\n     * GO111MODULE\n     * $GOPATH/pkg/mod\n   * go get : 不再循环拉取submodule子模块\n   * go mod 使用 最小版本选择（Minimal Version Selection）算法：为每个模块指定的依赖都是可用于构建的最低版本，最后实际选择的版本是所有出现过的最低版本中的最大值。\n   * go.mod 包含四部分：\n     * module:\n       \n       module /path/to/your/mod/v2\n       用来声明当前 module，如果当前版本大于 v1 的话，还需要在尾部显式的声明 /vN。\n       \n       \n       1\n       2\n       \n     * require:\n     \n     \trequire /your/mod tag/branch/commit/latest\n     \t可以使用 latest 来表示引用最新的 commit。如果对应的引用刚好是一个 Tag 的话，这个字符串会被重写为对应的 tag；如果不是的话，这个字符串会被规范化为形如 v2.0.0-20180128182452-d3ae77c26ac8 这样的字符串。\n     \n     \n     1\n     2\n     \n     * replace:只能作用于当前模块的构建。\n     \n     \treplace original_name => real_name tag/branch/commit\n     \treplace original_name => local_path\n     \n     \treplace test.dev/common => git.example.com/bravo/common.git v0.0.0-20190520075948-958a278528f8\n     \treplace test.dev/common => ../../another-porject/common-go\n     \n     \n     1\n     2\n     3\n     4\n     5\n     \n     * exclude:只能作用于当前模块的构建\n   * vendor\n     * 使用 go mod vendor 只是单纯地把 go.sum 中的所有依赖下载到 vendor 目录里，如果你用它迁移 godep 你会发现 vendor 目录里的包会和 godep 指定的产生相当大的差异，所以请务必不要这样做。\n     * 使用 go build -mod=vendor 来构建项目，因为在 go modules 模式下 go build 是屏蔽 vendor 机制的，所以需要特定参数重新开启 vendor 机制。\n * 常用指令\n\n\tgo mod graph | grep XXX 来看看谁在依赖这个XXX模块：\n\tgo list -m all\t列出当前模块依赖的所有模块\n\tgo list -u -m all\t列出当前模块依赖中可升级的模块\n\tgo get -u\t升级所有依赖至最新版本\n\tgo get -u=patch\t升级所有依赖至最新的修订版本\n\tgo mod tidy\t清理未使用/生效的依赖\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# reference\n\n * https://xuanwo.io/2019/05/27/go-modules/",normalizedContent:"# go mod 简介\n\n\n# gomod\n\n * goroot & gopath\n   * 如果没有自行设置的话，goroot 会取 /usr/lib/go 作为默认值，而 gopath 则会取 $home/go。\n * 依赖管理目标：\n   * api 稳定性和可重现构建\n * go_version < 1.12\n   * go get位置：$gopath/src\n * go_version >= 1.13\n   * go mod\n     * go111module\n     * $gopath/pkg/mod\n   * go get : 不再循环拉取submodule子模块\n   * go mod 使用 最小版本选择（minimal version selection）算法：为每个模块指定的依赖都是可用于构建的最低版本，最后实际选择的版本是所有出现过的最低版本中的最大值。\n   * go.mod 包含四部分：\n     * module:\n       \n       module /path/to/your/mod/v2\n       用来声明当前 module，如果当前版本大于 v1 的话，还需要在尾部显式的声明 /vn。\n       \n       \n       1\n       2\n       \n     * require:\n     \n     \trequire /your/mod tag/branch/commit/latest\n     \t可以使用 latest 来表示引用最新的 commit。如果对应的引用刚好是一个 tag 的话，这个字符串会被重写为对应的 tag；如果不是的话，这个字符串会被规范化为形如 v2.0.0-20180128182452-d3ae77c26ac8 这样的字符串。\n     \n     \n     1\n     2\n     \n     * replace:只能作用于当前模块的构建。\n     \n     \treplace original_name => real_name tag/branch/commit\n     \treplace original_name => local_path\n     \n     \treplace test.dev/common => git.example.com/bravo/common.git v0.0.0-20190520075948-958a278528f8\n     \treplace test.dev/common => ../../another-porject/common-go\n     \n     \n     1\n     2\n     3\n     4\n     5\n     \n     * exclude:只能作用于当前模块的构建\n   * vendor\n     * 使用 go mod vendor 只是单纯地把 go.sum 中的所有依赖下载到 vendor 目录里，如果你用它迁移 godep 你会发现 vendor 目录里的包会和 godep 指定的产生相当大的差异，所以请务必不要这样做。\n     * 使用 go build -mod=vendor 来构建项目，因为在 go modules 模式下 go build 是屏蔽 vendor 机制的，所以需要特定参数重新开启 vendor 机制。\n * 常用指令\n\n\tgo mod graph | grep xxx 来看看谁在依赖这个xxx模块：\n\tgo list -m all\t列出当前模块依赖的所有模块\n\tgo list -u -m all\t列出当前模块依赖中可升级的模块\n\tgo get -u\t升级所有依赖至最新版本\n\tgo get -u=patch\t升级所有依赖至最新的修订版本\n\tgo mod tidy\t清理未使用/生效的依赖\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# reference\n\n * https://xuanwo.io/2019/05/27/go-modules/",charsets:{cjk:!0}},{title:"优秀的 Go 文档",frontmatter:{title:"优秀的 Go 文档",date:"2021-07-27T00:00:00.000Z",lastmod:null,publish:!0,categories:["golang"],keywords:["nil error","reflection","interfaces"],description:"golang 中关键问题解析",tags:[null],permalink:null},regularPath:"/blog/lang/go/intrest_blogs.html",relativePath:"blog/lang/go/intrest_blogs.md",key:"v-65f07e87",path:"/blog/lang/go/intrest_blogs.html",headersStr:null,content:"# 优秀的 Go 文档\n\nID   SUBJECT                          URL                                          NOTE\n1    FAQ - nil_error                  https://golang.org/doc/faq#nil_error         \n2    laws of reflection               https://blog.golang.org/laws-of-reflection   PDF\n3    Go Data Structures: Interfaces   https://research.swtch.com/interfaces        PDF",normalizedContent:"# 优秀的 go 文档\n\nid   subject                          url                                          note\n1    faq - nil_error                  https://golang.org/doc/faq#nil_error         \n2    laws of reflection               https://blog.golang.org/laws-of-reflection   pdf\n3    go data structures: interfaces   https://research.swtch.com/interfaces        pdf",charsets:{cjk:!0}},{title:"recover & const 简述",frontmatter:{title:"recover & const 简述",date:"2019-12-23T00:00:00.000Z",lastmod:null,publish:!0,categories:["golang"],keywords:["recover","panic","const"],description:"golang 中 recover 的使用，以及 const 类型转换使用过程中遇到的的问题",tags:[null],permalink:null},regularPath:"/blog/lang/go/recover&const_desc.html",relativePath:"blog/lang/go/recover&const_desc.md",key:"v-6a7f071f",path:"/blog/lang/go/recover&const_desc.html",headers:[{level:2,title:"const类型转换",slug:"const类型转换",normalizedTitle:"const类型转换",charIndex:25},{level:2,title:"defer & panic & recover",slug:"defer-panic-recover",normalizedTitle:"defer &amp; panic &amp; recover",charIndex:null}],headersStr:"const类型转换 defer & panic & recover",content:'# recover & const 简述\n\n\n# const类型转换\n\n * 问题\n   \n   \tpackage main\n   \timport (\n   \t\t"fmt"\n   \t\t"reflect"\n   \t\t"time"\n   \t)\n   \tconst a = 1\n   \tfunc test(a time.Duration) {\n   \t\tfmt.Printf("%v \\n", a)\n   \t}\n   \tfunc main() {\n   \t\tb := a + 1\n   \t\tfmt.Printf("---- a = %v \\n", reflect.TypeOf(a))\n   \t\ttest(a)\n   \t\tfmt.Printf("---- b = %v \\n", reflect.TypeOf(b))\n   \t\t// test(b)  //> 打开注释后, 会编译不通过\n   \t}\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   \n * 原因\n   \n   Assignability\n   \tA value x is assignable to a variable of type T ("x is assignable to T") if one of the following conditions applies:\n   \t\t- x\'s type is identical to T.\n   \t\t- x\'s type V and T have identical underlying types and at least one of V or T is not a defined type.\n   \t\t- T is an interface type and x implements T.\n   \t\t- x is a bidirectional channel value, T is a channel type, x\'s type V and T have identical element types, and at least one of V or T is not a defined type.\n   \t\t- x is the predeclared identifier nil and T is a pointer, function, slice, map, channel, or interface type.\n   \t\t- x is an untyped constant representable by a value of type T.\t\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   \n   * const 修饰的变量如果没有明确指明类型时，会根据需要做类型转换; 而非 const 修饰的变量不会。\n   * reference: https://golang.org/ref/spec#Constants\n\n\n# defer & panic & recover\n\n * 详述\n   * defer\n     * 工作方式：先进后出\n     * 执行时机：\n       * 先说 return语句的处理过程\n         * return xxx 语句并不是一条原子指令，在执行时会分解成： a、返回变量=xxx b、执行return\n       * defer语句是在函数关闭时调用，确切的说是紧贴在执行return语句之前调用。\n         * 注意，是return 不是return xxx，就是说 defer 发生在上述流程的 a 和 b 之间。\n   * panic\n     * 执行过程：\n       * 当执行一个函数 F 的时候，如果显式地调用 panic 函数或者一个 run-time panics 发生时，F 会结束运行，所有 F 中 defer 的函数会按照 FILO 的规则被执行。\n       * 之后，F 函数的调用者中 defer 的函数再被执行，如此一直到最外层代码或者有效的 recover 调用。\n     * panic 函数的参数是空接口类型，所以可以接受任何类型的对象\n   * recover\n     * 目的：\n       * 当一个 goroutine 发生 panic 时，不影响其他的 goroutines 的执行\n     * 执行时机：\n       * recover 函数用来获取 panic 函数的参数信息，只能在延时调用 defer 语句调用的函数中直接调用才能生效\n       * 如果在 defer 语句中也调用 panic 函数，则只有最后一个被调用的 panic 函数的参数会被 recover 函数获取到。\n       * 如果 goroutine 没有 panic，那调用 recover 函数会返回 nil。\n\n> sample code\n\npackage main\n\nimport (\n\t"fmt"\n\t"runtime"\n\t"sync"\n\t"time"\n)\n\n/**\n*\n\n预期：\n   我们预期，定时器不停的工作，但当 goroutine 发生 panic 时，虽然不会影响其他 goroutine 但会造成定时器退出，不再继续工作\n伪码：\n   go func() {\n       defer func() {\n           if err := recover(); err != nil {\n               stackData := make([]byte, 1<<16)\n               runtime.Stack(stackData, false)\n               fmt.Printf("%v \\n", string(stackData))\n           }\n       }\n       ticker := time.NewTicker(1 * time.Second)\n       for range ticker.C {\n           var wg sync.WaitGroup\n           go func() {\n               //> do somethings\n           }\n           for i := 0; i < 100; i++ {\n               wg.Add(1)\n               go func() {\n                   defer wg.Done()\n                   //> do somethings\n               }\n           }\n           wg.Wait()\n       }\n   }\n\n*/\n\nfunc recovery(source string) {\n\tif err := recover(); err != nil { // recover只在defer的函数中有效\n\t\tfmt.Printf("-- %v \\n", err)\n\t\tstackData := make([]byte, 1<<16)\n\t\truntime.Stack(stackData, false)\n\t\tfmt.Printf("src=%s: %v \\n", source, string(stackData))\n\t} else {\n\t\tfmt.Printf("i am recovery: no : src=%s\\n", source)\n\t}\n}\n\nfunc firstCrash() {\n\tdefer func() {\n\t\tfmt.Printf("i am firstCrash: defer \\n")\n\t\t//> 这里的 recover 生效\n\t\tif err := recover(); err != nil {\n\t\t\tfmt.Printf("i am firstCrash: recovery \\n")\n\t\t}\n\t}()\n\tpanic("~~ panic ~~")\n}\n\nfunc nextCrash() {\n\tdefer func() {\n\t\tfmt.Printf("i am nextCrash: defer \\n")\n\t\trecovery("nextCrash") //> 这里的 recovery 里的 recover 不生效: recover 只在 defer 函数里才生效\n\t}()\n\tpanic("~~ panic ~~")\n}\n\nfunc next(w *sync.WaitGroup) {\n\tdefer w.Done()\n\tfmt.Printf("-- next: body \\n")\n\tnextCrash()\n}\n\nfunc first(w *sync.WaitGroup) {\n\tw.Add(1)\n\tgo func() {\n\t\tdefer recovery("first")\n\t\ttime.Sleep(1 * time.Second)\n\t\tfirstCrash()\n\t\tfmt.Printf("i am first: b \\n")\n\t\tnext(w)\n\t}()\n}\n\nfunc main() {\n\tdefer recovery("main")\n\tvar wg sync.WaitGroup\n\tfirst(&wg)\n\tfmt.Printf("i am wait \\n")\n\twg.Wait()\n\ttime.Sleep(2 * time.Second)\n\tfmt.Printf("i am ending \\n")\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n',normalizedContent:'# recover & const 简述\n\n\n# const类型转换\n\n * 问题\n   \n   \tpackage main\n   \timport (\n   \t\t"fmt"\n   \t\t"reflect"\n   \t\t"time"\n   \t)\n   \tconst a = 1\n   \tfunc test(a time.duration) {\n   \t\tfmt.printf("%v \\n", a)\n   \t}\n   \tfunc main() {\n   \t\tb := a + 1\n   \t\tfmt.printf("---- a = %v \\n", reflect.typeof(a))\n   \t\ttest(a)\n   \t\tfmt.printf("---- b = %v \\n", reflect.typeof(b))\n   \t\t// test(b)  //> 打开注释后, 会编译不通过\n   \t}\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   \n * 原因\n   \n   assignability\n   \ta value x is assignable to a variable of type t ("x is assignable to t") if one of the following conditions applies:\n   \t\t- x\'s type is identical to t.\n   \t\t- x\'s type v and t have identical underlying types and at least one of v or t is not a defined type.\n   \t\t- t is an interface type and x implements t.\n   \t\t- x is a bidirectional channel value, t is a channel type, x\'s type v and t have identical element types, and at least one of v or t is not a defined type.\n   \t\t- x is the predeclared identifier nil and t is a pointer, function, slice, map, channel, or interface type.\n   \t\t- x is an untyped constant representable by a value of type t.\t\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   \n   * const 修饰的变量如果没有明确指明类型时，会根据需要做类型转换; 而非 const 修饰的变量不会。\n   * reference: https://golang.org/ref/spec#constants\n\n\n# defer & panic & recover\n\n * 详述\n   * defer\n     * 工作方式：先进后出\n     * 执行时机：\n       * 先说 return语句的处理过程\n         * return xxx 语句并不是一条原子指令，在执行时会分解成： a、返回变量=xxx b、执行return\n       * defer语句是在函数关闭时调用，确切的说是紧贴在执行return语句之前调用。\n         * 注意，是return 不是return xxx，就是说 defer 发生在上述流程的 a 和 b 之间。\n   * panic\n     * 执行过程：\n       * 当执行一个函数 f 的时候，如果显式地调用 panic 函数或者一个 run-time panics 发生时，f 会结束运行，所有 f 中 defer 的函数会按照 filo 的规则被执行。\n       * 之后，f 函数的调用者中 defer 的函数再被执行，如此一直到最外层代码或者有效的 recover 调用。\n     * panic 函数的参数是空接口类型，所以可以接受任何类型的对象\n   * recover\n     * 目的：\n       * 当一个 goroutine 发生 panic 时，不影响其他的 goroutines 的执行\n     * 执行时机：\n       * recover 函数用来获取 panic 函数的参数信息，只能在延时调用 defer 语句调用的函数中直接调用才能生效\n       * 如果在 defer 语句中也调用 panic 函数，则只有最后一个被调用的 panic 函数的参数会被 recover 函数获取到。\n       * 如果 goroutine 没有 panic，那调用 recover 函数会返回 nil。\n\n> sample code\n\npackage main\n\nimport (\n\t"fmt"\n\t"runtime"\n\t"sync"\n\t"time"\n)\n\n/**\n*\n\n预期：\n   我们预期，定时器不停的工作，但当 goroutine 发生 panic 时，虽然不会影响其他 goroutine 但会造成定时器退出，不再继续工作\n伪码：\n   go func() {\n       defer func() {\n           if err := recover(); err != nil {\n               stackdata := make([]byte, 1<<16)\n               runtime.stack(stackdata, false)\n               fmt.printf("%v \\n", string(stackdata))\n           }\n       }\n       ticker := time.newticker(1 * time.second)\n       for range ticker.c {\n           var wg sync.waitgroup\n           go func() {\n               //> do somethings\n           }\n           for i := 0; i < 100; i++ {\n               wg.add(1)\n               go func() {\n                   defer wg.done()\n                   //> do somethings\n               }\n           }\n           wg.wait()\n       }\n   }\n\n*/\n\nfunc recovery(source string) {\n\tif err := recover(); err != nil { // recover只在defer的函数中有效\n\t\tfmt.printf("-- %v \\n", err)\n\t\tstackdata := make([]byte, 1<<16)\n\t\truntime.stack(stackdata, false)\n\t\tfmt.printf("src=%s: %v \\n", source, string(stackdata))\n\t} else {\n\t\tfmt.printf("i am recovery: no : src=%s\\n", source)\n\t}\n}\n\nfunc firstcrash() {\n\tdefer func() {\n\t\tfmt.printf("i am firstcrash: defer \\n")\n\t\t//> 这里的 recover 生效\n\t\tif err := recover(); err != nil {\n\t\t\tfmt.printf("i am firstcrash: recovery \\n")\n\t\t}\n\t}()\n\tpanic("~~ panic ~~")\n}\n\nfunc nextcrash() {\n\tdefer func() {\n\t\tfmt.printf("i am nextcrash: defer \\n")\n\t\trecovery("nextcrash") //> 这里的 recovery 里的 recover 不生效: recover 只在 defer 函数里才生效\n\t}()\n\tpanic("~~ panic ~~")\n}\n\nfunc next(w *sync.waitgroup) {\n\tdefer w.done()\n\tfmt.printf("-- next: body \\n")\n\tnextcrash()\n}\n\nfunc first(w *sync.waitgroup) {\n\tw.add(1)\n\tgo func() {\n\t\tdefer recovery("first")\n\t\ttime.sleep(1 * time.second)\n\t\tfirstcrash()\n\t\tfmt.printf("i am first: b \\n")\n\t\tnext(w)\n\t}()\n}\n\nfunc main() {\n\tdefer recovery("main")\n\tvar wg sync.waitgroup\n\tfirst(&wg)\n\tfmt.printf("i am wait \\n")\n\twg.wait()\n\ttime.sleep(2 * time.second)\n\tfmt.printf("i am ending \\n")\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n',charsets:{cjk:!0}},{title:"slice 底层结构",frontmatter:{title:"slice 底层结构",date:"2020-04-09T00:00:00.000Z",lastmod:null,taxonomies:["golang","slice"],categories:["golang","slice"],keywords:["golang","nil"],description:"slice 的底层结构，了解 slice 的实现基础",tags:["golang"],permalink:null},regularPath:"/blog/lang/go/slice_base.html",relativePath:"blog/lang/go/slice_base.md",key:"v-2c04e47f",path:"/blog/lang/go/slice_base.html",headers:[{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:17},{level:2,title:"Defination",slug:"defination",normalizedTitle:"defination",charIndex:326},{level:2,title:"nil切片 和 空切片",slug:"nil切片-和-空切片",normalizedTitle:"nil切片 和 空切片",charIndex:1107}],headersStr:"Summary Defination nil切片 和 空切片",content:"# slice 底层结构\n\n\n# Summary\n\nGo 中数组赋值和函数传参都是值复制的, 切片是引用传递\n\n * 数组\n   * 初始化时指定长度，如：\n   \n       a := [2]int{1,2}\n       var b [2]int\n   \n   \n   1\n   2\n   \n * 切片(slice)\n   * 是对数组一个连续片段的引用，所以切片是一个引用类型 (因此更类似于 C/C++ 中的数组类型，或者 Python 中的 list 类型)\n   * 初始化时不指定长度，如：\n   \n       a := []int{1,2}\n       var b []int\n   \n   \n   1\n   2\n   \n\n\n# Defination\n\nSlice 的数据结构定义如下:\n\n    // runtime/slice.go\n    type slice struct {\n        array unsafe.Pointer\n        len   int\n        cap   int\n    }\n\n\n1\n2\n3\n4\n5\n6\n\n\n如果想从 slice 中得到一块内存地址，可以这样做：\n\n    s := make([]byte, 10)defination\n    ptr := unsafe.Pointer(&s[0])\n\n\n1\n2\n\n\n如果反过来呢？从 Go 的内存地址中构造一个 slice。\n\n    var ptr unsafe.Pointer\n    var tmp = struct {\n        addr uintptr\n        len int\n        cap int\n    }{ptr, length, length}\n    s := *(*[]byte)(unsafe.Pointer(&tmp))\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n构造一个虚拟的结构体，把 slice 的数据结构拼出来。\n\n当然还有更加直接的方法，在 Go 的反射中就存在一个与之对应的数据结构 SliceHeader，我们可以用它来构造一个 slice\n\n    var o []byte\n    sliceHeader := (*reflect.SliceHeader)((unsafe.Pointer(&o)))\n    sliceHeader.Cap = length\n    sliceHeader.Len = length\n    sliceHeader.Data = uintptr(ptr)\n\n\n1\n2\n3\n4\n5\n\n\n\n# nil切片 和 空切片\n\nnil切片\n\n    // 内存布局：\n    //    Slice ---\x3e nil | Len = 0 | Cap = 0\n    var slice []int\n\n\n1\n2\n3\n\n\n空切片\n\n    // 内存布局：\n    //     Slice ---\x3e Pointer to Array | Len = 0 | Cap = 0\n    silce := make( []int , 0 )\n    slice := []int{ }\n\n\n1\n2\n3\n4\n",normalizedContent:"# slice 底层结构\n\n\n# summary\n\ngo 中数组赋值和函数传参都是值复制的, 切片是引用传递\n\n * 数组\n   * 初始化时指定长度，如：\n   \n       a := [2]int{1,2}\n       var b [2]int\n   \n   \n   1\n   2\n   \n * 切片(slice)\n   * 是对数组一个连续片段的引用，所以切片是一个引用类型 (因此更类似于 c/c++ 中的数组类型，或者 python 中的 list 类型)\n   * 初始化时不指定长度，如：\n   \n       a := []int{1,2}\n       var b []int\n   \n   \n   1\n   2\n   \n\n\n# defination\n\nslice 的数据结构定义如下:\n\n    // runtime/slice.go\n    type slice struct {\n        array unsafe.pointer\n        len   int\n        cap   int\n    }\n\n\n1\n2\n3\n4\n5\n6\n\n\n如果想从 slice 中得到一块内存地址，可以这样做：\n\n    s := make([]byte, 10)defination\n    ptr := unsafe.pointer(&s[0])\n\n\n1\n2\n\n\n如果反过来呢？从 go 的内存地址中构造一个 slice。\n\n    var ptr unsafe.pointer\n    var tmp = struct {\n        addr uintptr\n        len int\n        cap int\n    }{ptr, length, length}\n    s := *(*[]byte)(unsafe.pointer(&tmp))\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n构造一个虚拟的结构体，把 slice 的数据结构拼出来。\n\n当然还有更加直接的方法，在 go 的反射中就存在一个与之对应的数据结构 sliceheader，我们可以用它来构造一个 slice\n\n    var o []byte\n    sliceheader := (*reflect.sliceheader)((unsafe.pointer(&o)))\n    sliceheader.cap = length\n    sliceheader.len = length\n    sliceheader.data = uintptr(ptr)\n\n\n1\n2\n3\n4\n5\n\n\n\n# nil切片 和 空切片\n\nnil切片\n\n    // 内存布局：\n    //    slice ---\x3e nil | len = 0 | cap = 0\n    var slice []int\n\n\n1\n2\n3\n\n\n空切片\n\n    // 内存布局：\n    //     slice ---\x3e pointer to array | len = 0 | cap = 0\n    silce := make( []int , 0 )\n    slice := []int{ }\n\n\n1\n2\n3\n4\n",charsets:{cjk:!0}},{title:"关于 nil 判定的一些事情",frontmatter:{title:"关于 nil 判定的一些事情",date:"2020-04-09T00:00:00.000Z",lastmod:null,taxonomies:["golang"],categories:["golang"],keywords:["golang","nil"],description:"关于 nil 的一些事情",tags:["golang"],permalink:null},regularPath:"/blog/lang/go/somethings_about_nil.html",relativePath:"blog/lang/go/somethings_about_nil.md",key:"v-0c0b8bdf",path:"/blog/lang/go/somethings_about_nil.html",headers:[{level:2,title:"本质",slug:"本质",normalizedTitle:"本质",charIndex:19},{level:2,title:"示例",slug:"示例",normalizedTitle:"示例",charIndex:365},{level:3,title:"第一个问题",slug:"第一个问题",normalizedTitle:"第一个问题",charIndex:1989},{level:3,title:"关于第二个问题：",slug:"关于第二个问题",normalizedTitle:"关于第二个问题：",charIndex:2214},{level:3,title:"关于第三个问题：",slug:"关于第三个问题",normalizedTitle:"关于第三个问题：",charIndex:2334}],headersStr:"本质 示例 第一个问题 关于第二个问题： 关于第三个问题：",content:'# 关于 nil 的一些事情\n\n\n# 本质\n\n首先，nil 没有 type，并且，nil 也不是关键字 而是 预声明的标示符。\n\n其次，在 Go 语言中有以下几种类型可以取值 nil：\n\n类型                     NIL值含义\npointer                指向nothing, 比较时需要考虑类型是否一致\nslice                  slice变量中的3个成员值：buf为nil, len和cap都是0\ninterface              interface包含\'type,value\', 一个nil interface必须二者都为nil:\'nil, nil\'\nmap，channel，function   一个nil pointer，指向nothing\n\n\n# 示例\n\n接下来，我们来看一段代码，看看 go 语言中对 nil 判定的坑：\n\npackage nils\n\nimport (\n\t"net"\n\t"reflect"\n\t"testing"\n)\n\ntype TSlice []string\n\ntype IErrNil interface {\n\tIErrNil() IErrNil\n\tError() string\n}\n\ntype ErrNil struct {\n\tmsg string\n}\n\nfunc (t *ErrNil) Error() string {\n\treturn t.msg\n}\nfunc (t *ErrNil) ErrNil() *ErrNil {\n\treturn nil\n}\nfunc (t *ErrNil) IErrNil() IErrNil {\n\treturn nil\n}\nfunc (t *ErrNil) PrintMsg() string {\n\tif t == nil {\n\t\treturn "<nil>"\n\t}\n\treturn t.msg\n}\nfunc (t ErrNil) PrintMsgV2() string {\n\treturn t.msg\n}\n\nfunc Test_Nil(t *testing.T) {\n\tvar err error\n\n    var t ErrNil\n    t.PrintMsg()\n    t.PrintMsgV2()\n\n\ttmp := ErrNil{}\n\terr = tmp.ErrNil()\n\tif err == nil {\n\t\tt.Logf("(ErrNil == nil) ok: %v, err: %v", err == nil, err)\n\t} else {\n\t\tt.Errorf("(ErrNil == nil) err: %v, err: %v, type(err): %v", err == nil, err, reflect.TypeOf(err).Kind())\n\t}\n\n\terr = tmp.IErrNil()\n\tif err == nil {\n\t\tt.Logf("(IErrNil == nil) ok: %v, err: %v", err == nil, err)\n\t} else {\n\t\tt.Errorf("(IErrNil == nil) err: %v, err: %v, type(err): %v", err == nil, err, reflect.TypeOf(err).Kind())\n\t}\n\n\tip := net.ParseIP("111.1.111")\n\tif ip == nil {\n\t\tt.Logf("(ip == nil) ok: %v, err: %v, type(ip): %v", ip == nil, ip, reflect.TypeOf(ip).Kind())\n\t} else {\n\t\tt.Errorf("(ip == nil) err: %v, err: %v, type(ip): %v", ip == nil, ip, reflect.TypeOf(ip).Kind())\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n\n\n会发现两个问题：\n\n 1. t.PrintMsg() 可以执行 但是 t.PrintMsgV2() 会崩溃\n 2. 第二个判定竟然 err != nil\n 3. 第三个判断竟然 ip == nil\n\n\n# 第一个问题\n\nt.PrintMsg(): 当我们用一个空指针类型的变量(如，var t *ErrNil)调用此方法时，该方法是会执行的，只有在执行该空指针变量的解指针操作(t.msg)时，才会 panic。\n\nt.PrintMsgV2(): 由于接受者是 ErrNil 而不是 *ErrNil，使用指针访问该函数时，Golang 内部会在调用时自动解指针，故使用空指针类型的变量(如，var t *ErrNil)调用此方法时会 panic。\n\n\n# 关于第二个问题：\n\n简单说，interface 被两个元素 value 和 type 所表示。只有在 value 和 type 同时为 nil 的时候，判断 interface == nil 才会为 true。具体可以参考官方文档\n\n\n# 关于第三个问题：\n\n这就涉及到 slice 的使用问题。\n\ngolang 中的类型可以是基本类型，如：int、float、bool、string；结构化的（复合的），如：struct、array、slice、map、channel；只描述类型的行为的，如：interface。\n\n结构化的类型没有真正的值，它使用 nil 作为默认值。简单的说，[]interface{} 是一个指向 具体 slice 类型对象的指针。所以，可以用 nil 进行赋值 和 判断。',normalizedContent:'# 关于 nil 的一些事情\n\n\n# 本质\n\n首先，nil 没有 type，并且，nil 也不是关键字 而是 预声明的标示符。\n\n其次，在 go 语言中有以下几种类型可以取值 nil：\n\n类型                     nil值含义\npointer                指向nothing, 比较时需要考虑类型是否一致\nslice                  slice变量中的3个成员值：buf为nil, len和cap都是0\ninterface              interface包含\'type,value\', 一个nil interface必须二者都为nil:\'nil, nil\'\nmap，channel，function   一个nil pointer，指向nothing\n\n\n# 示例\n\n接下来，我们来看一段代码，看看 go 语言中对 nil 判定的坑：\n\npackage nils\n\nimport (\n\t"net"\n\t"reflect"\n\t"testing"\n)\n\ntype tslice []string\n\ntype ierrnil interface {\n\tierrnil() ierrnil\n\terror() string\n}\n\ntype errnil struct {\n\tmsg string\n}\n\nfunc (t *errnil) error() string {\n\treturn t.msg\n}\nfunc (t *errnil) errnil() *errnil {\n\treturn nil\n}\nfunc (t *errnil) ierrnil() ierrnil {\n\treturn nil\n}\nfunc (t *errnil) printmsg() string {\n\tif t == nil {\n\t\treturn "<nil>"\n\t}\n\treturn t.msg\n}\nfunc (t errnil) printmsgv2() string {\n\treturn t.msg\n}\n\nfunc test_nil(t *testing.t) {\n\tvar err error\n\n    var t errnil\n    t.printmsg()\n    t.printmsgv2()\n\n\ttmp := errnil{}\n\terr = tmp.errnil()\n\tif err == nil {\n\t\tt.logf("(errnil == nil) ok: %v, err: %v", err == nil, err)\n\t} else {\n\t\tt.errorf("(errnil == nil) err: %v, err: %v, type(err): %v", err == nil, err, reflect.typeof(err).kind())\n\t}\n\n\terr = tmp.ierrnil()\n\tif err == nil {\n\t\tt.logf("(ierrnil == nil) ok: %v, err: %v", err == nil, err)\n\t} else {\n\t\tt.errorf("(ierrnil == nil) err: %v, err: %v, type(err): %v", err == nil, err, reflect.typeof(err).kind())\n\t}\n\n\tip := net.parseip("111.1.111")\n\tif ip == nil {\n\t\tt.logf("(ip == nil) ok: %v, err: %v, type(ip): %v", ip == nil, ip, reflect.typeof(ip).kind())\n\t} else {\n\t\tt.errorf("(ip == nil) err: %v, err: %v, type(ip): %v", ip == nil, ip, reflect.typeof(ip).kind())\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n\n\n会发现两个问题：\n\n 1. t.printmsg() 可以执行 但是 t.printmsgv2() 会崩溃\n 2. 第二个判定竟然 err != nil\n 3. 第三个判断竟然 ip == nil\n\n\n# 第一个问题\n\nt.printmsg(): 当我们用一个空指针类型的变量(如，var t *errnil)调用此方法时，该方法是会执行的，只有在执行该空指针变量的解指针操作(t.msg)时，才会 panic。\n\nt.printmsgv2(): 由于接受者是 errnil 而不是 *errnil，使用指针访问该函数时，golang 内部会在调用时自动解指针，故使用空指针类型的变量(如，var t *errnil)调用此方法时会 panic。\n\n\n# 关于第二个问题：\n\n简单说，interface 被两个元素 value 和 type 所表示。只有在 value 和 type 同时为 nil 的时候，判断 interface == nil 才会为 true。具体可以参考官方文档\n\n\n# 关于第三个问题：\n\n这就涉及到 slice 的使用问题。\n\ngolang 中的类型可以是基本类型，如：int、float、bool、string；结构化的（复合的），如：struct、array、slice、map、channel；只描述类型的行为的，如：interface。\n\n结构化的类型没有真正的值，它使用 nil 作为默认值。简单的说，[]interface{} 是一个指向 具体 slice 类型对象的指针。所以，可以用 nil 进行赋值 和 判断。',charsets:{cjk:!0}},{title:"JS 零基础起步",frontmatter:{title:"JS 零基础起步",date:"2020-04-14T00:00:00.000Z",lastmod:null,publish:!0,categories:["js"],keywords:["js"],description:"js 基础知识汇总",tags:[null],permalink:null},regularPath:"/blog/lang/js.html",relativePath:"blog/lang/js.md",key:"v-95a0b5de",path:"/blog/lang/js.html",headers:[{level:2,title:"数据类型",slug:"数据类型",normalizedTitle:"数据类型",charIndex:15},{level:2,title:"关于 this",slug:"关于-this",normalizedTitle:"关于 this",charIndex:682},{level:2,title:"关于 DOM",slug:"关于-dom",normalizedTitle:"关于 dom",charIndex:858},{level:3,title:"关于 EVENT",slug:"关于-event",normalizedTitle:"关于 event",charIndex:1550},{level:2,title:"Effective",slug:"effective",normalizedTitle:"effective",charIndex:1644},{level:3,title:"hoisting（悬置/置顶解析/预解析）",slug:"hoisting-悬置-置顶解析-预解析",normalizedTitle:"hoisting（悬置/置顶解析/预解析）",charIndex:1658},{level:3,title:"eval()",slug:"eval",normalizedTitle:"eval()",charIndex:1972},{level:3,title:"(隐式)全局变量",slug:"隐式-全局变量",normalizedTitle:"(隐式)全局变量",charIndex:2311}],headersStr:"数据类型 关于 this 关于 DOM 关于 EVENT Effective hoisting（悬置/置顶解析/预解析） eval() (隐式)全局变量",content:'# JS 零基础起步\n\n\n# 数据类型\n\n * 基本类型： Undefined, Null, Boolean, Number, String , Symbol\n   * 基本类型值保存在栈空间，我们通过按值来访问的。\n * 引用类型： Array Object Date Function\n   * 引用类型的值是对象，栈内存中存放地址指向堆内存中的对象。是按引用访问的。栈内存中存放的只是该对象的访问地址，在堆内存中为这个值分配空间。\n\n检测数据类型常用 typeof 或者 instanceof\n\n * undefined 与 null 的区别\n\nnull：\n    是Null类型的值.\n    是个空值，空对象指针.\n    typeof null，结果为Object;\n    null用来表示尚未存在的对象.\nundefined :\n    是Undefined类型的值。\n    typeof undefined，结果为undefined;\n    一个声明了变量，但未初始化值，结果就是undefined\n    没有返回值的函数，返回的也是undefined,\n    没有实参的形参也是undefined;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n * compare\n   * JavaScript的变量在比较的时候会隐式类型转换。这就是为什么一些诸如：false == 0 或 “” == 0 返回的结果是true。\n   * 为避免引起混乱的隐含类型转换，在你比较值和表达式类型的时候始终使用===和!==操作符。\n\n\n# 关于 this\n\n原则，那就是this指的是调用函数的那个对象。\n\njavascript 的this主要是看如何调用这个函数，而不是这个函数所在的作用域。obj.fn() fn中的 this 就是 obj。 fn() this是undifine, 而在js进入函数之前，会有 if(!this) { this = window} 这样的操作。\n\n\n# 关于 DOM\n\nDOM（Document Object Model，文档对象模型）是一个通过和JavaScript进行内容交互的API。Javascript和DOM一般经常作为一个整体，因为Javascript通常都是用来进行DOM操作和交互的。\n\n关于DOM，有些知识需要注意：\n\n 1. window对象作为全局对象，也就是说你可以通过window来访问全局对象。\n    * 属性在对象下面以变量的形式存放，在页面上创建的所有全局对象都会变成window对象的属性。\n    * 方法在对象下面以函数的形式存放，因为左右的函数都存放在window对象下面，所以他们也可以称为方法。\n 2. DOM为web文档创建带有层级的结果，这些层级是通过node节点组成，这里有几种DOM node类型，最重要的是Element, Text, Document。\n    * Element节点在页面里展示的是一个元素，所以如果你有段落元素(\n      \n      )，你可以通过这个DOM节点来访问。\n    \n    * Text节点在页面里展示的所有文本相关的元素，所以如果你的段落有文本在里面的话，你可以直接通过DOM的Text节点来访问这个文本\n    * Document节点代表是整个文档，它是DOM的根节点。\n 3. 每个引擎对DOM标准的实现有一些轻微的不同。\n    * 例如，Firefox浏览器使用的Gecko引擎有着很好的实现（尽管没有完全遵守W3C规范），但IE浏览器使用的Trident引擎的实现却不完整而且还有bug，给开发人言带来了很多问题。\n\n\n# 关于 EVENT\n\n我们需要了解：\n\n 1. JS是单线程语言\n 2. JS的Event Loop是JS的执行机制。深入了解JS的执行,就等于深入了解JS里的event loop\n\n\n# Effective\n\n\n# hoisting（悬置/置顶解析/预解析）\n\nJavaScript中，你可以在函数的任何位置声明多个var语句，并且它们就好像是在函数顶部声明一样发挥作用，这种行为称为 hoisting（悬置/置顶解析/预解析）\n\n    // 反例\n    myname = "global"; // 全局变量\n    function func() {\n        alert(myname); // "undefined"\n        var myname = "local";\n        alert(myname); // "local"\n    }\n    func();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# eval()\n\n如果你现在的代码中使用了eval()，记住该咒语“eval()是魔鬼”。此方法接受任意的字符串，并当作JavaScript代码来处理。当有 问题的代码是事先知道的（不是运行时确定的），没有理由使用eval()。如果代码是在运行时动态生成，有一个更好的方式不使用eval而达到同样的目 标。例如，用方括号表示法来访问动态属性会更好更简单：\n\n    // 反面示例\n    var property = "name";\n    alert(eval("obj." + property));\n\n    // 更好的\n    var property = "name";\n    alert(obj[property]);\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# (隐式)全局变量\n\n隐式全局变量和明确定义的全局变量间有些小的差异，就是通过delete操作符让变量未定义的能力。\n\n * 通过var创建的全局变量（任何函数之外的程序中创建）是不能被删除的。\n * 无var创建的隐式全局变量（无视是否在函数中创建）是能被删除的\n\n    // 定义三个全局变量\n    var global_var = 1;\n    global_novar = 2; // 反面教材\n    (function () {\n    global_fromfunc = 3; // 反面教材\n    }());\n\n    // 试图删除\n    delete global_var; // false\n    delete global_novar; // true\n    delete global_fromfunc; // true\n\n    // 测试该删除\n    typeof global_var; // "number"\n    typeof global_novar; // "undefined"\n    typeof global_fromfunc; // "undefined"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n',normalizedContent:'# js 零基础起步\n\n\n# 数据类型\n\n * 基本类型： undefined, null, boolean, number, string , symbol\n   * 基本类型值保存在栈空间，我们通过按值来访问的。\n * 引用类型： array object date function\n   * 引用类型的值是对象，栈内存中存放地址指向堆内存中的对象。是按引用访问的。栈内存中存放的只是该对象的访问地址，在堆内存中为这个值分配空间。\n\n检测数据类型常用 typeof 或者 instanceof\n\n * undefined 与 null 的区别\n\nnull：\n    是null类型的值.\n    是个空值，空对象指针.\n    typeof null，结果为object;\n    null用来表示尚未存在的对象.\nundefined :\n    是undefined类型的值。\n    typeof undefined，结果为undefined;\n    一个声明了变量，但未初始化值，结果就是undefined\n    没有返回值的函数，返回的也是undefined,\n    没有实参的形参也是undefined;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n * compare\n   * javascript的变量在比较的时候会隐式类型转换。这就是为什么一些诸如：false == 0 或 “” == 0 返回的结果是true。\n   * 为避免引起混乱的隐含类型转换，在你比较值和表达式类型的时候始终使用===和!==操作符。\n\n\n# 关于 this\n\n原则，那就是this指的是调用函数的那个对象。\n\njavascript 的this主要是看如何调用这个函数，而不是这个函数所在的作用域。obj.fn() fn中的 this 就是 obj。 fn() this是undifine, 而在js进入函数之前，会有 if(!this) { this = window} 这样的操作。\n\n\n# 关于 dom\n\ndom（document object model，文档对象模型）是一个通过和javascript进行内容交互的api。javascript和dom一般经常作为一个整体，因为javascript通常都是用来进行dom操作和交互的。\n\n关于dom，有些知识需要注意：\n\n 1. window对象作为全局对象，也就是说你可以通过window来访问全局对象。\n    * 属性在对象下面以变量的形式存放，在页面上创建的所有全局对象都会变成window对象的属性。\n    * 方法在对象下面以函数的形式存放，因为左右的函数都存放在window对象下面，所以他们也可以称为方法。\n 2. dom为web文档创建带有层级的结果，这些层级是通过node节点组成，这里有几种dom node类型，最重要的是element, text, document。\n    * element节点在页面里展示的是一个元素，所以如果你有段落元素(\n      \n      )，你可以通过这个dom节点来访问。\n    \n    * text节点在页面里展示的所有文本相关的元素，所以如果你的段落有文本在里面的话，你可以直接通过dom的text节点来访问这个文本\n    * document节点代表是整个文档，它是dom的根节点。\n 3. 每个引擎对dom标准的实现有一些轻微的不同。\n    * 例如，firefox浏览器使用的gecko引擎有着很好的实现（尽管没有完全遵守w3c规范），但ie浏览器使用的trident引擎的实现却不完整而且还有bug，给开发人言带来了很多问题。\n\n\n# 关于 event\n\n我们需要了解：\n\n 1. js是单线程语言\n 2. js的event loop是js的执行机制。深入了解js的执行,就等于深入了解js里的event loop\n\n\n# effective\n\n\n# hoisting（悬置/置顶解析/预解析）\n\njavascript中，你可以在函数的任何位置声明多个var语句，并且它们就好像是在函数顶部声明一样发挥作用，这种行为称为 hoisting（悬置/置顶解析/预解析）\n\n    // 反例\n    myname = "global"; // 全局变量\n    function func() {\n        alert(myname); // "undefined"\n        var myname = "local";\n        alert(myname); // "local"\n    }\n    func();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# eval()\n\n如果你现在的代码中使用了eval()，记住该咒语“eval()是魔鬼”。此方法接受任意的字符串，并当作javascript代码来处理。当有 问题的代码是事先知道的（不是运行时确定的），没有理由使用eval()。如果代码是在运行时动态生成，有一个更好的方式不使用eval而达到同样的目 标。例如，用方括号表示法来访问动态属性会更好更简单：\n\n    // 反面示例\n    var property = "name";\n    alert(eval("obj." + property));\n\n    // 更好的\n    var property = "name";\n    alert(obj[property]);\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# (隐式)全局变量\n\n隐式全局变量和明确定义的全局变量间有些小的差异，就是通过delete操作符让变量未定义的能力。\n\n * 通过var创建的全局变量（任何函数之外的程序中创建）是不能被删除的。\n * 无var创建的隐式全局变量（无视是否在函数中创建）是能被删除的\n\n    // 定义三个全局变量\n    var global_var = 1;\n    global_novar = 2; // 反面教材\n    (function () {\n    global_fromfunc = 3; // 反面教材\n    }());\n\n    // 试图删除\n    delete global_var; // false\n    delete global_novar; // true\n    delete global_fromfunc; // true\n\n    // 测试该删除\n    typeof global_var; // "number"\n    typeof global_novar; // "undefined"\n    typeof global_fromfunc; // "undefined"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n',charsets:{cjk:!0}},{title:'Python 中 "_"、"__" 和 "__xx__" 的区别',frontmatter:{title:'Python 中 "\\_"、"\\_\\_" 和 "\\_\\_xx\\_\\_" 的区别',date:"2021-02-24T00:00:00.000Z",categories:["python"],tags:[null],permalink:null},regularPath:"/blog/lang/python/py__xx__.html",relativePath:"blog/lang/python/py__xx__.md",key:"v-d3589f42",path:"/blog/lang/python/py__xx__.html",headers:[{level:2,title:"`_`单下划线",slug:"单下划线",normalizedTitle:"<code>_</code>单下划线",charIndex:null},{level:2,title:"`__`双下划线",slug:"双下划线",normalizedTitle:"<code>__</code>双下划线",charIndex:null},{level:2,title:"`_xx_`前后各双下划线",slug:"xx-前后各双下划线",normalizedTitle:"<code>_xx_</code>前后各双下划线",charIndex:null},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:2389}],headersStr:"`_`单下划线 `__`双下划线 `_xx_`前后各双下划线 总结",content:'# Python 中 "_"、"__" 和 "__xx__" 的区别\n\n> 英文原文\n\n\n# _单下划线\n\nPython中不存在真正的私有方法。为了实现类似于c++中私有方法，可以在类的方法或属性前加一个“_”单下划线，意味着该方法或属性不应该去调用，它并不属于API。\n\n在使用property时，经常出现这个问题：\n\nclass BaseForm(StrAndUnicode):\n    ...\n    \n    def _get_errors(self):\n        "Returns an ErrorDict for the data provided for the form"\n        if self._errors is None:\n            self.full_clean()\n        return self._errors\n    \n    errors = property(_get_errors)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n上面的代码片段来自于django源码（django/forms/forms.py）。这里的errors是一个属性，属于API的一部分，但是_get_errors是私有的，是不应该访问的，但可以通过errors来访问该错误结果。\n\n\n# __双下划线\n\n这个双下划线更会造成更多混乱，但它并不是用来标识一个方法或属性是私有的，真正作用是用来避免子类覆盖其内容。\n\n让我们来看一个例子：\n\nclass A(object): \n    def __method(self): \n        print "I\'m a method in A" \n    def method(self): \n        self.__method() a = A() a.method()\n\n\n1\n2\n3\n4\n5\n\n\n输出是这样的：\n\n$ python example.py \nI\'m a method in A\n\n\n1\n2\n\n\n很好，出现了预计的结果。\n\n我们给A添加一个子类，并重新实现一个__method：\n\nclass B(A): \n    def __method(self): \n        print "I\'m a method in B" \n\nb = B() \nb.method()\n\n\n1\n2\n3\n4\n5\n6\n\n\n现在，结果是这样的：\n\n$ python example.py\nI\'m a method in A\n\n\n1\n2\n\n\n就像我们看到的一样，B.method()不能调用B.method的方法。实际上，它是""两个下划线的功能的正常显示。\n\n因此，在我们创建一个以"__"两个下划线开始的方法时，这意味着这个方法不能被重写，它只允许在该类的内部中使用。\n\n在Python中如是做的？很简单，它只是把方法重命名了，如下：\n\na = A()\na._A__method()  # never use this!! please!\n\n\n1\n2\n\n\n$ python example.py \nI\'m a method in A\n\n\n1\n2\n\n\n如果你试图调用a.__method，它还是无法运行的，就如上面所说，只可以在类的内部调用__method。\n\n\n# __xx__前后各双下划线\n\n当你看到__this__的时，就知道不要调用它。为什么？因为它的意思是它是用于Python调用的，如下：\n\n>>> name = "igor" \n>>> name.__len__()\n 4 \n>>> len(name)\n 4 \n>>> number = 10 \n>>> number.__add__(20) \n 30 \n>>> number + 20\n 30\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n__xx__经常是操作符或本地函数调用的magic methods。在上面的例子中，提供了一种重写类的操作符的功能。\n\n在特殊的情况下，它只是python调用的hook。例如，__init__()函数是当对象被创建初始化时调用的;__new__()是用来创建实例。\n\nclass CrazyNumber(object):\n    def __init__(self, n): \n        self.n = n \n    def __add__(self, other): \n        return self.n - other \n    def __sub__(self, other): \n        return self.n + other \n    def __str__(self): \n        return str(self.n) \n\nnum = CrazyNumber(10) \nprint num # 10\nprint num + 5 # 5\nprint num - 20 # 30\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n另一个例子\n\nclass Room(object):\n    def __init__(self): \n        self.people = [] \n    def add(self, person): \n        self.people.append(person) \n    def __len__(self): \n        return len(self.people)\n \nroom = Room() \nroom.add("Igor") \nprint len(room) # 1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 总结\n\n使用 _one_underline 来表示该方法或属性是私有的，不对外暴漏；当创建一个用于python调用或一些特殊情况时，使用 __two_underline__；使用 __just_to_underlines 可以避免子类重写，但这个属性比较复杂，不推荐～',normalizedContent:'# python 中 "_"、"__" 和 "__xx__" 的区别\n\n> 英文原文\n\n\n# _单下划线\n\npython中不存在真正的私有方法。为了实现类似于c++中私有方法，可以在类的方法或属性前加一个“_”单下划线，意味着该方法或属性不应该去调用，它并不属于api。\n\n在使用property时，经常出现这个问题：\n\nclass baseform(strandunicode):\n    ...\n    \n    def _get_errors(self):\n        "returns an errordict for the data provided for the form"\n        if self._errors is none:\n            self.full_clean()\n        return self._errors\n    \n    errors = property(_get_errors)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n上面的代码片段来自于django源码（django/forms/forms.py）。这里的errors是一个属性，属于api的一部分，但是_get_errors是私有的，是不应该访问的，但可以通过errors来访问该错误结果。\n\n\n# __双下划线\n\n这个双下划线更会造成更多混乱，但它并不是用来标识一个方法或属性是私有的，真正作用是用来避免子类覆盖其内容。\n\n让我们来看一个例子：\n\nclass a(object): \n    def __method(self): \n        print "i\'m a method in a" \n    def method(self): \n        self.__method() a = a() a.method()\n\n\n1\n2\n3\n4\n5\n\n\n输出是这样的：\n\n$ python example.py \ni\'m a method in a\n\n\n1\n2\n\n\n很好，出现了预计的结果。\n\n我们给a添加一个子类，并重新实现一个__method：\n\nclass b(a): \n    def __method(self): \n        print "i\'m a method in b" \n\nb = b() \nb.method()\n\n\n1\n2\n3\n4\n5\n6\n\n\n现在，结果是这样的：\n\n$ python example.py\ni\'m a method in a\n\n\n1\n2\n\n\n就像我们看到的一样，b.method()不能调用b.method的方法。实际上，它是""两个下划线的功能的正常显示。\n\n因此，在我们创建一个以"__"两个下划线开始的方法时，这意味着这个方法不能被重写，它只允许在该类的内部中使用。\n\n在python中如是做的？很简单，它只是把方法重命名了，如下：\n\na = a()\na._a__method()  # never use this!! please!\n\n\n1\n2\n\n\n$ python example.py \ni\'m a method in a\n\n\n1\n2\n\n\n如果你试图调用a.__method，它还是无法运行的，就如上面所说，只可以在类的内部调用__method。\n\n\n# __xx__前后各双下划线\n\n当你看到__this__的时，就知道不要调用它。为什么？因为它的意思是它是用于python调用的，如下：\n\n>>> name = "igor" \n>>> name.__len__()\n 4 \n>>> len(name)\n 4 \n>>> number = 10 \n>>> number.__add__(20) \n 30 \n>>> number + 20\n 30\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n__xx__经常是操作符或本地函数调用的magic methods。在上面的例子中，提供了一种重写类的操作符的功能。\n\n在特殊的情况下，它只是python调用的hook。例如，__init__()函数是当对象被创建初始化时调用的;__new__()是用来创建实例。\n\nclass crazynumber(object):\n    def __init__(self, n): \n        self.n = n \n    def __add__(self, other): \n        return self.n - other \n    def __sub__(self, other): \n        return self.n + other \n    def __str__(self): \n        return str(self.n) \n\nnum = crazynumber(10) \nprint num # 10\nprint num + 5 # 5\nprint num - 20 # 30\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n另一个例子\n\nclass room(object):\n    def __init__(self): \n        self.people = [] \n    def add(self, person): \n        self.people.append(person) \n    def __len__(self): \n        return len(self.people)\n \nroom = room() \nroom.add("igor") \nprint len(room) # 1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 总结\n\n使用 _one_underline 来表示该方法或属性是私有的，不对外暴漏；当创建一个用于python调用或一些特殊情况时，使用 __two_underline__；使用 __just_to_underlines 可以避免子类重写，但这个属性比较复杂，不推荐～',charsets:{cjk:!0}},{title:"Python 环境问题记录",frontmatter:{title:"Python 环境问题记录",date:"2021-01-29T00:00:00.000Z",categories:["python","environment"],tags:[null],permalink:null},regularPath:"/blog/lang/python/py_env.html",relativePath:"blog/lang/python/py_env.md",key:"v-90b5b0c2",path:"/blog/lang/python/py_env.html",headers:[{level:2,title:"常用源",slug:"常用源",normalizedTitle:"常用源",charIndex:20},{level:2,title:"Conda",slug:"conda",normalizedTitle:"conda",charIndex:327},{level:3,title:"error : PackagesNotFoundError",slug:"error-packagesnotfounderror",normalizedTitle:"error : packagesnotfounderror",charIndex:828},{level:2,title:"AI 框架",slug:"ai-框架",normalizedTitle:"ai 框架",charIndex:1249},{level:3,title:"Pytorch",slug:"pytorch",normalizedTitle:"pytorch",charIndex:1259},{level:3,title:"Tensorflow",slug:"tensorflow",normalizedTitle:"tensorflow",charIndex:1271},{level:2,title:"CUDA",slug:"cuda",normalizedTitle:"cuda",charIndex:1352},{level:3,title:"查看对GPU的支持",slug:"查看对gpu的支持",normalizedTitle:"查看对gpu的支持",charIndex:1361}],headersStr:"常用源 Conda error : PackagesNotFoundError AI 框架 Pytorch Tensorflow CUDA 查看对GPU的支持",content:"# Python 环境问题记录\n\n\n# 常用源\n\n有两种方式修改 python 源：\n\n 1. 编辑配置文件 ~/.pip/pip.conf，添加内容如下：\n    \n    [global]\n    index-url = https://pypi.doubanio.com/simple\n    trusted-host = pypi.doubanio.com\n    \n    \n    1\n    2\n    3\n    \n 2. 通过命令行的 -i 参数指定源\n    \n    pip install tensorflow -i https://pypi.douban.com/simple\n    \n    \n    1\n    \n\n\n# Conda\n\nConda 是一个开源跨平台语言无关的包管理与环境管理系统，允许用户通过虚拟环境方便地安装不同版本的二进制软件包与该计算平台需要的所有库。使用它可以方便、快捷的创建出用于科学计算、大数据等相关的一个 python 环境，例如：可以很方便的处理掉 windows 环境下 ssl 安装的问题等等.\n\n常用命令有：\n\n 1. conda env list\n 2. conda create -n [env.name] [python=3.8 | --clone exists.env.name | -f environment.xml]\n    * 可以指定 python 版本，也可以 clone 现有的环境\n 3. conda activate [env.name]\n 4. conda deactivate [env.name]\n 5. conda remove -n [env.name] --all\n 6. conda install [package(=version)]\n\n需要注意的是，在window环境下，需要使用 Anaconda Prompt 来运行相关的指令\n\n\n# error : PackagesNotFoundError\n\n有些时候，在安装 package 时，会出现这样的错误： PackagesNotFoundError: The following packages are not available from current channels:\n\n这时，可以通过以下操作尝试处理：\n\n 1. 通过命令 anaconda search -t conda pkg_name 查找 pkg 相关信息\n 2. search 指令会找到很多个版本的 pkg 相关信息，通过 anaconda show [Name] 查看详细信息，其中包括 channel 信息 c. 通过以下命令指定 channel 进行安装：conda install --channel https://xxxx [pkg_name] 或者 conda install -c https://xxxx [pkg_name]\n\n\n# AI 框架\n\n\n# Pytorch\n\n\n# Tensorflow\n\n 1. 安装\n    * 参考： https://www.tensorflow.org/install/pip?hl=zh-cn\n\n\n# CUDA\n\n\n# 查看对GPU的支持\n\n * 查看显卡信息： lspci | grep -i vga , 如果是 NVIDIA 可以用：lspci | grep -i nvidia\n * 查看NVIDIA显卡信息\n   * nvidia-smi\n     \n       Thu Feb  4 14:08:47 2021\n       +-----------------------------------------------------------------------------+\n       | NVIDIA-SMI 455.45.01    Driver Version: 455.45.01    CUDA Version: 11.1     |\n       |-------------------------------+----------------------+----------------------+\n       | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n       | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n       |                               |                      |               MIG M. |\n       |===============================+======================+======================|\n       |   0  GeForce RTX 3090    Off  | 00000000:65:00.0 Off |                  N/A |\n       | 80%   70C    P2   273W / 370W |   9957MiB / 24265MiB |    100%      Default |\n       |                               |                      |                  N/A |\n       +-------------------------------+----------------------+----------------------+\n       |   1  GeForce RTX 3090    Off  | 00000000:B3:00.0 Off |                  N/A |\n       | 57%   50C    P0   120W / 370W |      3MiB / 24268MiB |      0%      Default |\n       |                               |                      |                  N/A |\n       +-------------------------------+----------------------+----------------------+\n     \n       +-----------------------------------------------------------------------------+\n       | Processes:                                                                  |\n       |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n       |        ID   ID                                                   Usage      |\n       |=============================================================================|\n       |    0   N/A  N/A     76494      C   python                           1609MiB |\n       |    0   N/A  N/A   1848572      C   python                           8345MiB |\n       |    1   N/A  N/A     76494      C   python                              0MiB |\n       |    1   N/A  N/A   1848572      C   python                              0MiB |\n       +-----------------------------------------------------------------------------+\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     11\n     12\n     13\n     14\n     15\n     16\n     17\n     18\n     19\n     20\n     21\n     22\n     23\n     24\n     25\n     26\n     27\n     \n   * 注意，这个指令的结果会显示 CUDA Version (CUDA的版本信息)，此版本信息需要与 pytorch 的版本一致",normalizedContent:"# python 环境问题记录\n\n\n# 常用源\n\n有两种方式修改 python 源：\n\n 1. 编辑配置文件 ~/.pip/pip.conf，添加内容如下：\n    \n    [global]\n    index-url = https://pypi.doubanio.com/simple\n    trusted-host = pypi.doubanio.com\n    \n    \n    1\n    2\n    3\n    \n 2. 通过命令行的 -i 参数指定源\n    \n    pip install tensorflow -i https://pypi.douban.com/simple\n    \n    \n    1\n    \n\n\n# conda\n\nconda 是一个开源跨平台语言无关的包管理与环境管理系统，允许用户通过虚拟环境方便地安装不同版本的二进制软件包与该计算平台需要的所有库。使用它可以方便、快捷的创建出用于科学计算、大数据等相关的一个 python 环境，例如：可以很方便的处理掉 windows 环境下 ssl 安装的问题等等.\n\n常用命令有：\n\n 1. conda env list\n 2. conda create -n [env.name] [python=3.8 | --clone exists.env.name | -f environment.xml]\n    * 可以指定 python 版本，也可以 clone 现有的环境\n 3. conda activate [env.name]\n 4. conda deactivate [env.name]\n 5. conda remove -n [env.name] --all\n 6. conda install [package(=version)]\n\n需要注意的是，在window环境下，需要使用 anaconda prompt 来运行相关的指令\n\n\n# error : packagesnotfounderror\n\n有些时候，在安装 package 时，会出现这样的错误： packagesnotfounderror: the following packages are not available from current channels:\n\n这时，可以通过以下操作尝试处理：\n\n 1. 通过命令 anaconda search -t conda pkg_name 查找 pkg 相关信息\n 2. search 指令会找到很多个版本的 pkg 相关信息，通过 anaconda show [name] 查看详细信息，其中包括 channel 信息 c. 通过以下命令指定 channel 进行安装：conda install --channel https://xxxx [pkg_name] 或者 conda install -c https://xxxx [pkg_name]\n\n\n# ai 框架\n\n\n# pytorch\n\n\n# tensorflow\n\n 1. 安装\n    * 参考： https://www.tensorflow.org/install/pip?hl=zh-cn\n\n\n# cuda\n\n\n# 查看对gpu的支持\n\n * 查看显卡信息： lspci | grep -i vga , 如果是 nvidia 可以用：lspci | grep -i nvidia\n * 查看nvidia显卡信息\n   * nvidia-smi\n     \n       thu feb  4 14:08:47 2021\n       +-----------------------------------------------------------------------------+\n       | nvidia-smi 455.45.01    driver version: 455.45.01    cuda version: 11.1     |\n       |-------------------------------+----------------------+----------------------+\n       | gpu  name        persistence-m| bus-id        disp.a | volatile uncorr. ecc |\n       | fan  temp  perf  pwr:usage/cap|         memory-usage | gpu-util  compute m. |\n       |                               |                      |               mig m. |\n       |===============================+======================+======================|\n       |   0  geforce rtx 3090    off  | 00000000:65:00.0 off |                  n/a |\n       | 80%   70c    p2   273w / 370w |   9957mib / 24265mib |    100%      default |\n       |                               |                      |                  n/a |\n       +-------------------------------+----------------------+----------------------+\n       |   1  geforce rtx 3090    off  | 00000000:b3:00.0 off |                  n/a |\n       | 57%   50c    p0   120w / 370w |      3mib / 24268mib |      0%      default |\n       |                               |                      |                  n/a |\n       +-------------------------------+----------------------+----------------------+\n     \n       +-----------------------------------------------------------------------------+\n       | processes:                                                                  |\n       |  gpu   gi   ci        pid   type   process name                  gpu memory |\n       |        id   id                                                   usage      |\n       |=============================================================================|\n       |    0   n/a  n/a     76494      c   python                           1609mib |\n       |    0   n/a  n/a   1848572      c   python                           8345mib |\n       |    1   n/a  n/a     76494      c   python                              0mib |\n       |    1   n/a  n/a   1848572      c   python                              0mib |\n       +-----------------------------------------------------------------------------+\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     11\n     12\n     13\n     14\n     15\n     16\n     17\n     18\n     19\n     20\n     21\n     22\n     23\n     24\n     25\n     26\n     27\n     \n   * 注意，这个指令的结果会显示 cuda version (cuda的版本信息)，此版本信息需要与 pytorch 的版本一致",charsets:{cjk:!0}},{title:"Python 基础",frontmatter:{title:"Python 基础",date:"2021-03-30T23:29:06.000Z",categories:["blog","lang","python"],tags:[null],permalink:null},regularPath:"/blog/lang/python/utils.html",relativePath:"blog/lang/python/utils.md",key:"v-50b53767",path:"/blog/lang/python/utils.html",headers:[{level:2,title:"1. 万能函数",slug:"_1-万能函数",normalizedTitle:"1. 万能函数",charIndex:16},{level:2,title:"2. 模块",slug:"_2-模块",normalizedTitle:"2. 模块",charIndex:189},{level:2,title:"3. 语法",slug:"_3-语法",normalizedTitle:"3. 语法",charIndex:5421},{level:2,title:"4. 异步IO",slug:"_4-异步io",normalizedTitle:"4. 异步io",charIndex:5746},{level:3,title:"基础要素",slug:"基础要素",normalizedTitle:"基础要素",charIndex:5758},{level:3,title:"任务(Task)",slug:"任务-task",normalizedTitle:"任务(task)",charIndex:6433},{level:3,title:"协程返回值",slug:"协程返回值",normalizedTitle:"协程返回值",charIndex:6816},{level:3,title:"并发",slug:"并发",normalizedTitle:"并发",charIndex:7982},{level:3,title:"协程停止",slug:"协程停止",normalizedTitle:"协程停止",charIndex:8926},{level:3,title:"异步事件循环",slug:"异步事件循环",normalizedTitle:"异步事件循环",charIndex:10899},{level:3,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:11918},{level:2,title:"TO BE CONTINUE ...",slug:"to-be-continue",normalizedTitle:"to be continue ...",charIndex:12071}],headersStr:"1. 万能函数 2. 模块 3. 语法 4. 异步IO 基础要素 任务(Task) 协程返回值 并发 协程停止 异步事件循环 总结 TO BE CONTINUE ...",content:"# python 基础\n\n\n# 1. 万能函数\n\npython 中的两个万能函数：dir([pkg]) 和 help([attribute、pkg...])。\n\n之所以称之为万能，是因为可以在遇到不熟悉的 package 时，可以通过 dir() 快速查看 package 中的内容，遇到感兴趣的 attribute 时，又可以通过 help() 来打开其“说明书”。\n\n\n# 2. 模块\n\n# module\n\n * 通常模块为一个文件，直接使用import来导入就好了。可以作为module的文件类型有\".py\"、\".pyo\"、\".pyc\"、\".pyd\"、\".so\"、\".dll\"。\n * 系统在导入模块时，要做以下三件事：\n   1. 为源代码文件中定义的对象创建一个名字空间，通过这个名字空间可以访问到模块中定义的函数及变量.\n   2. 在新创建的名字空间里执行源代码文件.\n   3. 创建一个名为源代码文件的对象，该对象引用模块的名字空间，这样就可以通过这个对象访问模块中的函数及变量.\n\n# package\n\n * 通常包总是一个目录，可以使用import导入包，或者from + import来导入包中的部分模块。\n * 包目录下为首的一个文件便是__init__.py。然后是一些模块文件和子目录，假如子目录中也有__init__.py 那么它就是这个包的子包了。\n\n# 多模块导入\n\n用逗号分割可以同时导入多个模块, 也可以使用as关键字来改变模块的引用对象名字:\n\nimport socket, os, regex\nimport socket as net, thread as threads\n\n\n1\n2\n\n\n# from语句\n\n使用from语句可以将模块中的对象直接导入到当前的名字空间，from语句不创建一个到模块名字空间的引用对象，而是把被导入模块的一个或多个对象直接放入当前的名字空间:\n\n    from socket import gethostname # 将gethostname放如当前名字空间\n    print gethostname()            # 直接调用\n    socket.gethostname()           # 引发异常NameError: socket\n\n\n1\n2\n3\n\n\nfrom语句支持逗号分割的对象，也可以使用星号(*)代表模块中除下划线开头的所有对象:\n\nfrom socket import gethostname, socket\nfrom socket import *   # 载入所有对象到当前名字空间\n\n\n1\n2\n\n\n不过，如果一个模块如果定义有列表__all__，则from module import * 语句只能导入__all__列表中存在的对象。\n\n# module: foo.py\n__all__ = [ 'bar', 'spam' ]     # 定义使用 `*` 可以导入的对象\n\n\n1\n2\n\n\n另外, as 也可以和 from 联合使用:\n\nfrom socket import gethostname as hostname\nh = hostname()\n\n\n1\n2\n\n\nimport 语句可以在程序的任何位置使用，你可以在程序中多次导入同一个模块，但模块中的代码仅仅在该模块被首次导入时执行。后面的import语句只是简单的创建一个到模块名字空间的引用而已。sys.modules字典中保存着所有被导入模块的模块名到模块对象的映射。这个字典用来决定是否需要使用import语句来导入一个模块的最新拷贝.\n\nfrom module import * 语句只能用于一个模块的最顶层.\n特别注意：由于存在作用域冲突，不允许在函数中使用from 语句。\n\n# name 属性\n\n每个模块都拥有__name__ 属性，它是一个内容为模块名字的字符串。\n最顶层的模块名称是__main__ .命令行或是交互模式下程序都运行在__main__ 模块内部。\n利用__name__属性，我们可以让同一个程序在不同的场合（单独执行或被导入)具有不同的行为，象下面这样做：\n\n# 检查是单独执行还是被导入\nif __name__ == '__main__':\n    # Yes\n    statements\nelse:\n    # No (可能被作为模块导入)\n    statements \n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n# sys.path 和 sys.modules\n\nsys.path包含了module的查找路径； sys.modules包含了当前所load的所有的modules的dict（其中包含了builtin的modules）；\n\n# 模块搜索路径\n\n导入模块时,解释器会搜索sys.path列表,这个列表中保存着一系列目录。一个典型的sys.path 列表的值：\n\nLinux:\n['', '/usr/local/lib/python2.0', '/usr/local/lib/python2.0/plat-sunos5']\nWindows:\n['', 'C:\\\\Python24\\\\DLLs', 'C:\\\\Python24\\\\lib', 'C:\\\\Python24\\\\lib\\\\plat-win', 'C:\\\\Python24\\\\lib\\\\lib-tk']\n\n\n1\n2\n3\n4\n\n\n空字符串 代表当前目录. 要加入新的搜索路径,只需要将这个路径加入到这个列表.\n\n有些时候我们需要给 python interpreter 增加一些包的查找路径，如：想引用自定义的包时。这就需要修改包的搜索路径，一般来说，有两种方式：\n\n 1. 直接在运行时，修改 sys.path\n 2. 在开始运行前，修改 PYTHONPATH 环境变量（这个环境变量会在运行时被包含进 sys.path 以参与模块搜索）\n\n# 模块导入和汇编\n\n到现在为止，本章介绍的模块都是包含Python源代码的文本文件. 不过模块不限于此，可以被 import 语句导入的模块共有以下四类:\n\n * 使用Python写的程序( .py文件)\n * C或C++扩展(已编译为共享库或DLL文件)\n * 包(包含多个模块)\n * 内建模块(使用C编写并已链接到Python解释器内)\n\n当查询模块 foo 时,解释器按照 sys.path 列表中目录顺序来查找以下文件(目录也是文件的一种):\n\n 1. 定义为一个包的目录 foo\n 2. foo.so, foomodule.so, foomodule.sl,或 foomodule.dll (已编译扩展)\n 3. foo.pyo (只在使用 -O 或 -OO 选项时)\n 4. foo.pyc\n 5. foo.py\n\n如果在sys.path提供的所有路径均查找失败，解释器会继续在内建模块中寻找,如果再次失败，则引发 ImportError 异常.\n\n当 import 语句搜索文件时,文件名是大小写敏感的。即使在文件系统大小写不敏感的系统上也是如此(Windows等). 这样, import foo 只会导入文件foo.py而不会是FOO.PY.\n\n# 对于.py文件\n\n * 当一个模块第一次被导入时,它就被汇编为字节代码,并写入一个同名的 .pyc文件.\n * 后来的导入操作会直接读取.pyc文件而不是.py文件.(除非.py文件的修改日期更新,这种情况会重新生成.pyc文件)\n * 在解释器使用 -O 选项时，扩展名为.pyo的同名文件被使用.\n * pyo文件的内容虽去掉行号,断言,及其他调试信息的字节码，体积更小,运行速度更快.\n * 如果使用-OO选项代替-O,则文档字符串也会在创建.pyo文件时也被忽略.\n * .pyc和.pyo文件的汇编,当且仅当import 语句执行时进行.\n\n# 重新导入模块\n\n如果更新了一个已经用import语句导入的模块，内建函数reload()可以重新导入并运行更新后的模块代码.它需要一个模块对象做为参数.例如:\n\nimport foo\n... some code ...\nreload(foo)          # 重新导入 foo\n\n\n1\n2\n3\n\n\n在reload()运行之后的针对模块的操作都会使用新导入代码，不过reload()并不会更新使用旧模块创建的对象，因此有可能出现新旧版本对象共存的情况。\n注意： 使用C或C++编译的模块不能通过 reload() 函数来重新导入。记住一个原则，除非是在调试和开发过程中，否则不要使用reload()函数.\n\n# 二包\n\n多个关系密切的模块应该组织成一个包，以便于维护和使用。这项技术能有效避免名字空间冲突。创建一个名字为包名字的文件夹并在该文件夹下创建一个__init__.py 文件就定义了一个包。你可以根据需要在该文件夹下存放资源文件、已编译扩展及子包。举例来说，一个包可能有以下结构:\n\nGraphics/\n      __init__.py\n      Primitive/\n         __init__.py\n         lines.py\n         fill.py\n         text.py\n         ...\n      Graph2d/\n         __init__.py\n         plot2d.py\n         ...\n      Graph3d/\n         __init__.py\n         plot3d.py\n         ...\n      Formats/\n         __init__.py\n         gif.py\n         png.py\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\nimport语句使用以下几种方式导入包中的模块:\n\n * import Graphics.Primitive.fill 导入模块Graphics.Primitive.fill,只能以全名访问模块属性,例如 Graphics.Primitive.fill.floodfill(img,x,y,color).\n * from Graphics.Primitive import fill 导入模块fill ,只能以 fill.属性名这种方式访问模块属性,例如 fill.floodfill(img,x,y,color).\n * from Graphics.Primitive.fill import floodfill 导入模块fill ,并将函数floodfill放入当前名称空间,直接访问被导入的属性，例如 floodfill(img,x,y,color).\n\n无论一个包的哪个部分被导入, 在文件__init__.py中的代码都会运行.这个文件的内容允许为空,不过通常情况下它用来存放包的初始化代码。导入过程遇到的所有__init__.py文件都被运行.因此 import Graphics.Primitive.fill 语句会顺序运行 Graphics 和 Primitive 文件夹下的__init__.py文件.\n\n下边这个语句具有歧义: from Graphics.Primitive import * 这个语句的原意图是想将Graphics.Primitive包下的所有模块导入到当前的名称空间.然而,由于不同平台间文件名规则不同(比如大小写敏感问题), Python不能正确判定哪些模块要被导入.这个语句只会顺序运行 Graphics 和 Primitive 文件夹下的__init__.py文件. 要解决这个问题，应该在Primitive文件夹下面的__init__.py中定义一个名字all的列表，例如:\n\n# Graphics/Primitive/__init__.py\n__all__ = [\"lines\",\"text\",\"fill\",...]\n\n\n1\n2\n\n\n这样,上边的语句就可以导入列表中所有模块.\n\n下面这个语句只会执行Graphics目录下的__init__.py文件，而不会导入任何模块:\n\nimport Graphics\nGraphics.Primitive.fill.floodfill(img,x,y,color)  # 失败!\n\n\n1\n2\n\n\n不过既然 import Graphics 语句会运行 Graphics 目录下的__init__.py文件,我们就可以采取下面的手段来解决这个问题：\n\n# Graphics/__init__.py\nimport Primitive, Graph2d, Graph3d\n# Graphics/Primitive/__init__.py\nimport lines, fill, text, ...\n\n\n1\n2\n3\n4\n\n\n这样import Graphics语句就可以导入所有的子模块(只能用全名来访问这些模块的属性).\n\n\n# 3. 语法\n\n# Decorator\n\n@dec2\n@dec1\ndef func(arg1, arg2, ...):\n    pass\nThis is equivalent to:\n\ndef func(arg1, arg2, ...):\n    pass\nfunc = dec2(dec1(func))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n@decomaker(argA, argB, ...)\ndef func(arg1, arg2, ...):\n    pass\n \nThis is equivalent to:\n\nfunc = decomaker(argA, argB, ...)(func)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 4. 异步IO\n\n\n# 基础要素\n\nPython在3.4中引入了协程的概念，这个是以生成器对象为基础，3.5则确定了协程的语法。实现协程的不仅仅是asyncio，tornado和gevent都实现了类似的功能。\n\nasyncio 的几个主要元素有：\n\n 1. event_loop\n    1. 程序开启一个无限的事件循环，并依次执行满足条件的协程函数\n 2. coroutine\n    1. 协程对象，由关键字 async 定义的函数在被调用时不会立即执行，而是返回一个协程对象。协程对象需要通过注册动作交由事件循环来调用。\n 3. task\n    1. 任务，是对协程的进一步封装，其中包含了任务的各种状态。\n 4. future\n    1. 代表将要执行或没被执行的任务的结果。\n    2. task 对象是 Future 类的子类\n 5. async/await\n    1. python3.5 中用于定义协程的关键字，async定义一个协程，await用于挂起(阻塞的)异步调用。\n\n例如：\n\nimport asyncio\n\nasync def work(args):\n    print('i am working : {}'.format(x))\n\ncoroutine = work(\"new job\")\nloop = asyncio.get_event_loop() # 创建一个事件循环\nloop.run_until_complete(coroutine) # 将协程注册到事件循环，并启动事件循环\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 任务(Task)\n\n通过上边的示例，可以发现 coroutine 不能直接执行，而是需要通过 loop.run_until_complete() 来执行，这里边的隐含动作是：将协程包装成为了一个 task 对象，并在事件循环中执行。为什么？\n\nloop.run_until_complete() 的参数是一个 futrue 对象，但真正动作是执行注册到事件循环上的 coroutines。如上文提到的，task 是对 coroutine 的封装，同时也是 Future 类的子类。所以，当传入一个协程时，函数内部会自动封装成 task 以满足调用需要。\n\n当然，我们也可以主动构造 task 对象: asyncio.ensure_future(coroutine) 和 loop.create_task(coroutine) 都可以创建一个task 对象。\n\n\n# 协程返回值\n\n 1. task.add_done_callback\n\n通过 task.add_done_callback(callback) 可以对 task 绑定回调函数，在 coroutine 执行结束时候会调用这个回调函数。\n\nimport asyncio\n\nasync def work(args):\n    return 'i am working : {}'.format(args)\n\ndef callback(future):\n    print('callback: {}'.format(future.result()))\n\ncoroutine = work(\"new job\")\nloop = asyncio.get_event_loop()\ntask = asyncio.ensure_future(coroutine)\ntask.add_done_callback(callback)\nloop.run_until_complete(task)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n这里可以看到，callback 的参数是一个 future 对象，如果想传递其他数据到 callback，可以通过以下方式：\n\ndef callback(t, future):\n    print('callback:', t, future.result())\n\ntask.add_done_callback(functools.partial(callback, 1))\n\n\n1\n2\n3\n4\n\n\n此外，如果在调试过程中观察 task 和 其回调里的 future 的话，可以发现它们实际上是同一个对象。\n\n 2. future.result()\n\n上边的例子我们可以知道，运行结果实际上是可以通过 future.result() 来取得。而回调里的 futrue 和 创建的 task 是同一个对象，那我们是不是可以在任务执行结束后，主动调用 task.result() 来获取结果呢？当然可以。\n\nimport asyncio\n\nasync def work(args):\n    return 'i am working : {}'.format(args)\n\ncoroutine = work(\"new job\")\nloop = asyncio.get_event_loop()\ntask = asyncio.ensure_future(coroutine)\nloop.run_until_complete(task)\n\nprint('task result is {}'.format(task.result()))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 并发\n\n首先，要明白 并发和并行 是不一样的：并发指有多个任务需要同时进行(如，单核cpu通过时间片轮转运行不同的程序)，并行则是同一时刻有多个任务执行(多核cpu的每个核心在同一个时刻独立运行不同的程序)。\n\nasyncio 通过 事件循环和await/async 来协调多个协程来实现并发。每当有任务阻塞的时候就 await，然后其他协程继续工作。\n\nimport time\nimport asyncio\n\nasync def work(sleep_sec):\n    print('sleep {} : before'.format(sleep_sec))\n    await asyncio.sleep(sleep_sec)\n    return 'sleep {} : after'.format(sleep_sec)\n\nnow = lambda: time.time()\n\ncoroutine1 = work(1)\ncoroutine2 = work(2)\ncoroutine3 = work(4)\ntasks = [\n    asyncio.ensure_future(coroutine1),\n    asyncio.ensure_future(coroutine2),\n    asyncio.ensure_future(coroutine3)\n]\nloop = asyncio.get_event_loop()\n# 使用 syncio.wait(tasks) 或 asyncio.gather(*tasks) 来汇集多任务\nloop.run_until_complete(asyncio.wait(tasks))\n\nfor task in tasks:\n    print('task result is {}'.format(task.result()))\nprint('spend {} seconds'.format(now() - start))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n我们可以观察上例中的各个任务的执行时机和总耗时来确认并发现象。\n\n\n# 协程停止\n\n如果需要停止事件循环，就需要先把task取消。先看例子：\n\nimport time\nimport asyncio\n\nasync def work(sleep_sec):\n    print('sleep {} : before'.format(sleep_sec))\n    await asyncio.sleep(sleep_sec)\n    return 'sleep {} : after'.format(sleep_sec)\n\ncoroutine1 = work(1)\ncoroutine2 = work(2)\ncoroutine3 = work(4)\ntasks = [\n    asyncio.ensure_future(coroutine1),\n    asyncio.ensure_future(coroutine2),\n    asyncio.ensure_future(coroutine3)\n]\nloop = asyncio.get_event_loop()\ntry:\n    loop.run_until_complete(asyncio.wait(tasks))\nexcept KeyboardInterrupt as e:\n    print(asyncio.Task.all_tasks())\n    for task in asyncio.Task.all_tasks():\n        print(task.cancel())\n    loop.stop()\n    loop.run_forever()\nfinally:\n    loop.close()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n启动事件循环之后，马上ctrl+c，会触发run_until_complete的执行异常 KeyBorardInterrupt。然后通过循环asyncio.Task获取获取事件循环的task通过其 task.cancel() 取消future。注意，loop.stop()之后还需要再次开启事件循环，最后再close，不然还会抛出异常。\n\n我们还可以通过下边这种方式停止协程：\n\nimport time\nimport asyncio\n\nasync def work(sleep_sec):\n    print('sleep {} : before'.format(sleep_sec))\n    await asyncio.sleep(sleep_sec)\n    return 'sleep {} : after'.format(sleep_sec)\n\nasync def main():\n    coroutine1 = work(1)\n    coroutine2 = work(2)\n    coroutine3 = work(2)\n    tasks = [\n        asyncio.ensure_future(coroutine1),\n        asyncio.ensure_future(coroutine2),\n        asyncio.ensure_future(coroutine3)\n    ]\n    done, pending = await asyncio.wait(tasks)\n    for task in done:\n        print('task result is {}'.format(task.result()))\n\nloop = asyncio.get_event_loop()\ntask = asyncio.ensure_future(main())\ntry:\n    loop.run_until_complete(task)\nexcept KeyboardInterrupt as e:\n    print(asyncio.Task.all_tasks())\n    print(asyncio.gather(*asyncio.Task.all_tasks()).cancel())\n    loop.stop()\n    loop.run_forever()\nfinally:\n    loop.close()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n简单的说，就是通过协程嵌套，将一系列协程封装到另一个协程中，此时处理外层包装的 main 函数即可。\n\n\n# 异步事件循环\n\n除了在主线程运行事件循环，还可以在子线程中运行。在子线程中运行事件循环的好处，显而易见，不会阻塞主线程，但也带来了异步处理的问题。\n\n通过以下示例，细细品味下子线程的事件循环吧：\n\nfrom threading import Thread\n\ndef start_loop(loop):\n    asyncio.set_event_loop(loop)\n    loop.run_forever()\n\nasync def work(sleep_sec):\n    print('work: sleep {} : before'.format(sleep_sec))\n    await asyncio.sleep(sleep_sec)\n    return 'work: sleep {} : after'.format(sleep_sec)\n\ndef more_work(sleep_sec):\n    print('more_work: sleep {}:before'.format(sleep_sec))\n    time.sleep(sleep_sec)\n    print('more_work: sleep {}:after'.format(sleep_sec))\n\nnew_loop = asyncio.new_event_loop()\nt = Thread(target=start_loop, args=(new_loop,))\nt.start()\n\n# 新线程中会按照顺序执行通过 call_soon_threadsafe 注册的方法\nnew_loop.call_soon_threadsafe(more_work, 6)\nnew_loop.call_soon_threadsafe(more_work, 3)\n\n# 通过 run_coroutine_threadsafe 注册新协程对象，这样可以让子线程中的事件循环的并发的处理协程\nasyncio.run_coroutine_threadsafe(work(6), new_loop)\nasyncio.run_coroutine_threadsafe(work(4), new_loop)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n\n# 总结\n\n这里简单的介绍了 asyncio 的基础元素：事件循环，协程，future和任务。通过这些基础内容的组合，我们可以实现出更多更有意思的异步、并发任务，比如：生产者消费者模型... 更多用法亟待被开发出来。\n\n----------------------------------------\n\n\n# TO BE CONTINUE ...",normalizedContent:"# python 基础\n\n\n# 1. 万能函数\n\npython 中的两个万能函数：dir([pkg]) 和 help([attribute、pkg...])。\n\n之所以称之为万能，是因为可以在遇到不熟悉的 package 时，可以通过 dir() 快速查看 package 中的内容，遇到感兴趣的 attribute 时，又可以通过 help() 来打开其“说明书”。\n\n\n# 2. 模块\n\n# module\n\n * 通常模块为一个文件，直接使用import来导入就好了。可以作为module的文件类型有\".py\"、\".pyo\"、\".pyc\"、\".pyd\"、\".so\"、\".dll\"。\n * 系统在导入模块时，要做以下三件事：\n   1. 为源代码文件中定义的对象创建一个名字空间，通过这个名字空间可以访问到模块中定义的函数及变量.\n   2. 在新创建的名字空间里执行源代码文件.\n   3. 创建一个名为源代码文件的对象，该对象引用模块的名字空间，这样就可以通过这个对象访问模块中的函数及变量.\n\n# package\n\n * 通常包总是一个目录，可以使用import导入包，或者from + import来导入包中的部分模块。\n * 包目录下为首的一个文件便是__init__.py。然后是一些模块文件和子目录，假如子目录中也有__init__.py 那么它就是这个包的子包了。\n\n# 多模块导入\n\n用逗号分割可以同时导入多个模块, 也可以使用as关键字来改变模块的引用对象名字:\n\nimport socket, os, regex\nimport socket as net, thread as threads\n\n\n1\n2\n\n\n# from语句\n\n使用from语句可以将模块中的对象直接导入到当前的名字空间，from语句不创建一个到模块名字空间的引用对象，而是把被导入模块的一个或多个对象直接放入当前的名字空间:\n\n    from socket import gethostname # 将gethostname放如当前名字空间\n    print gethostname()            # 直接调用\n    socket.gethostname()           # 引发异常nameerror: socket\n\n\n1\n2\n3\n\n\nfrom语句支持逗号分割的对象，也可以使用星号(*)代表模块中除下划线开头的所有对象:\n\nfrom socket import gethostname, socket\nfrom socket import *   # 载入所有对象到当前名字空间\n\n\n1\n2\n\n\n不过，如果一个模块如果定义有列表__all__，则from module import * 语句只能导入__all__列表中存在的对象。\n\n# module: foo.py\n__all__ = [ 'bar', 'spam' ]     # 定义使用 `*` 可以导入的对象\n\n\n1\n2\n\n\n另外, as 也可以和 from 联合使用:\n\nfrom socket import gethostname as hostname\nh = hostname()\n\n\n1\n2\n\n\nimport 语句可以在程序的任何位置使用，你可以在程序中多次导入同一个模块，但模块中的代码仅仅在该模块被首次导入时执行。后面的import语句只是简单的创建一个到模块名字空间的引用而已。sys.modules字典中保存着所有被导入模块的模块名到模块对象的映射。这个字典用来决定是否需要使用import语句来导入一个模块的最新拷贝.\n\nfrom module import * 语句只能用于一个模块的最顶层.\n特别注意：由于存在作用域冲突，不允许在函数中使用from 语句。\n\n# name 属性\n\n每个模块都拥有__name__ 属性，它是一个内容为模块名字的字符串。\n最顶层的模块名称是__main__ .命令行或是交互模式下程序都运行在__main__ 模块内部。\n利用__name__属性，我们可以让同一个程序在不同的场合（单独执行或被导入)具有不同的行为，象下面这样做：\n\n# 检查是单独执行还是被导入\nif __name__ == '__main__':\n    # yes\n    statements\nelse:\n    # no (可能被作为模块导入)\n    statements \n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n# sys.path 和 sys.modules\n\nsys.path包含了module的查找路径； sys.modules包含了当前所load的所有的modules的dict（其中包含了builtin的modules）；\n\n# 模块搜索路径\n\n导入模块时,解释器会搜索sys.path列表,这个列表中保存着一系列目录。一个典型的sys.path 列表的值：\n\nlinux:\n['', '/usr/local/lib/python2.0', '/usr/local/lib/python2.0/plat-sunos5']\nwindows:\n['', 'c:\\\\python24\\\\dlls', 'c:\\\\python24\\\\lib', 'c:\\\\python24\\\\lib\\\\plat-win', 'c:\\\\python24\\\\lib\\\\lib-tk']\n\n\n1\n2\n3\n4\n\n\n空字符串 代表当前目录. 要加入新的搜索路径,只需要将这个路径加入到这个列表.\n\n有些时候我们需要给 python interpreter 增加一些包的查找路径，如：想引用自定义的包时。这就需要修改包的搜索路径，一般来说，有两种方式：\n\n 1. 直接在运行时，修改 sys.path\n 2. 在开始运行前，修改 pythonpath 环境变量（这个环境变量会在运行时被包含进 sys.path 以参与模块搜索）\n\n# 模块导入和汇编\n\n到现在为止，本章介绍的模块都是包含python源代码的文本文件. 不过模块不限于此，可以被 import 语句导入的模块共有以下四类:\n\n * 使用python写的程序( .py文件)\n * c或c++扩展(已编译为共享库或dll文件)\n * 包(包含多个模块)\n * 内建模块(使用c编写并已链接到python解释器内)\n\n当查询模块 foo 时,解释器按照 sys.path 列表中目录顺序来查找以下文件(目录也是文件的一种):\n\n 1. 定义为一个包的目录 foo\n 2. foo.so, foomodule.so, foomodule.sl,或 foomodule.dll (已编译扩展)\n 3. foo.pyo (只在使用 -o 或 -oo 选项时)\n 4. foo.pyc\n 5. foo.py\n\n如果在sys.path提供的所有路径均查找失败，解释器会继续在内建模块中寻找,如果再次失败，则引发 importerror 异常.\n\n当 import 语句搜索文件时,文件名是大小写敏感的。即使在文件系统大小写不敏感的系统上也是如此(windows等). 这样, import foo 只会导入文件foo.py而不会是foo.py.\n\n# 对于.py文件\n\n * 当一个模块第一次被导入时,它就被汇编为字节代码,并写入一个同名的 .pyc文件.\n * 后来的导入操作会直接读取.pyc文件而不是.py文件.(除非.py文件的修改日期更新,这种情况会重新生成.pyc文件)\n * 在解释器使用 -o 选项时，扩展名为.pyo的同名文件被使用.\n * pyo文件的内容虽去掉行号,断言,及其他调试信息的字节码，体积更小,运行速度更快.\n * 如果使用-oo选项代替-o,则文档字符串也会在创建.pyo文件时也被忽略.\n * .pyc和.pyo文件的汇编,当且仅当import 语句执行时进行.\n\n# 重新导入模块\n\n如果更新了一个已经用import语句导入的模块，内建函数reload()可以重新导入并运行更新后的模块代码.它需要一个模块对象做为参数.例如:\n\nimport foo\n... some code ...\nreload(foo)          # 重新导入 foo\n\n\n1\n2\n3\n\n\n在reload()运行之后的针对模块的操作都会使用新导入代码，不过reload()并不会更新使用旧模块创建的对象，因此有可能出现新旧版本对象共存的情况。\n注意： 使用c或c++编译的模块不能通过 reload() 函数来重新导入。记住一个原则，除非是在调试和开发过程中，否则不要使用reload()函数.\n\n# 二包\n\n多个关系密切的模块应该组织成一个包，以便于维护和使用。这项技术能有效避免名字空间冲突。创建一个名字为包名字的文件夹并在该文件夹下创建一个__init__.py 文件就定义了一个包。你可以根据需要在该文件夹下存放资源文件、已编译扩展及子包。举例来说，一个包可能有以下结构:\n\ngraphics/\n      __init__.py\n      primitive/\n         __init__.py\n         lines.py\n         fill.py\n         text.py\n         ...\n      graph2d/\n         __init__.py\n         plot2d.py\n         ...\n      graph3d/\n         __init__.py\n         plot3d.py\n         ...\n      formats/\n         __init__.py\n         gif.py\n         png.py\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\nimport语句使用以下几种方式导入包中的模块:\n\n * import graphics.primitive.fill 导入模块graphics.primitive.fill,只能以全名访问模块属性,例如 graphics.primitive.fill.floodfill(img,x,y,color).\n * from graphics.primitive import fill 导入模块fill ,只能以 fill.属性名这种方式访问模块属性,例如 fill.floodfill(img,x,y,color).\n * from graphics.primitive.fill import floodfill 导入模块fill ,并将函数floodfill放入当前名称空间,直接访问被导入的属性，例如 floodfill(img,x,y,color).\n\n无论一个包的哪个部分被导入, 在文件__init__.py中的代码都会运行.这个文件的内容允许为空,不过通常情况下它用来存放包的初始化代码。导入过程遇到的所有__init__.py文件都被运行.因此 import graphics.primitive.fill 语句会顺序运行 graphics 和 primitive 文件夹下的__init__.py文件.\n\n下边这个语句具有歧义: from graphics.primitive import * 这个语句的原意图是想将graphics.primitive包下的所有模块导入到当前的名称空间.然而,由于不同平台间文件名规则不同(比如大小写敏感问题), python不能正确判定哪些模块要被导入.这个语句只会顺序运行 graphics 和 primitive 文件夹下的__init__.py文件. 要解决这个问题，应该在primitive文件夹下面的__init__.py中定义一个名字all的列表，例如:\n\n# graphics/primitive/__init__.py\n__all__ = [\"lines\",\"text\",\"fill\",...]\n\n\n1\n2\n\n\n这样,上边的语句就可以导入列表中所有模块.\n\n下面这个语句只会执行graphics目录下的__init__.py文件，而不会导入任何模块:\n\nimport graphics\ngraphics.primitive.fill.floodfill(img,x,y,color)  # 失败!\n\n\n1\n2\n\n\n不过既然 import graphics 语句会运行 graphics 目录下的__init__.py文件,我们就可以采取下面的手段来解决这个问题：\n\n# graphics/__init__.py\nimport primitive, graph2d, graph3d\n# graphics/primitive/__init__.py\nimport lines, fill, text, ...\n\n\n1\n2\n3\n4\n\n\n这样import graphics语句就可以导入所有的子模块(只能用全名来访问这些模块的属性).\n\n\n# 3. 语法\n\n# decorator\n\n@dec2\n@dec1\ndef func(arg1, arg2, ...):\n    pass\nthis is equivalent to:\n\ndef func(arg1, arg2, ...):\n    pass\nfunc = dec2(dec1(func))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n@decomaker(arga, argb, ...)\ndef func(arg1, arg2, ...):\n    pass\n \nthis is equivalent to:\n\nfunc = decomaker(arga, argb, ...)(func)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 4. 异步io\n\n\n# 基础要素\n\npython在3.4中引入了协程的概念，这个是以生成器对象为基础，3.5则确定了协程的语法。实现协程的不仅仅是asyncio，tornado和gevent都实现了类似的功能。\n\nasyncio 的几个主要元素有：\n\n 1. event_loop\n    1. 程序开启一个无限的事件循环，并依次执行满足条件的协程函数\n 2. coroutine\n    1. 协程对象，由关键字 async 定义的函数在被调用时不会立即执行，而是返回一个协程对象。协程对象需要通过注册动作交由事件循环来调用。\n 3. task\n    1. 任务，是对协程的进一步封装，其中包含了任务的各种状态。\n 4. future\n    1. 代表将要执行或没被执行的任务的结果。\n    2. task 对象是 future 类的子类\n 5. async/await\n    1. python3.5 中用于定义协程的关键字，async定义一个协程，await用于挂起(阻塞的)异步调用。\n\n例如：\n\nimport asyncio\n\nasync def work(args):\n    print('i am working : {}'.format(x))\n\ncoroutine = work(\"new job\")\nloop = asyncio.get_event_loop() # 创建一个事件循环\nloop.run_until_complete(coroutine) # 将协程注册到事件循环，并启动事件循环\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 任务(task)\n\n通过上边的示例，可以发现 coroutine 不能直接执行，而是需要通过 loop.run_until_complete() 来执行，这里边的隐含动作是：将协程包装成为了一个 task 对象，并在事件循环中执行。为什么？\n\nloop.run_until_complete() 的参数是一个 futrue 对象，但真正动作是执行注册到事件循环上的 coroutines。如上文提到的，task 是对 coroutine 的封装，同时也是 future 类的子类。所以，当传入一个协程时，函数内部会自动封装成 task 以满足调用需要。\n\n当然，我们也可以主动构造 task 对象: asyncio.ensure_future(coroutine) 和 loop.create_task(coroutine) 都可以创建一个task 对象。\n\n\n# 协程返回值\n\n 1. task.add_done_callback\n\n通过 task.add_done_callback(callback) 可以对 task 绑定回调函数，在 coroutine 执行结束时候会调用这个回调函数。\n\nimport asyncio\n\nasync def work(args):\n    return 'i am working : {}'.format(args)\n\ndef callback(future):\n    print('callback: {}'.format(future.result()))\n\ncoroutine = work(\"new job\")\nloop = asyncio.get_event_loop()\ntask = asyncio.ensure_future(coroutine)\ntask.add_done_callback(callback)\nloop.run_until_complete(task)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n这里可以看到，callback 的参数是一个 future 对象，如果想传递其他数据到 callback，可以通过以下方式：\n\ndef callback(t, future):\n    print('callback:', t, future.result())\n\ntask.add_done_callback(functools.partial(callback, 1))\n\n\n1\n2\n3\n4\n\n\n此外，如果在调试过程中观察 task 和 其回调里的 future 的话，可以发现它们实际上是同一个对象。\n\n 2. future.result()\n\n上边的例子我们可以知道，运行结果实际上是可以通过 future.result() 来取得。而回调里的 futrue 和 创建的 task 是同一个对象，那我们是不是可以在任务执行结束后，主动调用 task.result() 来获取结果呢？当然可以。\n\nimport asyncio\n\nasync def work(args):\n    return 'i am working : {}'.format(args)\n\ncoroutine = work(\"new job\")\nloop = asyncio.get_event_loop()\ntask = asyncio.ensure_future(coroutine)\nloop.run_until_complete(task)\n\nprint('task result is {}'.format(task.result()))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 并发\n\n首先，要明白 并发和并行 是不一样的：并发指有多个任务需要同时进行(如，单核cpu通过时间片轮转运行不同的程序)，并行则是同一时刻有多个任务执行(多核cpu的每个核心在同一个时刻独立运行不同的程序)。\n\nasyncio 通过 事件循环和await/async 来协调多个协程来实现并发。每当有任务阻塞的时候就 await，然后其他协程继续工作。\n\nimport time\nimport asyncio\n\nasync def work(sleep_sec):\n    print('sleep {} : before'.format(sleep_sec))\n    await asyncio.sleep(sleep_sec)\n    return 'sleep {} : after'.format(sleep_sec)\n\nnow = lambda: time.time()\n\ncoroutine1 = work(1)\ncoroutine2 = work(2)\ncoroutine3 = work(4)\ntasks = [\n    asyncio.ensure_future(coroutine1),\n    asyncio.ensure_future(coroutine2),\n    asyncio.ensure_future(coroutine3)\n]\nloop = asyncio.get_event_loop()\n# 使用 syncio.wait(tasks) 或 asyncio.gather(*tasks) 来汇集多任务\nloop.run_until_complete(asyncio.wait(tasks))\n\nfor task in tasks:\n    print('task result is {}'.format(task.result()))\nprint('spend {} seconds'.format(now() - start))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n我们可以观察上例中的各个任务的执行时机和总耗时来确认并发现象。\n\n\n# 协程停止\n\n如果需要停止事件循环，就需要先把task取消。先看例子：\n\nimport time\nimport asyncio\n\nasync def work(sleep_sec):\n    print('sleep {} : before'.format(sleep_sec))\n    await asyncio.sleep(sleep_sec)\n    return 'sleep {} : after'.format(sleep_sec)\n\ncoroutine1 = work(1)\ncoroutine2 = work(2)\ncoroutine3 = work(4)\ntasks = [\n    asyncio.ensure_future(coroutine1),\n    asyncio.ensure_future(coroutine2),\n    asyncio.ensure_future(coroutine3)\n]\nloop = asyncio.get_event_loop()\ntry:\n    loop.run_until_complete(asyncio.wait(tasks))\nexcept keyboardinterrupt as e:\n    print(asyncio.task.all_tasks())\n    for task in asyncio.task.all_tasks():\n        print(task.cancel())\n    loop.stop()\n    loop.run_forever()\nfinally:\n    loop.close()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n启动事件循环之后，马上ctrl+c，会触发run_until_complete的执行异常 keyborardinterrupt。然后通过循环asyncio.task获取获取事件循环的task通过其 task.cancel() 取消future。注意，loop.stop()之后还需要再次开启事件循环，最后再close，不然还会抛出异常。\n\n我们还可以通过下边这种方式停止协程：\n\nimport time\nimport asyncio\n\nasync def work(sleep_sec):\n    print('sleep {} : before'.format(sleep_sec))\n    await asyncio.sleep(sleep_sec)\n    return 'sleep {} : after'.format(sleep_sec)\n\nasync def main():\n    coroutine1 = work(1)\n    coroutine2 = work(2)\n    coroutine3 = work(2)\n    tasks = [\n        asyncio.ensure_future(coroutine1),\n        asyncio.ensure_future(coroutine2),\n        asyncio.ensure_future(coroutine3)\n    ]\n    done, pending = await asyncio.wait(tasks)\n    for task in done:\n        print('task result is {}'.format(task.result()))\n\nloop = asyncio.get_event_loop()\ntask = asyncio.ensure_future(main())\ntry:\n    loop.run_until_complete(task)\nexcept keyboardinterrupt as e:\n    print(asyncio.task.all_tasks())\n    print(asyncio.gather(*asyncio.task.all_tasks()).cancel())\n    loop.stop()\n    loop.run_forever()\nfinally:\n    loop.close()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n简单的说，就是通过协程嵌套，将一系列协程封装到另一个协程中，此时处理外层包装的 main 函数即可。\n\n\n# 异步事件循环\n\n除了在主线程运行事件循环，还可以在子线程中运行。在子线程中运行事件循环的好处，显而易见，不会阻塞主线程，但也带来了异步处理的问题。\n\n通过以下示例，细细品味下子线程的事件循环吧：\n\nfrom threading import thread\n\ndef start_loop(loop):\n    asyncio.set_event_loop(loop)\n    loop.run_forever()\n\nasync def work(sleep_sec):\n    print('work: sleep {} : before'.format(sleep_sec))\n    await asyncio.sleep(sleep_sec)\n    return 'work: sleep {} : after'.format(sleep_sec)\n\ndef more_work(sleep_sec):\n    print('more_work: sleep {}:before'.format(sleep_sec))\n    time.sleep(sleep_sec)\n    print('more_work: sleep {}:after'.format(sleep_sec))\n\nnew_loop = asyncio.new_event_loop()\nt = thread(target=start_loop, args=(new_loop,))\nt.start()\n\n# 新线程中会按照顺序执行通过 call_soon_threadsafe 注册的方法\nnew_loop.call_soon_threadsafe(more_work, 6)\nnew_loop.call_soon_threadsafe(more_work, 3)\n\n# 通过 run_coroutine_threadsafe 注册新协程对象，这样可以让子线程中的事件循环的并发的处理协程\nasyncio.run_coroutine_threadsafe(work(6), new_loop)\nasyncio.run_coroutine_threadsafe(work(4), new_loop)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n\n# 总结\n\n这里简单的介绍了 asyncio 的基础元素：事件循环，协程，future和任务。通过这些基础内容的组合，我们可以实现出更多更有意思的异步、并发任务，比如：生产者消费者模型... 更多用法亟待被开发出来。\n\n----------------------------------------\n\n\n# to be continue ...",charsets:{cjk:!0}},{title:"Network 目录",frontmatter:{published:!0,title:"Network 目录",description:"网络基础知识汇总",keywords:[""],categories:["network"],permalink:"/blog/network/",date:"2020-04-13T00:00:00.000Z",tags:[null]},regularPath:"/blog/network/",relativePath:"blog/network/README.md",key:"v-718753e8",path:"/blog/network/",headers:[{level:2,title:"二、 Http2",slug:"二、-http2",normalizedTitle:"二、 http2",charIndex:31},{level:2,title:"三、 Grpc",slug:"三、-grpc",normalizedTitle:"三、 grpc",charIndex:76}],headersStr:"二、 Http2 三、 Grpc",content:"# NETWORK 目录\n\n * Tcpip思维导图\n\n\n# 二、 Http2\n\n * Http/2.0 And Http/2.0 In Go\n\n\n# 三、 Grpc\n\n * Grpc Interceptor With Go\n\n * Grpc Source Notes\n\n * Grpc Over Http2\n\n * Grpc Connectivity Semantics And Api\n\n * Tcp 与 Udp 对比",normalizedContent:"# network 目录\n\n * tcpip思维导图\n\n\n# 二、 http2\n\n * http/2.0 and http/2.0 in go\n\n\n# 三、 grpc\n\n * grpc interceptor with go\n\n * grpc source notes\n\n * grpc over http2\n\n * grpc connectivity semantics and api\n\n * tcp 与 udp 对比",charsets:{cjk:!0}},{title:"gRPC Connectivity Semantics and API",frontmatter:{title:"gRPC Connectivity Semantics and API",date:"2020-04-13T00:00:00.000Z",lastmod:null,description:"gRPC Connectivity Semantics and API",categories:["network","grpc"],tags:[null],permalink:null},regularPath:"/blog/network/grpc/grpc_connectivity_semantics_and_api.html",relativePath:"blog/network/grpc/grpc_connectivity_semantics_and_api.md",key:"v-570d3d9f",path:"/blog/network/grpc/grpc_connectivity_semantics_and_api.html",headers:[{level:2,title:"States of Connectivity",slug:"states-of-connectivity",normalizedTitle:"states of connectivity",charIndex:173},{level:3,title:"CONNECTING:",slug:"connecting",normalizedTitle:"connecting:",charIndex:506},{level:3,title:"READY:",slug:"ready",normalizedTitle:"ready:",charIndex:616},{level:3,title:"TRANSIENT_FAILURE:",slug:"transient-failure",normalizedTitle:"transient_failure:",charIndex:715},{level:3,title:"IDLE:",slug:"idle",normalizedTitle:"idle:",charIndex:1009},{level:3,title:"SHUTDOWN:",slug:"shutdown",normalizedTitle:"shutdown:",charIndex:1401},{level:2,title:"状态转换表",slug:"状态转换表",normalizedTitle:"状态转换表",charIndex:1644},{level:2,title:"Channel State API",slug:"channel-state-api",normalizedTitle:"channel state api",charIndex:3769}],headersStr:"States of Connectivity CONNECTING: READY: TRANSIENT_FAILURE: IDLE: SHUTDOWN: 状态转换表 Channel State API",content:"# gRPC Connectivity Semantics and API\n\n> 原文：https://github.com/grpc/grpc/blob/master/doc/connectivity-semantics-and-api.md\n\n本文主要描述 gRPC 通道的连接语义以及对 RPC 的相应影响，然后再探讨下 API。\n\n\n# States of Connectivity\n\ngRPC Channels 提供了一种 clients 与 servers 交互的抽象。客户端的 channel 对象可以通过使用一个 DNS 名字多一点的信息就可以构建出来。Channels 封装了一系列功能，包括：名称解析、建立TCP连接(包括 retries 和 backoff)和 TLS 握手。 Channels 还可以处理已建立连接上的错误并重新连接，或者在 HTTP/2 GO_AWAY 的情况下，重新解析名称并重新连接。\n\n为了对使用 gRPC API的用户(即应用程序代码)隐藏所有此活动的详细信息，同时暴露有关 channel 状态的有意义信息，我们使用了如下定义的五个状态表述的状态机：\n\n\n# CONNECTING:\n\n标识该 channel 正在尝试建立连接，并且正在等待在 名称解析、TCP 连接建立 或 TLS 握手 中涉及的其中一个步骤上取得进展。它可以被用作创建 channel 时的初始状态。\n\n\n# READY:\n\n标识该 channel 已经通过 TLS握手(或等效)和协议级(HTTP/2等)握手 成功建立了连接，并且所有后续的通信尝试都已成功(或者在没有任何已知故障的情况下等待)。\n\n\n# TRANSIENT_FAILURE:\n\n标识该 channel 出现了一些瞬时故障(例如，TCP 3次握手超时 或 套接字错误)。处于此状态的 channel 最终将切换到 CONNECTING 状态并尝试再次建立连接。\n\n由于重试是通过指数退避(exponential backoff)完成的，因此，连接失败的 channel 在刚开始时在此状态下花费很少的时间，但是随着重复尝试并失败的次数增加，channel 将在此状态下花费越来越多的时间。对于许多非致命故障(例如，由于服务器尚不可用而导致 TCP 连接尝试超时)，channel 可能在该状态下花费越来越多的大量时间。\n\n\n# IDLE:\n\n这个状态标识由于缺少新的(new)或未决(pending)的RPC，channel 甚至没有尝试创建连接。新的 RPC 可能会在这个状态被创建。任何在 channel 上启动 RPC 的尝试都会将通道从此状态推送到 CONNECTING 状态。\n\n如果 channel 上已经在指定的 IDLE_TIMEOUT 时间内没有 RPC 活动，即在此期间没有新的(new)或挂起(pending)的(或活跃的) RPC，则 READY 或 CONNECTING 状态的 channel 将转换到 IDLE 状态。通常情况下，IDLE_TIMEOUT 的默认值是 300秒。\n\n此外，已经接收到 GOAWAY 的 channel 在没有活跃(active)或挂起(pending)的 RPCs 时，也应当转换到 IDLE 状态，以避免尝试断开连接的服务器上的连接过载。\n\n\n# SHUTDOWN:\n\n标识该 channel 已经开始关闭。任何新的 RPCs 都应该立即失败。待处理(pending)的 RPCs 可能会继续运行，直到应用程序取消它们。channel 可能会因为应用程序显式请求关闭，或者在尝试连接通信期间发生了不可恢复的错误而进入此状态。(截至2015年12月6日，没有已知的错误(连接或通信时)被归类为不可恢复的错误。)\n\n一旦 channel 进入 SHUTDOWN 状态，就绝不会再离开。也就是说，SHUTDOWN 是状态机的结束。\n\n\n# 状态转换表\n\n下表列出了合法的状态转换和相关原因。空的单元表示不允许对应的状态转换。\n\nFROM/TO             CONNECTING                                                 READY                                                          TRANSIENT_FAILURE                                     IDLE                                                  SHUTDOWN\nCONNECTING          Incremental progress during connection establishment       All steps needed to establish a connection succeeded           Any failure in any of the steps needed to establish   No RPC activity on channel for IDLE_TIMEOUT           Shutdown triggered by application.\n                                                                                                                                              connection\nREADY                                                                          Incremental successful communication on established channel.   Any failure encountered while expecting successful    No RPC activity on channel for IDLE_TIMEOUT OR upon   Shutdown triggered by application.\n                                                                                                                                              communication on established channel.                 receiving a GOAWAY while there are no pending RPCs.\nTRANSIENT_FAILURE   Wait time required to implement (exponential) backoff is                                                                                                                                                                              Shutdown triggered by application.\n                    over.\nIDLE                Any new RPC activity on the channel                                                                                                                                                                                                   Shutdown triggered by application.\nSHUTDOWN                                                                                                                                                                                                                                                  \n\n\n# Channel State API\n\n所有的 gRPC 库都应该暴露一个 channel-level 的 API 方法以轮询 channel 的当前状态。\n\n在 C++ 中, 这个方法叫 GetState，它会返回一个标识五个合法状态中一个的枚举值。如果 channel 当前处于 IDLE 状态，它还接受布尔值 try_to_connect 以转换为 CONNECTING。The boolean should act as if an RPC occurred, so it should also reset IDLE_TIMEOUT. grpc_connectivity_state GetState(bool try_to_connect);\n\n所有的 gRPC 库还应该暴露一个 API 以在当 channel 状态发生变化时，应用程序(使用 gRPC API 的用户)可以得到通知。由于状态更改可以快速并且与任何此类通知竞争，因此通知应该仅通知用户已经发生了一些状态改变，将其留给用户以轮询该通道以获得当前状态。异步版本的这个 API如下： bool WaitForStateChange(grpc_connectivity_state source_state, gpr_timespec deadline);\n\n当状态不是 source_state 时返回 true，如果截止时间到期则返回 false。Asynchronous- and futures-based 的API应该有一个相应的方法，允许在通道状态发生变化时通知应用程序。\n\n请注意，每当从任何状态转换到任何其他状态时，都会发送通知。\n\n也就是说，合法状态转换的规则要求从 CONNECTING 转换到 TRANSIENT_FAILURE 并返回到每个可恢复故障的 CONNECTING，即使相应的指数退避在重试之前不需要等待。综合效果是应用程序可能会收到看似虚假的状态更改通知。例如，在 CONNECTING 状态的 channel 上等待状态变更的应用程序，可能会在收到状态更改通知，但在轮询当前状态时发现其依然处于 CONNECTING 状态，因为该 channel 可能在 TRANSIENT_FAILURE 状态下花费了极少的时间。",normalizedContent:"# grpc connectivity semantics and api\n\n> 原文：https://github.com/grpc/grpc/blob/master/doc/connectivity-semantics-and-api.md\n\n本文主要描述 grpc 通道的连接语义以及对 rpc 的相应影响，然后再探讨下 api。\n\n\n# states of connectivity\n\ngrpc channels 提供了一种 clients 与 servers 交互的抽象。客户端的 channel 对象可以通过使用一个 dns 名字多一点的信息就可以构建出来。channels 封装了一系列功能，包括：名称解析、建立tcp连接(包括 retries 和 backoff)和 tls 握手。 channels 还可以处理已建立连接上的错误并重新连接，或者在 http/2 go_away 的情况下，重新解析名称并重新连接。\n\n为了对使用 grpc api的用户(即应用程序代码)隐藏所有此活动的详细信息，同时暴露有关 channel 状态的有意义信息，我们使用了如下定义的五个状态表述的状态机：\n\n\n# connecting:\n\n标识该 channel 正在尝试建立连接，并且正在等待在 名称解析、tcp 连接建立 或 tls 握手 中涉及的其中一个步骤上取得进展。它可以被用作创建 channel 时的初始状态。\n\n\n# ready:\n\n标识该 channel 已经通过 tls握手(或等效)和协议级(http/2等)握手 成功建立了连接，并且所有后续的通信尝试都已成功(或者在没有任何已知故障的情况下等待)。\n\n\n# transient_failure:\n\n标识该 channel 出现了一些瞬时故障(例如，tcp 3次握手超时 或 套接字错误)。处于此状态的 channel 最终将切换到 connecting 状态并尝试再次建立连接。\n\n由于重试是通过指数退避(exponential backoff)完成的，因此，连接失败的 channel 在刚开始时在此状态下花费很少的时间，但是随着重复尝试并失败的次数增加，channel 将在此状态下花费越来越多的时间。对于许多非致命故障(例如，由于服务器尚不可用而导致 tcp 连接尝试超时)，channel 可能在该状态下花费越来越多的大量时间。\n\n\n# idle:\n\n这个状态标识由于缺少新的(new)或未决(pending)的rpc，channel 甚至没有尝试创建连接。新的 rpc 可能会在这个状态被创建。任何在 channel 上启动 rpc 的尝试都会将通道从此状态推送到 connecting 状态。\n\n如果 channel 上已经在指定的 idle_timeout 时间内没有 rpc 活动，即在此期间没有新的(new)或挂起(pending)的(或活跃的) rpc，则 ready 或 connecting 状态的 channel 将转换到 idle 状态。通常情况下，idle_timeout 的默认值是 300秒。\n\n此外，已经接收到 goaway 的 channel 在没有活跃(active)或挂起(pending)的 rpcs 时，也应当转换到 idle 状态，以避免尝试断开连接的服务器上的连接过载。\n\n\n# shutdown:\n\n标识该 channel 已经开始关闭。任何新的 rpcs 都应该立即失败。待处理(pending)的 rpcs 可能会继续运行，直到应用程序取消它们。channel 可能会因为应用程序显式请求关闭，或者在尝试连接通信期间发生了不可恢复的错误而进入此状态。(截至2015年12月6日，没有已知的错误(连接或通信时)被归类为不可恢复的错误。)\n\n一旦 channel 进入 shutdown 状态，就绝不会再离开。也就是说，shutdown 是状态机的结束。\n\n\n# 状态转换表\n\n下表列出了合法的状态转换和相关原因。空的单元表示不允许对应的状态转换。\n\nfrom/to             connecting                                                 ready                                                          transient_failure                                     idle                                                  shutdown\nconnecting          incremental progress during connection establishment       all steps needed to establish a connection succeeded           any failure in any of the steps needed to establish   no rpc activity on channel for idle_timeout           shutdown triggered by application.\n                                                                                                                                              connection\nready                                                                          incremental successful communication on established channel.   any failure encountered while expecting successful    no rpc activity on channel for idle_timeout or upon   shutdown triggered by application.\n                                                                                                                                              communication on established channel.                 receiving a goaway while there are no pending rpcs.\ntransient_failure   wait time required to implement (exponential) backoff is                                                                                                                                                                              shutdown triggered by application.\n                    over.\nidle                any new rpc activity on the channel                                                                                                                                                                                                   shutdown triggered by application.\nshutdown                                                                                                                                                                                                                                                  \n\n\n# channel state api\n\n所有的 grpc 库都应该暴露一个 channel-level 的 api 方法以轮询 channel 的当前状态。\n\n在 c++ 中, 这个方法叫 getstate，它会返回一个标识五个合法状态中一个的枚举值。如果 channel 当前处于 idle 状态，它还接受布尔值 try_to_connect 以转换为 connecting。the boolean should act as if an rpc occurred, so it should also reset idle_timeout. grpc_connectivity_state getstate(bool try_to_connect);\n\n所有的 grpc 库还应该暴露一个 api 以在当 channel 状态发生变化时，应用程序(使用 grpc api 的用户)可以得到通知。由于状态更改可以快速并且与任何此类通知竞争，因此通知应该仅通知用户已经发生了一些状态改变，将其留给用户以轮询该通道以获得当前状态。异步版本的这个 api如下： bool waitforstatechange(grpc_connectivity_state source_state, gpr_timespec deadline);\n\n当状态不是 source_state 时返回 true，如果截止时间到期则返回 false。asynchronous- and futures-based 的api应该有一个相应的方法，允许在通道状态发生变化时通知应用程序。\n\n请注意，每当从任何状态转换到任何其他状态时，都会发送通知。\n\n也就是说，合法状态转换的规则要求从 connecting 转换到 transient_failure 并返回到每个可恢复故障的 connecting，即使相应的指数退避在重试之前不需要等待。综合效果是应用程序可能会收到看似虚假的状态更改通知。例如，在 connecting 状态的 channel 上等待状态变更的应用程序，可能会在收到状态更改通知，但在轮询当前状态时发现其依然处于 connecting 状态，因为该 channel 可能在 transient_failure 状态下花费了极少的时间。",charsets:{cjk:!0}},{title:"grpc interceptor with go",frontmatter:{title:"grpc interceptor with go",date:"2020-04-13T00:00:00.000Z",lastmod:null,description:"grpc interceptor with go",categories:["network","grpc"],tags:[null],permalink:null},regularPath:"/blog/network/grpc/grpc_interceptor_with_go.html",relativePath:"blog/network/grpc/grpc_interceptor_with_go.md",key:"v-b9611c0e",path:"/blog/network/grpc/grpc_interceptor_with_go.html",headers:[{level:2,title:"Interceptor",slug:"interceptor",normalizedTitle:"interceptor",charIndex:31},{level:2,title:"grpc.stats",slug:"grpc-stats",normalizedTitle:"grpc.stats",charIndex:2100},{level:2,title:"Appendix A",slug:"appendix-a",normalizedTitle:"appendix a",charIndex:3689}],headersStr:"Interceptor grpc.stats Appendix A",content:"# grpc interceptor with go\n\n\n# Interceptor\n\n通过 ServerOption 给 grpc.Server 增加 interceptor 时有限制：Only one unary interceptor can be installed.。为了安装多个拦截器，我们需要一种可以将多个 interceptor 重新组合的方式。\n\n目前常用的方式是： package : github.com/grpc-ecosystem/go-grpc-middleware: func ChainUnaryClient(interceptors ...grpc.UnaryClientInterceptor) grpc.UnaryClientInterceptor func ChainUnaryServer(interceptors ...grpc.UnaryServerInterceptor) grpc.UnaryServerInterceptor 使用示例见：enceladus.wgrpc.server\n\n下边我们来看看它的实现： ``` // Execution is done in left-to-right order, including passing of context. func ChainUnaryServer(interceptors ...grpc.UnaryServerInterceptor) grpc.UnaryServerInterceptor { n := len(interceptors)\n\n        if n > 1 {\n            lastI := n - 1\n            return func(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface{}, error) {\n                var (\n                    chainHandler grpc.UnaryHandler\n                    curI         int\n                )\n\n                chainHandler = func(currentCtx context.Context, currentReq interface{}) (interface{}, error) {\n                    if curI == lastI {\n                        return handler(currentCtx, currentReq)\n                    }\n                    curI++\n                    resp, err := interceptors[curI](currentCtx, currentReq, info, chainHandler)\n                    curI--\n                    return resp, err\n                }\n\n                return interceptors[0](ctx, req, info, chainHandler)\n            }\n        }\n\n        if n == 1 {\n            return interceptors[0]\n        }\n\n        // n == 0; Dummy interceptor maintained for backward compatibility to avoid returning nil.\n        return func(ctx context.Context, req interface{}, _ *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface{}, error) {\n            return handler(ctx, req)\n        }\n    }\n```\n\n\n其实，它的实现的本质就是：利用闭包来引用栈中数据达到延迟使用的效果\n\n通过这种方式，我们就可以尽情的实现自己的各种 interceptor：UnaryServerInterceptorAccessLog、grpc_recovery.UnaryServerInterceptor(package: github.com/grpc-ecosystem/go-grpc-middleware/recovery) 等等。\n\n\n# grpc.stats\n\ngrpc.Server 可以通过安装 func WithStatsHandler(h stats.Handler) DialOption 生成的 ServerOption 实现 This package is for monitoring purpose only. All fields are read-only.\n\n首先，我们看看 stats.Handler 的定义:\n\n    type Handler interface {\n        // TagRPC can attach some information to the given context.\n        // The context used for the rest lifetime of the RPC will be derived from\n        // the returned context.\n        TagRPC(context.Context, *RPCTagInfo) context.Context\n        // HandleRPC processes the RPC stats.\n        HandleRPC(context.Context, RPCStats)\n\n        // TagConn can attach some information to the given context.\n        // The returned context will be used for stats handling.\n        // For conn stats handling, the context used in HandleConn for this\n        // connection will be derived from the context returned.\n        // For RPC stats handling,\n        //  - On server side, the context used in HandleRPC for all RPCs on this\n        // connection will be derived from the context returned.\n        //  - On client side, the context is not derived from the context returned.\n        TagConn(context.Context, *ConnTagInfo) context.Context\n        // HandleConn processes the Conn stats.\n        HandleConn(context.Context, ConnStats)\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n在 grpc 的方法调用过程中，RPCStats 在 stat.Begin、stat.ConnBegin、stat.ConnEnd、stat.End 几个状态之间转换。\n\n其中 Handler.HandleConn 发生在 grpc 的方法调用之前，而 grpc方法调用后，会调用 Handler.HandleRPC (此时 RPCStats 为 stat.End)。由此，我们可以通过这种方式，达到对 grpc 方法 装饰的效果。如：github.com/openzipkin/zipkin-go 的实现，使用示例：\n\n\n# Appendix A\n\n 1. gRPC server 的 go 实现片段",normalizedContent:"# grpc interceptor with go\n\n\n# interceptor\n\n通过 serveroption 给 grpc.server 增加 interceptor 时有限制：only one unary interceptor can be installed.。为了安装多个拦截器，我们需要一种可以将多个 interceptor 重新组合的方式。\n\n目前常用的方式是： package : github.com/grpc-ecosystem/go-grpc-middleware: func chainunaryclient(interceptors ...grpc.unaryclientinterceptor) grpc.unaryclientinterceptor func chainunaryserver(interceptors ...grpc.unaryserverinterceptor) grpc.unaryserverinterceptor 使用示例见：enceladus.wgrpc.server\n\n下边我们来看看它的实现： ``` // execution is done in left-to-right order, including passing of context. func chainunaryserver(interceptors ...grpc.unaryserverinterceptor) grpc.unaryserverinterceptor { n := len(interceptors)\n\n        if n > 1 {\n            lasti := n - 1\n            return func(ctx context.context, req interface{}, info *grpc.unaryserverinfo, handler grpc.unaryhandler) (interface{}, error) {\n                var (\n                    chainhandler grpc.unaryhandler\n                    curi         int\n                )\n\n                chainhandler = func(currentctx context.context, currentreq interface{}) (interface{}, error) {\n                    if curi == lasti {\n                        return handler(currentctx, currentreq)\n                    }\n                    curi++\n                    resp, err := interceptors[curi](currentctx, currentreq, info, chainhandler)\n                    curi--\n                    return resp, err\n                }\n\n                return interceptors[0](ctx, req, info, chainhandler)\n            }\n        }\n\n        if n == 1 {\n            return interceptors[0]\n        }\n\n        // n == 0; dummy interceptor maintained for backward compatibility to avoid returning nil.\n        return func(ctx context.context, req interface{}, _ *grpc.unaryserverinfo, handler grpc.unaryhandler) (interface{}, error) {\n            return handler(ctx, req)\n        }\n    }\n```\n\n\n其实，它的实现的本质就是：利用闭包来引用栈中数据达到延迟使用的效果\n\n通过这种方式，我们就可以尽情的实现自己的各种 interceptor：unaryserverinterceptoraccesslog、grpc_recovery.unaryserverinterceptor(package: github.com/grpc-ecosystem/go-grpc-middleware/recovery) 等等。\n\n\n# grpc.stats\n\ngrpc.server 可以通过安装 func withstatshandler(h stats.handler) dialoption 生成的 serveroption 实现 this package is for monitoring purpose only. all fields are read-only.\n\n首先，我们看看 stats.handler 的定义:\n\n    type handler interface {\n        // tagrpc can attach some information to the given context.\n        // the context used for the rest lifetime of the rpc will be derived from\n        // the returned context.\n        tagrpc(context.context, *rpctaginfo) context.context\n        // handlerpc processes the rpc stats.\n        handlerpc(context.context, rpcstats)\n\n        // tagconn can attach some information to the given context.\n        // the returned context will be used for stats handling.\n        // for conn stats handling, the context used in handleconn for this\n        // connection will be derived from the context returned.\n        // for rpc stats handling,\n        //  - on server side, the context used in handlerpc for all rpcs on this\n        // connection will be derived from the context returned.\n        //  - on client side, the context is not derived from the context returned.\n        tagconn(context.context, *conntaginfo) context.context\n        // handleconn processes the conn stats.\n        handleconn(context.context, connstats)\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n在 grpc 的方法调用过程中，rpcstats 在 stat.begin、stat.connbegin、stat.connend、stat.end 几个状态之间转换。\n\n其中 handler.handleconn 发生在 grpc 的方法调用之前，而 grpc方法调用后，会调用 handler.handlerpc (此时 rpcstats 为 stat.end)。由此，我们可以通过这种方式，达到对 grpc 方法 装饰的效果。如：github.com/openzipkin/zipkin-go 的实现，使用示例：\n\n\n# appendix a\n\n 1. grpc server 的 go 实现片段",charsets:{cjk:!0}},{title:"gRPC over HTTP2",frontmatter:{title:"gRPC over HTTP2",date:"2020-04-13T00:00:00.000Z",lastmod:null,description:"gRPC over HTTP2",categories:["network","grpc"],tags:[null],permalink:null},regularPath:"/blog/network/grpc/grpc_over_http2.html",relativePath:"blog/network/grpc/grpc_over_http2.md",key:"v-e4b92d82",path:"/blog/network/grpc/grpc_over_http2.html",headers:[{level:2,title:"介绍",slug:"介绍",normalizedTitle:"介绍",charIndex:91},{level:2,title:"大纲",slug:"大纲",normalizedTitle:"大纲",charIndex:132},{level:2,title:"Requests",slug:"requests",normalizedTitle:"requests",charIndex:309},{level:3,title:"Request-Headers",slug:"request-headers",normalizedTitle:"request-headers",charIndex:177},{level:3,title:"Length-Prefixed-Message",slug:"length-prefixed-message",normalizedTitle:"length-prefixed-message",charIndex:194},{level:3,title:"EOS(end-of-stream)",slug:"eos-end-of-stream",normalizedTitle:"eos(end-of-stream)",charIndex:4255},{level:2,title:"Responses",slug:"responses",normalizedTitle:"responses",charIndex:4415},{level:3,title:"Response-Headers",slug:"response-headers",normalizedTitle:"response-headers",charIndex:237},{level:2,title:"Example",slug:"example",normalizedTitle:"example",charIndex:5855},{level:3,title:"Request",slug:"request",normalizedTitle:"request",charIndex:167},{level:3,title:"Response",slug:"response",normalizedTitle:"response",charIndex:225},{level:2,title:"User Agents",slug:"user-agents",normalizedTitle:"user agents",charIndex:6633},{level:2,title:"幂等性 和 重试",slug:"幂等性-和-重试",normalizedTitle:"幂等性 和 重试",charIndex:6982},{level:2,title:"HTTP2 Transport Mapping",slug:"http2-transport-mapping",normalizedTitle:"http2 transport mapping",charIndex:7089},{level:3,title:"Stream Identification",slug:"stream-identification",normalizedTitle:"stream identification",charIndex:7117},{level:3,title:"Data Frames",slug:"data-frames",normalizedTitle:"data frames",charIndex:7268},{level:3,title:"Errors",slug:"errors",normalizedTitle:"errors",charIndex:7342},{level:3,title:"Security",slug:"security",normalizedTitle:"security",charIndex:7535},{level:2,title:"Connection Management",slug:"connection-management",normalizedTitle:"connection management",charIndex:7681},{level:3,title:"GOAWAY Frame",slug:"goaway-frame",normalizedTitle:"goaway frame",charIndex:7707},{level:3,title:"PING Frame",slug:"ping-frame",normalizedTitle:"ping frame",charIndex:7990},{level:3,title:"Connection failure",slug:"connection-failure",normalizedTitle:"connection failure",charIndex:8265},{level:2,title:"Appendix A - GRPC for Protobuf",slug:"appendix-a-grpc-for-protobuf",normalizedTitle:"appendix a - grpc for protobuf",charIndex:8360}],headersStr:"介绍 大纲 Requests Request-Headers Length-Prefixed-Message EOS(end-of-stream) Responses Response-Headers Example Request Response User Agents 幂等性 和 重试 HTTP2 Transport Mapping Stream Identification Data Frames Errors Security Connection Management GOAWAY Frame PING Frame Connection failure Appendix A - GRPC for Protobuf",content:'# gRPC over HTTP2\n\n> 原文：https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md\n\n\n# 介绍\n\n本文主要描述 grpc 基于 http2 framing 的实现\n\n\n# 大纲\n\n下述是在一次grpc请求和应答里通用的消息原子组成:\n\n * Request → Request-Headers *Length-Prefixed-Message EOS\n * Response → (Response-Headers *Length-Prefixed-Message Trailers) / Trailers-Only\n\n\n# Requests\n\n * Request → Request-Headers *Length-Prefixed-Message EOS\n\n\n# Request-Headers\n\nRequest-Headers 被当作用 http2 headers，通过 HEADERS + CONTINUATION 帧来传输\n\n * Request-Headers → Call-Definition *Custom-Metadata\n   * Call-Definition → Method Scheme Path TE [Authority] [Timeout] Content-Type [Message-Type] [Message-Encoding] [Message-Accept-Encoding] [User-Agent]\n     * Method → ":method POST"\n     * Scheme → ":scheme " ("http" / "https")\n     * Path → ":path" "/" Service-Name "/" {method name} # But see note below.\n       * Service-Name → {IDL-specific service name}\n     * Authority → ":authority" {virtual host name of authority}\n     * TE → "te" "trailers" # Used to detect incompatible proxies\n     * Timeout → "grpc-timeout" TimeoutValue TimeoutUnit\n     * TimeoutValue → {positive integer as ASCII string of at most 8 digits}\n     * TimeoutUnit → Hour / Minute / Second / Millisecond / Microsecond / Nanosecond\n       * Hour → "H"\n       * Minute → "M"\n       * Second → "S"\n       * Millisecond → "m"\n       * Microsecond → "u"\n       * Nanosecond → "n"\n     * Content-Type → "content-type" "application/grpc" [("+proto" / "+json" / {custom})]\n     * Content-Coding → "identity" / "gzip" / "deflate" / "snappy" / {custom}\n     * Message-Encoding → "grpc-encoding" Content-Coding\n     * Message-Accept-Encoding → "grpc-accept-encoding" Content-Coding *("," Content-Coding)\n     * User-Agent → "user-agent" {structured user-agent string}\n     * Message-Type → "grpc-message-type" {type name for message schema}\n   * Custom-Metadata → Binary-Header / ASCII-Header\n     * Binary-Header → {Header-Name "-bin" } {base64 encoded value}\n     * ASCII-Header → Header-Name ASCII-Value\n     * Header-Name → 1*( %x30-39 / %x61-7A / "_" / "-" / ".") ; 0-9 a-z _ - .\n     * ASCII-Value → 1*( %x20-%x7E ) ; space and printable ASCII\n\nHTTP2 协议要求 reserved headers (以 ":" 开头的 header) 必须出现在其他 headers 之前。此外，还要求 Timeout 头必须紧跟在 reserved headers 之后被发送。还有就是，Call-Definition 需要在发送 Custom-Metadata 之前发送。\n\n一些 gRPC 的实现可能会允许上面的 Path 格式被覆盖，但是这样的功能是强烈不推荐的。gRPC 不会特意的去阻止用户使用 Path 格式覆盖这个功能, 但我们绝不会主动的支持它，另外就是当 PATH 的格式不是上述那样的话, 一些功能(如：service config support)可能会不能正常工作。\n\n在 Timeout 被缺省时, 服务端应当假定 Timeout 是无穷大的。客户端实现可以根据其部署要求自由发送默认的最小超时时间。\n\n如果 Content-Type 不是以 "application/grpc" 开头时, gRPC 服务端应当以 HTTP 状态码 415 (Unsupported Media Type) 进行应答。这样, 能阻断 HTTP/2 的客户端(以状态码200标识成功)解析一个 gRPC 错误。\n\nCustom-Metadata 是一系列由应用层定义的 key-value 键值对组成的集合。应用程序不能使用以 "grpc-" 开头的 Header 名作为 Custom-Metadata 的 key, 因为以 "grpc-" 开头的 Header 名被用于预留的在未来给 GRPC 使用。\n\n注意，因为 HTTP2 不允许二进制序列作为 header 的值，所以二进制的 header 值必须使用 Base64 编码。实现时必须可以接收 padded 和 un-padded 的值，发送 un-padded 的值。应用程序定义的二进制 header 名需要以 "-bin" 为后缀。运行库可以使用这个后缀检测出二进制的 headers，然后在发送和接收时使用 base64 进行加解密。\n\nCustom-Metadata 不能保证 header 的顺序除非有重复的 header 名。当有重复的 header 名时，在语义上等价于将他们的值以 "," 作为分隔符拼接起来。所以，实现时需要注意，对于 二进制类型的 header，需要先用 "," 进行分割，然后再用 base64 进行解密处理。\n\nCustom-Metadata 的 ASCII 类型的值，不能有空格做前后缀，如果有的话，会被剥离掉。另外，这里可以使用的 ASCII 字符范围比 HTTP 更加严格。实现时，不能因为接收到在 HTTP 有效但在 Custom-Metadata 中无效的 ASCII 字符而出错，但是却没有严格定义具体的行为：可以抛弃也可以接受这个值。如果被接受，必须注意确保允许应用程序将值作为元数据回显。例如，如果这个元数据被当作一个列表在一个请求中传递给应用程序，那么如果应用程序把这个元数据放在应答中时不应引发一个错误。\n\n服务端可以限制 Request-Headers 的大小，建议默认 8kb。建议实现时计算 header 的总大小，像 HTTP/2 的 SETTINGS_MAX_HEADER_LIST_SIZE 那样：the sum of all header fields, for each field the sum of the uncompressed field name and value lengths plus 32, with binary values\' lengths being post-Base64.\n\n\n# Length-Prefixed-Message\n\n一个 Request 中可以有多个 Length-Prefixed-Message 数据，它们通过 http2 的 DATA 帧进行传输。\n\n * Length-Prefixed-Message → Compressed-Flag Message-Length Message\n   * Compressed-Flag → 0 / 1 # encoded as 1 byte unsigned integer\n   * Message-Length → {length of Message} # encoded as 4 byte unsigned integer (big endian)\n   * Message → *{binary octet}\n\n当 Compressed-Flag 值为1时，标识着二进制的 Message 是使用 Message-Encoding 头中声明的方式压缩过的。值为0时,意味着没有被压缩。 如果 Message-Encoding 头缺省的情况下，Compressed-Flag 值必须为0。压缩的上下文信息不会在跨越 message 边界时依然被维护，所以，实现时必须为流中的每一个 message 创建一个新的上下文。\n\n\n# EOS(end-of-stream)\n\n对于请求来说，EOS (end-of-stream) 通过接收到的最后一个 DATA 帧中的 END_STREAM 标记来标识的。在 Request 需要被关闭但是又没有数据需要发送的情况下，gRPC的实现必须发送一个包含 END_STREAM 标记的空 DATA 帧。\n\n\n# Responses\n\n * Response → (Response-Headers *Length-Prefixed-Message Trailers) / Trailers-Only\n\n\n# Response-Headers\n\n * Response-Headers → HTTP-Status [Message-Encoding] [Message-Accept-Encoding] Content-Type *Custom-Metadata\n * Trailers-Only → HTTP-Status Content-Type Trailers\n * Trailers → Status [Status-Message] *Custom-Metadata\n   * Status → "grpc-status" 1*DIGIT ; 0-9\n   * Status-Message → "grpc-message" Percent-Encoded\n     * Percent-Encoded → 1*(Percent-Byte-Unencoded / Percent-Byte-Encoded)\n       * Percent-Byte-Unencoded → 1*( %x20-%x24 / %x26-%x7E ) ; space and VCHAR, except %\n       * Percent-Byte-Encoded → "%" 2HEXDIGIT ; 0-9 A-F\n   * HTTP-Status → ":status 200"\n\nResponse-Headers 和 Trailers-Only 都是通过一个独立的 HTTP2 HEADERS 帧块进行传输。大多数的 responses 都应该既有 headers 又有 trailers，但是 Trailers-Only 当在需要产生一个即时错误时是被允许的。另外，Status 信息必须在 Trailers 中，即使 status code 是 OK.\n\n对于 responses 来说，end-of-stream 是通过最后一个传输 Trailers 的 HEADERS 帧的 END_STREAM 标记来标示的。\n\n实现时应当期望 broken deployments 在响应中发送 非200 的 HTTP状态代码以及各种非GRPC内容类型并且省略状态和状态消息。当这种情况发生时，实现时必须合成一个 Status & Status-Message 以传播给应用层\n\n客户端应当限制 Response-Headers, Trailers, 或 Trailers-Only 的大小，一般推荐上述对象的大小限制都是 8Kb\n\nStatus 的值部分是十进制编码的整数，作为ASCII字符串，没有任何前导零\n\nStatus-Message 的值部分理论上应当是一个描述错误的 Unicode 字符串，实际上多用 UTF-8 跟着是 url 编码(percent-encoding)。当解码无效值时，该实现一定不能抛出错误 或者 丢弃这个 message。最坏情况，就是终止解码这个 Status-Message，这样用户可以接收到原始的 url 编码格式数据。或者，该实现可以解码有效部分，同时保留损坏的％ - 编码，或者用替换字符(例如，\'？\'或Unicode替换字符)替换它们。\n\n\n# Example\n\n以下以 unary-call 为例展示 HTTP2 的帧序列\n\n\n# Request\n\n    HEADERS (flags = END_HEADERS)\n    :method = POST\n    :scheme = http\n    :path = /google.pubsub.v2.PublisherService/CreateTopic\n    :authority = pubsub.googleapis.com\n    grpc-timeout = 1S\n    content-type = application/grpc+proto\n    grpc-encoding = gzip\n    authorization = Bearer y235.wef315yfh138vh31hv93hv8h3v\n\n    DATA (flags = END_STREAM)\n    <Length-Prefixed Message>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# Response\n\n    HEADERS (flags = END_HEADERS)\n    :status = 200\n    grpc-encoding = gzip\n    content-type = application/grpc+proto\n\n    DATA\n    <Length-Prefixed Message>\n\n    HEADERS (flags = END_STREAM, END_HEADERS)\n    grpc-status = 0 # OK\n    trace-proto-bin = jher831yy13JHy3hc\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# User Agents\n\n虽然协议不要求用户代理来运行，但建议客户端提供结构化的用户代理字符串，该字符串提供了调用库、版本和平台的基本描述，以便在异构环境中进行问题诊断。建议库开发人员使用以下结构: User-Agent → "grpc-" Language ?("-" Variant) "/" Version ?( " (" *(AdditionalProperty ";") ")" ) E.g.\n\n    grpc-java/1.2.3\n    grpc-ruby/1.2.3\n    grpc-ruby-jruby/1.3.4\n    grpc-java-android/0.9.1 (gingerbread/1.2.4; nexus5; tmobile)\n\n\n1\n2\n3\n4\n\n\n\n# 幂等性 和 重试\n\n除非被显示的定位, 不然 gRPC 调用不应被假设为幂等的. 特别地:\n\n * 无法验证已启动的调用将不会重试\n * 没有重复抑制机制，因为没有必要\n * 标记为幂等的呼叫可以多次发送\n\n\n# HTTP2 Transport Mapping\n\n\n# Stream Identification\n\n所有 GRPC 调用都需要指定一个内部ID。我们将在此方案中使用 HTTP2 stream-id 作为调用标识符。注意：这些 ID 是已打开 HTTP2 会话的上下文，并且，在处理多个 HTTP2 会话的给定进程中不是唯一的，也不能用作GUID。\n\n\n# Data Frames\n\nDATA 帧边界与 Length-Prefixed-Message 边界无关，并且实现不应对其对齐做出任何假设。\n\n\n# Errors\n\n在 RPC 期间发生应用程序或运行时错误时，将在 Trailers 中传递 Status 和 Status-Message。\n\n在某些情况下，消息流的帧可能已损坏，RPC 运行时将选择使用 RST_STREAM 帧向其对等方指示此状态。RPC运行时实现应该将 RST_STREAM 解释为流的立即 full-closure，并且应该将错误传播到调用应用程序层。\n\n\n# Security\n\n当 TLS 与 HTTP2 一起使用时，HTTP2 规范要求使用 TLS 1.2 或更高版本。它还对部署中允许的密码施加了一些额外的限制，以避免已知问题以及需要SNI支持。另外，预计 HTTP2 将与专有传输安全机制结合使用，此时规范不能对其提出任何有意义的建议\n\n\n# Connection Management\n\n\n# GOAWAY Frame\n\n由 servers 发送给 clients 用于标识 servers 不再在相关的连接上接收任何新的 stream。这个帧包含了 server 成功接收的最后一个 stream id。clients 应该认为最后一个被 server 成功接收的 stream 之后的任何 stream 都是 UNAVAILABLE，应当在其他地方进行重试。clients 可以继续处理已接受的流，直到它们完成或连接终止。\n\nservers 应当在终止连接前发送 GOAWAY 帧，以可靠地通知 clients 哪些工作已被服务器接受并正在执行。\n\n\n# PING Frame\n\nclients 和 servers 都可以发送 PING 帧，对端必须以它接收到的内容进行回复。它被用来断定连接依然存活，并提供了一种评估 end-to-end 延迟的方法。如果 servers 启动的 PING 未在运行时期望的截止期限内收到响应，则服务器上的所有未完成调用将以 CANCELED 状态关闭。如果 clients 启动的 PING 超时未收到响应时，将导致所有调用以 UNAVAILABLE 状态关闭。请注意，PING 的频率高度依赖于网络环境，实现可以根据网络和应用要求自由调整 PING 频率。\n\n\n# Connection failure\n\n如果客户端上发生可检测的连接故障，则将以 UNAVAILABLE 状态关闭所有调用。对于服务器，将以 CANCELED 状态关闭打开的调用。\n\n\n# Appendix A - GRPC for Protobuf\n\n 1. protobuf 声明的服务接口很容易通过 protoc 的代码生成扩展映射到 GRPC 上。以下定义要使用的映射。\n    * Service-Name → ?( {proto package name} "." ) {service name}\n    * Message-Type → {fully qualified proto message name}\n    * Content-Type → "application/grpc+proto"',normalizedContent:'# grpc over http2\n\n> 原文：https://github.com/grpc/grpc/blob/master/doc/protocol-http2.md\n\n\n# 介绍\n\n本文主要描述 grpc 基于 http2 framing 的实现\n\n\n# 大纲\n\n下述是在一次grpc请求和应答里通用的消息原子组成:\n\n * request → request-headers *length-prefixed-message eos\n * response → (response-headers *length-prefixed-message trailers) / trailers-only\n\n\n# requests\n\n * request → request-headers *length-prefixed-message eos\n\n\n# request-headers\n\nrequest-headers 被当作用 http2 headers，通过 headers + continuation 帧来传输\n\n * request-headers → call-definition *custom-metadata\n   * call-definition → method scheme path te [authority] [timeout] content-type [message-type] [message-encoding] [message-accept-encoding] [user-agent]\n     * method → ":method post"\n     * scheme → ":scheme " ("http" / "https")\n     * path → ":path" "/" service-name "/" {method name} # but see note below.\n       * service-name → {idl-specific service name}\n     * authority → ":authority" {virtual host name of authority}\n     * te → "te" "trailers" # used to detect incompatible proxies\n     * timeout → "grpc-timeout" timeoutvalue timeoutunit\n     * timeoutvalue → {positive integer as ascii string of at most 8 digits}\n     * timeoutunit → hour / minute / second / millisecond / microsecond / nanosecond\n       * hour → "h"\n       * minute → "m"\n       * second → "s"\n       * millisecond → "m"\n       * microsecond → "u"\n       * nanosecond → "n"\n     * content-type → "content-type" "application/grpc" [("+proto" / "+json" / {custom})]\n     * content-coding → "identity" / "gzip" / "deflate" / "snappy" / {custom}\n     * message-encoding → "grpc-encoding" content-coding\n     * message-accept-encoding → "grpc-accept-encoding" content-coding *("," content-coding)\n     * user-agent → "user-agent" {structured user-agent string}\n     * message-type → "grpc-message-type" {type name for message schema}\n   * custom-metadata → binary-header / ascii-header\n     * binary-header → {header-name "-bin" } {base64 encoded value}\n     * ascii-header → header-name ascii-value\n     * header-name → 1*( %x30-39 / %x61-7a / "_" / "-" / ".") ; 0-9 a-z _ - .\n     * ascii-value → 1*( %x20-%x7e ) ; space and printable ascii\n\nhttp2 协议要求 reserved headers (以 ":" 开头的 header) 必须出现在其他 headers 之前。此外，还要求 timeout 头必须紧跟在 reserved headers 之后被发送。还有就是，call-definition 需要在发送 custom-metadata 之前发送。\n\n一些 grpc 的实现可能会允许上面的 path 格式被覆盖，但是这样的功能是强烈不推荐的。grpc 不会特意的去阻止用户使用 path 格式覆盖这个功能, 但我们绝不会主动的支持它，另外就是当 path 的格式不是上述那样的话, 一些功能(如：service config support)可能会不能正常工作。\n\n在 timeout 被缺省时, 服务端应当假定 timeout 是无穷大的。客户端实现可以根据其部署要求自由发送默认的最小超时时间。\n\n如果 content-type 不是以 "application/grpc" 开头时, grpc 服务端应当以 http 状态码 415 (unsupported media type) 进行应答。这样, 能阻断 http/2 的客户端(以状态码200标识成功)解析一个 grpc 错误。\n\ncustom-metadata 是一系列由应用层定义的 key-value 键值对组成的集合。应用程序不能使用以 "grpc-" 开头的 header 名作为 custom-metadata 的 key, 因为以 "grpc-" 开头的 header 名被用于预留的在未来给 grpc 使用。\n\n注意，因为 http2 不允许二进制序列作为 header 的值，所以二进制的 header 值必须使用 base64 编码。实现时必须可以接收 padded 和 un-padded 的值，发送 un-padded 的值。应用程序定义的二进制 header 名需要以 "-bin" 为后缀。运行库可以使用这个后缀检测出二进制的 headers，然后在发送和接收时使用 base64 进行加解密。\n\ncustom-metadata 不能保证 header 的顺序除非有重复的 header 名。当有重复的 header 名时，在语义上等价于将他们的值以 "," 作为分隔符拼接起来。所以，实现时需要注意，对于 二进制类型的 header，需要先用 "," 进行分割，然后再用 base64 进行解密处理。\n\ncustom-metadata 的 ascii 类型的值，不能有空格做前后缀，如果有的话，会被剥离掉。另外，这里可以使用的 ascii 字符范围比 http 更加严格。实现时，不能因为接收到在 http 有效但在 custom-metadata 中无效的 ascii 字符而出错，但是却没有严格定义具体的行为：可以抛弃也可以接受这个值。如果被接受，必须注意确保允许应用程序将值作为元数据回显。例如，如果这个元数据被当作一个列表在一个请求中传递给应用程序，那么如果应用程序把这个元数据放在应答中时不应引发一个错误。\n\n服务端可以限制 request-headers 的大小，建议默认 8kb。建议实现时计算 header 的总大小，像 http/2 的 settings_max_header_list_size 那样：the sum of all header fields, for each field the sum of the uncompressed field name and value lengths plus 32, with binary values\' lengths being post-base64.\n\n\n# length-prefixed-message\n\n一个 request 中可以有多个 length-prefixed-message 数据，它们通过 http2 的 data 帧进行传输。\n\n * length-prefixed-message → compressed-flag message-length message\n   * compressed-flag → 0 / 1 # encoded as 1 byte unsigned integer\n   * message-length → {length of message} # encoded as 4 byte unsigned integer (big endian)\n   * message → *{binary octet}\n\n当 compressed-flag 值为1时，标识着二进制的 message 是使用 message-encoding 头中声明的方式压缩过的。值为0时,意味着没有被压缩。 如果 message-encoding 头缺省的情况下，compressed-flag 值必须为0。压缩的上下文信息不会在跨越 message 边界时依然被维护，所以，实现时必须为流中的每一个 message 创建一个新的上下文。\n\n\n# eos(end-of-stream)\n\n对于请求来说，eos (end-of-stream) 通过接收到的最后一个 data 帧中的 end_stream 标记来标识的。在 request 需要被关闭但是又没有数据需要发送的情况下，grpc的实现必须发送一个包含 end_stream 标记的空 data 帧。\n\n\n# responses\n\n * response → (response-headers *length-prefixed-message trailers) / trailers-only\n\n\n# response-headers\n\n * response-headers → http-status [message-encoding] [message-accept-encoding] content-type *custom-metadata\n * trailers-only → http-status content-type trailers\n * trailers → status [status-message] *custom-metadata\n   * status → "grpc-status" 1*digit ; 0-9\n   * status-message → "grpc-message" percent-encoded\n     * percent-encoded → 1*(percent-byte-unencoded / percent-byte-encoded)\n       * percent-byte-unencoded → 1*( %x20-%x24 / %x26-%x7e ) ; space and vchar, except %\n       * percent-byte-encoded → "%" 2hexdigit ; 0-9 a-f\n   * http-status → ":status 200"\n\nresponse-headers 和 trailers-only 都是通过一个独立的 http2 headers 帧块进行传输。大多数的 responses 都应该既有 headers 又有 trailers，但是 trailers-only 当在需要产生一个即时错误时是被允许的。另外，status 信息必须在 trailers 中，即使 status code 是 ok.\n\n对于 responses 来说，end-of-stream 是通过最后一个传输 trailers 的 headers 帧的 end_stream 标记来标示的。\n\n实现时应当期望 broken deployments 在响应中发送 非200 的 http状态代码以及各种非grpc内容类型并且省略状态和状态消息。当这种情况发生时，实现时必须合成一个 status & status-message 以传播给应用层\n\n客户端应当限制 response-headers, trailers, 或 trailers-only 的大小，一般推荐上述对象的大小限制都是 8kb\n\nstatus 的值部分是十进制编码的整数，作为ascii字符串，没有任何前导零\n\nstatus-message 的值部分理论上应当是一个描述错误的 unicode 字符串，实际上多用 utf-8 跟着是 url 编码(percent-encoding)。当解码无效值时，该实现一定不能抛出错误 或者 丢弃这个 message。最坏情况，就是终止解码这个 status-message，这样用户可以接收到原始的 url 编码格式数据。或者，该实现可以解码有效部分，同时保留损坏的％ - 编码，或者用替换字符(例如，\'？\'或unicode替换字符)替换它们。\n\n\n# example\n\n以下以 unary-call 为例展示 http2 的帧序列\n\n\n# request\n\n    headers (flags = end_headers)\n    :method = post\n    :scheme = http\n    :path = /google.pubsub.v2.publisherservice/createtopic\n    :authority = pubsub.googleapis.com\n    grpc-timeout = 1s\n    content-type = application/grpc+proto\n    grpc-encoding = gzip\n    authorization = bearer y235.wef315yfh138vh31hv93hv8h3v\n\n    data (flags = end_stream)\n    <length-prefixed message>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# response\n\n    headers (flags = end_headers)\n    :status = 200\n    grpc-encoding = gzip\n    content-type = application/grpc+proto\n\n    data\n    <length-prefixed message>\n\n    headers (flags = end_stream, end_headers)\n    grpc-status = 0 # ok\n    trace-proto-bin = jher831yy13jhy3hc\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# user agents\n\n虽然协议不要求用户代理来运行，但建议客户端提供结构化的用户代理字符串，该字符串提供了调用库、版本和平台的基本描述，以便在异构环境中进行问题诊断。建议库开发人员使用以下结构: user-agent → "grpc-" language ?("-" variant) "/" version ?( " (" *(additionalproperty ";") ")" ) e.g.\n\n    grpc-java/1.2.3\n    grpc-ruby/1.2.3\n    grpc-ruby-jruby/1.3.4\n    grpc-java-android/0.9.1 (gingerbread/1.2.4; nexus5; tmobile)\n\n\n1\n2\n3\n4\n\n\n\n# 幂等性 和 重试\n\n除非被显示的定位, 不然 grpc 调用不应被假设为幂等的. 特别地:\n\n * 无法验证已启动的调用将不会重试\n * 没有重复抑制机制，因为没有必要\n * 标记为幂等的呼叫可以多次发送\n\n\n# http2 transport mapping\n\n\n# stream identification\n\n所有 grpc 调用都需要指定一个内部id。我们将在此方案中使用 http2 stream-id 作为调用标识符。注意：这些 id 是已打开 http2 会话的上下文，并且，在处理多个 http2 会话的给定进程中不是唯一的，也不能用作guid。\n\n\n# data frames\n\ndata 帧边界与 length-prefixed-message 边界无关，并且实现不应对其对齐做出任何假设。\n\n\n# errors\n\n在 rpc 期间发生应用程序或运行时错误时，将在 trailers 中传递 status 和 status-message。\n\n在某些情况下，消息流的帧可能已损坏，rpc 运行时将选择使用 rst_stream 帧向其对等方指示此状态。rpc运行时实现应该将 rst_stream 解释为流的立即 full-closure，并且应该将错误传播到调用应用程序层。\n\n\n# security\n\n当 tls 与 http2 一起使用时，http2 规范要求使用 tls 1.2 或更高版本。它还对部署中允许的密码施加了一些额外的限制，以避免已知问题以及需要sni支持。另外，预计 http2 将与专有传输安全机制结合使用，此时规范不能对其提出任何有意义的建议\n\n\n# connection management\n\n\n# goaway frame\n\n由 servers 发送给 clients 用于标识 servers 不再在相关的连接上接收任何新的 stream。这个帧包含了 server 成功接收的最后一个 stream id。clients 应该认为最后一个被 server 成功接收的 stream 之后的任何 stream 都是 unavailable，应当在其他地方进行重试。clients 可以继续处理已接受的流，直到它们完成或连接终止。\n\nservers 应当在终止连接前发送 goaway 帧，以可靠地通知 clients 哪些工作已被服务器接受并正在执行。\n\n\n# ping frame\n\nclients 和 servers 都可以发送 ping 帧，对端必须以它接收到的内容进行回复。它被用来断定连接依然存活，并提供了一种评估 end-to-end 延迟的方法。如果 servers 启动的 ping 未在运行时期望的截止期限内收到响应，则服务器上的所有未完成调用将以 canceled 状态关闭。如果 clients 启动的 ping 超时未收到响应时，将导致所有调用以 unavailable 状态关闭。请注意，ping 的频率高度依赖于网络环境，实现可以根据网络和应用要求自由调整 ping 频率。\n\n\n# connection failure\n\n如果客户端上发生可检测的连接故障，则将以 unavailable 状态关闭所有调用。对于服务器，将以 canceled 状态关闭打开的调用。\n\n\n# appendix a - grpc for protobuf\n\n 1. protobuf 声明的服务接口很容易通过 protoc 的代码生成扩展映射到 grpc 上。以下定义要使用的映射。\n    * service-name → ?( {proto package name} "." ) {service name}\n    * message-type → {fully qualified proto message name}\n    * content-type → "application/grpc+proto"',charsets:{cjk:!0}},{title:"grpc source notes",frontmatter:{title:"grpc source notes",date:"2020-04-13T00:00:00.000Z",lastmod:null,description:"grpc source notes",categories:["network","grpc"],tags:["grpc"],permalink:null},regularPath:"/blog/network/grpc/grpc_source_notes.html",relativePath:"blog/network/grpc/grpc_source_notes.md",key:"v-75d8bb3f",path:"/blog/network/grpc/grpc_source_notes.html",headersStr:null,content:'# grpc source notes\n\ngrpc.Server.Serve(lis net.Listener)  ::: google.golang.org/grpc/server.go : L545 :\n    ....\n    for {\n\t\trawConn, err := lis.Accept()\n        ...\n        s.serveWG.Add(1)\n\t\tgo func() {\n\t\t\ts.handleRawConn(rawConn)\n\t\t\ts.serveWG.Done()\n\t\t}()\n    }\n\ngrpc.Server.handleRawConn()\n    ...\n    // Finish handshaking (HTTP2)\n\tst := s.newHTTP2Transport(conn, authInfo)  //> google.golang.org/grpc/internal/transport/transport.go : L488\n                                               //>   google.golang.org/grpc/internal/transport/http2_server.go : L126 : http2Server : 主要逻辑所在地\n                                               //>   http2Server is an implementation of interface transport.ServerTransport\n                                               //>     go func(){ ... t.loopy.run() ...}() ：L276\n                                               //>     go t.keepalive() : L282\n\t                                           //>   http2Server 重要成员：\n\t                                           //>     framer\n\t                                           //>     \t    writer: w : newBufWriter(conn, writeBufferSize),\n\t                                           //>     \t    fr:     http2.NewFramer(w, r),    w,r都是conn的reader\n\t                                           //>     \t\t\t    golang.org/x/net/http2/frame.go ：L432\n\t                                           //>     conn\n\t                                           //>     controlBuf : 一个数据list\n\t                                           //>     loopy : loopyWriter : google.golang.org/grpc/internal/transport/controlbuf.go : L388\n                                               //>       run() : L420\n                                               //>         注意 processData 时数据超过 16K 时的处理: 两层流控：stream-level 和 connection-level\n\tif st == nil {\n\t\treturn\n\t}\n\n\trawConn.SetDeadline(time.Time{})\n\tif !s.addConn(st) {\n\t\treturn\n\t}\n\tgo func() {\n\t\ts.serveStreams(st)\n\t\ts.removeConn(st)\n\t}()\n\ngrpc.Server.serveStreams()\n    func (s *Server) serveStreams(st transport.ServerTransport) {\n        defer st.Close()\n        var wg sync.WaitGroup\n        //> google.golang.org/grpc/internal/transport/http2_server.go : L428 : func (t *http2Server) HandleStreams\n        //>      HandleStreams receives incoming streams using the given handler\n        st.HandleStreams(func(stream *transport.Stream) {\n            wg.Add(1)\n            go func() {\n                defer wg.Done()\n                s.handleStream(st, stream, s.traceInfo(st, stream))\n            }()\n        }, func(ctx context.Context, method string) context.Context {\n            if !EnableTracing {\n                return ctx\n            }\n            tr := trace.New("grpc.Recv."+methodFamily(method), method)\n            return trace.NewContext(ctx, tr)\n        })\n        wg.Wait()\n    }\n\nhttp2Server.HandleStreams(handle func(*Stream), traceCtx func(context.Context, string) context.Context) {\n\tdefer close(t.readerDone)\n\tfor {\n\t\tframe, err := t.framer.fr.ReadFrame()\n\t\tatomic.StoreUint32(&t.activity, 1)\n\t\tif err != nil {\n\t\t\t...\n\t\t\tt.Close()\n\t\t\treturn\n\t\t}\n\t\tswitch frame := frame.(type) {\n\t\tcase *http2.MetaHeadersFrame:\n\t\t\tif t.operateHeaders(frame, handle, traceCtx) {  //> use handle only here\n\t\t\t\tt.Close()\n\t\t\t\tbreak\n\t\t\t}\n\t\tcase *http2.DataFrame:\n\t\t\tt.handleData(frame) //> 数据读取到的数据写入 stream 的 buf 中待处理\n                                //>     检查到 中的 http2.FlagDataEndStream 标记时，写入 io.EOF 到 stream 的 buf，标记流的结束\n                                //>     注意，framer 里的数据到下一次读取时会被重写，所以会以copy的方式到对应的buf 以备后续处理\n                                //> 流控，如果需要进行控制，发送 outgoingWindowUpdate 信息到 http2Server.controlBuf 中\n\t\tcase *http2.RSTStreamFrame:\n\t\t\tt.handleRSTStream(frame)\n\t\tcase *http2.SettingsFrame:\n\t\t\tt.handleSettings(frame)\n\t\tcase *http2.PingFrame:\n\t\t\tt.handlePing(frame)\n\t\tcase *http2.WindowUpdateFrame:\n\t\t\tt.handleWindowUpdate(frame) //> 流控，发送 incomingWindowUpdate 信息到 http2Server.controlBuf 中\n\t\tcase *http2.GoAwayFrame:\n\t\t\t// TODO: Handle GoAway from the client appropriately.\n\t\tdefault:\n\t\t\terrorf("transport: http2Server.HandleStreams found unhandled frame type %v.", frame)\n\t\t}\n\t}\n}\n\ngrpc.Server.handleStream  ::: google.golang.org/grpc/server.go : L1248\n    func (s *Server) handleStream(t transport.ServerTransport, stream *transport.Stream, trInfo *traceInfo) {\n        sm := stream.Method()\n        if sm != "" && sm[0] == \'/\' {\n            sm = sm[1:]\n        }\n        pos := strings.LastIndex(sm, "/")\n        if pos == -1 {\n            if trInfo != nil {\n                trInfo.tr.LazyLog(&fmtStringer{"Malformed method name %q", []interface{}{sm}}, true)\n                trInfo.tr.SetError()\n            }\n            errDesc := fmt.Sprintf("malformed method name: %q", stream.Method())\n            if err := t.WriteStatus(stream, status.New(codes.ResourceExhausted, errDesc)); err != nil {\n                if trInfo != nil {\n                    trInfo.tr.LazyLog(&fmtStringer{"%v", []interface{}{err}}, true)\n                    trInfo.tr.SetError()\n                }\n                grpclog.Warningf("grpc: Server.handleStream failed to write status: %v", err)\n            }\n            if trInfo != nil {\n                trInfo.tr.Finish()\n            }\n            return\n        }\n        service := sm[:pos]\n        method := sm[pos+1:]\n\n        srv, knownService := s.m[service]\n        if knownService {\n            if md, ok := srv.md[method]; ok {\n                s.processUnaryRPC(t, stream, srv, md, trInfo)\n                return\n            }\n            if sd, ok := srv.sd[method]; ok {\n                s.processStreamingRPC(t, stream, srv, sd, trInfo)\n                return\n            }\n        }\n        // Unknown service, or known server unknown method.\n        if unknownDesc := s.opts.unknownStreamDesc; unknownDesc != nil {\n            s.processStreamingRPC(t, stream, nil, unknownDesc, trInfo)\n            return\n        }\n        var errDesc string\n        if !knownService {\n            errDesc = fmt.Sprintf("unknown service %v", service)\n        } else {\n            errDesc = fmt.Sprintf("unknown method %v for service %v", method, service)\n        }\n        if trInfo != nil {\n            trInfo.tr.LazyPrintf("%s", errDesc)\n            trInfo.tr.SetError()\n        }\n        if err := t.WriteStatus(stream, status.New(codes.Unimplemented, errDesc)); err != nil {\n            if trInfo != nil {\n                trInfo.tr.LazyLog(&fmtStringer{"%v", []interface{}{err}}, true)\n                trInfo.tr.SetError()\n            }\n            grpclog.Warningf("grpc: Server.handleStream failed to write status: %v", err)\n        }\n        if trInfo != nil {\n            trInfo.tr.Finish()\n        }\n    }\n\nnewHTTP2Server : google.golang.org/grpc/internal/transport/http2_server.go : L126\n    func newHTTP2Server(conn net.Conn, config *ServerConfig) (_ ServerTransport, err error) {\n        ... //> 为构造 http2Server 准备参数\n        ctx, cancel := context.WithCancel(context.Background())\n        t := &http2Server{\n            ctx:               ctx,\n            cancel:            cancel,\n            ctxDone:           ctx.Done(),\n            conn:              conn,\n            remoteAddr:        conn.RemoteAddr(),\n            localAddr:         conn.LocalAddr(),\n            authInfo:          config.AuthInfo,\n            framer:            framer,\n            readerDone:        make(chan struct{}),\n            writerDone:        make(chan struct{}),\n            maxStreams:        maxStreams,\n            inTapHandle:       config.InTapHandle,\n            fc:                &trInFlow{limit: uint32(icwz)},\n            state:             reachable,\n            activeStreams:     make(map[uint32]*Stream),\n            stats:             config.StatsHandler,\n            kp:                kp,\n            idle:              time.Now(),\n            kep:               kep,\n            initialWindowSize: iwz,\n            czData:            new(channelzData),\n        }\n        t.controlBuf = newControlBuffer(t.ctxDone)\n        if dynamicWindow {\n            t.bdpEst = &bdpEstimator{\n                bdp:               initialWindowSize,\n                updateFlowControl: t.updateFlowControl,\n            }\n        }\n        ...\n        ...  //> 处理 client preface.\n        go func() {\n            t.loopy = newLoopyWriter(serverSide, t.framer, t.controlBuf, t.bdpEst)\n            t.loopy.ssGoAwayHandler = t.outgoingGoAwayHandler\n            if err := t.loopy.run(); err != nil {\n                errorf("transport: loopyWriter.run returning. Err: %v", err)\n            }\n            t.conn.Close()\n            close(t.writerDone)\n        }()\n        go t.keepalive()\n        return t, nil\n    }\n\n//> conn 1---\x3en streams(以 linked-list 保存) 1---\x3en frames(以 linked-list 保存)\ntype loopyWriter struct{} : google.golang.org/grpc/internal/transport/controlbuf.go : L364\n    activeStreams is a linked-list of all streams that have data to send and some  stream-level flow control quota.\n    Each of these streams internally have a list of data items(and perhaps trailers on the server-side) to be sent out.\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n200\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n',normalizedContent:'# grpc source notes\n\ngrpc.server.serve(lis net.listener)  ::: google.golang.org/grpc/server.go : l545 :\n    ....\n    for {\n\t\trawconn, err := lis.accept()\n        ...\n        s.servewg.add(1)\n\t\tgo func() {\n\t\t\ts.handlerawconn(rawconn)\n\t\t\ts.servewg.done()\n\t\t}()\n    }\n\ngrpc.server.handlerawconn()\n    ...\n    // finish handshaking (http2)\n\tst := s.newhttp2transport(conn, authinfo)  //> google.golang.org/grpc/internal/transport/transport.go : l488\n                                               //>   google.golang.org/grpc/internal/transport/http2_server.go : l126 : http2server : 主要逻辑所在地\n                                               //>   http2server is an implementation of interface transport.servertransport\n                                               //>     go func(){ ... t.loopy.run() ...}() ：l276\n                                               //>     go t.keepalive() : l282\n\t                                           //>   http2server 重要成员：\n\t                                           //>     framer\n\t                                           //>     \t    writer: w : newbufwriter(conn, writebuffersize),\n\t                                           //>     \t    fr:     http2.newframer(w, r),    w,r都是conn的reader\n\t                                           //>     \t\t\t    golang.org/x/net/http2/frame.go ：l432\n\t                                           //>     conn\n\t                                           //>     controlbuf : 一个数据list\n\t                                           //>     loopy : loopywriter : google.golang.org/grpc/internal/transport/controlbuf.go : l388\n                                               //>       run() : l420\n                                               //>         注意 processdata 时数据超过 16k 时的处理: 两层流控：stream-level 和 connection-level\n\tif st == nil {\n\t\treturn\n\t}\n\n\trawconn.setdeadline(time.time{})\n\tif !s.addconn(st) {\n\t\treturn\n\t}\n\tgo func() {\n\t\ts.servestreams(st)\n\t\ts.removeconn(st)\n\t}()\n\ngrpc.server.servestreams()\n    func (s *server) servestreams(st transport.servertransport) {\n        defer st.close()\n        var wg sync.waitgroup\n        //> google.golang.org/grpc/internal/transport/http2_server.go : l428 : func (t *http2server) handlestreams\n        //>      handlestreams receives incoming streams using the given handler\n        st.handlestreams(func(stream *transport.stream) {\n            wg.add(1)\n            go func() {\n                defer wg.done()\n                s.handlestream(st, stream, s.traceinfo(st, stream))\n            }()\n        }, func(ctx context.context, method string) context.context {\n            if !enabletracing {\n                return ctx\n            }\n            tr := trace.new("grpc.recv."+methodfamily(method), method)\n            return trace.newcontext(ctx, tr)\n        })\n        wg.wait()\n    }\n\nhttp2server.handlestreams(handle func(*stream), tracectx func(context.context, string) context.context) {\n\tdefer close(t.readerdone)\n\tfor {\n\t\tframe, err := t.framer.fr.readframe()\n\t\tatomic.storeuint32(&t.activity, 1)\n\t\tif err != nil {\n\t\t\t...\n\t\t\tt.close()\n\t\t\treturn\n\t\t}\n\t\tswitch frame := frame.(type) {\n\t\tcase *http2.metaheadersframe:\n\t\t\tif t.operateheaders(frame, handle, tracectx) {  //> use handle only here\n\t\t\t\tt.close()\n\t\t\t\tbreak\n\t\t\t}\n\t\tcase *http2.dataframe:\n\t\t\tt.handledata(frame) //> 数据读取到的数据写入 stream 的 buf 中待处理\n                                //>     检查到 中的 http2.flagdataendstream 标记时，写入 io.eof 到 stream 的 buf，标记流的结束\n                                //>     注意，framer 里的数据到下一次读取时会被重写，所以会以copy的方式到对应的buf 以备后续处理\n                                //> 流控，如果需要进行控制，发送 outgoingwindowupdate 信息到 http2server.controlbuf 中\n\t\tcase *http2.rststreamframe:\n\t\t\tt.handlerststream(frame)\n\t\tcase *http2.settingsframe:\n\t\t\tt.handlesettings(frame)\n\t\tcase *http2.pingframe:\n\t\t\tt.handleping(frame)\n\t\tcase *http2.windowupdateframe:\n\t\t\tt.handlewindowupdate(frame) //> 流控，发送 incomingwindowupdate 信息到 http2server.controlbuf 中\n\t\tcase *http2.goawayframe:\n\t\t\t// todo: handle goaway from the client appropriately.\n\t\tdefault:\n\t\t\terrorf("transport: http2server.handlestreams found unhandled frame type %v.", frame)\n\t\t}\n\t}\n}\n\ngrpc.server.handlestream  ::: google.golang.org/grpc/server.go : l1248\n    func (s *server) handlestream(t transport.servertransport, stream *transport.stream, trinfo *traceinfo) {\n        sm := stream.method()\n        if sm != "" && sm[0] == \'/\' {\n            sm = sm[1:]\n        }\n        pos := strings.lastindex(sm, "/")\n        if pos == -1 {\n            if trinfo != nil {\n                trinfo.tr.lazylog(&fmtstringer{"malformed method name %q", []interface{}{sm}}, true)\n                trinfo.tr.seterror()\n            }\n            errdesc := fmt.sprintf("malformed method name: %q", stream.method())\n            if err := t.writestatus(stream, status.new(codes.resourceexhausted, errdesc)); err != nil {\n                if trinfo != nil {\n                    trinfo.tr.lazylog(&fmtstringer{"%v", []interface{}{err}}, true)\n                    trinfo.tr.seterror()\n                }\n                grpclog.warningf("grpc: server.handlestream failed to write status: %v", err)\n            }\n            if trinfo != nil {\n                trinfo.tr.finish()\n            }\n            return\n        }\n        service := sm[:pos]\n        method := sm[pos+1:]\n\n        srv, knownservice := s.m[service]\n        if knownservice {\n            if md, ok := srv.md[method]; ok {\n                s.processunaryrpc(t, stream, srv, md, trinfo)\n                return\n            }\n            if sd, ok := srv.sd[method]; ok {\n                s.processstreamingrpc(t, stream, srv, sd, trinfo)\n                return\n            }\n        }\n        // unknown service, or known server unknown method.\n        if unknowndesc := s.opts.unknownstreamdesc; unknowndesc != nil {\n            s.processstreamingrpc(t, stream, nil, unknowndesc, trinfo)\n            return\n        }\n        var errdesc string\n        if !knownservice {\n            errdesc = fmt.sprintf("unknown service %v", service)\n        } else {\n            errdesc = fmt.sprintf("unknown method %v for service %v", method, service)\n        }\n        if trinfo != nil {\n            trinfo.tr.lazyprintf("%s", errdesc)\n            trinfo.tr.seterror()\n        }\n        if err := t.writestatus(stream, status.new(codes.unimplemented, errdesc)); err != nil {\n            if trinfo != nil {\n                trinfo.tr.lazylog(&fmtstringer{"%v", []interface{}{err}}, true)\n                trinfo.tr.seterror()\n            }\n            grpclog.warningf("grpc: server.handlestream failed to write status: %v", err)\n        }\n        if trinfo != nil {\n            trinfo.tr.finish()\n        }\n    }\n\nnewhttp2server : google.golang.org/grpc/internal/transport/http2_server.go : l126\n    func newhttp2server(conn net.conn, config *serverconfig) (_ servertransport, err error) {\n        ... //> 为构造 http2server 准备参数\n        ctx, cancel := context.withcancel(context.background())\n        t := &http2server{\n            ctx:               ctx,\n            cancel:            cancel,\n            ctxdone:           ctx.done(),\n            conn:              conn,\n            remoteaddr:        conn.remoteaddr(),\n            localaddr:         conn.localaddr(),\n            authinfo:          config.authinfo,\n            framer:            framer,\n            readerdone:        make(chan struct{}),\n            writerdone:        make(chan struct{}),\n            maxstreams:        maxstreams,\n            intaphandle:       config.intaphandle,\n            fc:                &trinflow{limit: uint32(icwz)},\n            state:             reachable,\n            activestreams:     make(map[uint32]*stream),\n            stats:             config.statshandler,\n            kp:                kp,\n            idle:              time.now(),\n            kep:               kep,\n            initialwindowsize: iwz,\n            czdata:            new(channelzdata),\n        }\n        t.controlbuf = newcontrolbuffer(t.ctxdone)\n        if dynamicwindow {\n            t.bdpest = &bdpestimator{\n                bdp:               initialwindowsize,\n                updateflowcontrol: t.updateflowcontrol,\n            }\n        }\n        ...\n        ...  //> 处理 client preface.\n        go func() {\n            t.loopy = newloopywriter(serverside, t.framer, t.controlbuf, t.bdpest)\n            t.loopy.ssgoawayhandler = t.outgoinggoawayhandler\n            if err := t.loopy.run(); err != nil {\n                errorf("transport: loopywriter.run returning. err: %v", err)\n            }\n            t.conn.close()\n            close(t.writerdone)\n        }()\n        go t.keepalive()\n        return t, nil\n    }\n\n//> conn 1---\x3en streams(以 linked-list 保存) 1---\x3en frames(以 linked-list 保存)\ntype loopywriter struct{} : google.golang.org/grpc/internal/transport/controlbuf.go : l364\n    activestreams is a linked-list of all streams that have data to send and some  stream-level flow control quota.\n    each of these streams internally have a list of data items(and perhaps trailers on the server-side) to be sent out.\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n200\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n',charsets:{cjk:!0}},{title:"http/2.0 and http/2.0 in Go",frontmatter:{title:"http/2.0 and http/2.0 in Go",date:"2019-01-05T00:00:00.000Z",description:"http/2.0 and http/2.0 in Go",categories:["network","http2"],tags:[null],permalink:null},regularPath:"/blog/network/http2/http2_in_go.html",relativePath:"blog/network/http2/http2_in_go.md",key:"v-32fca817",path:"/blog/network/http2/http2_in_go.html",headers:[{level:2,title:"1、准备",slug:"_1、准备",normalizedTitle:"1、准备",charIndex:34},{level:2,title:"2、http/2.0 特性",slug:"_2、http-2-0-特性",normalizedTitle:"2、http/2.0 特性",charIndex:1256},{level:2,title:"3、Go: package net and net/http",slug:"_3、go-package-net-and-net-http",normalizedTitle:"3、go: package net and net/http",charIndex:1274},{level:3,title:"3.1 net",slug:"_3-1-net",normalizedTitle:"3.1 net",charIndex:1355},{level:3,title:"3.2 net.http",slug:"_3-2-net-http",normalizedTitle:"3.2 net.http",charIndex:2183},{level:2,title:"4、server使用http/2.0",slug:"_4、server使用http-2-0",normalizedTitle:"4、server使用http/2.0",charIndex:4766},{level:3,title:"4.1 使用 golang.org.x.net.http2.ConfigureServer",slug:"_4-1-使用-golang-org-x-net-http2-configureserver",normalizedTitle:"4.1 使用 golang.org.x.net.http2.configureserver",charIndex:4789},{level:3,title:"4.2 使用 golang.org.x.net.http2.h2c",slug:"_4-2-使用-golang-org-x-net-http2-h2c",normalizedTitle:"4.2 使用 golang.org.x.net.http2.h2c",charIndex:11429},{level:2,title:"5、Next",slug:"_5、next",normalizedTitle:"5、next",charIndex:14906},{level:2,title:"6、End",slug:"_6、end",normalizedTitle:"6、end",charIndex:15024}],headersStr:"1、准备 2、http/2.0 特性 3、Go: package net and net/http 3.1 net 3.2 net.http 4、server使用http/2.0 4.1 使用 golang.org.x.net.http2.ConfigureServer 4.2 使用 golang.org.x.net.http2.h2c 5、Next 6、End",content:'# http/2.0 and http/2.0 in Go\n\n\n# 1、准备\n\n * reference\n   * Go源码：https://github.com/golang/go - tag:1.12.4\n * http/2.0 tools\n   * Browser Indicators\n     * chrome extension : HTTP/2 and SPDY indicator\n   * curl\n     * cmd:\n       * curl -vso /dev/null --http2 https://www.cloudflare.com/\n     * note:\n       * --http2 option that causes it to use HTTP/2 (if it can).\n       * chrome 只支持了基于ALPN 的 HTTP 2.0 服务。不再支持 NPN 的 HTTP 2.0 服务。\n * note\n   * TLS 的扩展协议：SNI, NPN, ALPN : [通过扩展ClientHello/ServerHello消息为TLS增加新的功能]\n     * SNI(Server Name Indication)\n       * SNI指定了 TLS 握手时要连接的主机名。 SNI 协议是为了支持同一个 IP(和端口)支持多个域名。\n         * 因为在 TLS 握手期间服务器需要发送证书(Certificate)给客户端，为此需要知道客户请求的域名(因为不同域名的证书可能是不一样的)。\n           * 这时有同学要问了，要连接的主机名不就是发起 HTTP 时的 Host 么? TLS Handshake 时 HTTP 交互还没开始，自然 HTTP 头部还没到达服务器。\n     * NPN(Next Protocol Negotiation)\n       * NPN 是 Google 在 SPDY 中开发的一个 TLS 扩展。\n       * NPN 是利用 TLS 握手中的 ServerHello 消息，在其中追加 ProtocolNameList 字段包含自己支持的应用层协议，客户端检查该字段，并在之后的 ClientKeyExChange 消息中以 ProtocolName 字段返回选中的协议。\n     * ALPN(Application-Layer Protocol Negotiation)\n       * ALPN 则是客户端先声明自己支持的协议 (ClientHello)，服务器选择并确认协议 (ServerHello)。这样颠倒的目的主要是使 ALPN 与其他协议协商标准保持一致 (如 SSL)。\n   * TLS(Transport Layer Security)/SSL\n     * TLS的前身是SSL，TLS 1.0通常被标示为SSL 3.1\n\n\n# 2、http/2.0 特性\n\n\n# 3、Go: package net and net/http\n\n开始http/2.0之前，我们先回顾下Go的两个网络包：net and net/http\n\n\n# 3.1 net\n\n * net\n   * note\n     \n         Package net provides a portable interface for network I/O, including TCP/IP, UDP, domain name resolution, and Unix domain sockets.\n     \n     \n     1\n     \n   * net.conn : interface\n     * implementation\n       * UnixConn <--- DialUnix | ListenUnixgram\n       * UDPConn <--- DialUDP | ListenMulticastUDP | ListenUDP\n       * TCPConn <--- DialTCP\n       * IPConn <--- DialIP | ListenIP\n   * net.Listener : interface\n     * implementation\n       * UnixListener <--- ListenUnix\n       * TCPListener <--- ListenTCP\n   * net.Addr : interface\n     * implementation\n       * UnixAddr <--- ResolveUnixAddr\n       * UDPAddr <--- ResolveUDPAddr\n       * TCPAddr <--- ResolveTCPAddr\n       * IPAddr <--- ResolveIPAddr\n   * other\n     * 处理：DNS NS/MX/SRV 、HOST、CIDR、HardwareAddr 、IP/IPMask/IPNet\n\n\n# 3.2 net.http\n\n * net.http.Client\n   * dependency\n     * interface: RoundTripper\n       * method\n         * RoundTrip(*Request) (*Response, error)\n           * note\n             \n                 RoundTripper is an interface representing the ability to execute a single HTTP transaction, obtaining the Response for a given Request.\n                 A RoundTripper must be safe for concurrent use by multiple goroutines.\n             \n             \n             1\n             2\n             \n       * implementation\n         * net.http.Transport\n           * note\n             \n                 A Transport is a low-level primitive for making HTTP and HTTPS requests.\n             \n             \n             1\n             \n * net.http.Server\n   * dependency\n     * net.http.Handler : interface\n       * note\n         * handler to invoke, http.DefaultServeMux if nil\n       * method\n         * ServeHTTP(w ResponseWriter, r *Request)\n       * implementation\n         * net.http.ServeMux\n           * note:\n             * ServeMux is an HTTP request multiplexer.\n             * 通过 ServeHTTP 接管请求，然后再根据 pattern 路由到具体的handler\n         * net.http.HandlerFunc\n           * 将 func(ResponseWriter, *Request) 函数转换为 net.http.Handler 接口的实现\n             \n             type HandlerFunc func(ResponseWriter, *Request)\n             func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) \n                 ServeHTTP calls f(w, r)\n             \n             \n             1\n             2\n             3\n             \n       * usage:\n         * 生成一些常用的 handler\n           * net.http: func FileServer(root FileSystem) Handler\n           * net.http: func NotFoundHandler() Handler\n           * net.http: func RedirectHandler(url string, code int) Handler\n           * net.http: func StripPrefix(prefix string, h Handler) Handler\n           * net.http: func TimeoutHandler(h Handler, dt time.Duration, msg string) Handler\n           * net.http: func FileServer(root FileSystem) Handler\n             * note\n               * FileServer returns a handler that serves HTTP requests with the contents of the file system rooted at root.\n             * dependency\n               * interface : net.http.FileSystem\n                 * implementation\n                   * net.http.Dir\n               * interface : net.http.File\n     * net.http.Request\n     * net.http.Response\n     * net.http.ResponseWriter : interface\n       * implemented\n         * net.http.Pusher : interface\n           * note: for HTTP/2 server push\n         * net.http.Flusher : interface\n         * net.http.Hijacker : interface\n\n\n# 4、server使用http/2.0\n\n\n# 4.1 使用 golang.org.x.net.http2.ConfigureServer\n\n//> golang.org\\x\\net\\http2\\server.go : L205\n    func ConfigureServer(s *http.Server, conf *Server) error {\n        \n        ...\n\n        haveNPN := false\n        for _, p := range s.TLSConfig.NextProtos {\n            if p == NextProtoTLS {\n                haveNPN = true\n                break\n            }\n        }\n        if !haveNPN {\n            s.TLSConfig.NextProtos = append(s.TLSConfig.NextProtos, NextProtoTLS)\n        }\n\n        if s.TLSNextProto == nil {\n            s.TLSNextProto = map[string]func(*http.Server, *tls.Conn, http.Handler){}\n        }\n        protoHandler := func(hs *http.Server, c *tls.Conn, h http.Handler) {\n            if testHookOnConn != nil {\n                testHookOnConn()\n            }\n            conf.ServeConn(c, &ServeConnOpts{\n                Handler:    h,\n                BaseConfig: hs,\n            })\n        }\n        s.TLSNextProto[NextProtoTLS] = protoHandler\n        return nil\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n从上述代码可以看到核心在于：\n\n * 将 NextProtoTLS 附加在 net.http.Server.TLSConfig.NextProtos 尾部\n * 将 NextProtoTLS : protoHandler 插入到 net.http.Server.TLSNextProto 中\n\n由此，我们可以推测，在 net.http.Server 接收到连接请求时，会在某个时机使用这两个对象：在真是 serve 时调用 protoHandler 进行处理。接下来，我们看看 net.http.Server 的工作流程。\n\n在分析 net.http.Server 代码后，发现：服务启动的 ListenAndServe 和 ListenAndServeTLS 函数，最终都会走到 ServeTLS 和 Serve 函数。我们先来看看 ServeTLS 的实现：\n\n//> net\\http\\server.go : L2928\n    func (srv *Server) ServeTLS(l net.Listener, certFile, keyFile string) error {\n        // Setup HTTP/2 before srv.Serve, to initialize srv.TLSConfig\n        // before we clone it and create the TLS Listener.\n        if err := srv.setupHTTP2_ServeTLS(); err != nil {\n            return err\n        }\n\n        config := cloneTLSConfig(srv.TLSConfig)\n        if !strSliceContains(config.NextProtos, "http/1.1") {\n            config.NextProtos = append(config.NextProtos, "http/1.1")\n        }\n\n        ...\n\n        tlsListener := tls.NewListener(l, config)\n        return srv.Serve(tlsListener)\n    }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n这块代码有几个地方很重要：\n\n * 通过 setupHTTP2_ServeTLS 安装http2支持，从函数名就可以看出，go 提供的库只支持了带 tls 的 http2.0\n   \n   * 它会调用到 ：\n   \n   //> net\\http\\server.go : L3141\n       func (srv *Server) onceSetNextProtoDefaults() {\n           if strings.Contains(os.Getenv("GODEBUG"), "http2server=0") {\n               return\n           }\n           // Enable HTTP/2 by default if the user hasn\'t otherwise\n           // configured their TLSNextProto map.\n           if srv.TLSNextProto == nil {\n               conf := &http2Server{\n                   NewWriteScheduler: func() http2WriteScheduler { return http2NewPriorityWriteScheduler(nil) },\n               }\n               srv.nextProtoErr = http2ConfigureServer(srv, conf)\n           }\n       }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   \n   \n   先看是否通过环境变量禁用了http2的支持，再在 srv.TLSNextProto == nil 时通过 http2ConfigureServer 添加 http2.0 的支持。\n   \n       //> net\\http\\h2_bundle.go : L3763\n       func http2ConfigureServer(s *Server, conf *http2Server) error {\n           ...\n       }\n   \n   \n   1\n   2\n   3\n   4\n   \n   \n   通过分析 http2ConfigureServer, 发现它和golang.org.x.net.http2.ConfigureServer的处理流程几乎完全一样，也就是说net/http默认就支持了http2.0, 只不过完全采用完全默认的 http2Server 配置。\n   \n   另外，注意到：只有当 srv.TLSNextProto == nil 时才添加 http2.0 的支持，费解~\n\n * 调用 cloneTLSConfig 拷贝 TLSConfig 配置\n\n * 添加一个默认的处理协议 "http/1.1" 到 TLSConfig.NextProtos\n\n * 调用 Serve 函数，并传递参数：通过 net.Listener 和 TLSConfig 构造的 tls.listener 对象 tlsListener\n   \n   * 注意，最终也是调用了 Serve 函数，也就是说 Serve 函数既要处理 http 也要处理 https\n\n接下来我们看看 Serve 的实现：\n\n//> net\\http\\server.go : L2850\n    func (srv *Server) Serve(l net.Listener) error {\n        ...\n        if err := srv.setupHTTP2_Serve(); err != nil {\n            return err\n        }\n        ...\n        ctx := context.WithValue(baseCtx, ServerContextKey, srv)\n        for {\n            rw, e := l.Accept()\n            if e != nil {\n                select {\n                case <-srv.getDoneChan():\n                    return ErrServerClosed\n                default:\n                }\n                if ne, ok := e.(net.Error); ok && ne.Temporary() {\n                    ...\n                    continue\n                }\n                return e\n            }\n            if cc := srv.ConnContext; cc != nil {\n                ctx = cc(ctx, rw)\n                if ctx == nil {\n                    panic("ConnContext returned nil")\n                }\n            }\n            tempDelay = 0\n            c := srv.newConn(rw)\n            c.setState(c.rwc, StateNew) // before Serve can return\n            go c.serve(ctx)\n        }\n    }\n\n\n//> net\\http\\server.go : L3132\n    func (srv *Server) onceSetNextProtoDefaults_Serve() {\n        if srv.shouldConfigureHTTP2ForServe() {\n            srv.onceSetNextProtoDefaults()\n        }\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n\n\nsetupHTTP2_Serve 最终调用了 onceSetNextProtoDefaults_Serve，看看它的实现，what ? setupHTTP2_Serve 什么鬼~ 又调用一次 onceSetNextProtoDefaults，这个其实是为了处理：调用 ListenAndServe 但是配置了 TLSConfig 的情形\n\n将 net.Conn 对象 rw 通过 srv.newConn 封装到一个新的 net.http.Server.conn 对象，并启动一个goroutine调用 conn.serve 处理新接收到的连接请求。\n\n注意，每次 accept 一个连接请求，net.http 都会创建一个 goroutine，问题来了，如果突然间涌入大量连接请求会发生什么？\n\n//> net\\http\\server.go : L1759\n    func (c *conn) serve(ctx context.Context) {\n        ...\n        if tlsConn, ok := c.rwc.(*tls.Conn); ok {\n            ...\n            if err := tlsConn.Handshake(); err != nil {\n                ...\n                return\n            }\n            c.tlsState = new(tls.ConnectionState)\n            *c.tlsState = tlsConn.ConnectionState()\n            if proto := c.tlsState.NegotiatedProtocol; validNPN(proto) {\n                if fn := c.server.TLSNextProto[proto]; fn != nil {\n                    h := initNPNRequest{tlsConn, serverHandler{c.server}}\n                    fn(c.server, tlsConn, h)\n                }\n                return\n            }\n        }\n\n        // HTTP/1.x from here on.\n\n        ...\n\n        for {\n            w, err := c.readRequest(ctx)\n            ...\n            serverHandler{c.server}.ServeHTTP(w, w.req)\n            ...\n        }\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n通过上述代码可以看出，如果是 tls 连接，则先处理 tls握手协议，然后根据 TLSNextProto 调用对应协议的serverHandler; 如果是普通连接，则进入 for 循环读取数据，并调用 ServeHTTP 进行处理。\n\n此时，我们可以确认，http2.0 在连接建立之后，会调用 protoHandler 接管数据的处理。同时，需要注意，readRequest 处理了数据包转换为 http 请求的动作，同样的protoHandler 也会处理 frame 转换为 http 请求的动作，以兼容http1.1的语法。\n\n\n# 4.2 使用 golang.org.x.net.http2.h2c\n\nh2c 的主要目的是提供一个 non-TLS 版本的 http/2.0, 这个包只提供了一个函数：NewHandler。使用时，将其返回值当作普通的handler使用即可。\n\n//> golang.org\\x\\net\\http2\\h2c\\h2c.go : L64\n    func NewHandler(h http.Handler, s *http2.Server) http.Handler {\n        return &h2cHandler{\n            Handler: h,\n            s:       s,\n        }\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n从上述代码可以看到，NewHandler 只是使用 http.Hander 和 http2.Server 封装了一个 h2cHandler。当 net/http 的连接建立后，会调用 h2cHandler 对象的 ServeHTTP 处理函数。\n\n//> golang.org\\x\\net\\http2\\h2c\\h2c.go : L72\n    func (s h2cHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n        // Handle h2c with prior knowledge (RFC 7540 Section 3.4)\n        if r.Method == "PRI" && len(r.Header) == 0 && r.URL.Path == "*" && r.Proto == "HTTP/2.0" {\n            ...\n            conn, err := initH2CWithPriorKnowledge(w)\n            if err != nil {\n                ...\n                return\n            }\n            defer conn.Close()\n\n            s.s.ServeConn(conn, &http2.ServeConnOpts{Handler: s.Handler})\n            return\n        }\n        // Handle Upgrade to h2c (RFC 7540 Section 3.2)\n        if conn, err := h2cUpgrade(w, r); err == nil {\n            defer conn.Close()\n\n            s.s.ServeConn(conn, &http2.ServeConnOpts{Handler: s.Handler})\n            return\n        }\n\n        s.Handler.ServeHTTP(w, r)\n        return\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n很明显，当满足条件时会调用 http2.Server 的 ServeConn 进行处理，进入 ServeConn 后就是常规的 http2 处理流程，这里就先不深入了。这里有两种升级方式：\n\n * r.Method == "PRI"\n   * 通过使用 PRI 标识当前发送的是一个前言，紧接着就会发送http/2.0的frame了。前言数据以：PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n 开始。go 的 http2.Transport 就是使用这种方式来构建http/2.0连接。\n * h2cUpgrade\n   * 使用 http/1.1 通过头部信息 Connection: Upgrade, HTTP2-Settings 和 Upgrade: h2c 标识需要升级以及通过HTTP2-Settings来设置http/2.0的连接信息。其中 HTTP2-Settings 是以 base64url 编码。 curl -k --http2 http://localhost:8972?data=curltest 就是使用这种方式。\n\n我们来看看 h2cUpgrade 的实现方式：\n\n//> golang.org\\x\\net\\http2\\h2c\\h2c.go : L161\n    func h2cUpgrade(w http.ResponseWriter, r *http.Request) (net.Conn, error) {\n        if !isH2CUpgrade(r.Header) {\n            return nil, errors.New("non-conforming h2c headers")\n        }\n\n        // Initial bytes we put into conn to fool http2 server\n        initBytes, _, err := convertH1ReqToH2(r)\n        if err != nil {\n            return nil, err\n        }\n\n        hijacker, ok := w.(http.Hijacker)\n        if !ok {\n            return nil, errors.New("hijack not supported.")\n        }\n        conn, rw, err := hijacker.Hijack()\n        if err != nil {\n            return nil, fmt.Errorf("hijack failed: %v", err)\n        }\n\n        rw.Write([]byte("HTTP/1.1 101 Switching Protocols\\r\\n" +\n            "Connection: Upgrade\\r\\n" +\n            "Upgrade: h2c\\r\\n\\r\\n"))\n        rw.Flush()\n\n        // A conforming client will now send an H2 client preface which need to drain\n        // since we already sent this.\n        if err := drainClientPreface(rw); err != nil {\n            return nil, err\n        }\n\n        c := &rwConn{\n            Conn:      conn,\n            Reader:    io.MultiReader(initBytes, rw),\n            BufWriter: newSettingsAckSwallowWriter(rw.Writer),\n        }\n        return c, nil\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\nh2cUpgrade 先通过 isH2CUpgrade 判断是否能够进行协议升级，然后再利用 http.Hijacker 完全接管连接，包括数据读写，并构成新的连接对象以供 http2.Server.ServerConn 进行 http2 协议处理数据成 net.http 的 ResponseWriter, *Request 对象。\n\n\n# 5、Next\n\nhttp2.0 in grpc\n\n对 client 发起请求的核心 net.http.Transport 进行解读\n\n对 websocket 的包 golang.org.x.net.websocket 进行解读\n\n\n# 6、End\n\n * reference\n   \n   * [https://blog.cloudflare.com/tools-for-debugging-testing-and-using-http-2/]\n   * Go http2 和 h2c\n   * rfc - h2c\n   * rfc - pri\n   * rfc - HTTPLayer\n   * rfc - streamid=0x01\n     \n         HTTP/1.1 requests that are upgraded to HTTP/2 (see Section 3.2) are responded to with a stream identifier of one (0x1).\n         After the upgrade completes, stream 0x1 is "half-closed (local)" to the client. \n         Therefore, stream 0x1 cannot be selected as a new stream identifier by a client that upgrades from HTTP/1.1.\n     \n     \n     1\n     2\n     3\n     \n   * htt2\n\n * sample\n   \n   * github',normalizedContent:'# http/2.0 and http/2.0 in go\n\n\n# 1、准备\n\n * reference\n   * go源码：https://github.com/golang/go - tag:1.12.4\n * http/2.0 tools\n   * browser indicators\n     * chrome extension : http/2 and spdy indicator\n   * curl\n     * cmd:\n       * curl -vso /dev/null --http2 https://www.cloudflare.com/\n     * note:\n       * --http2 option that causes it to use http/2 (if it can).\n       * chrome 只支持了基于alpn 的 http 2.0 服务。不再支持 npn 的 http 2.0 服务。\n * note\n   * tls 的扩展协议：sni, npn, alpn : [通过扩展clienthello/serverhello消息为tls增加新的功能]\n     * sni(server name indication)\n       * sni指定了 tls 握手时要连接的主机名。 sni 协议是为了支持同一个 ip(和端口)支持多个域名。\n         * 因为在 tls 握手期间服务器需要发送证书(certificate)给客户端，为此需要知道客户请求的域名(因为不同域名的证书可能是不一样的)。\n           * 这时有同学要问了，要连接的主机名不就是发起 http 时的 host 么? tls handshake 时 http 交互还没开始，自然 http 头部还没到达服务器。\n     * npn(next protocol negotiation)\n       * npn 是 google 在 spdy 中开发的一个 tls 扩展。\n       * npn 是利用 tls 握手中的 serverhello 消息，在其中追加 protocolnamelist 字段包含自己支持的应用层协议，客户端检查该字段，并在之后的 clientkeyexchange 消息中以 protocolname 字段返回选中的协议。\n     * alpn(application-layer protocol negotiation)\n       * alpn 则是客户端先声明自己支持的协议 (clienthello)，服务器选择并确认协议 (serverhello)。这样颠倒的目的主要是使 alpn 与其他协议协商标准保持一致 (如 ssl)。\n   * tls(transport layer security)/ssl\n     * tls的前身是ssl，tls 1.0通常被标示为ssl 3.1\n\n\n# 2、http/2.0 特性\n\n\n# 3、go: package net and net/http\n\n开始http/2.0之前，我们先回顾下go的两个网络包：net and net/http\n\n\n# 3.1 net\n\n * net\n   * note\n     \n         package net provides a portable interface for network i/o, including tcp/ip, udp, domain name resolution, and unix domain sockets.\n     \n     \n     1\n     \n   * net.conn : interface\n     * implementation\n       * unixconn <--- dialunix | listenunixgram\n       * udpconn <--- dialudp | listenmulticastudp | listenudp\n       * tcpconn <--- dialtcp\n       * ipconn <--- dialip | listenip\n   * net.listener : interface\n     * implementation\n       * unixlistener <--- listenunix\n       * tcplistener <--- listentcp\n   * net.addr : interface\n     * implementation\n       * unixaddr <--- resolveunixaddr\n       * udpaddr <--- resolveudpaddr\n       * tcpaddr <--- resolvetcpaddr\n       * ipaddr <--- resolveipaddr\n   * other\n     * 处理：dns ns/mx/srv 、host、cidr、hardwareaddr 、ip/ipmask/ipnet\n\n\n# 3.2 net.http\n\n * net.http.client\n   * dependency\n     * interface: roundtripper\n       * method\n         * roundtrip(*request) (*response, error)\n           * note\n             \n                 roundtripper is an interface representing the ability to execute a single http transaction, obtaining the response for a given request.\n                 a roundtripper must be safe for concurrent use by multiple goroutines.\n             \n             \n             1\n             2\n             \n       * implementation\n         * net.http.transport\n           * note\n             \n                 a transport is a low-level primitive for making http and https requests.\n             \n             \n             1\n             \n * net.http.server\n   * dependency\n     * net.http.handler : interface\n       * note\n         * handler to invoke, http.defaultservemux if nil\n       * method\n         * servehttp(w responsewriter, r *request)\n       * implementation\n         * net.http.servemux\n           * note:\n             * servemux is an http request multiplexer.\n             * 通过 servehttp 接管请求，然后再根据 pattern 路由到具体的handler\n         * net.http.handlerfunc\n           * 将 func(responsewriter, *request) 函数转换为 net.http.handler 接口的实现\n             \n             type handlerfunc func(responsewriter, *request)\n             func (f handlerfunc) servehttp(w responsewriter, r *request) \n                 servehttp calls f(w, r)\n             \n             \n             1\n             2\n             3\n             \n       * usage:\n         * 生成一些常用的 handler\n           * net.http: func fileserver(root filesystem) handler\n           * net.http: func notfoundhandler() handler\n           * net.http: func redirecthandler(url string, code int) handler\n           * net.http: func stripprefix(prefix string, h handler) handler\n           * net.http: func timeouthandler(h handler, dt time.duration, msg string) handler\n           * net.http: func fileserver(root filesystem) handler\n             * note\n               * fileserver returns a handler that serves http requests with the contents of the file system rooted at root.\n             * dependency\n               * interface : net.http.filesystem\n                 * implementation\n                   * net.http.dir\n               * interface : net.http.file\n     * net.http.request\n     * net.http.response\n     * net.http.responsewriter : interface\n       * implemented\n         * net.http.pusher : interface\n           * note: for http/2 server push\n         * net.http.flusher : interface\n         * net.http.hijacker : interface\n\n\n# 4、server使用http/2.0\n\n\n# 4.1 使用 golang.org.x.net.http2.configureserver\n\n//> golang.org\\x\\net\\http2\\server.go : l205\n    func configureserver(s *http.server, conf *server) error {\n        \n        ...\n\n        havenpn := false\n        for _, p := range s.tlsconfig.nextprotos {\n            if p == nextprototls {\n                havenpn = true\n                break\n            }\n        }\n        if !havenpn {\n            s.tlsconfig.nextprotos = append(s.tlsconfig.nextprotos, nextprototls)\n        }\n\n        if s.tlsnextproto == nil {\n            s.tlsnextproto = map[string]func(*http.server, *tls.conn, http.handler){}\n        }\n        protohandler := func(hs *http.server, c *tls.conn, h http.handler) {\n            if testhookonconn != nil {\n                testhookonconn()\n            }\n            conf.serveconn(c, &serveconnopts{\n                handler:    h,\n                baseconfig: hs,\n            })\n        }\n        s.tlsnextproto[nextprototls] = protohandler\n        return nil\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n从上述代码可以看到核心在于：\n\n * 将 nextprototls 附加在 net.http.server.tlsconfig.nextprotos 尾部\n * 将 nextprototls : protohandler 插入到 net.http.server.tlsnextproto 中\n\n由此，我们可以推测，在 net.http.server 接收到连接请求时，会在某个时机使用这两个对象：在真是 serve 时调用 protohandler 进行处理。接下来，我们看看 net.http.server 的工作流程。\n\n在分析 net.http.server 代码后，发现：服务启动的 listenandserve 和 listenandservetls 函数，最终都会走到 servetls 和 serve 函数。我们先来看看 servetls 的实现：\n\n//> net\\http\\server.go : l2928\n    func (srv *server) servetls(l net.listener, certfile, keyfile string) error {\n        // setup http/2 before srv.serve, to initialize srv.tlsconfig\n        // before we clone it and create the tls listener.\n        if err := srv.setuphttp2_servetls(); err != nil {\n            return err\n        }\n\n        config := clonetlsconfig(srv.tlsconfig)\n        if !strslicecontains(config.nextprotos, "http/1.1") {\n            config.nextprotos = append(config.nextprotos, "http/1.1")\n        }\n\n        ...\n\n        tlslistener := tls.newlistener(l, config)\n        return srv.serve(tlslistener)\n    }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n这块代码有几个地方很重要：\n\n * 通过 setuphttp2_servetls 安装http2支持，从函数名就可以看出，go 提供的库只支持了带 tls 的 http2.0\n   \n   * 它会调用到 ：\n   \n   //> net\\http\\server.go : l3141\n       func (srv *server) oncesetnextprotodefaults() {\n           if strings.contains(os.getenv("godebug"), "http2server=0") {\n               return\n           }\n           // enable http/2 by default if the user hasn\'t otherwise\n           // configured their tlsnextproto map.\n           if srv.tlsnextproto == nil {\n               conf := &http2server{\n                   newwritescheduler: func() http2writescheduler { return http2newprioritywritescheduler(nil) },\n               }\n               srv.nextprotoerr = http2configureserver(srv, conf)\n           }\n       }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   \n   \n   先看是否通过环境变量禁用了http2的支持，再在 srv.tlsnextproto == nil 时通过 http2configureserver 添加 http2.0 的支持。\n   \n       //> net\\http\\h2_bundle.go : l3763\n       func http2configureserver(s *server, conf *http2server) error {\n           ...\n       }\n   \n   \n   1\n   2\n   3\n   4\n   \n   \n   通过分析 http2configureserver, 发现它和golang.org.x.net.http2.configureserver的处理流程几乎完全一样，也就是说net/http默认就支持了http2.0, 只不过完全采用完全默认的 http2server 配置。\n   \n   另外，注意到：只有当 srv.tlsnextproto == nil 时才添加 http2.0 的支持，费解~\n\n * 调用 clonetlsconfig 拷贝 tlsconfig 配置\n\n * 添加一个默认的处理协议 "http/1.1" 到 tlsconfig.nextprotos\n\n * 调用 serve 函数，并传递参数：通过 net.listener 和 tlsconfig 构造的 tls.listener 对象 tlslistener\n   \n   * 注意，最终也是调用了 serve 函数，也就是说 serve 函数既要处理 http 也要处理 https\n\n接下来我们看看 serve 的实现：\n\n//> net\\http\\server.go : l2850\n    func (srv *server) serve(l net.listener) error {\n        ...\n        if err := srv.setuphttp2_serve(); err != nil {\n            return err\n        }\n        ...\n        ctx := context.withvalue(basectx, servercontextkey, srv)\n        for {\n            rw, e := l.accept()\n            if e != nil {\n                select {\n                case <-srv.getdonechan():\n                    return errserverclosed\n                default:\n                }\n                if ne, ok := e.(net.error); ok && ne.temporary() {\n                    ...\n                    continue\n                }\n                return e\n            }\n            if cc := srv.conncontext; cc != nil {\n                ctx = cc(ctx, rw)\n                if ctx == nil {\n                    panic("conncontext returned nil")\n                }\n            }\n            tempdelay = 0\n            c := srv.newconn(rw)\n            c.setstate(c.rwc, statenew) // before serve can return\n            go c.serve(ctx)\n        }\n    }\n\n\n//> net\\http\\server.go : l3132\n    func (srv *server) oncesetnextprotodefaults_serve() {\n        if srv.shouldconfigurehttp2forserve() {\n            srv.oncesetnextprotodefaults()\n        }\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n\n\nsetuphttp2_serve 最终调用了 oncesetnextprotodefaults_serve，看看它的实现，what ? setuphttp2_serve 什么鬼~ 又调用一次 oncesetnextprotodefaults，这个其实是为了处理：调用 listenandserve 但是配置了 tlsconfig 的情形\n\n将 net.conn 对象 rw 通过 srv.newconn 封装到一个新的 net.http.server.conn 对象，并启动一个goroutine调用 conn.serve 处理新接收到的连接请求。\n\n注意，每次 accept 一个连接请求，net.http 都会创建一个 goroutine，问题来了，如果突然间涌入大量连接请求会发生什么？\n\n//> net\\http\\server.go : l1759\n    func (c *conn) serve(ctx context.context) {\n        ...\n        if tlsconn, ok := c.rwc.(*tls.conn); ok {\n            ...\n            if err := tlsconn.handshake(); err != nil {\n                ...\n                return\n            }\n            c.tlsstate = new(tls.connectionstate)\n            *c.tlsstate = tlsconn.connectionstate()\n            if proto := c.tlsstate.negotiatedprotocol; validnpn(proto) {\n                if fn := c.server.tlsnextproto[proto]; fn != nil {\n                    h := initnpnrequest{tlsconn, serverhandler{c.server}}\n                    fn(c.server, tlsconn, h)\n                }\n                return\n            }\n        }\n\n        // http/1.x from here on.\n\n        ...\n\n        for {\n            w, err := c.readrequest(ctx)\n            ...\n            serverhandler{c.server}.servehttp(w, w.req)\n            ...\n        }\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n通过上述代码可以看出，如果是 tls 连接，则先处理 tls握手协议，然后根据 tlsnextproto 调用对应协议的serverhandler; 如果是普通连接，则进入 for 循环读取数据，并调用 servehttp 进行处理。\n\n此时，我们可以确认，http2.0 在连接建立之后，会调用 protohandler 接管数据的处理。同时，需要注意，readrequest 处理了数据包转换为 http 请求的动作，同样的protohandler 也会处理 frame 转换为 http 请求的动作，以兼容http1.1的语法。\n\n\n# 4.2 使用 golang.org.x.net.http2.h2c\n\nh2c 的主要目的是提供一个 non-tls 版本的 http/2.0, 这个包只提供了一个函数：newhandler。使用时，将其返回值当作普通的handler使用即可。\n\n//> golang.org\\x\\net\\http2\\h2c\\h2c.go : l64\n    func newhandler(h http.handler, s *http2.server) http.handler {\n        return &h2chandler{\n            handler: h,\n            s:       s,\n        }\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n从上述代码可以看到，newhandler 只是使用 http.hander 和 http2.server 封装了一个 h2chandler。当 net/http 的连接建立后，会调用 h2chandler 对象的 servehttp 处理函数。\n\n//> golang.org\\x\\net\\http2\\h2c\\h2c.go : l72\n    func (s h2chandler) servehttp(w http.responsewriter, r *http.request) {\n        // handle h2c with prior knowledge (rfc 7540 section 3.4)\n        if r.method == "pri" && len(r.header) == 0 && r.url.path == "*" && r.proto == "http/2.0" {\n            ...\n            conn, err := inith2cwithpriorknowledge(w)\n            if err != nil {\n                ...\n                return\n            }\n            defer conn.close()\n\n            s.s.serveconn(conn, &http2.serveconnopts{handler: s.handler})\n            return\n        }\n        // handle upgrade to h2c (rfc 7540 section 3.2)\n        if conn, err := h2cupgrade(w, r); err == nil {\n            defer conn.close()\n\n            s.s.serveconn(conn, &http2.serveconnopts{handler: s.handler})\n            return\n        }\n\n        s.handler.servehttp(w, r)\n        return\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n很明显，当满足条件时会调用 http2.server 的 serveconn 进行处理，进入 serveconn 后就是常规的 http2 处理流程，这里就先不深入了。这里有两种升级方式：\n\n * r.method == "pri"\n   * 通过使用 pri 标识当前发送的是一个前言，紧接着就会发送http/2.0的frame了。前言数据以：pri * http/2.0\\r\\n\\r\\nsm\\r\\n\\r\\n 开始。go 的 http2.transport 就是使用这种方式来构建http/2.0连接。\n * h2cupgrade\n   * 使用 http/1.1 通过头部信息 connection: upgrade, http2-settings 和 upgrade: h2c 标识需要升级以及通过http2-settings来设置http/2.0的连接信息。其中 http2-settings 是以 base64url 编码。 curl -k --http2 http://localhost:8972?data=curltest 就是使用这种方式。\n\n我们来看看 h2cupgrade 的实现方式：\n\n//> golang.org\\x\\net\\http2\\h2c\\h2c.go : l161\n    func h2cupgrade(w http.responsewriter, r *http.request) (net.conn, error) {\n        if !ish2cupgrade(r.header) {\n            return nil, errors.new("non-conforming h2c headers")\n        }\n\n        // initial bytes we put into conn to fool http2 server\n        initbytes, _, err := converth1reqtoh2(r)\n        if err != nil {\n            return nil, err\n        }\n\n        hijacker, ok := w.(http.hijacker)\n        if !ok {\n            return nil, errors.new("hijack not supported.")\n        }\n        conn, rw, err := hijacker.hijack()\n        if err != nil {\n            return nil, fmt.errorf("hijack failed: %v", err)\n        }\n\n        rw.write([]byte("http/1.1 101 switching protocols\\r\\n" +\n            "connection: upgrade\\r\\n" +\n            "upgrade: h2c\\r\\n\\r\\n"))\n        rw.flush()\n\n        // a conforming client will now send an h2 client preface which need to drain\n        // since we already sent this.\n        if err := drainclientpreface(rw); err != nil {\n            return nil, err\n        }\n\n        c := &rwconn{\n            conn:      conn,\n            reader:    io.multireader(initbytes, rw),\n            bufwriter: newsettingsackswallowwriter(rw.writer),\n        }\n        return c, nil\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\nh2cupgrade 先通过 ish2cupgrade 判断是否能够进行协议升级，然后再利用 http.hijacker 完全接管连接，包括数据读写，并构成新的连接对象以供 http2.server.serverconn 进行 http2 协议处理数据成 net.http 的 responsewriter, *request 对象。\n\n\n# 5、next\n\nhttp2.0 in grpc\n\n对 client 发起请求的核心 net.http.transport 进行解读\n\n对 websocket 的包 golang.org.x.net.websocket 进行解读\n\n\n# 6、end\n\n * reference\n   \n   * [https://blog.cloudflare.com/tools-for-debugging-testing-and-using-http-2/]\n   * go http2 和 h2c\n   * rfc - h2c\n   * rfc - pri\n   * rfc - httplayer\n   * rfc - streamid=0x01\n     \n         http/1.1 requests that are upgraded to http/2 (see section 3.2) are responded to with a stream identifier of one (0x1).\n         after the upgrade completes, stream 0x1 is "half-closed (local)" to the client. \n         therefore, stream 0x1 cannot be selected as a new stream identifier by a client that upgrades from http/1.1.\n     \n     \n     1\n     2\n     3\n     \n   * htt2\n\n * sample\n   \n   * github',charsets:{cjk:!0}},{title:"TCP 与 UDP 对比",frontmatter:{title:"TCP 与 UDP 对比",date:"2019-01-05T00:00:00.000Z",description:"TCP 与 UDP 对比",categories:["network"],tags:["tcp","udp"],permalink:null},regularPath:"/blog/network/introduce_tcp_udp.html",relativePath:"blog/network/introduce_tcp_udp.md",key:"v-398f0321",path:"/blog/network/introduce_tcp_udp.html",headers:[{level:2,title:"TCP协议",slug:"tcp协议",normalizedTitle:"tcp协议",charIndex:327},{level:2,title:"三次握手的过程：",slug:"三次握手的过程",normalizedTitle:"三次握手的过程：",charIndex:435},{level:2,title:"四次挥手过程",slug:"四次挥手过程",normalizedTitle:"四次挥手过程",charIndex:618},{level:2,title:"UDP协议",slug:"udp协议",normalizedTitle:"udp协议",charIndex:1051},{level:2,title:"TCP与UDP的区别",slug:"tcp与udp的区别",normalizedTitle:"tcp与udp的区别",charIndex:1820},{level:2,title:"为什么UDP比TCP快",slug:"为什么udp比tcp快",normalizedTitle:"为什么udp比tcp快",charIndex:2124},{level:2,title:"为什么TCP比UDP可靠",slug:"为什么tcp比udp可靠",normalizedTitle:"为什么tcp比udp可靠",charIndex:2176},{level:2,title:"什么时候使用TCP",slug:"什么时候使用tcp",normalizedTitle:"什么时候使用tcp",charIndex:2308},{level:2,title:"TCP无边界，UDP有边界",slug:"tcp无边界-udp有边界",normalizedTitle:"tcp无边界，udp有边界",charIndex:2631}],headersStr:"TCP协议 三次握手的过程： 四次挥手过程 UDP协议 TCP与UDP的区别 为什么UDP比TCP快 为什么TCP比UDP可靠 什么时候使用TCP TCP无边界，UDP有边界",content:"# TCP与UDP 对比\n\n----------------------------------------\n\n面向报文的传输方式是应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付给IP层。既不拆分，也不合并，而是保留这些报文的边界，因此，应用程序需要选择合适的报文大小。\n\n面向字节流的话，虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送。如果应用程序一次只发送一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去。\n\n\n# TCP协议\n\n * Transmission Control Protocol，传输控制协议\n * 面向连接的协议\n * 需要三次握手建立连接\n * 需要四次挥手断开连接\n * TCP报头最小长度：20字节\n\n\n# 三次握手的过程：\n\n 1. 客户端发送：SYN = 1, SEQ = X, 端口号\n 2. 服务器回复：SYN = 1, ACK = X + 1, SEQ = Y\n 3. 客户端发送：ACK = Y + 1, SEQ = X + 1\n\n> 确认应答信号ACK = 收到的SEQ + 1。 连接建立中，同步信号SYN始终为1。连接建立后，同步信号SYN=0。\n\n\n# 四次挥手过程\n\n 1. A向B提出停止连接请求，FIN = 1\n 2. B收到，ACK = 1\n 3. B向A提出停止连接请求，FIN = 1\n 4. A收到，ACK = 1\n\n优点：\n\n * 可靠，稳定\n   * 传递数据前，会有三次握手建立连接\n   * 传递数据时，有确认、窗口、重传、拥塞控制\n   * 传递数据后，会断开连接节省系统资源\n\n缺点：\n\n * 传输慢，效率低，占用系统资源高\n   * 传递数据前，建立连接需要耗时\n   * 传递数据时，确认、重传、拥塞等会消耗大量时间以及CPU和内存等硬件资源\n * 易被攻击\n   * 因为有确认机制，三次握手等机制，容易被人利用，实现DOS 、DDOS攻击\n\n如何保证接收的顺序性：\n\n * TCP协议使用SEQ和ACK机制保证了顺序性\n * TCP的每个报文都是有序号的。确认应答信号ACK=收到的SEQ+1\n\n----------------------------------------\n\n\n# UDP协议\n\n * User Data Protocol，用户数据包协议\n * 面向无连接的协议\n * UDP报头只有8字节\n\n简介：\n\n * 传输数据之前源端和终端不建立连接\n * 在发送端，UDP传送数据的速度仅仅是受应用程序生成数据的速度、计算机的能力和传输带宽的限制\n * 在接收端，UDP把每个消息段放在队列中，应用程序每次从队列中读一个消息段\n * 由于传输数据不建立连接，因此也就不需要维护连接状态，包括收发状态等，因此一台服务机可同时向多个客户机传输相同的消息\n * UDP信息包的标题很短，只有8个字节，相对于TCP的20个字节信息包的额外开销很小\n * 吞吐量不受拥挤控制算法的调节，只受应用软件生成数据的速率、传输带宽、源端和终端主机性能的限制\n * UDP使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态表。\n * UDP是面向报文的。\n\n> 使用“ping”命令来测试两台主机之间TCP/IP通信是否正常，其实“ping”命令的原理就是向对方主机发送UDP数据包，然后对方主机确认收到数据包，如果数据包是否到达的消息及时反馈回来，那么网络就是通的。\n\n优点：\n\n * 传输速率快\n   * 传输数据前，不需要像TCP一样建立连接\n   * 传输数据时，没有确认、窗口、重传、拥塞控制等机制\n * 较安全\n   * 由于没有了TCP的一些机制，被攻击者利用的漏洞就少了\n\n缺点：\n\n * 不可靠，不稳定\n   * 由于没有了TCP的机制，在数据传输时如果网络不好，很可能丢包\n\n用UDP协议通讯时怎样得知目标机是否获得了数据包 仿造TCP的做法，每发一个UDP包，都在里面加一个SEQ序号，接收方收到包后，将SEQ序号回复给发送方。如果发送方在指定时间以内没有收到回应，说明丢包了。\n\n\n# TCP与UDP的区别\n\n----------------------------------------\n\nTCP             UDP\nTCP面向有链接的通信服务   TCP面向无链接的通信服务\nTCP提供可靠的通信传输    UDP不可靠,会丢包\nTCP保证数据顺序       UDP不保证\nTCP数据无边界        UDP有边界\nTCP速度慢          UDP速度快\nTCP面向字节流        UDP面向报文\nTCP一对一          UDP可以一对一，一对多\nTCP报头至少20字节     UDP报头8字节\nTCP有流量控制，拥塞控制   UDP没有\n\n\n# 为什么UDP比TCP快\n\n 1. TCP需要三次握手\n 2. TCP有拥塞控制，控制流量等机制\n\n\n# 为什么TCP比UDP可靠\n\n 1. TCP是面向有连接的，建立连接之后才发送数据；而UDP则不管对方存不存在都会发送数据。\n 2. TCP有确认机制，接收端每收到一个正确包都会回应给发送端。超时或者数据包不完整的话发送端会重传。UDP没有。因此可能丢包。\n\n\n# 什么时候使用TCP\n\n当对网络通讯质量有要求的时候：\n\n * 比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，\n * 比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。\n\n在日常生活中，常见使用TCP协议的应用如下：\n\n * 浏览器，用的HTTP\n * FlashFXP，用的FTP\n * Outlook，用的POP、SMTP\n * QQ文件传输\n\n什么时候应该使用UDP：\n\n * 当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。\n * 比如，日常生活中，常见使用UDP协议的应用如下：\n   * QQ语音\n   * QQ视频\n   * TFTP\n\n\n# TCP无边界，UDP有边界\n\nTCP无边界\n\n * 客户端分多次发送数据给服务器，若服务器的缓冲区够大，那么服务器端会在客户端发送完之后一次性接收过来，所以是无边界的；\n\nUDP有边界\n\n * 客户端每发送一次，服务器端就会接收一次，也就是说发送多少次就会接收多少次，因此是有边界的。",normalizedContent:"# tcp与udp 对比\n\n----------------------------------------\n\n面向报文的传输方式是应用层交给udp多长的报文，udp就照样发送，即一次发送一个报文。发送方的udp对应用程序交下来的报文，在添加首部后就向下交付给ip层。既不拆分，也不合并，而是保留这些报文的边界，因此，应用程序需要选择合适的报文大小。\n\n面向字节流的话，虽然应用程序和tcp的交互是一次一个数据块（大小不等），但tcp把应用程序看成是一连串的无结构的字节流。tcp有一个缓冲，当应用程序传送的数据块太长，tcp就可以把它划分短一些再传送。如果应用程序一次只发送一个字节，tcp也可以等待积累有足够多的字节后再构成报文段发送出去。\n\n\n# tcp协议\n\n * transmission control protocol，传输控制协议\n * 面向连接的协议\n * 需要三次握手建立连接\n * 需要四次挥手断开连接\n * tcp报头最小长度：20字节\n\n\n# 三次握手的过程：\n\n 1. 客户端发送：syn = 1, seq = x, 端口号\n 2. 服务器回复：syn = 1, ack = x + 1, seq = y\n 3. 客户端发送：ack = y + 1, seq = x + 1\n\n> 确认应答信号ack = 收到的seq + 1。 连接建立中，同步信号syn始终为1。连接建立后，同步信号syn=0。\n\n\n# 四次挥手过程\n\n 1. a向b提出停止连接请求，fin = 1\n 2. b收到，ack = 1\n 3. b向a提出停止连接请求，fin = 1\n 4. a收到，ack = 1\n\n优点：\n\n * 可靠，稳定\n   * 传递数据前，会有三次握手建立连接\n   * 传递数据时，有确认、窗口、重传、拥塞控制\n   * 传递数据后，会断开连接节省系统资源\n\n缺点：\n\n * 传输慢，效率低，占用系统资源高\n   * 传递数据前，建立连接需要耗时\n   * 传递数据时，确认、重传、拥塞等会消耗大量时间以及cpu和内存等硬件资源\n * 易被攻击\n   * 因为有确认机制，三次握手等机制，容易被人利用，实现dos 、ddos攻击\n\n如何保证接收的顺序性：\n\n * tcp协议使用seq和ack机制保证了顺序性\n * tcp的每个报文都是有序号的。确认应答信号ack=收到的seq+1\n\n----------------------------------------\n\n\n# udp协议\n\n * user data protocol，用户数据包协议\n * 面向无连接的协议\n * udp报头只有8字节\n\n简介：\n\n * 传输数据之前源端和终端不建立连接\n * 在发送端，udp传送数据的速度仅仅是受应用程序生成数据的速度、计算机的能力和传输带宽的限制\n * 在接收端，udp把每个消息段放在队列中，应用程序每次从队列中读一个消息段\n * 由于传输数据不建立连接，因此也就不需要维护连接状态，包括收发状态等，因此一台服务机可同时向多个客户机传输相同的消息\n * udp信息包的标题很短，只有8个字节，相对于tcp的20个字节信息包的额外开销很小\n * 吞吐量不受拥挤控制算法的调节，只受应用软件生成数据的速率、传输带宽、源端和终端主机性能的限制\n * udp使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态表。\n * udp是面向报文的。\n\n> 使用“ping”命令来测试两台主机之间tcp/ip通信是否正常，其实“ping”命令的原理就是向对方主机发送udp数据包，然后对方主机确认收到数据包，如果数据包是否到达的消息及时反馈回来，那么网络就是通的。\n\n优点：\n\n * 传输速率快\n   * 传输数据前，不需要像tcp一样建立连接\n   * 传输数据时，没有确认、窗口、重传、拥塞控制等机制\n * 较安全\n   * 由于没有了tcp的一些机制，被攻击者利用的漏洞就少了\n\n缺点：\n\n * 不可靠，不稳定\n   * 由于没有了tcp的机制，在数据传输时如果网络不好，很可能丢包\n\n用udp协议通讯时怎样得知目标机是否获得了数据包 仿造tcp的做法，每发一个udp包，都在里面加一个seq序号，接收方收到包后，将seq序号回复给发送方。如果发送方在指定时间以内没有收到回应，说明丢包了。\n\n\n# tcp与udp的区别\n\n----------------------------------------\n\ntcp             udp\ntcp面向有链接的通信服务   tcp面向无链接的通信服务\ntcp提供可靠的通信传输    udp不可靠,会丢包\ntcp保证数据顺序       udp不保证\ntcp数据无边界        udp有边界\ntcp速度慢          udp速度快\ntcp面向字节流        udp面向报文\ntcp一对一          udp可以一对一，一对多\ntcp报头至少20字节     udp报头8字节\ntcp有流量控制，拥塞控制   udp没有\n\n\n# 为什么udp比tcp快\n\n 1. tcp需要三次握手\n 2. tcp有拥塞控制，控制流量等机制\n\n\n# 为什么tcp比udp可靠\n\n 1. tcp是面向有连接的，建立连接之后才发送数据；而udp则不管对方存不存在都会发送数据。\n 2. tcp有确认机制，接收端每收到一个正确包都会回应给发送端。超时或者数据包不完整的话发送端会重传。udp没有。因此可能丢包。\n\n\n# 什么时候使用tcp\n\n当对网络通讯质量有要求的时候：\n\n * 比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，\n * 比如http、https、ftp等传输文件的协议，pop、smtp等邮件传输的协议。\n\n在日常生活中，常见使用tcp协议的应用如下：\n\n * 浏览器，用的http\n * flashfxp，用的ftp\n * outlook，用的pop、smtp\n * qq文件传输\n\n什么时候应该使用udp：\n\n * 当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用udp。\n * 比如，日常生活中，常见使用udp协议的应用如下：\n   * qq语音\n   * qq视频\n   * tftp\n\n\n# tcp无边界，udp有边界\n\ntcp无边界\n\n * 客户端分多次发送数据给服务器，若服务器的缓冲区够大，那么服务器端会在客户端发送完之后一次性接收过来，所以是无边界的；\n\nudp有边界\n\n * 客户端每发送一次，服务器端就会接收一次，也就是说发送多少次就会接收多少次，因此是有边界的。",charsets:{cjk:!0}},{title:"tcpip思维导图",frontmatter:{title:"tcpip思维导图",date:"2019-01-05T00:00:00.000Z",description:"tcpip思维导图",categories:["network"],tags:["tcp"],permalink:null},regularPath:"/blog/network/tcpip_mind_map.html",relativePath:"blog/network/tcpip_mind_map.md",key:"v-319db75f",path:"/blog/network/tcpip_mind_map.html",headersStr:null,content:"# tcpip思维导图\n\n",normalizedContent:"# tcpip思维导图\n\n",charsets:{cjk:!0}},{title:"Platform 目录",frontmatter:{published:!0,title:"Platform 目录",description:"platform 相关知识汇总",keywords:[""],categories:["platform"],permalink:"/blog/platform/",date:"2020-04-14T00:00:00.000Z",tags:[null]},regularPath:"/blog/platform/",relativePath:"blog/platform/README.md",key:"v-5354451a",path:"/blog/platform/",headers:[{level:2,title:"一、 Android",slug:"一、-android",normalizedTitle:"一、 android",charIndex:18},{level:2,title:"二、 Linux",slug:"二、-linux",normalizedTitle:"二、 linux",charIndex:45},{level:2,title:"三、 Windows",slug:"三、-windows",normalizedTitle:"三、 windows",charIndex:91}],headersStr:"一、 Android 二、 Linux 三、 Windows",content:"# PLATFORM 目录\n\n\n# 一、 Android\n\n * Android\n\n\n# 二、 Linux\n\n * Linux Cmds\n * Linux 内存缓慢增长问题\n\n\n# 三、 Windows\n\n * Pe 签名\n * 运行时库\n * Introduction To Pdb\n * 生成 Win10 下调试服务时的证书",normalizedContent:"# platform 目录\n\n\n# 一、 android\n\n * android\n\n\n# 二、 linux\n\n * linux cmds\n * linux 内存缓慢增长问题\n\n\n# 三、 windows\n\n * pe 签名\n * 运行时库\n * introduction to pdb\n * 生成 win10 下调试服务时的证书",charsets:{cjk:!0}},{title:"Android",frontmatter:{title:"Android",date:"2021-11-24T11:50:00.000Z",lastmod:null,publish:!0,categories:null,keywords:null,description:null,tags:null,permalink:null},regularPath:"/blog/platform/android/android_utils.html",relativePath:"blog/platform/android/android_utils.md",key:"v-48032f1f",path:"/blog/platform/android/android_utils.html",headers:[{level:2,title:"UIAutomatorViewer",slug:"uiautomatorviewer",normalizedTitle:"uiautomatorviewer",charIndex:23}],headersStr:"UIAutomatorViewer",content:"# Android\n\n * 设计模式\n\n\n# UIAutomatorViewer\n\n * Broken GUI of UIAutomatorViewer on MacOS Big Sur\n   \n   https://github.com/android/android-test/issues/911\n   \n     Download the latest swt.jar, from https://download.eclipse.org/eclipse/downloads/index.html, rename downloaded swt.jar to swt2.jar, copy to Android/sdk/tools/lib/x86_64/, NOT REPLACE, NOT DELETE, then, try it~~\n   \n     You must use version 4.20:\n       https://www.eclipse.org/downloads/download.php?file=/eclipse/downloads/drops4/R-4.20-202106111600/swt-4.20-cocoa-macosx-x86_64.zip\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   ",normalizedContent:"# android\n\n * 设计模式\n\n\n# uiautomatorviewer\n\n * broken gui of uiautomatorviewer on macos big sur\n   \n   https://github.com/android/android-test/issues/911\n   \n     download the latest swt.jar, from https://download.eclipse.org/eclipse/downloads/index.html, rename downloaded swt.jar to swt2.jar, copy to android/sdk/tools/lib/x86_64/, not replace, not delete, then, try it~~\n   \n     you must use version 4.20:\n       https://www.eclipse.org/downloads/download.php?file=/eclipse/downloads/drops4/r-4.20-202106111600/swt-4.20-cocoa-macosx-x86_64.zip\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   ",charsets:{cjk:!0}},{title:"linux cmds",frontmatter:{title:"linux cmds",date:"2019-12-23T00:00:00.000Z",description:"linux 常用命令集锦",categories:["blog","platform","linux"],tags:[null],permalink:null},regularPath:"/blog/platform/linux/linux_cmds.html",relativePath:"blog/platform/linux/linux_cmds.md",key:"v-485139ef",path:"/blog/platform/linux/linux_cmds.html",headers:[{level:2,title:"Common",slug:"common",normalizedTitle:"common",charIndex:2},{level:2,title:"systemctl",slug:"systemctl",normalizedTitle:"systemctl",charIndex:2921},{level:2,title:"Git",slug:"git",normalizedTitle:"git",charIndex:3263},{level:2,title:"Problems",slug:"problems",normalizedTitle:"problems",charIndex:3776},{level:2,title:"CentOS创建SSH密钥",slug:"centos创建ssh密钥",normalizedTitle:"centos创建ssh密钥",charIndex:3958},{level:2,title:"Linux 性能领域大师布伦丹·格雷格的工具图谱",slug:"linux-性能领域大师布伦丹·格雷格的工具图谱",normalizedTitle:"linux 性能领域大师布伦丹·格雷格的工具图谱",charIndex:4172}],headersStr:"Common systemctl Git Problems CentOS创建SSH密钥 Linux 性能领域大师布伦丹·格雷格的工具图谱",content:'# Common\n\nCATEGORY   COMMAND    FUNCTION       EXAMPLE                                                       NOTE\n.          grep       grep 查找        grep -ar "select" ./conf                                      \n.          sed        sed 编辑                                                                       \n.          awk        awk 分析         awk \'{arr[$3]++}END{for(i in arr) print                       \n                                     substr(i,0,length(i)-1)}\'\n.          xargs      将标准输入作为命令的参数   ps -ef | pgrep %s | xargs -I {} kill -9 {}                    管道是将前面的标准输出作为后面的标准输入\n.          lsof                      lsof | grep -i delete                                         \n.          nohup                     sudo nohup xxx &                                              \n.          top                       内存排序 : top -a -n 1 -c CPU排序 : top -n 1 -c                     \n.          tcpdump                   tcpdump -i any -Xxns0 -c 100 host xx.xx.xx.xx and port xxxx   \n.          perf                      perf top -p {pid}                                             \n.          iftop                                                                                   \n.          dos2unix                                                                                \n.          pstree                    pstree -c -a > pstree.log                                     \n.          ulimit                    ulimit [type: -H/-S] [cmd: -a/...] [arg: 0/unlimited/...]     \n.          strace                    strace -p 34542 -s 128 -T                                     truss、strace 以及 ltrace\n\n * pig\n   * 本地执行：pig -x local xxx.pig\n * gdb\n   * gdb [bin] core_dump\n   * gdb attach [pid]\n     * c : continue\n * memcache\n   \n   memcache:\n       telnet host port\n           强制退出：ctrl + \']\'\n       stats\n       stats cachedump slabs_id limit_num\n   \n   \n   1\n   2\n   3\n   4\n   5\n   \n * 自启动\n   \n   # 下面任务可以在 chkconfig 配置自启动\n   /etc/init.d/*    \n   # 直接写到脚本里面\n   /etc/rc.local    \n   # 查看某个服务（下面以redis为例）是否自启动\n   chkconfig --list|grep redis\n   # 如果 3，4，5为 off则不会自启动\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   \n * 没有配置host时，函数 gethostbyname 会返回空：\n   * 修改：/etc/hosts\n   * 修改(重启后依然生效)：/etc/sysconfig/network\n   * 执行(当次生效)：hostname xxx\n * Makefile\n   * 静态库：-L[lib_dir] -l[lib(libname)] ：注意，gcc在查找库的时候会自动添加式lib前缀再查找\n   * 多线程：-lpthread ：注意，编译多线程时，需要链接pthread\n * 条件变量是 GNU/Linux 提供的第三种同步工具(第一互斥体、第二这信号量)\n * crontab\n   * 用户 : /var/spool/cron/*\n   * 系统 : /etc/crontab、/etc/cron.d\n   * 不常用 : /etc/[cron.hourly、cron.daily、cron.weekly、cron.monthly]\n * hadoop\n   * HADOOP_USER_NAME=hdfs hdfs dfs -rmr\n * pyspark\n   * 提交任务 &\n     \n     sudo -u news_db spark-submit --master local[*] --conf spark.ui.port=12399 --queue offline --py-files pyspark_dashboard_util.py pyspark_dashboard.py\n     \n     \n     1\n     \n   * 打开文件\n     * sc.textFile("file://[absolute path]")\n     * sc.textFile("hdfs://url:port/[path]")\n\n\n# systemctl\n\n * CentOS 7\n   * 位置：服务systemctl脚本存放在：(配置文件优先级依次从低到高)\n     * /usr/lib/systemd/，有系统 system 和用户 user 之分，即：/usr/lib/systemd/system 和 /usr/lib/systemd/user\n     * /run/systemd/system\n     * /etc/systemd/system\n   * 开机启动\n     * systemctl enable [service, 如：nginx.service]\n   * 关机/重启\n     * systemctl poweroff\n     * systemctl reboot\n\n\n# Git\n\n * create\n   * local\n     * git checkout -b [origin/]\n        * 默认是基于本地HEAD创建分支\n   \n   * remote\n     * git push A B:C\n       * 其中A和C是分别remote端的一个repository的名字和branch的名字，B是本地端branch的名字\n       * 意思是把本地的B推送到remotes/A/C下\n       * 当B==C时可以直接省略为：git push A B\n * delete\n   * remote\n     * git push origin :A\n       * 推送一个空分支到远程分支，就相当于删除远程分支\n     * git push origin --delete A\n   * local\n     * git branch -D dev\n * tag\n   * git tag -a v0.0.1 -m \'tag message to describe this version\'\n   * git push origin v0.0.1\n\n\n# Problems\n\n 1. 在 ubuntu 中移动 50000 张图片的图片的时候遇到如下问题：-bash: /bin/mv: Argument list too long\n    * 使用 find sourcePath/ -type f -name "*.*" -exec mv {} targetPath/ \\; 可以解决，注意不能缺少结尾的 ;\n\n\n# CentOS创建SSH密钥\n\n 1. 输入以下命令以创建 rsa 秘钥：ssh-keygen -t rsa\n 2. 查看产生两个文件：id_rsa、id_rsa.pub (一般在 ~/.ssh/ 目录下)\n 3. 重命名 id_rsa.pub 为 authorized_key: cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys\n 4. 执行 ssh localhost 进行验证\n\n\n# Linux 性能领域大师布伦丹·格雷格的工具图谱\n\n',normalizedContent:'# common\n\ncategory   command    function       example                                                       note\n.          grep       grep 查找        grep -ar "select" ./conf                                      \n.          sed        sed 编辑                                                                       \n.          awk        awk 分析         awk \'{arr[$3]++}end{for(i in arr) print                       \n                                     substr(i,0,length(i)-1)}\'\n.          xargs      将标准输入作为命令的参数   ps -ef | pgrep %s | xargs -i {} kill -9 {}                    管道是将前面的标准输出作为后面的标准输入\n.          lsof                      lsof | grep -i delete                                         \n.          nohup                     sudo nohup xxx &                                              \n.          top                       内存排序 : top -a -n 1 -c cpu排序 : top -n 1 -c                     \n.          tcpdump                   tcpdump -i any -xxns0 -c 100 host xx.xx.xx.xx and port xxxx   \n.          perf                      perf top -p {pid}                                             \n.          iftop                                                                                   \n.          dos2unix                                                                                \n.          pstree                    pstree -c -a > pstree.log                                     \n.          ulimit                    ulimit [type: -h/-s] [cmd: -a/...] [arg: 0/unlimited/...]     \n.          strace                    strace -p 34542 -s 128 -t                                     truss、strace 以及 ltrace\n\n * pig\n   * 本地执行：pig -x local xxx.pig\n * gdb\n   * gdb [bin] core_dump\n   * gdb attach [pid]\n     * c : continue\n * memcache\n   \n   memcache:\n       telnet host port\n           强制退出：ctrl + \']\'\n       stats\n       stats cachedump slabs_id limit_num\n   \n   \n   1\n   2\n   3\n   4\n   5\n   \n * 自启动\n   \n   # 下面任务可以在 chkconfig 配置自启动\n   /etc/init.d/*    \n   # 直接写到脚本里面\n   /etc/rc.local    \n   # 查看某个服务（下面以redis为例）是否自启动\n   chkconfig --list|grep redis\n   # 如果 3，4，5为 off则不会自启动\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   \n * 没有配置host时，函数 gethostbyname 会返回空：\n   * 修改：/etc/hosts\n   * 修改(重启后依然生效)：/etc/sysconfig/network\n   * 执行(当次生效)：hostname xxx\n * makefile\n   * 静态库：-l[lib_dir] -l[lib(libname)] ：注意，gcc在查找库的时候会自动添加式lib前缀再查找\n   * 多线程：-lpthread ：注意，编译多线程时，需要链接pthread\n * 条件变量是 gnu/linux 提供的第三种同步工具(第一互斥体、第二这信号量)\n * crontab\n   * 用户 : /var/spool/cron/*\n   * 系统 : /etc/crontab、/etc/cron.d\n   * 不常用 : /etc/[cron.hourly、cron.daily、cron.weekly、cron.monthly]\n * hadoop\n   * hadoop_user_name=hdfs hdfs dfs -rmr\n * pyspark\n   * 提交任务 &\n     \n     sudo -u news_db spark-submit --master local[*] --conf spark.ui.port=12399 --queue offline --py-files pyspark_dashboard_util.py pyspark_dashboard.py\n     \n     \n     1\n     \n   * 打开文件\n     * sc.textfile("file://[absolute path]")\n     * sc.textfile("hdfs://url:port/[path]")\n\n\n# systemctl\n\n * centos 7\n   * 位置：服务systemctl脚本存放在：(配置文件优先级依次从低到高)\n     * /usr/lib/systemd/，有系统 system 和用户 user 之分，即：/usr/lib/systemd/system 和 /usr/lib/systemd/user\n     * /run/systemd/system\n     * /etc/systemd/system\n   * 开机启动\n     * systemctl enable [service, 如：nginx.service]\n   * 关机/重启\n     * systemctl poweroff\n     * systemctl reboot\n\n\n# git\n\n * create\n   * local\n     * git checkout -b [origin/]\n        * 默认是基于本地head创建分支\n   \n   * remote\n     * git push a b:c\n       * 其中a和c是分别remote端的一个repository的名字和branch的名字，b是本地端branch的名字\n       * 意思是把本地的b推送到remotes/a/c下\n       * 当b==c时可以直接省略为：git push a b\n * delete\n   * remote\n     * git push origin :a\n       * 推送一个空分支到远程分支，就相当于删除远程分支\n     * git push origin --delete a\n   * local\n     * git branch -d dev\n * tag\n   * git tag -a v0.0.1 -m \'tag message to describe this version\'\n   * git push origin v0.0.1\n\n\n# problems\n\n 1. 在 ubuntu 中移动 50000 张图片的图片的时候遇到如下问题：-bash: /bin/mv: argument list too long\n    * 使用 find sourcepath/ -type f -name "*.*" -exec mv {} targetpath/ \\; 可以解决，注意不能缺少结尾的 ;\n\n\n# centos创建ssh密钥\n\n 1. 输入以下命令以创建 rsa 秘钥：ssh-keygen -t rsa\n 2. 查看产生两个文件：id_rsa、id_rsa.pub (一般在 ~/.ssh/ 目录下)\n 3. 重命名 id_rsa.pub 为 authorized_key: cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys\n 4. 执行 ssh localhost 进行验证\n\n\n# linux 性能领域大师布伦丹·格雷格的工具图谱\n\n',charsets:{cjk:!0}},{title:"linux 内存缓慢增长问题",frontmatter:{title:"linux 内存缓慢增长问题",date:"2019-10-15T00:00:00.000Z",description:"linux 内存缓慢增长问题的一种简单处理方式",categories:["blog","platform","linux"],tags:[null],permalink:null},regularPath:"/blog/platform/linux/linux_mem_grows.html",relativePath:"blog/platform/linux/linux_mem_grows.md",key:"v-29d661ff",path:"/blog/platform/linux/linux_mem_grows.html",headers:[{level:2,title:"监控脚本",slug:"监控脚本",normalizedTitle:"监控脚本",charIndex:89},{level:2,title:"分析数据",slug:"分析数据",normalizedTitle:"分析数据",charIndex:471}],headersStr:"监控脚本 分析数据",content:'# linux 内存缓慢增长问题\n\n在遇到 内存、cpu 等系统资源 缓慢增长问题时，可以使用类似的脚本进行数据采样，然后通过对格式化数据分析找到 具体的服务(进程)。\n\n\n# 监控脚本\n\n    #!/bin/bash\n\n    # */1 * * * * bash /data/data_tmp/monitor.sh\n\n    now=`date +%Y%m%d`\n    /usr/bin/top -c -b -n 1 | sort -nr -k10 | head -n 20 | tee >>/data/data_tmp/top_$now.txt\n\n    tow_days_ago=`date +%Y%m%d -d "5 day ago"`\n    if [ -f /data/data_tmp/top_${tow_days_ago}.txt ];then\n    rm -f /data/data_tmp/top_${tow_days_ago}.txt\n    fi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 分析数据\n\n    # 按进程名分组写入不同的文件\n    cat tmp.txt | grep -v % | grep -v KiB | grep -v Tasks | sort -r -k12 -k11 | awk \'{print $0 >> $12".rlog"}\'\n\n\n1\n2\n',normalizedContent:'# linux 内存缓慢增长问题\n\n在遇到 内存、cpu 等系统资源 缓慢增长问题时，可以使用类似的脚本进行数据采样，然后通过对格式化数据分析找到 具体的服务(进程)。\n\n\n# 监控脚本\n\n    #!/bin/bash\n\n    # */1 * * * * bash /data/data_tmp/monitor.sh\n\n    now=`date +%y%m%d`\n    /usr/bin/top -c -b -n 1 | sort -nr -k10 | head -n 20 | tee >>/data/data_tmp/top_$now.txt\n\n    tow_days_ago=`date +%y%m%d -d "5 day ago"`\n    if [ -f /data/data_tmp/top_${tow_days_ago}.txt ];then\n    rm -f /data/data_tmp/top_${tow_days_ago}.txt\n    fi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 分析数据\n\n    # 按进程名分组写入不同的文件\n    cat tmp.txt | grep -v % | grep -v kib | grep -v tasks | sort -r -k12 -k11 | awk \'{print $0 >> $12".rlog"}\'\n\n\n1\n2\n',charsets:{cjk:!0}},{title:"PE 签名",frontmatter:{title:"PE 签名",date:"2021-07-16T09:50:00.000Z",description:"PE签名、证书包含的内容以及作用",categories:["platform"],tags:["certificate"],permalink:null},regularPath:"/blog/platform/windows/certificate.html",relativePath:"blog/platform/windows/certificate.md",key:"v-4976d5df",path:"/blog/platform/windows/certificate.html",headers:[{level:2,title:"签名介绍",slug:"签名介绍",normalizedTitle:"签名介绍",charIndex:170},{level:3,title:"查看签名",slug:"查看签名",normalizedTitle:"查看签名",charIndex:624},{level:3,title:"PE文件中签名结构",slug:"pe文件中签名结构",normalizedTitle:"pe文件中签名结构",charIndex:2344},{level:2,title:"签名验证",slug:"签名验证",normalizedTitle:"签名验证",charIndex:2370},{level:3,title:"证书生成",slug:"证书生成",normalizedTitle:"证书生成",charIndex:2379},{level:3,title:"证书验证",slug:"证书验证",normalizedTitle:"证书验证",charIndex:2515},{level:3,title:"验证证书的证书",slug:"验证证书的证书",normalizedTitle:"验证证书的证书",charIndex:2688},{level:3,title:"签名验证",slug:"签名验证-2",normalizedTitle:"签名验证",charIndex:2370},{level:2,title:"实践",slug:"实践",normalizedTitle:"实践",charIndex:2987},{level:3,title:"嵌入式",slug:"嵌入式",normalizedTitle:"嵌入式",charIndex:243},{level:3,title:"编录式",slug:"编录式",normalizedTitle:"编录式",charIndex:321},{level:3,title:"验证签名",slug:"验证签名",normalizedTitle:"验证签名",charIndex:2924},{level:2,title:"签名代码",slug:"签名代码",normalizedTitle:"签名代码",charIndex:4014},{level:3,title:"1. 取出签名",slug:"_1-取出签名",normalizedTitle:"1. 取出签名",charIndex:7353},{level:3,title:"2. 校验文件自身的签名",slug:"_2-校验文件自身的签名",normalizedTitle:"2. 校验文件自身的签名",charIndex:7998},{level:3,title:"3. 验证证书链",slug:"_3-验证证书链",normalizedTitle:"3. 验证证书链",charIndex:9789},{level:3,title:"4. 比对PE文件和签名数据中的Hash",slug:"_4-比对pe文件和签名数据中的hash",normalizedTitle:"4. 比对pe文件和签名数据中的hash",charIndex:11924},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:13043},{level:2,title:"思考",slug:"思考",normalizedTitle:"思考",charIndex:13146},{level:2,title:"Reference",slug:"reference",normalizedTitle:"reference",charIndex:5860}],headersStr:"签名介绍 查看签名 PE文件中签名结构 签名验证 证书生成 证书验证 验证证书的证书 签名验证 实践 嵌入式 编录式 验证签名 签名代码 1. 取出签名 2. 校验文件自身的签名 3. 验证证书链 4. 比对PE文件和签名数据中的Hash 总结 思考 Reference",content:'# PE 签名\n\n简单来说，数字签名(digital signature)是非对称公钥密码系统的逆应用：用私钥加密消息，用公钥解密消息。\n\n而证书，实际上就是对公钥进行数字签名，它是对公钥合法性提供证明的技术。\n\n一般来说，证书有两个作用：确保软件来自软件发布者、保护软件在发行后不被更改。本文就是围绕这两个核心问题进行展开说明。\n\n\n# 签名介绍\n\nwindows 平台下的 PE签名 大致可以分为embedded、catalog两种，区别如下：\n\n * embedded\n   * 嵌入式签名，顾名思义，将签名数据嵌入到 PE 文件中\n   * 右键属性即可查看相关信息\n   * 格式公开，可以自己解析\n * catalog\n   * 编录式签名，将签名数据放到一个后缀为.cat的编录文件中，并不嵌入到 PE 文件中。这种签名方法可以对任意格式的文件签名，并不局限于PE文件\n   * 右键查看文件属性看不到数字签名标签(因为签名数据是独立文件)\n   * 微软未公开格式文档\n\n另外，对于运行于内核中的文件，Microsoft 要求必须进行交叉证书认证。(可以通过 signtool verify /v /kp <mydriver.sys> 查看交叉证书链)。\n\n【在2021年7月1日之后，必须使用 WHQL 签名对内核模式驱动程序签名。不能使用链接到2021年7月1日之后过期的交叉证书的证书来对内核模式驱动程序进行签名。】\n\n\n# 查看签名\n\n嵌入式签名内容如下：\n\n签名中包含的主要信息有：\n\n * 签名者(signer)\n   * 名字、邮箱、签名时间(一般以\'副署\'中时间戳为准)\n * 签名时间\n   * 一般用副署签名中的时间戳\n * 副署签名(counter signature)\n   * optional，一个独立、完整的签名\n   * 一般用于签名时间戳，指明允许用当前时间签名数据\n   * 常见的两种数据格式:\n     * szOID_RFC3161_counterSign\n       * To obtain the timestamp information (RFC3161) of that signature, search the Unauthenticated attribute with pszObjId = szOID_RFC3161_counterSign (1.3.6.1.4.1.311.3.3.1).\n       * 暂未找到此字段的完整格式描述，但能找到解出时间戳的相关代码\n     * szOID_RSA_counterSign\n * 嵌套签名(nested signature)\n   * optional，一个独立、完整的签名\n   * 如果文件属性中的签名列表有多个签名，从结构上讲，第二个(包含)签名开始就是嵌套签名\n   * Authenticode stores secondary signatures in the UnauthenticatedAttributes of primary signer (index 0), instead of additional PKCS 7 signer.\n     * From the primary signature, search the UnauthenticatedAttribue for below: define szOID_NESTED_SIGNATURE "1.3.6.1.4.1.311.2.4.1". The encoded object of this attribute is a full PKCS 7 signer.\n   * 注意对照下文 SignedData 结构的 SignerInfos 字段的用途\n * 证书(certificate)：\n   * 证书链(certificate chain)\n     * 文件中内嵌的证书链，只到 ca 证书，不包含根证书\n   * 签名\n     * 不能在属性中查看\n     * 用 CA 私钥对证书主体(即下文 X509 证书的TBSCertificate结构)加密形成的签名\n   * 证书详情\n     * 版本(Version)\n     * 序列号(Serial Number)\n       * 由 CA 指定的独一无二的 ID\n     * 颁发者(Issuer)、使用者(Subject)\n     * 证书有效期(Not Before、Not After)\n     * 签名算法、公钥、公钥参数\n       * Subject Public Key 相关的信息\n     * 签名哈希算法\n     * CRL(证书吊销列表, Certificate revocation list) 分发点\n     * 指纹\n       * windows 查看 PE 属性时能看到，对 证书完整内容 进行 SHA1 计算得到\n     * 秘钥用法(Key Usage)、增强型(enhanced)秘钥用法\n       * 指明证书的用途范围\n     * 证书策略\n     * 授权信息访问、授权秘钥标识符、使用者秘钥标识符\n\n可以通过命令 openssl x509 -in abc.cer -text -noout 查看证书的详细信息(此工具不支持 DER 编码二进制 X.509, 只支持 Base64 编码的 X.509)。\n\n可以在 Windows 系统的运行中输入certmgr.msc可以看到系统默认的ECC签名的根证书。\n\n\n# PE文件中签名结构\n\n嵌入式签名结构如下：\n\n\n# 签名验证\n\n\n# 证书生成\n\n 1. 服务器将公钥A给CA(公钥是服务器的)\n 2. CA用自己的私钥B给公钥A加密，生成数字签名A\n 3. CA把公钥A，数字签名A，附加一些服务器信息整合在一起，生成证书，发回给服务器\n\n注：私钥B是用于加密公钥A的，私钥B和公钥A并不是配对的\n\n\n# 证书验证\n\n 1. 客户端得到证书\n 2. 客户端得到用于证书验证的公钥B(通过CA或系统内嵌或其它途径)\n 3. 客户端用公钥B对证书中的数字签名解密，得到哈希值\n 4. 客户端对证书中的公钥A进行哈希值计算\n 5. 两个哈希值对比，如果相同，则证书合法\n\n注：公钥B和上述的私钥B是配对的，分别用于对证书的验证(解密)和生成(加密)\n\n\n# 验证证书的证书\n\n客户端得到的用于证书验证的公钥B是合法的吗？为了解决这个问题，我们也需要想办法对公钥B也进行验证，这就需要找到对公钥B也进行签名、验证，就就是前面讲到的生成证书、验证证书。不过，这个过程何时是个尽头呢？根证书(Root Certificate)。\n\n根证书是属于根证书颁发机构(CA)的公钥证书，是在公开金钥基础建设中，信任链的起点。安装根证书意味着对这个CA认证中心的信任。另外，根证书是自签名的证书。\n\n\n# 签名验证\n\n 1. 验证时间戳\n 2. 验证签名 hash 一致性\n 3. 验证证书是否被吊销\n 4. 沿证书链，重复以上流程以验证证书的有效性，直到根证书\n\n\n# 实践\n\n\n# 嵌入式\n\n 1. 用 makecert 生成一个自签名的根证书: makecert -n "cn=root" -r -sv test_root.pvk test_root.cer\n 2. 用根证书签发一个子证书: makecert -n "cn=child" -iv test_root.pvk -ic test_root.cer -sv test_child.pvk test_child.cer\n 3. 当然，此时这种证书是不被系统所信任的，需要手动把生成的证书导入到系统：\n    * 在 Windows 系统的运行中输入certmgr.msc\n    * 找到 "受信任的根证书颁发机构"，右键 -> 所有任务 -> 导入\n 4. 此时，就可以使用微软的 signtool 工具对PE文件进行嵌入式签名了\n\n\n# 编录式\n\n 1. 根据需要创建一个 cdf 文件，例如：\n    \n    [CatalogHeader]\n    Name=tstamd64.cat\n    PublicVersion=0x0000001\n    EncodingType=0x00010001\n    CATATTR1=0x10010001:OSAttr:2:6.0\n    [CatalogFiles]\n    <hash>File1=amd64\\toaster.pdb\n    <hash>File2=amd64\\toaster.sys\n    <hash>File3=amd64\\toastva.exe\n    <hash>File4=amd64\\toastva.pdb\n    \n    \n    1\n    2\n    3\n    4\n    5\n    6\n    7\n    8\n    9\n    10\n    \n 2. 使用微软的 makecat 工具从上一步创建的 cdf 文件生成 cat 文件, 例如：makecat -v tstamd64.cdf\n 3. 使用微软的 signtool 工具对 cat 文件进行签名\n\n注：当然也要将证书加入信任列表\n\n注：参考 using-makecat-to-create-a-catalog-file\n\n\n# 验证签名\n\n使用命令行进行验证： signtool verify /v /kp [service-new.exe]\n\n注：参考 生成 win10 下调试服务时的证书\n\n\n# 签名代码\n\n常见的验证签名的代码片段：\n\n    BOOL CheckFileTrust( LPCWSTR lpFileName )\n    {\n        BOOL bRet = FALSE;\n        WINTRUST_DATA wd = { 0 };\n        WINTRUST_FILE_INFO wfi = { 0 };\n        WINTRUST_CATALOG_INFO wci = { 0 };\n        CATALOG_INFO ci = { 0 };\n    \n        HCATADMIN hCatAdmin = NULL;\n        if ( !CryptCATAdminAcquireContext( &amp;hCatAdmin, NULL, 0 ) )\n        {\n            return FALSE;\n        }\n    \n        HANDLE hFile = CreateFileW( lpFileName, GENERIC_READ, FILE_SHARE_READ, NULL, OPEN_EXISTING, 0, NULL );\n        if ( INVALID_HANDLE_VALUE == hFile )\n        {\n            CryptCATAdminReleaseContext( hCatAdmin, 0 );\n            return FALSE;\n        }\n    \n        DWORD dwCnt = 100;\n        BYTE byHash[100];\n        CryptCATAdminCalcHashFromFileHandle( hFile, &amp;dwCnt, byHash, 0 );\n        CloseHandle( hFile );\n    \n        LPWSTR pszMemberTag = new WCHAR[dwCnt * 2 + 1];\n        for ( DWORD dw = 0; dw &lt; dwCnt; ++dw )\n        {\n            wsprintfW( &amp;pszMemberTag[dw * 2], L"%02X", byHash[dw] );\n        }\n    \n        HCATINFO hCatInfo = CryptCATAdminEnumCatalogFromHash( hCatAdmin, byHash, dwCnt, 0, NULL );\n        if ( NULL == hCatInfo )   // 编录中没有则验证是否有嵌入式签名\n        {\n            wfi.cbStruct       = sizeof( WINTRUST_FILE_INFO );\n            wfi.pcwszFilePath  = lpFileName;\n            wfi.hFile          = NULL;\n            wfi.pgKnownSubject = NULL;\n    \n            wd.cbStruct            = sizeof( WINTRUST_DATA );\n            wd.dwUnionChoice       = WTD_CHOICE_FILE;\n            wd.pFile               = &amp;wfi;\n            wd.dwUIChoice          = WTD_UI_NONE;\n            wd.fdwRevocationChecks = WTD_REVOKE_NONE;\n            wd.dwStateAction       = WTD_STATEACTION_IGNORE;\n            wd.dwProvFlags         = WTD_SAFER_FLAG;\n            wd.hWVTStateData       = NULL;\n            wd.pwszURLReference    = NULL;\n        }\n        else  // 编录中有，验证编录文件的签名是否有效\n        {\n            CryptCATCatalogInfoFromContext( hCatInfo, &amp;ci, 0 );\n            wci.cbStruct             = sizeof( WINTRUST_CATALOG_INFO );\n            wci.pcwszCatalogFilePath = ci.wszCatalogFile;\n            wci.pcwszMemberFilePath  = lpFileName;\n            wci.pcwszMemberTag       = pszMemberTag;\n    \n            wd.cbStruct            = sizeof( WINTRUST_DATA );\n            wd.dwUnionChoice       = WTD_CHOICE_CATALOG;\n            wd.pCatalog            = &amp;wci;\n            wd.dwUIChoice          = WTD_UI_NONE;\n            wd.fdwRevocationChecks = WTD_STATEACTION_VERIFY;\n            wd.dwProvFlags         = 0;\n            wd.hWVTStateData       = NULL;\n            wd.pwszURLReference    = NULL;\n        }\n        GUID action = WINTRUST_ACTION_GENERIC_VERIFY_V2;\n        HRESULT hr  = WinVerifyTrust( NULL, &amp;action, &amp;wd );\n        bRet        = SUCCEEDED( hr );\n    \n        if ( NULL != hCatInfo )\n        {\n            CryptCATAdminReleaseCatalogContext( hCatAdmin, hCatInfo, 0 );\n        }\n        CryptCATAdminReleaseContext( hCatAdmin, 0 );\n        delete[] pszMemberTag;\n        return bRet;\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n\n\n以上是通过 Windows 的 API 进行验证操作，如果让我们自己去进行完整的验证流程，我们该怎么弄呢？\n\n\n# 1. 取出签名\n\n根据上文中 PE 结构可知，PE头的Data Directories中Certificate Table里面指明了WIN_CERTIFICATE的存放位置和大小，WIN_CERTIFICATE的bCertificate就是是SignedData格式的签名。结构如下：\n\n    typedef struct _IMAGE_DATA_DIRECTORY {\n        DWORD   VirtualAddress;  // PE文件的偏移\n        DWORD   Size;\n    } IMAGE_DATA_DIRECTORY, *PIMAGE_DATA_DIRECTORY;\n    \n    typedef struct _WIN_CERTIFICATE\n    {\n        DWORD       dwLength; // WIN_CERTIFICATE 的长度（含bCertificate的大小）\n        WORD        wRevision;\n        WORD        wCertificateType;\n        BYTE        bCertificate[ANYSIZE_ARRAY]; // signedData开始的位置\n    \n    } WIN_CERTIFICATE, *LPWIN_CERTIFICATE;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 2. 校验文件自身的签名\n\n文件签名本身是遵循PKCS7标准中的 SignedData 格式，用 ASN1 表述的格式如下：\n\n    SignedData ::= SEQUENCE {\n        version Version,\n        digestAlgorithms DigestAlgorithmIdentifiers,\n        contentInfo ContentInfo,  -- 这个里面包含了PE文件的Hash\n        certificates  --证书的数组（不包括根证书）\n            [0] IMPLICIT ExtendedCertificatesAndCertificates OPTIONAL,\n        Crls \n            [1] IMPLICIT CertificateRevocationLists OPTIONAL,\n        signerInfos SignerInfos }  -- 签名者的信息\n    \n    SignerInfos ::= SET OF SignerInfo\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\nPKCS7是加密消息的语法标准，X.509是证书的格式。ASN1是一种描述对象结构的语法，在一行的定义中可以简单的认为前面的是变量名后面的是类型。\n\nASN1并未定义编码方法，DER是一种常见的编码方法，其他还有 Base64 等编码方法。\n\nSignerInfos的结构如下：\n\n    SignerInfo ::= SEQUENCE {\n        version Version,\n        issuerAndSerialNumber IssuerAndSerialNumber,\n        digestAlgorithm DigestAlgorithmIdentifier,\n        authenticatedAttributes -- 内含SignedData中contentInfo的摘要\n            [0] IMPLICIT Attributes OPTIONAL,\n        digestEncryptionAlgorithm DigestEncryptionAlgorithmIdentifier,\n        encryptedDigest EncryptedDigest, -- 加密后的摘要\n        unauthenticatedAttributes \n            [1] IMPLICIT Attributes OPTIONAL }\n    IssuerAndSerialNumber ::= SEQUENCE {\n        issuer Name,\n        serialNumber CertificateSerialNumber }\n    EncryptedDigest ::= OCTET STRING\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\nauthenticatedAttributes 包含了 contentType和messageDigest，messageDigest 内就是对 SignedData 的 ContentInfo 做的摘要。对authenticatedAttributes 做摘要得到一个 DigestInfo 结构的数据，DigestInfo 的结构如下：\n\n    DigestInfo ::= SEQUENCE {\n        digestAlgorithm DigestAlgorithmIdentifier,\n        digest Digest }\n    \n    Digest ::= OCTET STRING\n\n\n1\n2\n3\n4\n5\n\n\n用 IssuerAndSerialNumber 找到签名者的证书，使用里面的公钥解密EncryptedDigest 得到一个 DigestInfo 结构（一般是RSA算法），将这个结构与authenticatedAttributes 做摘要得到的结构对比，一致的话才进行下一步。\n\n\n# 3. 验证证书链\n\n相关结构如下：\n\n-- X509的证书格式\n   Certificate  ::=  SEQUENCE  {\n        tbsCertificate       TBSCertificate,   -- 证书主体\n        signatureAlgorithm   AlgorithmIdentifier,  -- 签名用的算法，一般为sha1RSA\n        signatureValue       BIT STRING  }     -- 证书的签名\n \n   TBSCertificate  ::=  SEQUENCE  {\n        version         [0]  EXPLICIT Version DEFAULT v1, -- PE文件数字签名用的版本为3\n        serialNumber         CertificateSerialNumber,\n        signature            AlgorithmIdentifier,\n        issuer               Name,\n        validity             Validity, -- 有效期\n        subject              Name,\n        subjectPublicKeyInfo SubjectPublicKeyInfo,  -- 含有这个证书的公钥\n        issuerUniqueID  [1]  IMPLICIT UniqueIdentifier OPTIONAL,\n                             -- If present, version MUST be v2 or v3        \n        subjectUniqueID [2]  IMPLICIT UniqueIdentifier OPTIONAL,\n                             -- If present, version MUST be v2 or v3\n        extensions      [3]  EXPLICIT Extensions OPTIONAL  -- 扩展\n                             -- If present, version MUST be v3\n        }\n \n   -- 含有公钥的信息\n   SubjectPublicKeyInfo  ::=  SEQUENCE  {\n        algorithm            AlgorithmIdentifier,\n        subjectPublicKey     BIT STRING  }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n首先构建证书链，从终端签发数字签名的证书一直到自签名的根证书。这时要了解到证书最后一个成员为扩展，扩展是一列其他的数据，其中两项比较重要的是AuthorityKeyIdentifier和SubjectKeyIdentifier，结构分别如下\n\nAuthorityKeyIdentifier ::= SEQUENCE {\n      keyIdentifier             [0] KeyIdentifier           OPTIONAL,\n      authorityCertIssuer       [1] GeneralNames            OPTIONAL,\n      authorityCertSerialNumber [2] CertificateSerialNumber OPTIONAL  }\n \n   KeyIdentifier ::= OCTET STRING\n \n   SubjectKeyIdentifier ::= KeyIdentifier\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n组建证书链时，将把A证书的中的 AuthorityKeyIdentifier（简称AKID） 的keyIdentifier、authorityCertIssuer、authorityCertSerialNumber 与B证书的 SubjectKeyIdentifier（简称SKID）、issuer 、serialNumber 分别匹配，如果匹配上则B证书为A证书的签发者。如果A证书的上面三项与自己对应数据匹配上，则A证书为自签名的证书，证书链构建完毕。\n\n然后，校验证书链中每个证书的签名、有效期和用法（是否可以用于代码签名）。签名验证的算法为证书中的 signatureAlgorithm，签名是 signatureValue，被签名的数据为 tbsCertificate，公钥从父证书的 subjectPublicKeyInfo 里面拿。\n\n\n# 4. 比对PE文件和签名数据中的Hash\n\n签名数据中的Hash算法和Hash在SignedData的contentInfo中，contentinfo的结构为：\n\n    ContentInfo ::= SEQUENCE {\n    contentType ContentType,\n    content\n        [0] EXPLICIT ANY DEFINED BY contentType OPTIONAL \n    }\n\n\n1\n2\n3\n4\n5\n\n\ncontentType 是SPC_INDIRECT_DATA_OBJID (1.3.6.1.4.1.311.2.1.4)，表明了content的类型。content是是一个SpcIndirectDataContent结构的数据。\n\n    SpcIndirectDataContent ::= SEQUENCE {\n        data                    SpcAttributeTypeAndOptionalValue,\n        messageDigest           DigestInfo\n    } --#public—\n    \n    DigestInfo ::= SEQUENCE {\n        digestAlgorithm     AlgorithmIdentifier,\n        digest              OCTETSTRING\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndigestAlgorithm 就是Hash算法，一般为sha1。digest就是文件的Hash。\n\nHash的计算原则为排除且仅排除掉签名过程中可能会改动的数据以及数字签名本身。大概计算过程如下：\n\n * 除去PE头中 checksum 和 Certificate Table 计算PE头的HASH（含 Section Table）\n * 按每个节偏移的顺序依次对每个节的数据算HASH\n * 对PE附加数据算HASH\n   * 附加数据的起始偏移为：PE头大小+每个节的大小\n   * 附加数据大小=文件大小-(PE头+每个节)-签名的大小\n   * 签名的大小是 Optional Header Data Directories[Certificate Table].Size\n\n另外，由这个Hash算法可以看出，PE文件的签名数据都是放到PE文件最尾部的，因为只有附加数据最末尾一段为签名数据大小的数据是没有计算在PE的Hash内的。这就给文件带来了在文件尾部进行修改的可能，不是吗？\n\n\n# 总结\n\n通过上文，我们对 Windows 下的签名有了一定的了解，而这只是 Microsoft 复杂的签名系统中的一小部分，不过有了这些认知，就更容易去学习签名相关的其他细节以及更加复杂的内容了。\n\n\n# 思考\n\n * counter signature 是对哪块内容计算签名内容呢？\n   * 这个 signature 是父签名的一个属性，表达这个属性的结构体(参考链接)为：\n     \n     typedef struct _CRYPT_ATTRIBUTE {\n         LPSTR            pszObjId;\n         DWORD            cValue;\n         PCRYPT_ATTR_BLOB rgValue;\n     } CRYPT_ATTRIBUTE, *PCRYPT_ATTRIBUTE;\n     \n     typedef struct _CRYPTOAPI_BLOB {\n     DWORD cbData;\n     BYTE  *pbData;\n     } CRYPT_INTEGER_BLOB, *PCRYPT_ATTR_BLOB;\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     \n\n\n# Reference\n\n * 对Windows 平台下PE文件数字签名的一些研究\n * using-inf2cat-to-create-a-catalog-file\n * CSP学习之CryptoAPI初识\n * 用于内核模式代码签名的交叉证书\n * RFC3161 timestamp information in digital signature (authenticode)',normalizedContent:'# pe 签名\n\n简单来说，数字签名(digital signature)是非对称公钥密码系统的逆应用：用私钥加密消息，用公钥解密消息。\n\n而证书，实际上就是对公钥进行数字签名，它是对公钥合法性提供证明的技术。\n\n一般来说，证书有两个作用：确保软件来自软件发布者、保护软件在发行后不被更改。本文就是围绕这两个核心问题进行展开说明。\n\n\n# 签名介绍\n\nwindows 平台下的 pe签名 大致可以分为embedded、catalog两种，区别如下：\n\n * embedded\n   * 嵌入式签名，顾名思义，将签名数据嵌入到 pe 文件中\n   * 右键属性即可查看相关信息\n   * 格式公开，可以自己解析\n * catalog\n   * 编录式签名，将签名数据放到一个后缀为.cat的编录文件中，并不嵌入到 pe 文件中。这种签名方法可以对任意格式的文件签名，并不局限于pe文件\n   * 右键查看文件属性看不到数字签名标签(因为签名数据是独立文件)\n   * 微软未公开格式文档\n\n另外，对于运行于内核中的文件，microsoft 要求必须进行交叉证书认证。(可以通过 signtool verify /v /kp <mydriver.sys> 查看交叉证书链)。\n\n【在2021年7月1日之后，必须使用 whql 签名对内核模式驱动程序签名。不能使用链接到2021年7月1日之后过期的交叉证书的证书来对内核模式驱动程序进行签名。】\n\n\n# 查看签名\n\n嵌入式签名内容如下：\n\n签名中包含的主要信息有：\n\n * 签名者(signer)\n   * 名字、邮箱、签名时间(一般以\'副署\'中时间戳为准)\n * 签名时间\n   * 一般用副署签名中的时间戳\n * 副署签名(counter signature)\n   * optional，一个独立、完整的签名\n   * 一般用于签名时间戳，指明允许用当前时间签名数据\n   * 常见的两种数据格式:\n     * szoid_rfc3161_countersign\n       * to obtain the timestamp information (rfc3161) of that signature, search the unauthenticated attribute with pszobjid = szoid_rfc3161_countersign (1.3.6.1.4.1.311.3.3.1).\n       * 暂未找到此字段的完整格式描述，但能找到解出时间戳的相关代码\n     * szoid_rsa_countersign\n * 嵌套签名(nested signature)\n   * optional，一个独立、完整的签名\n   * 如果文件属性中的签名列表有多个签名，从结构上讲，第二个(包含)签名开始就是嵌套签名\n   * authenticode stores secondary signatures in the unauthenticatedattributes of primary signer (index 0), instead of additional pkcs 7 signer.\n     * from the primary signature, search the unauthenticatedattribue for below: define szoid_nested_signature "1.3.6.1.4.1.311.2.4.1". the encoded object of this attribute is a full pkcs 7 signer.\n   * 注意对照下文 signeddata 结构的 signerinfos 字段的用途\n * 证书(certificate)：\n   * 证书链(certificate chain)\n     * 文件中内嵌的证书链，只到 ca 证书，不包含根证书\n   * 签名\n     * 不能在属性中查看\n     * 用 ca 私钥对证书主体(即下文 x509 证书的tbscertificate结构)加密形成的签名\n   * 证书详情\n     * 版本(version)\n     * 序列号(serial number)\n       * 由 ca 指定的独一无二的 id\n     * 颁发者(issuer)、使用者(subject)\n     * 证书有效期(not before、not after)\n     * 签名算法、公钥、公钥参数\n       * subject public key 相关的信息\n     * 签名哈希算法\n     * crl(证书吊销列表, certificate revocation list) 分发点\n     * 指纹\n       * windows 查看 pe 属性时能看到，对 证书完整内容 进行 sha1 计算得到\n     * 秘钥用法(key usage)、增强型(enhanced)秘钥用法\n       * 指明证书的用途范围\n     * 证书策略\n     * 授权信息访问、授权秘钥标识符、使用者秘钥标识符\n\n可以通过命令 openssl x509 -in abc.cer -text -noout 查看证书的详细信息(此工具不支持 der 编码二进制 x.509, 只支持 base64 编码的 x.509)。\n\n可以在 windows 系统的运行中输入certmgr.msc可以看到系统默认的ecc签名的根证书。\n\n\n# pe文件中签名结构\n\n嵌入式签名结构如下：\n\n\n# 签名验证\n\n\n# 证书生成\n\n 1. 服务器将公钥a给ca(公钥是服务器的)\n 2. ca用自己的私钥b给公钥a加密，生成数字签名a\n 3. ca把公钥a，数字签名a，附加一些服务器信息整合在一起，生成证书，发回给服务器\n\n注：私钥b是用于加密公钥a的，私钥b和公钥a并不是配对的\n\n\n# 证书验证\n\n 1. 客户端得到证书\n 2. 客户端得到用于证书验证的公钥b(通过ca或系统内嵌或其它途径)\n 3. 客户端用公钥b对证书中的数字签名解密，得到哈希值\n 4. 客户端对证书中的公钥a进行哈希值计算\n 5. 两个哈希值对比，如果相同，则证书合法\n\n注：公钥b和上述的私钥b是配对的，分别用于对证书的验证(解密)和生成(加密)\n\n\n# 验证证书的证书\n\n客户端得到的用于证书验证的公钥b是合法的吗？为了解决这个问题，我们也需要想办法对公钥b也进行验证，这就需要找到对公钥b也进行签名、验证，就就是前面讲到的生成证书、验证证书。不过，这个过程何时是个尽头呢？根证书(root certificate)。\n\n根证书是属于根证书颁发机构(ca)的公钥证书，是在公开金钥基础建设中，信任链的起点。安装根证书意味着对这个ca认证中心的信任。另外，根证书是自签名的证书。\n\n\n# 签名验证\n\n 1. 验证时间戳\n 2. 验证签名 hash 一致性\n 3. 验证证书是否被吊销\n 4. 沿证书链，重复以上流程以验证证书的有效性，直到根证书\n\n\n# 实践\n\n\n# 嵌入式\n\n 1. 用 makecert 生成一个自签名的根证书: makecert -n "cn=root" -r -sv test_root.pvk test_root.cer\n 2. 用根证书签发一个子证书: makecert -n "cn=child" -iv test_root.pvk -ic test_root.cer -sv test_child.pvk test_child.cer\n 3. 当然，此时这种证书是不被系统所信任的，需要手动把生成的证书导入到系统：\n    * 在 windows 系统的运行中输入certmgr.msc\n    * 找到 "受信任的根证书颁发机构"，右键 -> 所有任务 -> 导入\n 4. 此时，就可以使用微软的 signtool 工具对pe文件进行嵌入式签名了\n\n\n# 编录式\n\n 1. 根据需要创建一个 cdf 文件，例如：\n    \n    [catalogheader]\n    name=tstamd64.cat\n    publicversion=0x0000001\n    encodingtype=0x00010001\n    catattr1=0x10010001:osattr:2:6.0\n    [catalogfiles]\n    <hash>file1=amd64\\toaster.pdb\n    <hash>file2=amd64\\toaster.sys\n    <hash>file3=amd64\\toastva.exe\n    <hash>file4=amd64\\toastva.pdb\n    \n    \n    1\n    2\n    3\n    4\n    5\n    6\n    7\n    8\n    9\n    10\n    \n 2. 使用微软的 makecat 工具从上一步创建的 cdf 文件生成 cat 文件, 例如：makecat -v tstamd64.cdf\n 3. 使用微软的 signtool 工具对 cat 文件进行签名\n\n注：当然也要将证书加入信任列表\n\n注：参考 using-makecat-to-create-a-catalog-file\n\n\n# 验证签名\n\n使用命令行进行验证： signtool verify /v /kp [service-new.exe]\n\n注：参考 生成 win10 下调试服务时的证书\n\n\n# 签名代码\n\n常见的验证签名的代码片段：\n\n    bool checkfiletrust( lpcwstr lpfilename )\n    {\n        bool bret = false;\n        wintrust_data wd = { 0 };\n        wintrust_file_info wfi = { 0 };\n        wintrust_catalog_info wci = { 0 };\n        catalog_info ci = { 0 };\n    \n        hcatadmin hcatadmin = null;\n        if ( !cryptcatadminacquirecontext( &amp;hcatadmin, null, 0 ) )\n        {\n            return false;\n        }\n    \n        handle hfile = createfilew( lpfilename, generic_read, file_share_read, null, open_existing, 0, null );\n        if ( invalid_handle_value == hfile )\n        {\n            cryptcatadminreleasecontext( hcatadmin, 0 );\n            return false;\n        }\n    \n        dword dwcnt = 100;\n        byte byhash[100];\n        cryptcatadmincalchashfromfilehandle( hfile, &amp;dwcnt, byhash, 0 );\n        closehandle( hfile );\n    \n        lpwstr pszmembertag = new wchar[dwcnt * 2 + 1];\n        for ( dword dw = 0; dw &lt; dwcnt; ++dw )\n        {\n            wsprintfw( &amp;pszmembertag[dw * 2], l"%02x", byhash[dw] );\n        }\n    \n        hcatinfo hcatinfo = cryptcatadminenumcatalogfromhash( hcatadmin, byhash, dwcnt, 0, null );\n        if ( null == hcatinfo )   // 编录中没有则验证是否有嵌入式签名\n        {\n            wfi.cbstruct       = sizeof( wintrust_file_info );\n            wfi.pcwszfilepath  = lpfilename;\n            wfi.hfile          = null;\n            wfi.pgknownsubject = null;\n    \n            wd.cbstruct            = sizeof( wintrust_data );\n            wd.dwunionchoice       = wtd_choice_file;\n            wd.pfile               = &amp;wfi;\n            wd.dwuichoice          = wtd_ui_none;\n            wd.fdwrevocationchecks = wtd_revoke_none;\n            wd.dwstateaction       = wtd_stateaction_ignore;\n            wd.dwprovflags         = wtd_safer_flag;\n            wd.hwvtstatedata       = null;\n            wd.pwszurlreference    = null;\n        }\n        else  // 编录中有，验证编录文件的签名是否有效\n        {\n            cryptcatcataloginfofromcontext( hcatinfo, &amp;ci, 0 );\n            wci.cbstruct             = sizeof( wintrust_catalog_info );\n            wci.pcwszcatalogfilepath = ci.wszcatalogfile;\n            wci.pcwszmemberfilepath  = lpfilename;\n            wci.pcwszmembertag       = pszmembertag;\n    \n            wd.cbstruct            = sizeof( wintrust_data );\n            wd.dwunionchoice       = wtd_choice_catalog;\n            wd.pcatalog            = &amp;wci;\n            wd.dwuichoice          = wtd_ui_none;\n            wd.fdwrevocationchecks = wtd_stateaction_verify;\n            wd.dwprovflags         = 0;\n            wd.hwvtstatedata       = null;\n            wd.pwszurlreference    = null;\n        }\n        guid action = wintrust_action_generic_verify_v2;\n        hresult hr  = winverifytrust( null, &amp;action, &amp;wd );\n        bret        = succeeded( hr );\n    \n        if ( null != hcatinfo )\n        {\n            cryptcatadminreleasecatalogcontext( hcatadmin, hcatinfo, 0 );\n        }\n        cryptcatadminreleasecontext( hcatadmin, 0 );\n        delete[] pszmembertag;\n        return bret;\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n\n\n以上是通过 windows 的 api 进行验证操作，如果让我们自己去进行完整的验证流程，我们该怎么弄呢？\n\n\n# 1. 取出签名\n\n根据上文中 pe 结构可知，pe头的data directories中certificate table里面指明了win_certificate的存放位置和大小，win_certificate的bcertificate就是是signeddata格式的签名。结构如下：\n\n    typedef struct _image_data_directory {\n        dword   virtualaddress;  // pe文件的偏移\n        dword   size;\n    } image_data_directory, *pimage_data_directory;\n    \n    typedef struct _win_certificate\n    {\n        dword       dwlength; // win_certificate 的长度（含bcertificate的大小）\n        word        wrevision;\n        word        wcertificatetype;\n        byte        bcertificate[anysize_array]; // signeddata开始的位置\n    \n    } win_certificate, *lpwin_certificate;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 2. 校验文件自身的签名\n\n文件签名本身是遵循pkcs7标准中的 signeddata 格式，用 asn1 表述的格式如下：\n\n    signeddata ::= sequence {\n        version version,\n        digestalgorithms digestalgorithmidentifiers,\n        contentinfo contentinfo,  -- 这个里面包含了pe文件的hash\n        certificates  --证书的数组（不包括根证书）\n            [0] implicit extendedcertificatesandcertificates optional,\n        crls \n            [1] implicit certificaterevocationlists optional,\n        signerinfos signerinfos }  -- 签名者的信息\n    \n    signerinfos ::= set of signerinfo\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\npkcs7是加密消息的语法标准，x.509是证书的格式。asn1是一种描述对象结构的语法，在一行的定义中可以简单的认为前面的是变量名后面的是类型。\n\nasn1并未定义编码方法，der是一种常见的编码方法，其他还有 base64 等编码方法。\n\nsignerinfos的结构如下：\n\n    signerinfo ::= sequence {\n        version version,\n        issuerandserialnumber issuerandserialnumber,\n        digestalgorithm digestalgorithmidentifier,\n        authenticatedattributes -- 内含signeddata中contentinfo的摘要\n            [0] implicit attributes optional,\n        digestencryptionalgorithm digestencryptionalgorithmidentifier,\n        encrypteddigest encrypteddigest, -- 加密后的摘要\n        unauthenticatedattributes \n            [1] implicit attributes optional }\n    issuerandserialnumber ::= sequence {\n        issuer name,\n        serialnumber certificateserialnumber }\n    encrypteddigest ::= octet string\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\nauthenticatedattributes 包含了 contenttype和messagedigest，messagedigest 内就是对 signeddata 的 contentinfo 做的摘要。对authenticatedattributes 做摘要得到一个 digestinfo 结构的数据，digestinfo 的结构如下：\n\n    digestinfo ::= sequence {\n        digestalgorithm digestalgorithmidentifier,\n        digest digest }\n    \n    digest ::= octet string\n\n\n1\n2\n3\n4\n5\n\n\n用 issuerandserialnumber 找到签名者的证书，使用里面的公钥解密encrypteddigest 得到一个 digestinfo 结构（一般是rsa算法），将这个结构与authenticatedattributes 做摘要得到的结构对比，一致的话才进行下一步。\n\n\n# 3. 验证证书链\n\n相关结构如下：\n\n-- x509的证书格式\n   certificate  ::=  sequence  {\n        tbscertificate       tbscertificate,   -- 证书主体\n        signaturealgorithm   algorithmidentifier,  -- 签名用的算法，一般为sha1rsa\n        signaturevalue       bit string  }     -- 证书的签名\n \n   tbscertificate  ::=  sequence  {\n        version         [0]  explicit version default v1, -- pe文件数字签名用的版本为3\n        serialnumber         certificateserialnumber,\n        signature            algorithmidentifier,\n        issuer               name,\n        validity             validity, -- 有效期\n        subject              name,\n        subjectpublickeyinfo subjectpublickeyinfo,  -- 含有这个证书的公钥\n        issueruniqueid  [1]  implicit uniqueidentifier optional,\n                             -- if present, version must be v2 or v3        \n        subjectuniqueid [2]  implicit uniqueidentifier optional,\n                             -- if present, version must be v2 or v3\n        extensions      [3]  explicit extensions optional  -- 扩展\n                             -- if present, version must be v3\n        }\n \n   -- 含有公钥的信息\n   subjectpublickeyinfo  ::=  sequence  {\n        algorithm            algorithmidentifier,\n        subjectpublickey     bit string  }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n首先构建证书链，从终端签发数字签名的证书一直到自签名的根证书。这时要了解到证书最后一个成员为扩展，扩展是一列其他的数据，其中两项比较重要的是authoritykeyidentifier和subjectkeyidentifier，结构分别如下\n\nauthoritykeyidentifier ::= sequence {\n      keyidentifier             [0] keyidentifier           optional,\n      authoritycertissuer       [1] generalnames            optional,\n      authoritycertserialnumber [2] certificateserialnumber optional  }\n \n   keyidentifier ::= octet string\n \n   subjectkeyidentifier ::= keyidentifier\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n组建证书链时，将把a证书的中的 authoritykeyidentifier（简称akid） 的keyidentifier、authoritycertissuer、authoritycertserialnumber 与b证书的 subjectkeyidentifier（简称skid）、issuer 、serialnumber 分别匹配，如果匹配上则b证书为a证书的签发者。如果a证书的上面三项与自己对应数据匹配上，则a证书为自签名的证书，证书链构建完毕。\n\n然后，校验证书链中每个证书的签名、有效期和用法（是否可以用于代码签名）。签名验证的算法为证书中的 signaturealgorithm，签名是 signaturevalue，被签名的数据为 tbscertificate，公钥从父证书的 subjectpublickeyinfo 里面拿。\n\n\n# 4. 比对pe文件和签名数据中的hash\n\n签名数据中的hash算法和hash在signeddata的contentinfo中，contentinfo的结构为：\n\n    contentinfo ::= sequence {\n    contenttype contenttype,\n    content\n        [0] explicit any defined by contenttype optional \n    }\n\n\n1\n2\n3\n4\n5\n\n\ncontenttype 是spc_indirect_data_objid (1.3.6.1.4.1.311.2.1.4)，表明了content的类型。content是是一个spcindirectdatacontent结构的数据。\n\n    spcindirectdatacontent ::= sequence {\n        data                    spcattributetypeandoptionalvalue,\n        messagedigest           digestinfo\n    } --#public—\n    \n    digestinfo ::= sequence {\n        digestalgorithm     algorithmidentifier,\n        digest              octetstring\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndigestalgorithm 就是hash算法，一般为sha1。digest就是文件的hash。\n\nhash的计算原则为排除且仅排除掉签名过程中可能会改动的数据以及数字签名本身。大概计算过程如下：\n\n * 除去pe头中 checksum 和 certificate table 计算pe头的hash（含 section table）\n * 按每个节偏移的顺序依次对每个节的数据算hash\n * 对pe附加数据算hash\n   * 附加数据的起始偏移为：pe头大小+每个节的大小\n   * 附加数据大小=文件大小-(pe头+每个节)-签名的大小\n   * 签名的大小是 optional header data directories[certificate table].size\n\n另外，由这个hash算法可以看出，pe文件的签名数据都是放到pe文件最尾部的，因为只有附加数据最末尾一段为签名数据大小的数据是没有计算在pe的hash内的。这就给文件带来了在文件尾部进行修改的可能，不是吗？\n\n\n# 总结\n\n通过上文，我们对 windows 下的签名有了一定的了解，而这只是 microsoft 复杂的签名系统中的一小部分，不过有了这些认知，就更容易去学习签名相关的其他细节以及更加复杂的内容了。\n\n\n# 思考\n\n * counter signature 是对哪块内容计算签名内容呢？\n   * 这个 signature 是父签名的一个属性，表达这个属性的结构体(参考链接)为：\n     \n     typedef struct _crypt_attribute {\n         lpstr            pszobjid;\n         dword            cvalue;\n         pcrypt_attr_blob rgvalue;\n     } crypt_attribute, *pcrypt_attribute;\n     \n     typedef struct _cryptoapi_blob {\n     dword cbdata;\n     byte  *pbdata;\n     } crypt_integer_blob, *pcrypt_attr_blob;\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     \n\n\n# reference\n\n * 对windows 平台下pe文件数字签名的一些研究\n * using-inf2cat-to-create-a-catalog-file\n * csp学习之cryptoapi初识\n * 用于内核模式代码签名的交叉证书\n * rfc3161 timestamp information in digital signature (authenticode)',charsets:{cjk:!0}},{title:"生成 win10 下调试服务时的证书",frontmatter:{title:"生成 win10 下调试服务时的证书",date:"2021-04-21T09:50:00.000Z",description:"win10 下调试服务提示证书问题的一种解决方案",categories:["platform"],tags:["win10","服务调试"],permalink:null},regularPath:"/blog/platform/windows/make_cert.html",relativePath:"blog/platform/windows/make_cert.md",key:"v-6a62161f",path:"/blog/platform/windows/make_cert.html",headers:[{level:2,title:"生成、验证证书",slug:"生成、验证证书",normalizedTitle:"生成、验证证书",charIndex:118},{level:2,title:"说明：",slug:"说明",normalizedTitle:"说明：",charIndex:660}],headersStr:"生成、验证证书 说明：",content:"# 生成 win10 下调试服务时的证书\n\n> reference: https://docs.microsoft.com/zh-cn/windows-hardware/drivers/install/test-signing\n\n\n# 生成、验证证书\n\n 1. 制作证书：(使用以下 MakeCert 命令创建 Contoso.com (测试) 证书)\n    \n    makecert -r -pe -ss PrivateCertStore -n CN=Contoso.com(Test) ContosoTest.cer\n    \n    \n    1\n    \n\n 2. 打开测试：(管理员权限，需要重启) : bcdedit /set testsigning on\n\n 3. 信任：(管理员权限) : CertMgr.exe /add ContosoTest.cer /s /r localMachine root\n\n 4. 签名：:\n    \n    Signtool sign /v /s PrivateCertStore /n Contoso.com(Test) /t http://timestamp.digicert.com tstamd64.cat\n    \n    \n    1\n    \n\n 5. 验证：signtool verify /v /kp [service-new.exe]\n\nvs2008 以上，自带以上所需工具（建议使用 vs 的 Command Prompt 工具执行）\n\n\n# 说明：\n\n * 服务 和 驱动，需要有 Cross Certificate Chain",normalizedContent:"# 生成 win10 下调试服务时的证书\n\n> reference: https://docs.microsoft.com/zh-cn/windows-hardware/drivers/install/test-signing\n\n\n# 生成、验证证书\n\n 1. 制作证书：(使用以下 makecert 命令创建 contoso.com (测试) 证书)\n    \n    makecert -r -pe -ss privatecertstore -n cn=contoso.com(test) contosotest.cer\n    \n    \n    1\n    \n\n 2. 打开测试：(管理员权限，需要重启) : bcdedit /set testsigning on\n\n 3. 信任：(管理员权限) : certmgr.exe /add contosotest.cer /s /r localmachine root\n\n 4. 签名：:\n    \n    signtool sign /v /s privatecertstore /n contoso.com(test) /t http://timestamp.digicert.com tstamd64.cat\n    \n    \n    1\n    \n\n 5. 验证：signtool verify /v /kp [service-new.exe]\n\nvs2008 以上，自带以上所需工具（建议使用 vs 的 command prompt 工具执行）\n\n\n# 说明：\n\n * 服务 和 驱动，需要有 cross certificate chain",charsets:{cjk:!0}},{title:"Introduction to PDB",frontmatter:{title:"Introduction to PDB",date:"2021-07-28T20:50:00.000Z",description:"Introduction to PDB",categories:["platform"],tags:["pdb"],permalink:null},regularPath:"/blog/platform/windows/pdb_structure.html",relativePath:"blog/platform/windows/pdb_structure.md",key:"v-de8bce82",path:"/blog/platform/windows/pdb_structure.html",headers:[{level:2,title:"Reference",slug:"reference",normalizedTitle:"reference",charIndex:26}],headersStr:"Reference",content:"# Introduction to PDB\n\n\n# Reference\n\nhttps://www.cnblogs.com/yilang/p/11978852.html https://www.jianshu.com/p/7ad20a047bb4\n\n../rsc/The_RSDS_pdb_format.mhtml",normalizedContent:"# introduction to pdb\n\n\n# reference\n\nhttps://www.cnblogs.com/yilang/p/11978852.html https://www.jianshu.com/p/7ad20a047bb4\n\n../rsc/the_rsds_pdb_format.mhtml",charsets:{}},{title:"运行时库",frontmatter:{title:"运行时库",date:"2021-07-28T20:50:00.000Z",description:"Windows 下运行时库",categories:["platform"],tags:["runtime library","window sdk version"],permalink:null},regularPath:"/blog/platform/windows/runtime_lib.html",relativePath:"blog/platform/windows/runtime_lib.md",key:"v-3682497f",path:"/blog/platform/windows/runtime_lib.html",headers:[{level:2,title:'一 "Windows SDK 版本" 和 "平台工具集"',slug:"一-windows-sdk-版本-和-平台工具集",normalizedTitle:"一 &quot;windows sdk 版本&quot; 和 &quot;平台工具集&quot;",charIndex:null},{level:3,title:'"Windows SDK 版本"',slug:"windows-sdk-版本",normalizedTitle:"&quot;windows sdk 版本&quot;",charIndex:null},{level:3,title:'"平台工具集"',slug:"平台工具集",normalizedTitle:"&quot;平台工具集&quot;",charIndex:null},{level:2,title:"二 运行库(MT MTd MD MDd)",slug:"二-运行库-mt-mtd-md-mdd",normalizedTitle:"二 运行库(mt mtd md mdd)",charIndex:1780},{level:3,title:"VS2013及以前版本",slug:"vs2013及以前版本",normalizedTitle:"vs2013及以前版本",charIndex:2090},{level:3,title:"VS2015及以后版本",slug:"vs2015及以后版本",normalizedTitle:"vs2015及以后版本",charIndex:3097},{level:2,title:"三 (动态链接)库文件",slug:"三-动态链接-库文件",normalizedTitle:"三 (动态链接)库文件",charIndex:4137},{level:2,title:"四 思考",slug:"四-思考",normalizedTitle:"四 思考",charIndex:6091},{level:2,title:"五 Reference",slug:"五-reference",normalizedTitle:"五 reference",charIndex:6150}],headersStr:'一 "Windows SDK 版本" 和 "平台工具集" "Windows SDK 版本" "平台工具集" 二 运行库(MT MTd MD MDd) VS2013及以前版本 VS2015及以后版本 三 (动态链接)库文件 四 思考 五 Reference',content:'# 运行时库\n\n在用 visual studio 进行开发时，属性->常规 设置页面里看到的 "Windows SDK 版本" 和 "平台工具集" 两个属性，是否不明白用途？开发的程序发布后经常遇到提示缺少msvcp140.dll 或 msvcr100.dll 或者其他的运行库文件？是否经常遇到安装软件时提示需要安装 "vc_redist.x86.exe" 文件？这里会为你解答这些疑惑。\n\n\n# 一 "Windows SDK 版本" 和 "平台工具集"\n\n\n# "Windows SDK 版本"\n\n此属性指定用于生成项目的 Windows SDK 的版本。"Windows SDK 版本" 是 Visual Studio 2019 中的属性名，在 ~ Visual Studio 2015 中名为 "目标平台版本"。\n\n如果你的应用程序可以利用此 Windows SDK 版本中的功能，但仍可在不使用这些功能的早期 Windows 版本上运行（可能会丢失某些功能），则此属性和 目标平台最小版本 属性的值可能不同。 如果是这样，则您的代码应在运行时检查其正在运行的平台的版本，并禁用旧平台版本中不可用的功能。\n\n此外，我们需要注意：\n\n * 预处理器宏 _WIN32_WINNT，WINVER 指定代码支持的最低操作系统版本\n * 任何给定的 Windows SDK 大多都与 Windows SDK 的较早版本向后兼容\n   * 这允许我们使用较新的 Windows SDK 版本，但运行在不使用这些功能的早期 Windows 版本上\n * _WIN32_WINNT，WINVER 和 NTDDI_VERSION 宏以及 "平台工具集" 字段，它们共同决定了应用程序可以运行的 Windows 系统版本\n\n如果您的应用程序需要在 Windows XP 上运行，则必须选择一个以_xp结尾的 平台工具集，选择一个较旧的 Windows SDK 版本并设置 _WIN32_WINNT，WINVER 和 NTDDI_VERSION 宏。\n\n例如，我们可以使用以下配置C ++项目：\n\n    C ++项目=>属性=>配置属性=>常规\n        目标平台版本= 10  (使用此SDK，您可以利用Windows 10操作系统的功能)\n    将名为 TargetVer.h 的头文件添加到您的项目中，该文件包含以下预处理器宏：\n        #define WINVER 0x0603 // Windows 8.1\n        #define _WIN32_WINNT 0x0603 // Windows 8.1\n\n\n1\n2\n3\n4\n5\n\n\n\n# "平台工具集"\n\n此属性指定用于生成当前配置的工具集。包含了(不限于)需要为 C++ 项目指定的以下内容：\n\n * 编译器\n   * 例如：v142 导致使用 Visual Studio 2019 编译器\n * Visual C ++库\n   * 例如：v142 表示您正在使用 Visual Studio 2019 C++ 库，这意味着，您的应用程序在部署期间将需要 Visual Studio 2019 C++ 可再发行组件(MSVCRxxx.dll)\n     * 可再发行组件安装到：C:\\\\Windows\\\\ 或 C:\\\\Windows\\\\SysWOW64\\\\\n   * Visual Studio 的 Redist 位置：\n   * 2019：C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Redist\\\\\n   * 2005：C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 8\\\\VC\\\\redist\\\\\n * MSVCR\n   * MS =微软，V =视觉，C =C++，R =可再发行\n   * 应用程序可以通过引用 _MSC_VER 预处理程序宏来确定使用哪个 C++ 库\n\n另外，需要注意的是 Platform Toolset 是项目级别的设置(请参见 *.vcxproj 中的 PlatformToolset)，而所选的 Windows SDK Version 保存在其他位置。\n\n\n# 二 运行库(MT MTd MD MDd)\n\n运行时库(Runtime Library), 也简称 CRT(C Run Time Library)。是程序在运行时所需要的库文件，通常运行时库是以 Lib 或 Dll 形式提供的。\n\nWindows 下 C Runtime Library 是微软对 C 标准库函数的实现，这样每个程序可以直接使用 C 标准库的函数；后来出现了 C++，于是又在 C Runtime Library 基础上开发了 C++ Runtime Library，实现了对 C++ 标准库的支持。因此现在 Windows 下的 C/C++ 运行时库既包含 C 标准库，也包含 C++ 标准库。\n\n\n# VS2013及以前版本\n\nVS2015以前版本 中的 Runtime Library 的类型有：CRT 和 C++ Standard Library.\n\nThis table lists the libraries that implement CRT initialization and termination.\n\n类型                         简称     含义                依赖的库\nMulti-Threaded             /MT    Release版的多线程静态库   libcmt.lib\nMulti-Threaded Debug       /MTd   Debug版的多线程静态库     libcmtd.lib\nMulti-Threaded DLL         /MD    Release版的多线程动态库   msvcrt.lib + msvcr*.dll\nMulti-Threaded DLL Debug   /MDd   Debug版的多线程动态库     msvcrtd.lib + msvcr*d.dll\n\n此外，为了支持 .NET 和 C 的混编，引入了 /clr 选项(只支持 /MD 选项)：\n\n选项     版本        依赖的库\n/clr   Release   msvcmrt.lib\n/clr   Debug     msvcmrtd.lib\n\nC++ Standard Library .lib files\n\n类型                         简称     含义                依赖的库\nMulti-Threaded             /MT    Release版的多线程静态库   libcpmt.lib\nMulti-Threaded Debug       /MTd   Debug版的多线程静态库     libcpmtd.lib\nMulti-Threaded DLL         /MD    Release版的多线程动态库   msvcprt.lib + msvcp*.dll\nMulti-Threaded DLL Debug   /MDd   Debug版的多线程动态库     msvcprtd.lib + msvcp*d.dll\n\n\n# VS2015及以后版本\n\nVS2015及以后版本 中 CRT 被拆分成了两部分：UCRT 和 vcruntime library。(注意，C++ Standard Librar 跟原来一样，这里就不再重复。)\n\nThe following table lists the libraries that implement the UCRT.\n\n类型                         简称     含义                依赖的库\nMulti-Threaded             /MT    Release版的多线程静态库   libucrt.lib\nMulti-Threaded Debug       /MTd   Debug版的多线程静态库     libucrtd.lib\nMulti-Threaded DLL         /MD    Release版的多线程动态库   ucrt.lib + ucrtbase.dll\nMulti-Threaded DLL Debug   /MDd   Debug版的多线程动态库     ucrtd.lib + ucrtbased.dll\n\nThis table lists the libraries that implement the vcruntime library.\n\n类型                         简称     含义                依赖的库\nMulti-Threaded             /MT    Release版的多线程静态库   libvcruntime.lib\nMulti-Threaded Debug       /MTd   Debug版的多线程静态库     libvcruntimed.lib\nMulti-Threaded DLL         /MD    Release版的多线程动态库   vcruntime.lib + vcruntime*.dll\nMulti-Threaded DLL Debug   /MDd   Debug版的多线程动态库     vcruntimed.lib + vcruntime*d.dll\n\n根据上表，我们可以发现 MT MTd MD MDd 的依赖不同。至于 动态库、静态库 的不同，大伙可以自行查找资料(主要区别在于一个进程中的多个模块使用的同一个库是否共享)~\n\n\n# 三 (动态链接)库文件\n\n 1. msvcrt*.dll\n    * 它是 vc6 以及之前的 CRT 库，特点是 c 和 c++ 的函数都在一个文件\n 2. msvcp*.dll 和 msvcr*.dll\n    * 它是 vc7 ~ vs2013使用 CRT 库\n    * c 和 c++ 的函数是分开存放在不同文件的，c 对应 msvcr*.dll， c++ 对应 msvcp*.dll\n 3. msvcp*.dll、ucrtbase.dll 和 vcruntime*.dll\n    * 它是 vs2015 ~使用的 CRT 库\n    * vs2015 已经没有 msvcr140.dll 了, 它被拆成了两个文件：\n      * ucrtbase.dll 包含标准c库的内容\n        * UCRT(The Universal CRT) contains the functions and globals exported by the standard C99 CRT library.\n      * vcruntime140.dll 包含 c++ 运行期需要处理的特别功能，如：调试支持、异常处理、以及耦合到相关编译器的功能。\n 4. api-ms-win-*.dll\n    * vs2015 以及之后版本的 redist 库还包含 Windows API Sets (形如api-ms-win-crt-runtime-l1-1-0.dll)\n    * 所有版本的 Windows 10 共享一个通用的操作系统组件基础，称为core OS（在某些情况下，此通用基础也称为 OneCore）。在核心操作系统组件中，Win32 API 被组织成称为 API 集的功能组。\n    * Windows API Sets 主要是为了以下场景：跨各种不同的 win10 设备平台(如 HoloLens, Xbox, and other devices running Windows 10x)、为各平台提供最小的可用 API 集合\n\n还有一些其他的库文件如：\n\n 1. vcomp140.dll\n    * 它是 Microsoft Visual C++ Redistributable Packages for Visual Studio 2015 的一部分，用于支持 OpenMP 功能\n    * 这个文件相关的功能，目前只能 动态链接\n\n相关的版本信息如下：\n\nMSVC          MSC_VER (VISUAL STUDIO)                      C/C++ RUN TIME\nMSVC++ 14.0   _MSC_VER == 1900 (Visual Studio 2015)        ucrtbase.dll vcruntime140.dll msvcp140.dll\nMSVC++ 12.0   _MSC_VER == 1800 (Visual Studio 2013)        msvcr120.dll msvcp120.dll\nMSVC++ 11.0   _MSC_VER == 1700 (Visual Studio 2012)        msvcr110.dll msvcp110.dll\nMSVC++ 10.0   _MSC_VER == 1600 (Visual Studio 2010)        msvcr100.dll msvcp100.dll\nMSVC++ 9.0    _MSC_VER == 1500 (Visual Studio 2008)        msvcr90.dll msvcp90.dll\nMSVC++ 8.0    _MSC_VER == 1400 (Visual Studio 2005)        msvcr80.dll msvcp80.dll\nMSVC++ 7.1    _MSC_VER == 1310 (Visual Studio .NET 2003)   msvcr71.dll msvcp71.dll\nMSVC++ 7.0    _MSC_VER == 1300 (Visual Studio .NET 2002)   msvcr70.dll msvcp70.dll\nMSVC++ 6.0    _MSC_VER == 1200 (Visual Studio 6.0)         msvcrt.dll\nMSVC++ 5.0    _MSC_VER == 1100 (Visual Studio 97)          msvcrt.dll\n\n\n# 四 思考\n\n 1. c++ 版本的选择 怎么生效的？\n 2. 为什么运行库会有这么多历史变化？\n 3. 总结\n\n\n# 五 Reference\n\n * “常规”属性页（项目）\n * C runtime (CRT) and C++ Standard Library (STL) .lib files\n * Windows API sets\n * vs2015部署---下一代VC运行时库系统：the Universal CRT\n * 带你玩转 Visual Studio——带你跳出坑爹的 Runtime Library 坑',normalizedContent:'# 运行时库\n\n在用 visual studio 进行开发时，属性->常规 设置页面里看到的 "windows sdk 版本" 和 "平台工具集" 两个属性，是否不明白用途？开发的程序发布后经常遇到提示缺少msvcp140.dll 或 msvcr100.dll 或者其他的运行库文件？是否经常遇到安装软件时提示需要安装 "vc_redist.x86.exe" 文件？这里会为你解答这些疑惑。\n\n\n# 一 "windows sdk 版本" 和 "平台工具集"\n\n\n# "windows sdk 版本"\n\n此属性指定用于生成项目的 windows sdk 的版本。"windows sdk 版本" 是 visual studio 2019 中的属性名，在 ~ visual studio 2015 中名为 "目标平台版本"。\n\n如果你的应用程序可以利用此 windows sdk 版本中的功能，但仍可在不使用这些功能的早期 windows 版本上运行（可能会丢失某些功能），则此属性和 目标平台最小版本 属性的值可能不同。 如果是这样，则您的代码应在运行时检查其正在运行的平台的版本，并禁用旧平台版本中不可用的功能。\n\n此外，我们需要注意：\n\n * 预处理器宏 _win32_winnt，winver 指定代码支持的最低操作系统版本\n * 任何给定的 windows sdk 大多都与 windows sdk 的较早版本向后兼容\n   * 这允许我们使用较新的 windows sdk 版本，但运行在不使用这些功能的早期 windows 版本上\n * _win32_winnt，winver 和 ntddi_version 宏以及 "平台工具集" 字段，它们共同决定了应用程序可以运行的 windows 系统版本\n\n如果您的应用程序需要在 windows xp 上运行，则必须选择一个以_xp结尾的 平台工具集，选择一个较旧的 windows sdk 版本并设置 _win32_winnt，winver 和 ntddi_version 宏。\n\n例如，我们可以使用以下配置c ++项目：\n\n    c ++项目=>属性=>配置属性=>常规\n        目标平台版本= 10  (使用此sdk，您可以利用windows 10操作系统的功能)\n    将名为 targetver.h 的头文件添加到您的项目中，该文件包含以下预处理器宏：\n        #define winver 0x0603 // windows 8.1\n        #define _win32_winnt 0x0603 // windows 8.1\n\n\n1\n2\n3\n4\n5\n\n\n\n# "平台工具集"\n\n此属性指定用于生成当前配置的工具集。包含了(不限于)需要为 c++ 项目指定的以下内容：\n\n * 编译器\n   * 例如：v142 导致使用 visual studio 2019 编译器\n * visual c ++库\n   * 例如：v142 表示您正在使用 visual studio 2019 c++ 库，这意味着，您的应用程序在部署期间将需要 visual studio 2019 c++ 可再发行组件(msvcrxxx.dll)\n     * 可再发行组件安装到：c:\\\\windows\\\\ 或 c:\\\\windows\\\\syswow64\\\\\n   * visual studio 的 redist 位置：\n   * 2019：c:\\\\program files (x86)\\\\windows kits\\\\10\\\\redist\\\\\n   * 2005：c:\\\\program files (x86)\\\\microsoft visual studio 8\\\\vc\\\\redist\\\\\n * msvcr\n   * ms =微软，v =视觉，c =c++，r =可再发行\n   * 应用程序可以通过引用 _msc_ver 预处理程序宏来确定使用哪个 c++ 库\n\n另外，需要注意的是 platform toolset 是项目级别的设置(请参见 *.vcxproj 中的 platformtoolset)，而所选的 windows sdk version 保存在其他位置。\n\n\n# 二 运行库(mt mtd md mdd)\n\n运行时库(runtime library), 也简称 crt(c run time library)。是程序在运行时所需要的库文件，通常运行时库是以 lib 或 dll 形式提供的。\n\nwindows 下 c runtime library 是微软对 c 标准库函数的实现，这样每个程序可以直接使用 c 标准库的函数；后来出现了 c++，于是又在 c runtime library 基础上开发了 c++ runtime library，实现了对 c++ 标准库的支持。因此现在 windows 下的 c/c++ 运行时库既包含 c 标准库，也包含 c++ 标准库。\n\n\n# vs2013及以前版本\n\nvs2015以前版本 中的 runtime library 的类型有：crt 和 c++ standard library.\n\nthis table lists the libraries that implement crt initialization and termination.\n\n类型                         简称     含义                依赖的库\nmulti-threaded             /mt    release版的多线程静态库   libcmt.lib\nmulti-threaded debug       /mtd   debug版的多线程静态库     libcmtd.lib\nmulti-threaded dll         /md    release版的多线程动态库   msvcrt.lib + msvcr*.dll\nmulti-threaded dll debug   /mdd   debug版的多线程动态库     msvcrtd.lib + msvcr*d.dll\n\n此外，为了支持 .net 和 c 的混编，引入了 /clr 选项(只支持 /md 选项)：\n\n选项     版本        依赖的库\n/clr   release   msvcmrt.lib\n/clr   debug     msvcmrtd.lib\n\nc++ standard library .lib files\n\n类型                         简称     含义                依赖的库\nmulti-threaded             /mt    release版的多线程静态库   libcpmt.lib\nmulti-threaded debug       /mtd   debug版的多线程静态库     libcpmtd.lib\nmulti-threaded dll         /md    release版的多线程动态库   msvcprt.lib + msvcp*.dll\nmulti-threaded dll debug   /mdd   debug版的多线程动态库     msvcprtd.lib + msvcp*d.dll\n\n\n# vs2015及以后版本\n\nvs2015及以后版本 中 crt 被拆分成了两部分：ucrt 和 vcruntime library。(注意，c++ standard librar 跟原来一样，这里就不再重复。)\n\nthe following table lists the libraries that implement the ucrt.\n\n类型                         简称     含义                依赖的库\nmulti-threaded             /mt    release版的多线程静态库   libucrt.lib\nmulti-threaded debug       /mtd   debug版的多线程静态库     libucrtd.lib\nmulti-threaded dll         /md    release版的多线程动态库   ucrt.lib + ucrtbase.dll\nmulti-threaded dll debug   /mdd   debug版的多线程动态库     ucrtd.lib + ucrtbased.dll\n\nthis table lists the libraries that implement the vcruntime library.\n\n类型                         简称     含义                依赖的库\nmulti-threaded             /mt    release版的多线程静态库   libvcruntime.lib\nmulti-threaded debug       /mtd   debug版的多线程静态库     libvcruntimed.lib\nmulti-threaded dll         /md    release版的多线程动态库   vcruntime.lib + vcruntime*.dll\nmulti-threaded dll debug   /mdd   debug版的多线程动态库     vcruntimed.lib + vcruntime*d.dll\n\n根据上表，我们可以发现 mt mtd md mdd 的依赖不同。至于 动态库、静态库 的不同，大伙可以自行查找资料(主要区别在于一个进程中的多个模块使用的同一个库是否共享)~\n\n\n# 三 (动态链接)库文件\n\n 1. msvcrt*.dll\n    * 它是 vc6 以及之前的 crt 库，特点是 c 和 c++ 的函数都在一个文件\n 2. msvcp*.dll 和 msvcr*.dll\n    * 它是 vc7 ~ vs2013使用 crt 库\n    * c 和 c++ 的函数是分开存放在不同文件的，c 对应 msvcr*.dll， c++ 对应 msvcp*.dll\n 3. msvcp*.dll、ucrtbase.dll 和 vcruntime*.dll\n    * 它是 vs2015 ~使用的 crt 库\n    * vs2015 已经没有 msvcr140.dll 了, 它被拆成了两个文件：\n      * ucrtbase.dll 包含标准c库的内容\n        * ucrt(the universal crt) contains the functions and globals exported by the standard c99 crt library.\n      * vcruntime140.dll 包含 c++ 运行期需要处理的特别功能，如：调试支持、异常处理、以及耦合到相关编译器的功能。\n 4. api-ms-win-*.dll\n    * vs2015 以及之后版本的 redist 库还包含 windows api sets (形如api-ms-win-crt-runtime-l1-1-0.dll)\n    * 所有版本的 windows 10 共享一个通用的操作系统组件基础，称为core os（在某些情况下，此通用基础也称为 onecore）。在核心操作系统组件中，win32 api 被组织成称为 api 集的功能组。\n    * windows api sets 主要是为了以下场景：跨各种不同的 win10 设备平台(如 hololens, xbox, and other devices running windows 10x)、为各平台提供最小的可用 api 集合\n\n还有一些其他的库文件如：\n\n 1. vcomp140.dll\n    * 它是 microsoft visual c++ redistributable packages for visual studio 2015 的一部分，用于支持 openmp 功能\n    * 这个文件相关的功能，目前只能 动态链接\n\n相关的版本信息如下：\n\nmsvc          msc_ver (visual studio)                      c/c++ run time\nmsvc++ 14.0   _msc_ver == 1900 (visual studio 2015)        ucrtbase.dll vcruntime140.dll msvcp140.dll\nmsvc++ 12.0   _msc_ver == 1800 (visual studio 2013)        msvcr120.dll msvcp120.dll\nmsvc++ 11.0   _msc_ver == 1700 (visual studio 2012)        msvcr110.dll msvcp110.dll\nmsvc++ 10.0   _msc_ver == 1600 (visual studio 2010)        msvcr100.dll msvcp100.dll\nmsvc++ 9.0    _msc_ver == 1500 (visual studio 2008)        msvcr90.dll msvcp90.dll\nmsvc++ 8.0    _msc_ver == 1400 (visual studio 2005)        msvcr80.dll msvcp80.dll\nmsvc++ 7.1    _msc_ver == 1310 (visual studio .net 2003)   msvcr71.dll msvcp71.dll\nmsvc++ 7.0    _msc_ver == 1300 (visual studio .net 2002)   msvcr70.dll msvcp70.dll\nmsvc++ 6.0    _msc_ver == 1200 (visual studio 6.0)         msvcrt.dll\nmsvc++ 5.0    _msc_ver == 1100 (visual studio 97)          msvcrt.dll\n\n\n# 四 思考\n\n 1. c++ 版本的选择 怎么生效的？\n 2. 为什么运行库会有这么多历史变化？\n 3. 总结\n\n\n# 五 reference\n\n * “常规”属性页（项目）\n * c runtime (crt) and c++ standard library (stl) .lib files\n * windows api sets\n * vs2015部署---下一代vc运行时库系统：the universal crt\n * 带你玩转 visual studio——带你跳出坑爹的 runtime library 坑',charsets:{cjk:!0}},{title:"Skills 目录",frontmatter:{published:!0,title:"Skills 目录",description:"devops、bigdata、ml、ai 等前沿技术技能",keywords:[""],categories:["skills","devops","image processing","k8s"],permalink:"/blog/skills/",date:"2020-04-13T00:00:00.000Z",tags:[null]},regularPath:"/blog/skills/",relativePath:"blog/skills/README.md",key:"v-1d6a5088",path:"/blog/skills/",headers:[{level:2,title:"一、 Office",slug:"一、-office",normalizedTitle:"一、 office",charIndex:16},{level:2,title:"二、 Ui",slug:"二、-ui",normalizedTitle:"二、 ui",charIndex:92},{level:2,title:"三、 Ai",slug:"三、-ai",normalizedTitle:"三、 ai",charIndex:124},{level:2,title:"四、 Utils",slug:"四、-utils",normalizedTitle:"四、 utils",charIndex:258},{level:2,title:"五、 Pdf",slug:"五、-pdf",normalizedTitle:"五、 pdf",charIndex:333},{level:2,title:"六、 Devops",slug:"六、-devops",normalizedTitle:"六、 devops",charIndex:357}],headersStr:"一、 Office 二、 Ui 三、 Ai 四、 Utils 五、 Pdf 六、 Devops",content:"# SKILLS 目录\n\n\n# 一、 Office\n\n * Ms Shell Link 格式简析\n * Office 格式简析\n * Office 格式简析 - Crypto\n\n\n# 二、 Ui\n\n * Ui 杂项\n * Inkscape\n\n\n# 三、 Ai\n\n * Nn 论文阅读\n * 大数据架构理论\n * Single Image Super Resolution\n * 图像处理基础\n * 机器学习评估指标:分类\n * Pca原理推导\n * 漫步神经网络应用\n * Pytorch入门(快速、深度)\n\n\n# 四、 Utils\n\n * Programing For Children\n * 字符集 & 编码\n * Windows Wallpapers\n\n\n# 五、 Pdf\n\n * Pdf 格式简析\n\n\n# 六、 Devops\n\n * K8S-Ipvs连接保持\n * Docker 基础知识\n * K8S网络之Service间的通信\n * K8S网络之网络框架\n * Kubernetes 简述\n * K8S网络之集群外访问Service的方式\n * K8S 的 Rolling Update\n * Opentracing 简介",normalizedContent:"# skills 目录\n\n\n# 一、 office\n\n * ms shell link 格式简析\n * office 格式简析\n * office 格式简析 - crypto\n\n\n# 二、 ui\n\n * ui 杂项\n * inkscape\n\n\n# 三、 ai\n\n * nn 论文阅读\n * 大数据架构理论\n * single image super resolution\n * 图像处理基础\n * 机器学习评估指标:分类\n * pca原理推导\n * 漫步神经网络应用\n * pytorch入门(快速、深度)\n\n\n# 四、 utils\n\n * programing for children\n * 字符集 & 编码\n * windows wallpapers\n\n\n# 五、 pdf\n\n * pdf 格式简析\n\n\n# 六、 devops\n\n * k8s-ipvs连接保持\n * docker 基础知识\n * k8s网络之service间的通信\n * k8s网络之网络框架\n * kubernetes 简述\n * k8s网络之集群外访问service的方式\n * k8s 的 rolling update\n * opentracing 简介",charsets:{cjk:!0}},{title:"漫步神经网络应用",frontmatter:{title:"漫步神经网络应用",date:"2021-02-22T09:50:00.000Z",description:"照片转换为动漫风格、常见的优质网络",categories:["imgproc"],tags:["anime style"],permalink:null},regularPath:"/blog/skills/ai/anime_roam.html",relativePath:"blog/skills/ai/anime_roam.md",key:"v-091c8f7f",path:"/blog/skills/ai/anime_roam.html",headers:[{level:2,title:"1. 动漫风格转换",slug:"_1-动漫风格转换",normalizedTitle:"1. 动漫风格转换",charIndex:2},{level:3,title:"相关阅读",slug:"相关阅读",normalizedTitle:"相关阅读",charIndex:1164},{level:2,title:"2. 真人眨眼睛",slug:"_2-真人眨眼睛",normalizedTitle:"2. 真人眨眼睛",charIndex:1276},{level:3,title:"facial-action-units introduce",slug:"facial-action-units-introduce",normalizedTitle:"facial-action-units introduce",charIndex:1500},{level:3,title:"paper : FLNet: Landmark Driven Fetching and Learning Network for Faithful Talking Facial Animation Synthesis",slug:"paper-flnet-landmark-driven-fetching-and-learning-network-for-faithful-talking-facial-animation-synthesis",normalizedTitle:"paper : flnet: landmark driven fetching and learning network for faithful talking facial animation synthesis",charIndex:1534},{level:2,title:"3. 扣图",slug:"_3-扣图",normalizedTitle:"3. 扣图",charIndex:1869},{level:2,title:"4. Scaling",slug:"_4-scaling",normalizedTitle:"4. scaling",charIndex:2020},{level:3,title:"去燥",slug:"去燥",normalizedTitle:"去燥",charIndex:3068},{level:2,title:"5. 优质模型",slug:"_5-优质模型",normalizedTitle:"5. 优质模型",charIndex:3301},{level:2,title:"6. Notes",slug:"_6-notes",normalizedTitle:"6. notes",charIndex:4619},{level:3,title:"1. 杂项记录",slug:"_1-杂项记录",normalizedTitle:"1. 杂项记录",charIndex:4632},{level:3,title:"2. 深度阅读",slug:"_2-深度阅读",normalizedTitle:"2. 深度阅读",charIndex:4970}],headersStr:"1. 动漫风格转换 相关阅读 2. 真人眨眼睛 facial-action-units introduce paper : FLNet: Landmark Driven Fetching and Learning Network for Faithful Talking Facial Animation Synthesis 3. 扣图 4. Scaling 去燥 5. 优质模型 6. Notes 1. 杂项记录 2. 深度阅读",content:"# 1. 动漫风格转换\n\nGAN                 TYPE         CODE                                                          ONLINE     NOTE\nCartoonGAN          pytorch      https://github.com/znxlwm/pytorch-CartoonGAN                  x          \nCartoonGAN          tensorflow   https://github.com/mnicnc404/CartoonGan-tensorflow            自带预训练      预训练模型:\n                                                                                                          http://cg.cs.tsinghua.edu.cn/people/~Yongjin/CartoonGAN-Models.rar，\n                                                                                                          效果较差（图片细节保留不足）\nAnimeGAN            tensorflow   https://github.com/TachibanaYoshino/AnimeGAN                  x          pytorch 实现：https://github.com/XuHangkun/AnimeGAN_in_Pytorch\nAnimeGANv2          tensorflow   https://github.com/TachibanaYoshino/AnimeGANv2                x ｜ 效果未知   \nWhite-box Cartoon   tensorflow   https://github.com/SystemErrorWang/White-box-Cartoonization   自带预训练      效果最好，应用：https://github.com/margaretmz/cartoonizer-with-tflite\n\nhttps://github.com/zhen8838/AnimeStylized 用 pytorch 实现了以上几种 GAN，但是训练出的效果和原版有差异\n\n\n# 相关阅读\n\n * Making Anime Faces With StyleGAN\n * AnimeGAN将现实照片动漫化，超越清华的CartoonGAN\n * AI灵魂画手——扒一扒抖音爆款”变身漫画“后的技术事\n\n\n# 2. 真人眨眼睛\n\nGANimation: Anatomically-aware Facial Animation from a Single Image\n\nAn Out-of-the-Box Replicate of GANimation using PyTorch, pretrained weights are available! https://github.com/donydchen/ganimation_replicate\n\n\n# facial-action-units introduce\n\n\n# paper : FLNet: Landmark Driven Fetching and Learning Network for Faithful Talking Facial Animation Synthesis\n\n * Facial Action Units (AUs) Based Methods\n   * GANimation: Anatomically-aware Facial Animation from a Single Image\n * Landmark Driven Methods\n   * First Order Motion Model for Image Animation （自监督特征点识别）\n\nFLNet 融合了以上两个方法\n\n\n# 3. 扣图\n\n人脸识别：https://github.com/cmusatyalab/openface https://github.com/Hsintao/pfld_106_face_landmarks https://github.com/polarisZhao/PFLD-pytorch\n\n\n# 4. Scaling\n\nNAME                ATTR                             NOTE                                                GITHUB\nvideo2x             x                                只是应用框架，需要下述算法驱动                                     https://github.com/k4yt3x/video2x\nReal-SR             x                                winner of CVPR NTIRE 2020 Challenge on Real-World   https://github.com/Tencent/Real-SR\n                                                     Super-Resolution\nBSRGAN ｜ x ｜ 2021   https://github.com/cszn/BSRGAN                                                       \n\nUSRNet ｜ x ｜ CVPR 2020 ｜ https://github.com/cszn/USRNet waifu2x | x | x | https://github.com/nagadomi/waifu2x/ RCAN ｜ x ｜ ECCV 2018 ｜ https://github.com/xinntao/BasicSR ESRGAN | 比 RCAN 更晚出现，虽然 PSNR 值比 RCAN 稍低，但视觉效果更高 | ECCV 2018 | https://github.com/xinntao/ESRGAN Anime4K | x | non-machine-learning based | https://github.com/bloc97/Anime4K SRMD | x | CVPR 2018 | https://github.com/cszn/KAIR\n\nreference：https://blog.csdn.net/gwplovekimi/article/details/83041627\n\n\n# 去燥\n\n * hdrnet\n   * https://github.com/google/hdrnet\n     * https://groups.csail.mit.edu/graphics/hdrnet/\n   * https://github.com/creotiv/hdrnet-pytorch\n * Image-Adaptive-3DLUT\n   * https://github.com/HuiZeng/Image-Adaptive-3DLUT\n\n\n# 5. 优质模型\n\nNAME                               DESCRIPTION                                                  TYPE      CODE                                                            NOTE\nface-alignment                     2D and 3D Face alignment library                             pytorch   https://github.com/1adrianb/face-alignment                      x\nface_recognition                   simplest facial recognition api                              dlib      https://github.com/ageitgey/face_recognition                    x\nfirst-order-model                  the source code for the paper First Order Motion Model for   pytorch   https://github.com/AliaksandrSiarohin/first-order-model         x\n                                   Image Animation\nMMDetection                        最强的目标检测                                                      pytorch   https://github.com/open-mmlab/mmdetection                       x\nBringing-Old-Photos-Back-to-Life   Bringing Old Photo Back to Life (CVPR 2020 oral)             pytorch   https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life   x\n\n头像动态：https://github.com/alievk/avatarify-python 动漫识别：https://github.com/soruly/trace.moe ：（数据源：https://anilist.co/anime）\n\nModels https://github.com/tensorflow/models\n\n垃圾分类： https://github.com/wusaifei/garbage_classify\n\n\n# 6. Notes\n\n\n# 1. 杂项记录\n\n 1. tensorflow 版本\n\n * tensorflow==1.12.0 -> python[version='>=3.6,❤️.7.0a0']\n\n 2. 图片读取\n\nLIB      TYPE         CHANNELS\nopencv   numpy 类型     默认 BGR，shape 为 HWC\nPIL      PIL中的具体的类型   根据图像格式：一般为 RGB，shape 为 HWC\n\npytorch 中使用 torchvision.datasets 模块读取图像，输出的数据类型为 PILImage，并且图像中的每一个数据大小范围已经不再是[0,255]，而是[0,1].\n\n 3. 常用数据集：imagenet\n\n\n# 2. 深度阅读\n\n * 训练GANs一年我学到的10个教训\n * 纵览轻量化卷积神经网络：SqueezeNet、MobileNet、ShuffleNet、Xception\n * 机器学习：各种优化器Optimizer的总结与比较\n\n理解 Normalize： https://blog.csdn.net/qq_35027690/article/details/103742697 Softmax：https://zhuanlan.zhihu.com/p/67759205\n\nhttps://tools.fun/",normalizedContent:"# 1. 动漫风格转换\n\ngan                 type         code                                                          online     note\ncartoongan          pytorch      https://github.com/znxlwm/pytorch-cartoongan                  x          \ncartoongan          tensorflow   https://github.com/mnicnc404/cartoongan-tensorflow            自带预训练      预训练模型:\n                                                                                                          http://cg.cs.tsinghua.edu.cn/people/~yongjin/cartoongan-models.rar，\n                                                                                                          效果较差（图片细节保留不足）\nanimegan            tensorflow   https://github.com/tachibanayoshino/animegan                  x          pytorch 实现：https://github.com/xuhangkun/animegan_in_pytorch\nanimeganv2          tensorflow   https://github.com/tachibanayoshino/animeganv2                x ｜ 效果未知   \nwhite-box cartoon   tensorflow   https://github.com/systemerrorwang/white-box-cartoonization   自带预训练      效果最好，应用：https://github.com/margaretmz/cartoonizer-with-tflite\n\nhttps://github.com/zhen8838/animestylized 用 pytorch 实现了以上几种 gan，但是训练出的效果和原版有差异\n\n\n# 相关阅读\n\n * making anime faces with stylegan\n * animegan将现实照片动漫化，超越清华的cartoongan\n * ai灵魂画手——扒一扒抖音爆款”变身漫画“后的技术事\n\n\n# 2. 真人眨眼睛\n\nganimation: anatomically-aware facial animation from a single image\n\nan out-of-the-box replicate of ganimation using pytorch, pretrained weights are available! https://github.com/donydchen/ganimation_replicate\n\n\n# facial-action-units introduce\n\n\n# paper : flnet: landmark driven fetching and learning network for faithful talking facial animation synthesis\n\n * facial action units (aus) based methods\n   * ganimation: anatomically-aware facial animation from a single image\n * landmark driven methods\n   * first order motion model for image animation （自监督特征点识别）\n\nflnet 融合了以上两个方法\n\n\n# 3. 扣图\n\n人脸识别：https://github.com/cmusatyalab/openface https://github.com/hsintao/pfld_106_face_landmarks https://github.com/polariszhao/pfld-pytorch\n\n\n# 4. scaling\n\nname                attr                             note                                                github\nvideo2x             x                                只是应用框架，需要下述算法驱动                                     https://github.com/k4yt3x/video2x\nreal-sr             x                                winner of cvpr ntire 2020 challenge on real-world   https://github.com/tencent/real-sr\n                                                     super-resolution\nbsrgan ｜ x ｜ 2021   https://github.com/cszn/bsrgan                                                       \n\nusrnet ｜ x ｜ cvpr 2020 ｜ https://github.com/cszn/usrnet waifu2x | x | x | https://github.com/nagadomi/waifu2x/ rcan ｜ x ｜ eccv 2018 ｜ https://github.com/xinntao/basicsr esrgan | 比 rcan 更晚出现，虽然 psnr 值比 rcan 稍低，但视觉效果更高 | eccv 2018 | https://github.com/xinntao/esrgan anime4k | x | non-machine-learning based | https://github.com/bloc97/anime4k srmd | x | cvpr 2018 | https://github.com/cszn/kair\n\nreference：https://blog.csdn.net/gwplovekimi/article/details/83041627\n\n\n# 去燥\n\n * hdrnet\n   * https://github.com/google/hdrnet\n     * https://groups.csail.mit.edu/graphics/hdrnet/\n   * https://github.com/creotiv/hdrnet-pytorch\n * image-adaptive-3dlut\n   * https://github.com/huizeng/image-adaptive-3dlut\n\n\n# 5. 优质模型\n\nname                               description                                                  type      code                                                            note\nface-alignment                     2d and 3d face alignment library                             pytorch   https://github.com/1adrianb/face-alignment                      x\nface_recognition                   simplest facial recognition api                              dlib      https://github.com/ageitgey/face_recognition                    x\nfirst-order-model                  the source code for the paper first order motion model for   pytorch   https://github.com/aliaksandrsiarohin/first-order-model         x\n                                   image animation\nmmdetection                        最强的目标检测                                                      pytorch   https://github.com/open-mmlab/mmdetection                       x\nbringing-old-photos-back-to-life   bringing old photo back to life (cvpr 2020 oral)             pytorch   https://github.com/microsoft/bringing-old-photos-back-to-life   x\n\n头像动态：https://github.com/alievk/avatarify-python 动漫识别：https://github.com/soruly/trace.moe ：（数据源：https://anilist.co/anime）\n\nmodels https://github.com/tensorflow/models\n\n垃圾分类： https://github.com/wusaifei/garbage_classify\n\n\n# 6. notes\n\n\n# 1. 杂项记录\n\n 1. tensorflow 版本\n\n * tensorflow==1.12.0 -> python[version='>=3.6,❤️.7.0a0']\n\n 2. 图片读取\n\nlib      type         channels\nopencv   numpy 类型     默认 bgr，shape 为 hwc\npil      pil中的具体的类型   根据图像格式：一般为 rgb，shape 为 hwc\n\npytorch 中使用 torchvision.datasets 模块读取图像，输出的数据类型为 pilimage，并且图像中的每一个数据大小范围已经不再是[0,255]，而是[0,1].\n\n 3. 常用数据集：imagenet\n\n\n# 2. 深度阅读\n\n * 训练gans一年我学到的10个教训\n * 纵览轻量化卷积神经网络：squeezenet、mobilenet、shufflenet、xception\n * 机器学习：各种优化器optimizer的总结与比较\n\n理解 normalize： https://blog.csdn.net/qq_35027690/article/details/103742697 softmax：https://zhuanlan.zhihu.com/p/67759205\n\nhttps://tools.fun/",charsets:{cjk:!0}},{title:"机器学习评估指标:分类",frontmatter:{title:"机器学习评估指标:分类",date:"2021-02-22T09:50:00.000Z",description:"分类任务的性能度量",categories:["imgproc"],tags:["AUC、ROC"],permalink:null},regularPath:"/blog/skills/ai/auc_roc.html",relativePath:"blog/skills/ai/auc_roc.md",key:"v-7103a3ed",path:"/blog/skills/ai/auc_roc.html",headersStr:null,content:"https://zhuanlan.zhihu.com/p/46714763 https://zhuanlan.zhihu.com/p/84035782\n\n从AUC 判断分类器（预测模型）优劣的标准：\n\n * AUC = 1，是完美分类器。\n * AUC = [0.85, 0.95], 效果很好\n * AUC = [0.7, 0.85], 效果一般\n * AUC = [0.5, 0.7],效果较低，但用于预测股票已经很不错了\n * AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。\n * AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。\n\nhttps://www.zhihu.com/question/39840928",normalizedContent:"https://zhuanlan.zhihu.com/p/46714763 https://zhuanlan.zhihu.com/p/84035782\n\n从auc 判断分类器（预测模型）优劣的标准：\n\n * auc = 1，是完美分类器。\n * auc = [0.85, 0.95], 效果很好\n * auc = [0.7, 0.85], 效果一般\n * auc = [0.5, 0.7],效果较低，但用于预测股票已经很不错了\n * auc = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。\n * auc < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。\n\nhttps://www.zhihu.com/question/39840928",charsets:{cjk:!0}},{title:"大数据架构理论",frontmatter:{title:"大数据架构理论",date:"2020-04-13T00:00:00.000Z",description:"大数据架构理论",categories:["blog","skills","bigdata"],tags:[null],permalink:null},regularPath:"/blog/skills/ai/bigdata_arch_theory.html",relativePath:"blog/skills/ai/bigdata_arch_theory.md",key:"v-5240d527",path:"/blog/skills/ai/bigdata_arch_theory.html",headers:[{level:2,title:"LAMBDA 架构",slug:"lambda-架构",normalizedTitle:"lambda 架构",charIndex:14},{level:3,title:"数据的本质",slug:"数据的本质",normalizedTitle:"数据的本质",charIndex:795},{level:3,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:875}],headersStr:"LAMBDA 架构 数据的本质 总结",content:"# 大数据架构理论\n\n\n# LAMBDA 架构\n\nMarz认为大数据系统应具有以下的关键特性：\n\n * Robust and fault-tolerant（容错性和鲁棒性）\n   * 对大规模分布式系统来说，机器是不可靠的，可能会当机，但是系统需要是健壮、行为正确的，即使是遇到机器错误。除了机器错误，人更可能会犯错误。在软件开发中难免会有一些Bug，系统必须对有Bug的程序写入的错误数据有足够的适应能力，所以比机器容错性更加重要的容错性是人为操作容错性。对于大规模的分布式系统来说，人和机器的错误每天都可能会发生，如何应对人和机器的错误，让系统能够从错误中快速恢复尤其重要。\n * Low latency reads and updates（低延时）：很多应用对于读和写操作的延时要求非常高，要求对更新和查询的响应是低延时的。\n * Scalable（横向扩容）：当数据量/负载增大时，可扩展性的系统通过增加更多的机器资源来维持性能。也就是常说的系统需要线性可扩展，通常采用scale out（通过增加机器的个数）而不是scale up（通过增强机器的性能）。\n * General（通用性）：系统需要能够适应广泛的应用，包括金融领域、社交网络、电子商务数据分析等。\n * Extensible（可扩展）：需要增加新功能、新特性时，可扩展的系统能以最小的开发代价来增加新功能。\n * Allows ad hoc queries（方便查询）：数据中蕴含有价值，需要能够方便、快速的查询出所需要的数据。\n * Minimal maintenance（易于维护）：系统要想做到易于维护，其关键是控制其复杂性，越是复杂的系统越容易出错、越难维护。\n * Debuggable（易调试）：当出问题时，系统需要有足够的信息来调试错误，找到问题的根源。其关键是能够追根溯源到每个数据生成点。\n\n\n# 数据的本质\n\n 1. 数据的特性：When & What\n 2. 数据的存储：Store Everything Rawly and Immutably\n\n\n# 总结\n\nLambda架构通过对数据和查询的本质认识，融合了不可变性（Immunability），读写分离和复杂性隔离等一系列架构原则，将大数据处理系统划分为Batch Layer, Speed Layer和Serving Layer三层，从而设计出一个能满足实时大数据系统关键特性（如高容错、低延时和可扩展等）的架构。Lambda架构作为一个通用的大数据处理框架，可以很方便的集成Hadoop，Kafka，Storm，Spark，Hbase等各类大数据组件。\n\nkappa",normalizedContent:"# 大数据架构理论\n\n\n# lambda 架构\n\nmarz认为大数据系统应具有以下的关键特性：\n\n * robust and fault-tolerant（容错性和鲁棒性）\n   * 对大规模分布式系统来说，机器是不可靠的，可能会当机，但是系统需要是健壮、行为正确的，即使是遇到机器错误。除了机器错误，人更可能会犯错误。在软件开发中难免会有一些bug，系统必须对有bug的程序写入的错误数据有足够的适应能力，所以比机器容错性更加重要的容错性是人为操作容错性。对于大规模的分布式系统来说，人和机器的错误每天都可能会发生，如何应对人和机器的错误，让系统能够从错误中快速恢复尤其重要。\n * low latency reads and updates（低延时）：很多应用对于读和写操作的延时要求非常高，要求对更新和查询的响应是低延时的。\n * scalable（横向扩容）：当数据量/负载增大时，可扩展性的系统通过增加更多的机器资源来维持性能。也就是常说的系统需要线性可扩展，通常采用scale out（通过增加机器的个数）而不是scale up（通过增强机器的性能）。\n * general（通用性）：系统需要能够适应广泛的应用，包括金融领域、社交网络、电子商务数据分析等。\n * extensible（可扩展）：需要增加新功能、新特性时，可扩展的系统能以最小的开发代价来增加新功能。\n * allows ad hoc queries（方便查询）：数据中蕴含有价值，需要能够方便、快速的查询出所需要的数据。\n * minimal maintenance（易于维护）：系统要想做到易于维护，其关键是控制其复杂性，越是复杂的系统越容易出错、越难维护。\n * debuggable（易调试）：当出问题时，系统需要有足够的信息来调试错误，找到问题的根源。其关键是能够追根溯源到每个数据生成点。\n\n\n# 数据的本质\n\n 1. 数据的特性：when & what\n 2. 数据的存储：store everything rawly and immutably\n\n\n# 总结\n\nlambda架构通过对数据和查询的本质认识，融合了不可变性（immunability），读写分离和复杂性隔离等一系列架构原则，将大数据处理系统划分为batch layer, speed layer和serving layer三层，从而设计出一个能满足实时大数据系统关键特性（如高容错、低延时和可扩展等）的架构。lambda架构作为一个通用的大数据处理框架，可以很方便的集成hadoop，kafka，storm，spark，hbase等各类大数据组件。\n\nkappa",charsets:{cjk:!0}},{title:"PCA原理推导",frontmatter:{title:"PCA原理推导",date:"2020-04-13T00:00:00.000Z",description:"PCA原理推导",categories:["blog","skills","bigdata"],tags:[null],permalink:null},regularPath:"/blog/skills/ai/derivation_of_PCA.html",relativePath:"blog/skills/ai/derivation_of_PCA.md",key:"v-5e7e6c7d",path:"/blog/skills/ai/derivation_of_PCA.html",headers:[{level:2,title:"理论基础",slug:"理论基础",normalizedTitle:"理论基础",charIndex:14},{level:2,title:"样本预处理",slug:"样本预处理",normalizedTitle:"样本预处理",charIndex:802},{level:2,title:"相关公式推导：",slug:"相关公式推导",normalizedTitle:"相关公式推导：",charIndex:868},{level:2,title:"降维目标",slug:"降维目标",normalizedTitle:"降维目标",charIndex:1353},{level:2,title:"推导过程",slug:"推导过程",normalizedTitle:"推导过程",charIndex:1487}],headersStr:"理论基础 样本预处理 相关公式推导： 降维目标 推导过程",content:"# PCA原理推导\n\n\n# 理论基础\n\n> 1、矩阵相乘的物理解释\n\n两个矩阵相乘的意义是将右边矩阵中的每一列列向量变换到左边矩阵中每一行行向量为基所表示的空间中去。\n\n> 2、协方差的意义\n\nN维向量中的两个纬度 a、b 的协方差表示两个纬度上的相关性。相关性越大，协方差越大; 协方差为0表示两个纬度完全独立。\n\n> 3、一般的, 向量A的表示方法\n\nA={a1a2⋯an}A=\\left\\{\\begin{matrix} a_1 \\\\ a_2 \\\\ \\cdots \\\\ a_n \\end{matrix} \\right\\} A=⎩⎨⎧ a1 a2 ⋯an ⎭⎬⎫\n\nAT={a1a2⋯an}A^T=\\left\\{\\begin{matrix} a_1 & a_2& \\cdots & a_n \\end{matrix} \\right\\} AT={a1 a2 ⋯ an }\n\n> 4、实对称矩阵的性质(实对称矩阵对角化)\n\n一个n行n列的实对称矩阵一定可以找到n个单位正交特征向量，设这n个特征向量为：\n\ne1,e2,⋯ ,ene_1,e_2,\\cdots,e_n e1 ,e2 ,⋯,en\n\n将其按列组成矩阵：\n\nE={e1e2⋯en}E=\\left\\{ \\begin{matrix} e_1&e_2&\\cdots&e_n \\end{matrix} \\right\\} E={e1 e2 ⋯ en }\n\n则对其协方差矩阵C有如下结论：\n\nETCE=Λ={λ1λ1⋯λn}E^TCE=\\Lambda=\\left\\{ \\begin{matrix} \\lambda_1 &&& \\\\ & \\lambda_1&& \\\\ &&\\cdots& \\\\ &&&\\lambda_n \\end{matrix} \\right\\} ETCE=Λ=⎩⎨⎧ λ1 λ1 ⋯ λn ⎭⎬⎫\n\n其对角元素为个特征向量对应的特征值。\n\n\n# 样本预处理\n\n> 样本归一化\n\n * 每个维度都减去维度上所有样本的平均值\n * 降维后，样本的方差越大保留的原始信息越多\n\n\n# 相关公式推导：\n\nA. 由矩阵的方差公式：\n\nVar(a)=1m∑i=1m(ai−μ)2Var(a)=\\frac{1}{m}\\sum_{i=1}^{m}(a_i-\\mu)^2 Var(a)=m1 i=1∑m (ai −μ)2\n\n对于归一化后的X矩阵，得到的Y的每行(每个维度)的均值依旧为0所以有：\n\nVar(a)=1m∑i=1m(ai)2Var(a)=\\frac{1}{m}\\sum_{i=1}^{m}(a_i)^2 Var(a)=m1 i=1∑m (ai )2\n\nB. 由矩阵的协方差公式：\n\nVar(a)=1m∑i=1m(ai−μ)(bi−μ)Var(a)=\\frac{1}{m}\\sum_{i=1}^{m}(a_i-\\mu)(b_i-\\mu) Var(a)=m1 i=1∑m (ai −μ)(bi −μ)\n\n对于归一化后的X矩阵，得到的Y的每行(每个维度)的均值依旧为0所以有：\n\nVar(a)=1m∑i=1m(aibi)Var(a)=\\frac{1}{m}\\sum_{i=1}^{m}(a_ib_i) Var(a)=m1 i=1∑m (ai bi )\n\n\n# 降维目标\n\n将一组N维向量降为K维(0<K<N), 其目标是选择K个单位正交基, 使得原始数据变换到这组基上后, 各字段两两间协方差为0, 而字段内的方差则尽可能大(在正交的约束下，取最大的K个方差)\n\n> PCA 归一化后的特性之一 : 每个维度的均值为0\n\n\n# 推导过程\n\n> 概述: 将一组n维向量降k维(0<k<n), 其目标是选择k个单位正交基, 使得原始数据变换到这组基上后, 各字段两两间协方差为0, 而字段内的方差则尽可能大(在正交的约束下，取最大的k个方差)\n\n有m个n维的样本集X，如下：\n\nX={A1A2⋯Am}X=\\left\\{ \\begin{matrix} A_1 & A_2 \\cdots A_m \\end{matrix} \\right\\} X={A1 A2 ⋯Am }\n\n有k个n维单位向量表示的向量空间P，如下：\n\nP={P1TP2T⋯PkT}P=\\left\\{\\begin{matrix} P_1^T \\\\ P_2^T \\\\ \\cdots \\\\ P_k^T \\end{matrix} \\right\\} P=⎩⎨⎧ P1T P2T ⋯PkT ⎭⎬⎫\n\n要将X降维，即在当 0<k<n 时，存在P，使得：\n\nY=PXY=PX Y=PX\n\n即：\n\nY={Y1Y2⋯Ym}Y=\\left\\{ \\begin{matrix} Y_1 & Y_2 \\cdots Y_m \\end{matrix} \\right\\} Y={Y1 Y2 ⋯Ym }\n\n其中每一项都是k维的向量。\n\n此时，我们可知：\n    单位向量空间矩阵 P 为 ：k x n\n    原始样本数据矩阵 X 为 ：n x m\n    转换后的数据矩阵 Y 为 ：k x m\n\n\n1\n2\n3\n4\n\n\n由理论基础可知：\n\n 1. 为了使Y尽可能多的保留X中的信息，就要使降维后的样本离散程度最大，即要使得Y的方差最大\n 2. 通过方差最大化，可以选择出第一个维度，后续的维度选择依然要保留尽可能多的原始信息，所以不希望两个纬度间存在相关性，即每个维度的协方差均值为0。\n\n即，最终要达到的目的与字段内方差以及字段间协方差有密切关系，因此我们希望能将两者统一表示。仔细观察发现，两者均可以表示为内积形式，而内积与矩阵相乘密切相关。\n\n先看下述公式得到的矩阵C：\n\nC=1mXXTC=\\frac{1}{m}XX^T C=m1 XXT\n\n如果X是归一化后的矩阵，矩阵C有以下性质(最后两个结论需要结合‘相关公式推导A和B’)：\n\n * 是矩阵X的协方差矩阵\n * 是对称矩阵\n * 对角线分别为各个维度的方差\n * 第i行j列和j行i列的元素相同，表示i和j两个字段的协方差\n\n由此可知，为了达到上述的降维目的，即需要矩阵Y的协方差矩阵对角化：除对角线外的其它元素化为0，并且将在对角线上的元素按大小从上到下排列。\n\n接下来，我们看下原矩阵与基变换后矩阵的协方差矩阵的关系:设原始数据矩阵X对应的协方差矩阵为C，而P是一组基按行组成的矩阵，设 Y=PX，则Y为X对E做基变换后的数据。设Y的协方差矩阵为D，则有以下推导：\n\nD=1mYYT=1m(PX)(PX)T=1mPXXTPT=P(1mXXT)PT=PCPTD=\\frac{1}{m}YY^T =\\frac{1}{m}(PX)(PX)^T =\\frac{1}{m}PXX^TP^T =P(\\frac{1}{m}XX^T)P^T =PCP^T D=m1 YYT=m1 (PX)(PX)T=m1 PXXTPT=P(m1 XXT)PT=PCPT\n\n所以，可以发现我们要找的就是能让原始协方差矩阵对角化的P。\n\n根据理论基础4(实对称矩阵的性质)：\n\nETCE=ΛE^TCE=\\Lambda ETCE=Λ\n\n找到我们需要的矩阵P：\n\nP=ETP=E^T P=ET\n\nP是协方差矩阵的特征向量单位化后按行排列出的矩阵，其中每一行都是C的一个特征向量。如果将P按照\n\nΛ\\Lambda Λ\n\n中特征值的从大到小，将特征向量从上到下排列，则用P的前k行组成的k*n维矩阵乘以原始数据矩阵X，就得到我们需要的降维后的数据矩阵Y。\n\n> 参考 http://www.360doc.com/content/13/1124/02/9482_331688889.shtml",normalizedContent:"# pca原理推导\n\n\n# 理论基础\n\n> 1、矩阵相乘的物理解释\n\n两个矩阵相乘的意义是将右边矩阵中的每一列列向量变换到左边矩阵中每一行行向量为基所表示的空间中去。\n\n> 2、协方差的意义\n\nn维向量中的两个纬度 a、b 的协方差表示两个纬度上的相关性。相关性越大，协方差越大; 协方差为0表示两个纬度完全独立。\n\n> 3、一般的, 向量a的表示方法\n\na={a1a2⋯an}a=\\left\\{\\begin{matrix} a_1 \\\\ a_2 \\\\ \\cdots \\\\ a_n \\end{matrix} \\right\\} a=⎩⎨⎧ a1 a2 ⋯an ⎭⎬⎫\n\nat={a1a2⋯an}a^t=\\left\\{\\begin{matrix} a_1 & a_2& \\cdots & a_n \\end{matrix} \\right\\} at={a1 a2 ⋯ an }\n\n> 4、实对称矩阵的性质(实对称矩阵对角化)\n\n一个n行n列的实对称矩阵一定可以找到n个单位正交特征向量，设这n个特征向量为：\n\ne1,e2,⋯ ,ene_1,e_2,\\cdots,e_n e1 ,e2 ,⋯,en\n\n将其按列组成矩阵：\n\ne={e1e2⋯en}e=\\left\\{ \\begin{matrix} e_1&e_2&\\cdots&e_n \\end{matrix} \\right\\} e={e1 e2 ⋯ en }\n\n则对其协方差矩阵c有如下结论：\n\netce=λ={λ1λ1⋯λn}e^tce=\\lambda=\\left\\{ \\begin{matrix} \\lambda_1 &&& \\\\ & \\lambda_1&& \\\\ &&\\cdots& \\\\ &&&\\lambda_n \\end{matrix} \\right\\} etce=λ=⎩⎨⎧ λ1 λ1 ⋯ λn ⎭⎬⎫\n\n其对角元素为个特征向量对应的特征值。\n\n\n# 样本预处理\n\n> 样本归一化\n\n * 每个维度都减去维度上所有样本的平均值\n * 降维后，样本的方差越大保留的原始信息越多\n\n\n# 相关公式推导：\n\na. 由矩阵的方差公式：\n\nvar(a)=1m∑i=1m(ai−μ)2var(a)=\\frac{1}{m}\\sum_{i=1}^{m}(a_i-\\mu)^2 var(a)=m1 i=1∑m (ai −μ)2\n\n对于归一化后的x矩阵，得到的y的每行(每个维度)的均值依旧为0所以有：\n\nvar(a)=1m∑i=1m(ai)2var(a)=\\frac{1}{m}\\sum_{i=1}^{m}(a_i)^2 var(a)=m1 i=1∑m (ai )2\n\nb. 由矩阵的协方差公式：\n\nvar(a)=1m∑i=1m(ai−μ)(bi−μ)var(a)=\\frac{1}{m}\\sum_{i=1}^{m}(a_i-\\mu)(b_i-\\mu) var(a)=m1 i=1∑m (ai −μ)(bi −μ)\n\n对于归一化后的x矩阵，得到的y的每行(每个维度)的均值依旧为0所以有：\n\nvar(a)=1m∑i=1m(aibi)var(a)=\\frac{1}{m}\\sum_{i=1}^{m}(a_ib_i) var(a)=m1 i=1∑m (ai bi )\n\n\n# 降维目标\n\n将一组n维向量降为k维(0<k<n), 其目标是选择k个单位正交基, 使得原始数据变换到这组基上后, 各字段两两间协方差为0, 而字段内的方差则尽可能大(在正交的约束下，取最大的k个方差)\n\n> pca 归一化后的特性之一 : 每个维度的均值为0\n\n\n# 推导过程\n\n> 概述: 将一组n维向量降k维(0<k<n), 其目标是选择k个单位正交基, 使得原始数据变换到这组基上后, 各字段两两间协方差为0, 而字段内的方差则尽可能大(在正交的约束下，取最大的k个方差)\n\n有m个n维的样本集x，如下：\n\nx={a1a2⋯am}x=\\left\\{ \\begin{matrix} a_1 & a_2 \\cdots a_m \\end{matrix} \\right\\} x={a1 a2 ⋯am }\n\n有k个n维单位向量表示的向量空间p，如下：\n\np={p1tp2t⋯pkt}p=\\left\\{\\begin{matrix} p_1^t \\\\ p_2^t \\\\ \\cdots \\\\ p_k^t \\end{matrix} \\right\\} p=⎩⎨⎧ p1t p2t ⋯pkt ⎭⎬⎫\n\n要将x降维，即在当 0<k<n 时，存在p，使得：\n\ny=pxy=px y=px\n\n即：\n\ny={y1y2⋯ym}y=\\left\\{ \\begin{matrix} y_1 & y_2 \\cdots y_m \\end{matrix} \\right\\} y={y1 y2 ⋯ym }\n\n其中每一项都是k维的向量。\n\n此时，我们可知：\n    单位向量空间矩阵 p 为 ：k x n\n    原始样本数据矩阵 x 为 ：n x m\n    转换后的数据矩阵 y 为 ：k x m\n\n\n1\n2\n3\n4\n\n\n由理论基础可知：\n\n 1. 为了使y尽可能多的保留x中的信息，就要使降维后的样本离散程度最大，即要使得y的方差最大\n 2. 通过方差最大化，可以选择出第一个维度，后续的维度选择依然要保留尽可能多的原始信息，所以不希望两个纬度间存在相关性，即每个维度的协方差均值为0。\n\n即，最终要达到的目的与字段内方差以及字段间协方差有密切关系，因此我们希望能将两者统一表示。仔细观察发现，两者均可以表示为内积形式，而内积与矩阵相乘密切相关。\n\n先看下述公式得到的矩阵c：\n\nc=1mxxtc=\\frac{1}{m}xx^t c=m1 xxt\n\n如果x是归一化后的矩阵，矩阵c有以下性质(最后两个结论需要结合‘相关公式推导a和b’)：\n\n * 是矩阵x的协方差矩阵\n * 是对称矩阵\n * 对角线分别为各个维度的方差\n * 第i行j列和j行i列的元素相同，表示i和j两个字段的协方差\n\n由此可知，为了达到上述的降维目的，即需要矩阵y的协方差矩阵对角化：除对角线外的其它元素化为0，并且将在对角线上的元素按大小从上到下排列。\n\n接下来，我们看下原矩阵与基变换后矩阵的协方差矩阵的关系:设原始数据矩阵x对应的协方差矩阵为c，而p是一组基按行组成的矩阵，设 y=px，则y为x对e做基变换后的数据。设y的协方差矩阵为d，则有以下推导：\n\nd=1myyt=1m(px)(px)t=1mpxxtpt=p(1mxxt)pt=pcptd=\\frac{1}{m}yy^t =\\frac{1}{m}(px)(px)^t =\\frac{1}{m}pxx^tp^t =p(\\frac{1}{m}xx^t)p^t =pcp^t d=m1 yyt=m1 (px)(px)t=m1 pxxtpt=p(m1 xxt)pt=pcpt\n\n所以，可以发现我们要找的就是能让原始协方差矩阵对角化的p。\n\n根据理论基础4(实对称矩阵的性质)：\n\netce=λe^tce=\\lambda etce=λ\n\n找到我们需要的矩阵p：\n\np=etp=e^t p=et\n\np是协方差矩阵的特征向量单位化后按行排列出的矩阵，其中每一行都是c的一个特征向量。如果将p按照\n\nλ\\lambda λ\n\n中特征值的从大到小，将特征向量从上到下排列，则用p的前k行组成的k*n维矩阵乘以原始数据矩阵x，就得到我们需要的降维后的数据矩阵y。\n\n> 参考 http://www.360doc.com/content/13/1124/02/9482_331688889.shtml",charsets:{cjk:!0}},{title:"NN 论文阅读",frontmatter:{title:"NN 论文阅读",date:"2021-03-10T09:50:00.000Z",description:"神经网络论文阅读、翻译",categories:["imgproc","pixel2pixel"],tags:[null],permalink:null},regularPath:"/blog/skills/ai/image_papers.html",relativePath:"blog/skills/ai/image_papers.md",key:"v-633581c2",path:"/blog/skills/ai/image_papers.html",headers:[{level:2,title:"Abstract",slug:"abstract",normalizedTitle:"abstract",charIndex:82},{level:2,title:"1. Introduction",slug:"_1-introduction",normalizedTitle:"1. introduction",charIndex:442},{level:2,title:"2. Related Work",slug:"_2-related-work",normalizedTitle:"2. related work",charIndex:890},{level:2,title:"3. Method",slug:"_3-method",normalizedTitle:"3. method",charIndex:1300},{level:3,title:"3.1 Objective",slug:"_3-1-objective",normalizedTitle:"3.1 objective",charIndex:1541},{level:3,title:"3.2 Network architectures",slug:"_3-2-network-architectures",normalizedTitle:"3.2 network architectures",charIndex:1811},{level:3,title:"3.3 Optimization and inference",slug:"_3-3-optimization-and-inference",normalizedTitle:"3.3 optimization and inference",charIndex:2751},{level:2,title:"4. Experiments",slug:"_4-experiments",normalizedTitle:"4. experiments",charIndex:3267},{level:3,title:"4.2 Analysis of the objective function",slug:"_4-2-analysis-of-the-objective-function",normalizedTitle:"4.2 analysis of the objective function",charIndex:3687},{level:3,title:"4.3 Analysis of the generator architecture",slug:"_4-3-analysis-of-the-generator-architecture",normalizedTitle:"4.3 analysis of the generator architecture",charIndex:4645},{level:3,title:"4.4 From PixelGANs to PatchGANs to ImageGANs",slug:"_4-4-from-pixelgans-to-patchgans-to-imagegans",normalizedTitle:"4.4 from pixelgans to patchgans to imagegans",charIndex:4937},{level:3,title:"4.5 Perceptual validation",slug:"_4-5-perceptual-validation",normalizedTitle:"4.5 perceptual validation",charIndex:5575},{level:3,title:"4.6 Semantic segmentation",slug:"_4-6-semantic-segmentation",normalizedTitle:"4.6 semantic segmentation",charIndex:5761},{level:3,title:"4.7. Community-driven Research",slug:"_4-7-community-driven-research",normalizedTitle:"4.7. community-driven research",charIndex:6236},{level:2,title:"5. Conclusion",slug:"_5-conclusion",normalizedTitle:"5. conclusion",charIndex:6440},{level:2,title:"Abstract",slug:"abstract-2",normalizedTitle:"abstract",charIndex:82},{level:2,title:"Deconvolution & Overlap",slug:"deconvolution-overlap",normalizedTitle:"deconvolution &amp; overlap",charIndex:null},{level:2,title:"Overlap & Learning",slug:"overlap-learning",normalizedTitle:"overlap &amp; learning",charIndex:null},{level:2,title:"Better Upsampling",slug:"better-upsampling",normalizedTitle:"better upsampling",charIndex:8271},{level:2,title:"Image Generation Results",slug:"image-generation-results",normalizedTitle:"image generation results",charIndex:8865},{level:2,title:"Artifacts in Gradients",slug:"artifacts-in-gradients",normalizedTitle:"artifacts in gradients",charIndex:9397},{level:2,title:"Conclusion",slug:"conclusion",normalizedTitle:"conclusion",charIndex:6443}],headersStr:"Abstract 1. Introduction 2. Related Work 3. Method 3.1 Objective 3.2 Network architectures 3.3 Optimization and inference 4. Experiments 4.2 Analysis of the objective function 4.3 Analysis of the generator architecture 4.4 From PixelGANs to PatchGANs to ImageGANs 4.5 Perceptual validation 4.6 Semantic segmentation 4.7. Community-driven Research 5. Conclusion Abstract Deconvolution & Overlap Overlap & Learning Better Upsampling Image Generation Results Artifacts in Gradients Conclusion",content:'# 论文阅读摘要\n\n\n# Image-to-Image Translation with Conditional Adversarial Networks\n\n\n# Abstract\n\n针对 转化输入图像到一种关联的输出(image-to-image, map pixels to pixels)类型的任务，提出了一种通用的 architecture 和 objective，只是使用不同的数据即可满足各种任务\n\n一般来说，Conditional adversarial nets 在这类任务中有不俗的表现。这些网络不仅学习到了 输入到输出 的映射，还学习到了一个用于训练这个映射的 loss function。另外，我们证明了：这种方法在以下任务中都是卓有成效的：从 (semantic) label maps 合成照片、从图像轮廓重构完整图形、图像着色，以及其他的类似任务。而且，不用进行 parameters、loss function 的调整就可以达到比较合理的结果。\n\n\n# 1. Introduction\n\n使用 CNNs 以及针对性设计的 loss，也可以达到不错的效果。但是这要求精心的设计损失函数。如果简单的使用输入、输出的欧式距离作为损失函数，会大概率得到比较模糊的结果：这是因为为了使欧式距离最小化，网络会更倾向于将合理的输出平均化，这会造成模糊。\n\n一般的，我们一些专业知识才能够设计出合理的损失函数，以使得 CNNs 可以有效的收敛出符合我们预期的结果。\n\n幸运的事，通过 GANs，我们可以指定更高纬度的目标(如，使输出与现实无法区分)，就能自主学习出适合于所用数据、所期目标的 loss 函数。也就是说，GANs 可以通过使用不同的数据，自主学习到满足我们需要的损失函数。这在以前是需要使用不同的损失函数才能做到的。\n\n本论文的主要贡献有：\n\n 1. cGANs 可以对多种 image-to-image 问题产生合理的结果\n 2. 提出一个简单并且足以取得良好的结果的框架，并分析几种重要的体系结构的效果。Code is available\n\n\n# 2. Related Work\n\nStructured losses for image modeling 针对 image-to-image 转换问题建模的损失函数，通常被表达成像素级(per-pixel)的分类或回归方程式。这些方程式认为解空间是"unstructured"，也就是说每个输出的pixel被认为在条件上独立于给定输入图像的所有其他像素。\n\n相反，cGANs会学习结构性损失。结构化的损失会惩罚输出的联合配置。理论上，cGANs的损失函数可以对输入和输出间的任何不同结构进行惩罚。\n\n事实上，在此之前已经有很多使用 cGANSs 来解决图像生成问题。本文与他们的几个不同的地方在于 generator 和 discriminator 的框架选择上。我们的生成器使用 "U-Net"-based 框架，评判器使用了卷积网络的分离器 "PatchGAN"（它只惩罚 patch 规模的图像结构）。\n\n\n# 3. Method\n\nGANs are generative models that learn a mapping from random noise vector z to output image y, G : z → y [24]. In contrast, conditional GANs learn a mapping from observed image x and random noise vector z, to y, G : {x, z} → y\n\n\n# 3.1 Objective\n\n\n\n这里需要注意的是 z 是必须的。以往的 cGANs 使用已经意识到这点，并且通常采用 Gaussian noise 作为 z 来微调输入。\n\n在最初的实验中，我们使用了这种策略，但没有效果，生成器好像忽略了这个噪音。相反，对于最终模型，我们仅以 dropout 的形式提供噪音，并应用于 训练和测试时的生成器的几层。\n\n尽管采用了 dropout 噪声，我们观察到我们的网络输出的随机性依然很小。设计可产生更大随机性的条件GAN，从而捕获他们建模的条件分布的完全熵，是当前工作悬而未决的重要问题。\n\n\n# 3.2 Network architectures\n\n 1. Generator with skips\n\n一个 image-to-image 转换问题的定义特征是：他们将高分辨率的输入网格映射到高分辨率的输出网格。此外，对于我们考虑的问题，输入和输出的表面外观不同，但是两者是相同基础结构的效果图。所以，输入与输出中的结构是大致对齐的。我们围绕这些事项来设计生成架构。\n\n一些以前解决这类问题的方法是使用 encoder-decoder network。这种网络要求所有的信息流需要通过所有的层，包括瓶颈层。对于许多图像翻译问题，有很多底层信息在输入和输出之间共享，就是说，希望将这些信息直接穿梭在网络上。例如，在图像着色的情况下，输入和输出共享显著边缘的位置，\n\n为了给生成器一种避免此类信息瓶颈的方法，我们按照“ U-Net”的一般形状添加了跳过连接。具体来说，我们在第i层和第n-i层之间添加跳过连接，其中n是层的总数。每个跳过连接仅将第i层和第n-i层的所有通道连接在一起。\n\n 2. Markovian discriminator (PatchGAN)\n\n众所周知，L2 和 L1 loss 在图像生成任务中会产生模糊结果。尽管这些损失并不能鼓励高频率清晰度，尽管如此，它们在许多情况下仍能准确捕获低频信息。对于这里的问题，确实是这样，我们不需要全新的框架来强化低频信息的正确性，L1 已经做了。\n\n依靠 L1 来强制低频正确性，这促使将 GAN 判别器限制为仅对高频结构信息进行建模。为了对高频信息建模，将注意力集中在本地图像 patch 中的结构就足够了。因此，我们设计了被称为 PatchGAN 的判别架构，它仅对 patch 规模的结构进行惩罚。这个判别器尝试去分类图像中的 N * N 个 patch 是真是假。我们对该图像进行卷积运算，对所有响应求平均值以提供 D 的最终输出。\n\n下文中，我们证明了：N 可以比图像小很多，也依然可以生成高质量的结果。这是有利的，因为较小的 PatchGAN 具有较少的参数，运行速度更快，并且可以适用于任意大图像。这样的鉴别器可以有效地将图像建模为马尔可夫随机场，假设像素之间的独立性相差大于 patch 直径。\n\n\n# 3.3 Optimization and inference\n\n了优化我们的网络，我们遵循 GAN 中的标准方法：在 D 的一个梯度下降步骤与 G 的一个步骤之间交替。如原始 GAN 论文建议的那样，不是训练 G 以使 log(1 − D(x，G(x，z)) 最小化，而是训练以最大化 log(D(x，G(x，z))。此外，我们在优化 D 的同时将目标除以2，这会降低 D 相对于 G 的学习率。我们使用 minibatch SGD 和 应用 Adam 求解器，指定参数：学习率=0.0002、β1=0.5, β2=0.999。\n\n在推理时，我们以和训练阶段完全相同的方式运行 生成器网络。这和通常的协议不太一样，在测试阶段，我们使用了 dropout 与训练阶段相同的方式，并且我们使用测试 batch 的统计信息进行 batch normalization，而不是训练批次的汇总统计信息。这种方法进行 batch normalization 时，设置 batch size 为 1 时被称为“实例归一化”，并已证明在图像生成任务中有效。在我们的实验中，我们使用 batch size 介于1到10之间，具体取决于实验。\n\n\n# 4. Experiments\n\n为了探索 cGANs 的普遍性，我们在各种任务和数据集上测试了这种方法，包括 图形任务，例如照片生成，和视觉任务，例如语义分割：\n\n 1. Semantic labels ↔ photoo, trained on the Cityscapes dataset\n 2. Architectural labels → photo, trained on CMP Facades\n 3. Map↔aerial photo, trained on data scraped from Google Maps\n 4. BW → color photos\n 5. Edges → photo\n 6. Sketch → photo\n 7. Day → night\n 8. Thermal → color photos\n 9. Photo with missing pixels → inpainted photo\n\n\n# 4.2 Analysis of the objective function\n\n在 final objective 中，哪部分比较重要呢？我们进行消融研究来隔离 L1 、GAN 项的影响，以比较 cGAN 和 GAN 分别作用在输入上的效果。\n\n论文中的 Figure 4 显示了这些变化在 two labels → photo 问题上的定性影响：\n\n * 仅L1会导致合理但模糊的结果\n * 单独使用cGAN（将 λ=0）给出了更清晰的结果，但在某些应用程序上引入了视觉瑕疵\n * 将两个部分加在一起（λ= 100）减少了这些伪像\n\n使用 FCN-score 量化这些在 cityscapes labels → photo 任务中的观察研究(论文 Table 1)：\n\n * 基于 GAN 的目标任务得分更高，也就是说 合成的图像包含更多的可识别结构\n * 在衡量输入和输出匹配度的损失函数上，cGAN 表现的要比 GAN 好的多。\n   * 我们测试了从 final objective 中去掉 conditioning 部分的影响，发现，此时的损失函数不会惩罚输入和输出之间的不匹配，只关心是否输出看起来很真实。检查结果表明，生成器崩溃了，不管输入的照片如何都产生了几乎完全相同的输出。\n * 另外，添加 L1 项也会鼓励 输出尊重输入，因为 L1 损失会对正确匹配输入的 ground truth 输出与可能不正确的合成输出之间的距离进行惩罚。\n * 相应地，L1 + GAN 在创建尊重输入标签图的逼真渲染时也是有效的。结合所有项，L1 + cGAN 执行的同样的好。\n\nColorfulness cGANs 的一个引人注目的影响就是 它会产生 sharp images，幻想出的即使在输入标签图中不存在的空间结构。有人就开始想象 cGANs 在光谱纬度也有类似的“锐化”作用，例如，使得图像具有更加丰富的色彩。就像 L1 在不能精确定位边缘的位置时会激发模糊一样，它也会在不确定像素应采用几种可能的颜色值中的哪种时激励颜色为平均灰色。特别是，通过在可能的颜色上选择条件概率密度函数的中值，可以使L1最小。另一方面，对抗性损失原则上可以变成能够意识到灰色输出是不现实的，并鼓励匹配真实的颜色分布。\n\n\n# 4.3 Analysis of the generator architecture\n\nU-Net 架构允许低维度信息快捷的穿越网络，这会带来更好的结果吗？通过对比 U-Net 和 encoder-decoder(简单的移除 U-Net 中的 skip connections 形成) 在 cityscape generation 任务上的表现，我们了解到：\n\n 1. 在我们的实验中，encoder-decoder 无法学习生成逼真的图像\n 2. U-Net 不仅在使用 cGANs 时 优于 encoder-decoder，在使用 L1 loss 时，也有更加优越的结果\n\n\n# 4.4 From PixelGANs to PatchGANs to ImageGANs\n\n我们测试了改变鉴别器感受野的 patch size N 的各种效果，从 1×1 的 “PixelGAN” 到 286×286 的整图 "ImageGAN"。\n\nPixelGAN 对空间清晰度没有特别的影响，但是可以增加结果的色彩。颜色直方图匹配是一个图像处理领域常见的问题，也许 PixelGAN 会是一个有潜力的轻量化解决方案。\n\n使用 16×16 PatchGAN 足以促进锐利的输出，并获得良好的FCN得分，但也导致 tiling artifacts。70×70 PatchGAN 缓解了这些问题并获得更好的分数。缩放到超出这个范围，到完整的 286×286 ImageGAN，似乎并没有改善结果的视觉质量，并且，事实上得到了相对低的多的分数。这也许是因为 ImageGAN 比 70 × 70 PatchGAN 有更多的参数和更大的深度，从而更加难以训练造成的。\n\nFully-convolutional translation PatchGAN 的优势是固定 patch 大小的判别器可以适用于任意大的图像。我们也可以将生成器卷积的应用于比训练用的图像更大的图像上。我们在 map ↔ aerial 任务上测试了这种做法。我们在 512×512 的图片上测试了用 256×256 的图像训练得到的生成器，效果在 论文的 Figure 8 中可以看出效果还是不俗的。\n\n\n# 4.5 Perceptual validation\n\n我们在 map↔aerial 和 grayscale→color 任务上验证了结果的 perceptual realism（感性现实主义？？？）。用志愿者来测试生成的结果，看是否能够骗过志愿者：一般情况下，我们的方法(使用 L1+cGANs)有更加优越的表现，除非别的方法是针对特定问题进行了专门设计、优化。\n\n\n# 4.6 Semantic segmentation\n\n有条件的 GAN 似乎可以有效解决输出高度细节化或摄影类的问题，这在图像处理和图形任务中很常见。那么在视觉问题（如语义分割）上的表现如何呢？这类问题的特点是：输入比输出更复杂。\n\n为了开始对此进行测试，我们训练了一个 cGAN（带/不带 L1 损失）用于 cityscape photo→labels 任务。论文 Figure 10 显示了定性结果，分类准确性的定量报告在论文 Table 6 中。有趣的是，训练出的不带 L1 损失的 cGAN 能够在合理程度的准确性上解决这个问题。据我们所知，这是 GAN 成功生成“标签”的首次演示，这些"标签"是具有连续变化且几乎离散的值，而不是“图像”。尽管 cGAN 取得了一些成功，但他们还远不是解决下面这个问题的最佳方法：如论文 Table 6 所示：仅使用 L1 回归可以获得比 cGAN 更好的分数。我们认为，对于视觉问题，目标（即预测接近 ground truth 的产出）可能不如图形任务那么含糊，像 L1 这样的重建损失就足够了\n\n\n# 4.7. Community-driven Research\n\n自从最初发布论文和我们的 pix2pix 代码，Twitter社区，包括计算机视觉和图形从业人员以及视觉艺术家，都有成功地将我们的框架应用于各种新颖的图像到图像的翻译任务，远远超出了原始论文。尽管有些是基于 pix2pix 进行了修改，但是，他们证明了我们的方法作为 image-to-image 转换问题的一种通用的商品工具的前景。\n\n\n# 5. Conclusion\n\n本文的结果表明，条件对抗网络是许多 image-to-image 转换任务的有前途的方法，特别是那些涉及高度结构化图形输出的任务。这些网络可以学到适应于手头的任务和数据的 loss，这就让这些网络可以适用于各种各样的设置。\n\n----------------------------------------\n\n\n# Deconvolution and Checkerboard Artifacts\n\n> paper: Deconvolution and Checkerboard Artifacts\n\n\n# Abstract\n\n当我们非常仔细地观察由神经网络生成的图像时，我们经常会看到一种奇怪的棋盘状伪像图案。这种现象在一些模型中尤为明显，但是最近的模型中有很大一部分都表现出了这种行为。\n\n难以理解的是，棋盘格图案在色彩浓烈的图像中往往最为突出。这是怎么回事？神经网络讨厌鲜艳的色彩吗？这些伪像的实际原因实际上非常简单，这是避免它们的方法。\n\n\n# Deconvolution & Overlap\n\n当我们让神经网络生成图像时，我们通常会根据低分辨率，高水平的描述来构建它们。这使网络可以描述粗糙图像，然后填写细节信息。\n\n为了做到这一点，我们需要某种方法将低分辨率的图像转换成高分辨率的图像。通常，我们通过 Deconvolution 操作来执行此操作。粗略地讲，Deconvolution 层允许模型使用小图像中的每个点来“绘制”较大图像中的正方形。\n\n（反卷积具有多种解释和不同的名称，包括“转置卷积”。为简洁起见，我们在本文中使用“反卷积”这个名称。）\n\n不幸的是，反卷积很容易出现“不均匀的重叠”，在某些地方比在其他地方放置更多的隐喻绘画。特别是，当内核大小（输出窗口大小）无法被步幅（顶部各点之间的间距）整除时，反卷积具有不均匀的重叠。尽管原则上网络可以仔细地学习权重来避免这种情况（我们将在后面详细讨论），但实际上神经网络却在努力避免这种情况。\n\n重叠图案也以二维形式形成。两根轴上的不均匀重叠部分会相互叠加，从而形成一个变化幅度大的棋盘状特征图案。\n\n实际上，不均匀的重叠在二维上往往更加极端！因为两个图案相乘在一起，所以不均匀度平方。例如，在一维中，步幅2，大小3的反卷积具有一些输出，其输入数量是其他输入的两倍，但是在二维中，这变成四分之一。\n\n现在，神经网络在创建图像时通常使用多层反卷积，从一系列较低分辨率的描述中迭代构建较大的图像。这些堆叠的反卷积可能会消除伪影，但它们通常会复合，从而在各种规模上创建伪影。\n\n步幅1反卷积-在成功模型中通常被视为最后一层 - 在抑制伪像方面非常有效。他们可以删除划分其大小的频率伪像，并减少其他频率小于其大小的伪像。但是，正如许多最新模型中所看到的那样，伪影仍可能泄漏出去。\n\n除了我们上面观察到的类似于高频棋盘格的伪像外，早期的反卷积还可以创建低频伪像，我们将在后面对此进行详细介绍。\n\n当输出不寻常的颜色时，这些伪像往往最突出。由于神经网络层通常会有偏差（将学习值添加到输出中），因此很容易输出平均颜色。颜色（如亮红色）与平均颜色的距离越远，反卷积就需要贡献越多。\n\n\n# Overlap & Learning\n\n用不均匀的重叠来思考事物是一种虽然简单化但有用的框架方法。不管好坏，我们的模型都为它们的反卷积学习权重。\n\n从理论上讲，我们的模型可以学习仔细地写到不均匀重叠的位置，从而使输出均匀平衡。\n\n这是一项棘手的平衡操作，尤其是当有多个通道交互时。避免伪像会显着限制可能的过滤器，从而牺牲模型容量。在实践中，神经网络努力学习完全避免这些模式。\n\n实际上，不仅重叠不均匀的模型不能避免这种情况，而且重叠均匀的模型经常学习到导致相似伪像的内核！尽管这不是均匀重叠方式的默认行为，但即使重叠反卷积也仍然很容易会导致伪像。\n\n完全避免伪像仍然是对过滤器的重要限制，并且在实践中，伪像仍然存在于这些模型中，尽管它们看起来较为温和。\n\n这里可能有很多因素在起作用。例如，在生成对抗网络（GAN）的情况下，一个问题可能是鉴别器及其梯度（我们将在后面再讨论）。但是问题的很大一部分似乎是反卷积。最好说，反卷积是脆弱的，因为即使很仔细地选择大小，反卷积也很容易代表伪像创建函数。最糟糕的是，创建伪像是反卷积的默认行为。\n\n是否有其他方法可以对伪像具有更高的抵抗力？\n\n\n# Better Upsampling\n\n为避免这些伪像，我们希望使用 regular deconvolution（“转置卷积”）的替代方法。与反卷积不同，这种向上采样的方法不应将伪像作为其默认行为。理想情况下，它会走得更远，并且偏向于此类工件。\n\n一种方法是确保您使用的内核大小被步幅除尽，从而避免了重叠问题。这等效于“亚像素卷积”，该技术最近在图像超分辨率方面获得了成功。但是，尽管这种方法有所帮助，但是反卷积仍然很容易陷入创建伪像的过程中。\n\n另一种方法是从卷积到计算特征中分离出较高分辨率的上采样。例如，您可以调整图像大小（使用最近邻插值或双线性插值），然后进行卷积层。这似乎是一种自然的方法，并且大致类似的方法在图像超分辨率中效果很好。\n\n解卷积和不同的大小调整卷积方法都是线性运算，可以解释为矩阵。这是查看它们之间差异的有用方法。反卷积在每个输出窗口都有唯一的条目，而resize-convolution则隐含了权重绑定，以阻止高频伪像。\n\n我们曾经使用最近邻插值法取得了最好的结果，同时在使双线性调整大小的工作中遇到了困难。这可能仅意味着，对于我们的模型，最近邻居恰好与针对反卷积优化的超参数配合使用。这可能指出了天真的使用双线性插值可能会遇到棘手的问题，因为它过于强烈地抵抗了高频图像特征。我们不认为这两种方法都是上采样的最终解决方案，但它们确实可以修复棋盘状工件。\n\n\n# Image Generation Results\n\n我们的经验是，在多种情况下，最近邻调整大小后再进行卷积效果非常好。我们发现这种方法可为您提供帮助的一个例子是“生成对抗网络”。简单地将标准反卷积层切换为最近邻调整大小，然后再进行卷积，将导致不同频率的伪像消失。\n\n事实上，在进行任何训练之前就可以看到伪像的差异。如果我们使用随机权重对其进行了初始化，并查看生成器生成的图像，那么我们已经可以看到这些伪像：\n\n这表明伪像是由于这种生成图像的方法，而不是对抗训练。（这也表明我们可以在没有慢速训练模型反馈周期的情况下，学习到很多好的生成器设计。）\n\n相信这些伪影不是GAN特有的另一个原因是，我们在其他类型的模型中看到了它们，并且发现当我们切换到调整大小卷积上采样时，它们也会消失。例如，考虑实时艺术风格转移，其中训练神经网络直接生成样式转移的图像。我们发现它们很容易受到棋盘伪像的影响（尤其是在成本并未明确抵制它们的情况下）。但是，将反卷积层切换为调整大小卷积层会使伪像消失。\n\nGoogle Brain团队即将发表的论文将在更全面的实验和最新结果中证明该技术的优势。 （我们选择单独介绍此技术，是因为我们认为它值得进行更详细的讨论，并且涉及多篇论文。）\n\n\n# Artifacts in Gradients\n\n每当我们计算卷积层的梯度时，我们都会在向后遍历上进行反卷积（transposed convolution）。就像我们使用反卷积生成图像时一样，这会导致渐变中的棋盘格图案。\n\n特征可视化社区已经知道图像模型梯度中存在高频“噪声”，这是一个重大挑战。以某种方式，特征可视化方法必须补偿这种噪声。\n\n例如，DeepDream 似乎以多种方式引起伪影之间的破坏性干扰，例如同时优化许多功能，以及在许多偏移和比例上进行优化。特别是，在不同偏移量处进行优化的“抖动”消除了一些棋盘伪像。 （尽管某些伪像是我们的标准棋盘格图案，而其他伪像是组织性较差的高频图案。我们认为，这些是由最大合并引起的。最大合并以前与Geodesics of learned representations中的高频伪像相关联。）\n\n特征可视化的最新工作（例如DeepDreaming with TensorFlow）已明确识别并补偿了这些高频梯度分量。人们想知道，更好的神经网络架构是否可以使这些工作变得不必要。\n\n这些梯度伪影会影响GAN吗？如果梯度伪影可以影响基于特征可视化中的神经网络梯度优化的图像，那么我们也可以预期它会影响由生成器参数化的图像族，因为它们由GAN中的鉴别器进行了优化。我们发现在某些情况下确实会发生这种情况。当生成器既不偏斜也不偏斜棋盘图案时，鉴别器中的大卷积会导致它们。\n\n目前尚不清楚这些梯度伪像的广泛含义是什么。考虑它们的一种方法是，某些神经元基本上可以任意地获得其邻居的许多倍的梯度。等效地，出于充分的理由，网络将比其他像素更关心输入中的某些像素。这些听起来都不是理想的。\n\n似乎有些像素比其他像素对网络输出的影响更大，可能会夸大对抗性反例。由于导数集中在少量像素上，因此这些像素的较小摄动可能会产生较大的影响。我们尚未对此进行调查。\n\n\n# Conclusion\n\n使用反卷积生成图像的标准方法尽管取得了成功但存在一些理论上简单的问题，这些问题会导致生成的图像中出现伪像。使用没有这些问题的自然替代方法会导致伪像消失（类似的论点表明，standard strided convolutional 层也可能存在问题）。',normalizedContent:'# 论文阅读摘要\n\n\n# image-to-image translation with conditional adversarial networks\n\n\n# abstract\n\n针对 转化输入图像到一种关联的输出(image-to-image, map pixels to pixels)类型的任务，提出了一种通用的 architecture 和 objective，只是使用不同的数据即可满足各种任务\n\n一般来说，conditional adversarial nets 在这类任务中有不俗的表现。这些网络不仅学习到了 输入到输出 的映射，还学习到了一个用于训练这个映射的 loss function。另外，我们证明了：这种方法在以下任务中都是卓有成效的：从 (semantic) label maps 合成照片、从图像轮廓重构完整图形、图像着色，以及其他的类似任务。而且，不用进行 parameters、loss function 的调整就可以达到比较合理的结果。\n\n\n# 1. introduction\n\n使用 cnns 以及针对性设计的 loss，也可以达到不错的效果。但是这要求精心的设计损失函数。如果简单的使用输入、输出的欧式距离作为损失函数，会大概率得到比较模糊的结果：这是因为为了使欧式距离最小化，网络会更倾向于将合理的输出平均化，这会造成模糊。\n\n一般的，我们一些专业知识才能够设计出合理的损失函数，以使得 cnns 可以有效的收敛出符合我们预期的结果。\n\n幸运的事，通过 gans，我们可以指定更高纬度的目标(如，使输出与现实无法区分)，就能自主学习出适合于所用数据、所期目标的 loss 函数。也就是说，gans 可以通过使用不同的数据，自主学习到满足我们需要的损失函数。这在以前是需要使用不同的损失函数才能做到的。\n\n本论文的主要贡献有：\n\n 1. cgans 可以对多种 image-to-image 问题产生合理的结果\n 2. 提出一个简单并且足以取得良好的结果的框架，并分析几种重要的体系结构的效果。code is available\n\n\n# 2. related work\n\nstructured losses for image modeling 针对 image-to-image 转换问题建模的损失函数，通常被表达成像素级(per-pixel)的分类或回归方程式。这些方程式认为解空间是"unstructured"，也就是说每个输出的pixel被认为在条件上独立于给定输入图像的所有其他像素。\n\n相反，cgans会学习结构性损失。结构化的损失会惩罚输出的联合配置。理论上，cgans的损失函数可以对输入和输出间的任何不同结构进行惩罚。\n\n事实上，在此之前已经有很多使用 cganss 来解决图像生成问题。本文与他们的几个不同的地方在于 generator 和 discriminator 的框架选择上。我们的生成器使用 "u-net"-based 框架，评判器使用了卷积网络的分离器 "patchgan"（它只惩罚 patch 规模的图像结构）。\n\n\n# 3. method\n\ngans are generative models that learn a mapping from random noise vector z to output image y, g : z → y [24]. in contrast, conditional gans learn a mapping from observed image x and random noise vector z, to y, g : {x, z} → y\n\n\n# 3.1 objective\n\n\n\n这里需要注意的是 z 是必须的。以往的 cgans 使用已经意识到这点，并且通常采用 gaussian noise 作为 z 来微调输入。\n\n在最初的实验中，我们使用了这种策略，但没有效果，生成器好像忽略了这个噪音。相反，对于最终模型，我们仅以 dropout 的形式提供噪音，并应用于 训练和测试时的生成器的几层。\n\n尽管采用了 dropout 噪声，我们观察到我们的网络输出的随机性依然很小。设计可产生更大随机性的条件gan，从而捕获他们建模的条件分布的完全熵，是当前工作悬而未决的重要问题。\n\n\n# 3.2 network architectures\n\n 1. generator with skips\n\n一个 image-to-image 转换问题的定义特征是：他们将高分辨率的输入网格映射到高分辨率的输出网格。此外，对于我们考虑的问题，输入和输出的表面外观不同，但是两者是相同基础结构的效果图。所以，输入与输出中的结构是大致对齐的。我们围绕这些事项来设计生成架构。\n\n一些以前解决这类问题的方法是使用 encoder-decoder network。这种网络要求所有的信息流需要通过所有的层，包括瓶颈层。对于许多图像翻译问题，有很多底层信息在输入和输出之间共享，就是说，希望将这些信息直接穿梭在网络上。例如，在图像着色的情况下，输入和输出共享显著边缘的位置，\n\n为了给生成器一种避免此类信息瓶颈的方法，我们按照“ u-net”的一般形状添加了跳过连接。具体来说，我们在第i层和第n-i层之间添加跳过连接，其中n是层的总数。每个跳过连接仅将第i层和第n-i层的所有通道连接在一起。\n\n 2. markovian discriminator (patchgan)\n\n众所周知，l2 和 l1 loss 在图像生成任务中会产生模糊结果。尽管这些损失并不能鼓励高频率清晰度，尽管如此，它们在许多情况下仍能准确捕获低频信息。对于这里的问题，确实是这样，我们不需要全新的框架来强化低频信息的正确性，l1 已经做了。\n\n依靠 l1 来强制低频正确性，这促使将 gan 判别器限制为仅对高频结构信息进行建模。为了对高频信息建模，将注意力集中在本地图像 patch 中的结构就足够了。因此，我们设计了被称为 patchgan 的判别架构，它仅对 patch 规模的结构进行惩罚。这个判别器尝试去分类图像中的 n * n 个 patch 是真是假。我们对该图像进行卷积运算，对所有响应求平均值以提供 d 的最终输出。\n\n下文中，我们证明了：n 可以比图像小很多，也依然可以生成高质量的结果。这是有利的，因为较小的 patchgan 具有较少的参数，运行速度更快，并且可以适用于任意大图像。这样的鉴别器可以有效地将图像建模为马尔可夫随机场，假设像素之间的独立性相差大于 patch 直径。\n\n\n# 3.3 optimization and inference\n\n了优化我们的网络，我们遵循 gan 中的标准方法：在 d 的一个梯度下降步骤与 g 的一个步骤之间交替。如原始 gan 论文建议的那样，不是训练 g 以使 log(1 − d(x，g(x，z)) 最小化，而是训练以最大化 log(d(x，g(x，z))。此外，我们在优化 d 的同时将目标除以2，这会降低 d 相对于 g 的学习率。我们使用 minibatch sgd 和 应用 adam 求解器，指定参数：学习率=0.0002、β1=0.5, β2=0.999。\n\n在推理时，我们以和训练阶段完全相同的方式运行 生成器网络。这和通常的协议不太一样，在测试阶段，我们使用了 dropout 与训练阶段相同的方式，并且我们使用测试 batch 的统计信息进行 batch normalization，而不是训练批次的汇总统计信息。这种方法进行 batch normalization 时，设置 batch size 为 1 时被称为“实例归一化”，并已证明在图像生成任务中有效。在我们的实验中，我们使用 batch size 介于1到10之间，具体取决于实验。\n\n\n# 4. experiments\n\n为了探索 cgans 的普遍性，我们在各种任务和数据集上测试了这种方法，包括 图形任务，例如照片生成，和视觉任务，例如语义分割：\n\n 1. semantic labels ↔ photoo, trained on the cityscapes dataset\n 2. architectural labels → photo, trained on cmp facades\n 3. map↔aerial photo, trained on data scraped from google maps\n 4. bw → color photos\n 5. edges → photo\n 6. sketch → photo\n 7. day → night\n 8. thermal → color photos\n 9. photo with missing pixels → inpainted photo\n\n\n# 4.2 analysis of the objective function\n\n在 final objective 中，哪部分比较重要呢？我们进行消融研究来隔离 l1 、gan 项的影响，以比较 cgan 和 gan 分别作用在输入上的效果。\n\n论文中的 figure 4 显示了这些变化在 two labels → photo 问题上的定性影响：\n\n * 仅l1会导致合理但模糊的结果\n * 单独使用cgan（将 λ=0）给出了更清晰的结果，但在某些应用程序上引入了视觉瑕疵\n * 将两个部分加在一起（λ= 100）减少了这些伪像\n\n使用 fcn-score 量化这些在 cityscapes labels → photo 任务中的观察研究(论文 table 1)：\n\n * 基于 gan 的目标任务得分更高，也就是说 合成的图像包含更多的可识别结构\n * 在衡量输入和输出匹配度的损失函数上，cgan 表现的要比 gan 好的多。\n   * 我们测试了从 final objective 中去掉 conditioning 部分的影响，发现，此时的损失函数不会惩罚输入和输出之间的不匹配，只关心是否输出看起来很真实。检查结果表明，生成器崩溃了，不管输入的照片如何都产生了几乎完全相同的输出。\n * 另外，添加 l1 项也会鼓励 输出尊重输入，因为 l1 损失会对正确匹配输入的 ground truth 输出与可能不正确的合成输出之间的距离进行惩罚。\n * 相应地，l1 + gan 在创建尊重输入标签图的逼真渲染时也是有效的。结合所有项，l1 + cgan 执行的同样的好。\n\ncolorfulness cgans 的一个引人注目的影响就是 它会产生 sharp images，幻想出的即使在输入标签图中不存在的空间结构。有人就开始想象 cgans 在光谱纬度也有类似的“锐化”作用，例如，使得图像具有更加丰富的色彩。就像 l1 在不能精确定位边缘的位置时会激发模糊一样，它也会在不确定像素应采用几种可能的颜色值中的哪种时激励颜色为平均灰色。特别是，通过在可能的颜色上选择条件概率密度函数的中值，可以使l1最小。另一方面，对抗性损失原则上可以变成能够意识到灰色输出是不现实的，并鼓励匹配真实的颜色分布。\n\n\n# 4.3 analysis of the generator architecture\n\nu-net 架构允许低维度信息快捷的穿越网络，这会带来更好的结果吗？通过对比 u-net 和 encoder-decoder(简单的移除 u-net 中的 skip connections 形成) 在 cityscape generation 任务上的表现，我们了解到：\n\n 1. 在我们的实验中，encoder-decoder 无法学习生成逼真的图像\n 2. u-net 不仅在使用 cgans 时 优于 encoder-decoder，在使用 l1 loss 时，也有更加优越的结果\n\n\n# 4.4 from pixelgans to patchgans to imagegans\n\n我们测试了改变鉴别器感受野的 patch size n 的各种效果，从 1×1 的 “pixelgan” 到 286×286 的整图 "imagegan"。\n\npixelgan 对空间清晰度没有特别的影响，但是可以增加结果的色彩。颜色直方图匹配是一个图像处理领域常见的问题，也许 pixelgan 会是一个有潜力的轻量化解决方案。\n\n使用 16×16 patchgan 足以促进锐利的输出，并获得良好的fcn得分，但也导致 tiling artifacts。70×70 patchgan 缓解了这些问题并获得更好的分数。缩放到超出这个范围，到完整的 286×286 imagegan，似乎并没有改善结果的视觉质量，并且，事实上得到了相对低的多的分数。这也许是因为 imagegan 比 70 × 70 patchgan 有更多的参数和更大的深度，从而更加难以训练造成的。\n\nfully-convolutional translation patchgan 的优势是固定 patch 大小的判别器可以适用于任意大的图像。我们也可以将生成器卷积的应用于比训练用的图像更大的图像上。我们在 map ↔ aerial 任务上测试了这种做法。我们在 512×512 的图片上测试了用 256×256 的图像训练得到的生成器，效果在 论文的 figure 8 中可以看出效果还是不俗的。\n\n\n# 4.5 perceptual validation\n\n我们在 map↔aerial 和 grayscale→color 任务上验证了结果的 perceptual realism（感性现实主义？？？）。用志愿者来测试生成的结果，看是否能够骗过志愿者：一般情况下，我们的方法(使用 l1+cgans)有更加优越的表现，除非别的方法是针对特定问题进行了专门设计、优化。\n\n\n# 4.6 semantic segmentation\n\n有条件的 gan 似乎可以有效解决输出高度细节化或摄影类的问题，这在图像处理和图形任务中很常见。那么在视觉问题（如语义分割）上的表现如何呢？这类问题的特点是：输入比输出更复杂。\n\n为了开始对此进行测试，我们训练了一个 cgan（带/不带 l1 损失）用于 cityscape photo→labels 任务。论文 figure 10 显示了定性结果，分类准确性的定量报告在论文 table 6 中。有趣的是，训练出的不带 l1 损失的 cgan 能够在合理程度的准确性上解决这个问题。据我们所知，这是 gan 成功生成“标签”的首次演示，这些"标签"是具有连续变化且几乎离散的值，而不是“图像”。尽管 cgan 取得了一些成功，但他们还远不是解决下面这个问题的最佳方法：如论文 table 6 所示：仅使用 l1 回归可以获得比 cgan 更好的分数。我们认为，对于视觉问题，目标（即预测接近 ground truth 的产出）可能不如图形任务那么含糊，像 l1 这样的重建损失就足够了\n\n\n# 4.7. community-driven research\n\n自从最初发布论文和我们的 pix2pix 代码，twitter社区，包括计算机视觉和图形从业人员以及视觉艺术家，都有成功地将我们的框架应用于各种新颖的图像到图像的翻译任务，远远超出了原始论文。尽管有些是基于 pix2pix 进行了修改，但是，他们证明了我们的方法作为 image-to-image 转换问题的一种通用的商品工具的前景。\n\n\n# 5. conclusion\n\n本文的结果表明，条件对抗网络是许多 image-to-image 转换任务的有前途的方法，特别是那些涉及高度结构化图形输出的任务。这些网络可以学到适应于手头的任务和数据的 loss，这就让这些网络可以适用于各种各样的设置。\n\n----------------------------------------\n\n\n# deconvolution and checkerboard artifacts\n\n> paper: deconvolution and checkerboard artifacts\n\n\n# abstract\n\n当我们非常仔细地观察由神经网络生成的图像时，我们经常会看到一种奇怪的棋盘状伪像图案。这种现象在一些模型中尤为明显，但是最近的模型中有很大一部分都表现出了这种行为。\n\n难以理解的是，棋盘格图案在色彩浓烈的图像中往往最为突出。这是怎么回事？神经网络讨厌鲜艳的色彩吗？这些伪像的实际原因实际上非常简单，这是避免它们的方法。\n\n\n# deconvolution & overlap\n\n当我们让神经网络生成图像时，我们通常会根据低分辨率，高水平的描述来构建它们。这使网络可以描述粗糙图像，然后填写细节信息。\n\n为了做到这一点，我们需要某种方法将低分辨率的图像转换成高分辨率的图像。通常，我们通过 deconvolution 操作来执行此操作。粗略地讲，deconvolution 层允许模型使用小图像中的每个点来“绘制”较大图像中的正方形。\n\n（反卷积具有多种解释和不同的名称，包括“转置卷积”。为简洁起见，我们在本文中使用“反卷积”这个名称。）\n\n不幸的是，反卷积很容易出现“不均匀的重叠”，在某些地方比在其他地方放置更多的隐喻绘画。特别是，当内核大小（输出窗口大小）无法被步幅（顶部各点之间的间距）整除时，反卷积具有不均匀的重叠。尽管原则上网络可以仔细地学习权重来避免这种情况（我们将在后面详细讨论），但实际上神经网络却在努力避免这种情况。\n\n重叠图案也以二维形式形成。两根轴上的不均匀重叠部分会相互叠加，从而形成一个变化幅度大的棋盘状特征图案。\n\n实际上，不均匀的重叠在二维上往往更加极端！因为两个图案相乘在一起，所以不均匀度平方。例如，在一维中，步幅2，大小3的反卷积具有一些输出，其输入数量是其他输入的两倍，但是在二维中，这变成四分之一。\n\n现在，神经网络在创建图像时通常使用多层反卷积，从一系列较低分辨率的描述中迭代构建较大的图像。这些堆叠的反卷积可能会消除伪影，但它们通常会复合，从而在各种规模上创建伪影。\n\n步幅1反卷积-在成功模型中通常被视为最后一层 - 在抑制伪像方面非常有效。他们可以删除划分其大小的频率伪像，并减少其他频率小于其大小的伪像。但是，正如许多最新模型中所看到的那样，伪影仍可能泄漏出去。\n\n除了我们上面观察到的类似于高频棋盘格的伪像外，早期的反卷积还可以创建低频伪像，我们将在后面对此进行详细介绍。\n\n当输出不寻常的颜色时，这些伪像往往最突出。由于神经网络层通常会有偏差（将学习值添加到输出中），因此很容易输出平均颜色。颜色（如亮红色）与平均颜色的距离越远，反卷积就需要贡献越多。\n\n\n# overlap & learning\n\n用不均匀的重叠来思考事物是一种虽然简单化但有用的框架方法。不管好坏，我们的模型都为它们的反卷积学习权重。\n\n从理论上讲，我们的模型可以学习仔细地写到不均匀重叠的位置，从而使输出均匀平衡。\n\n这是一项棘手的平衡操作，尤其是当有多个通道交互时。避免伪像会显着限制可能的过滤器，从而牺牲模型容量。在实践中，神经网络努力学习完全避免这些模式。\n\n实际上，不仅重叠不均匀的模型不能避免这种情况，而且重叠均匀的模型经常学习到导致相似伪像的内核！尽管这不是均匀重叠方式的默认行为，但即使重叠反卷积也仍然很容易会导致伪像。\n\n完全避免伪像仍然是对过滤器的重要限制，并且在实践中，伪像仍然存在于这些模型中，尽管它们看起来较为温和。\n\n这里可能有很多因素在起作用。例如，在生成对抗网络（gan）的情况下，一个问题可能是鉴别器及其梯度（我们将在后面再讨论）。但是问题的很大一部分似乎是反卷积。最好说，反卷积是脆弱的，因为即使很仔细地选择大小，反卷积也很容易代表伪像创建函数。最糟糕的是，创建伪像是反卷积的默认行为。\n\n是否有其他方法可以对伪像具有更高的抵抗力？\n\n\n# better upsampling\n\n为避免这些伪像，我们希望使用 regular deconvolution（“转置卷积”）的替代方法。与反卷积不同，这种向上采样的方法不应将伪像作为其默认行为。理想情况下，它会走得更远，并且偏向于此类工件。\n\n一种方法是确保您使用的内核大小被步幅除尽，从而避免了重叠问题。这等效于“亚像素卷积”，该技术最近在图像超分辨率方面获得了成功。但是，尽管这种方法有所帮助，但是反卷积仍然很容易陷入创建伪像的过程中。\n\n另一种方法是从卷积到计算特征中分离出较高分辨率的上采样。例如，您可以调整图像大小（使用最近邻插值或双线性插值），然后进行卷积层。这似乎是一种自然的方法，并且大致类似的方法在图像超分辨率中效果很好。\n\n解卷积和不同的大小调整卷积方法都是线性运算，可以解释为矩阵。这是查看它们之间差异的有用方法。反卷积在每个输出窗口都有唯一的条目，而resize-convolution则隐含了权重绑定，以阻止高频伪像。\n\n我们曾经使用最近邻插值法取得了最好的结果，同时在使双线性调整大小的工作中遇到了困难。这可能仅意味着，对于我们的模型，最近邻居恰好与针对反卷积优化的超参数配合使用。这可能指出了天真的使用双线性插值可能会遇到棘手的问题，因为它过于强烈地抵抗了高频图像特征。我们不认为这两种方法都是上采样的最终解决方案，但它们确实可以修复棋盘状工件。\n\n\n# image generation results\n\n我们的经验是，在多种情况下，最近邻调整大小后再进行卷积效果非常好。我们发现这种方法可为您提供帮助的一个例子是“生成对抗网络”。简单地将标准反卷积层切换为最近邻调整大小，然后再进行卷积，将导致不同频率的伪像消失。\n\n事实上，在进行任何训练之前就可以看到伪像的差异。如果我们使用随机权重对其进行了初始化，并查看生成器生成的图像，那么我们已经可以看到这些伪像：\n\n这表明伪像是由于这种生成图像的方法，而不是对抗训练。（这也表明我们可以在没有慢速训练模型反馈周期的情况下，学习到很多好的生成器设计。）\n\n相信这些伪影不是gan特有的另一个原因是，我们在其他类型的模型中看到了它们，并且发现当我们切换到调整大小卷积上采样时，它们也会消失。例如，考虑实时艺术风格转移，其中训练神经网络直接生成样式转移的图像。我们发现它们很容易受到棋盘伪像的影响（尤其是在成本并未明确抵制它们的情况下）。但是，将反卷积层切换为调整大小卷积层会使伪像消失。\n\ngoogle brain团队即将发表的论文将在更全面的实验和最新结果中证明该技术的优势。 （我们选择单独介绍此技术，是因为我们认为它值得进行更详细的讨论，并且涉及多篇论文。）\n\n\n# artifacts in gradients\n\n每当我们计算卷积层的梯度时，我们都会在向后遍历上进行反卷积（transposed convolution）。就像我们使用反卷积生成图像时一样，这会导致渐变中的棋盘格图案。\n\n特征可视化社区已经知道图像模型梯度中存在高频“噪声”，这是一个重大挑战。以某种方式，特征可视化方法必须补偿这种噪声。\n\n例如，deepdream 似乎以多种方式引起伪影之间的破坏性干扰，例如同时优化许多功能，以及在许多偏移和比例上进行优化。特别是，在不同偏移量处进行优化的“抖动”消除了一些棋盘伪像。 （尽管某些伪像是我们的标准棋盘格图案，而其他伪像是组织性较差的高频图案。我们认为，这些是由最大合并引起的。最大合并以前与geodesics of learned representations中的高频伪像相关联。）\n\n特征可视化的最新工作（例如deepdreaming with tensorflow）已明确识别并补偿了这些高频梯度分量。人们想知道，更好的神经网络架构是否可以使这些工作变得不必要。\n\n这些梯度伪影会影响gan吗？如果梯度伪影可以影响基于特征可视化中的神经网络梯度优化的图像，那么我们也可以预期它会影响由生成器参数化的图像族，因为它们由gan中的鉴别器进行了优化。我们发现在某些情况下确实会发生这种情况。当生成器既不偏斜也不偏斜棋盘图案时，鉴别器中的大卷积会导致它们。\n\n目前尚不清楚这些梯度伪像的广泛含义是什么。考虑它们的一种方法是，某些神经元基本上可以任意地获得其邻居的许多倍的梯度。等效地，出于充分的理由，网络将比其他像素更关心输入中的某些像素。这些听起来都不是理想的。\n\n似乎有些像素比其他像素对网络输出的影响更大，可能会夸大对抗性反例。由于导数集中在少量像素上，因此这些像素的较小摄动可能会产生较大的影响。我们尚未对此进行调查。\n\n\n# conclusion\n\n使用反卷积生成图像的标准方法尽管取得了成功但存在一些理论上简单的问题，这些问题会导致生成的图像中出现伪像。使用没有这些问题的自然替代方法会导致伪像消失（类似的论点表明，standard strided convolutional 层也可能存在问题）。',charsets:{cjk:!0}},{title:"图像处理基础",frontmatter:{title:"图像处理基础",date:"2019-12-18T00:00:00.000Z",description:"图像处理基础",categories:["blog","skills","imgproc"],tags:[null],permalink:null},regularPath:"/blog/skills/ai/imgproc_base.html",relativePath:"blog/skills/ai/imgproc_base.md",key:"v-4b4d8c9f",path:"/blog/skills/ai/imgproc_base.html",headers:[{level:2,title:"卷积核(滤波器)",slug:"卷积核-滤波器",normalizedTitle:"卷积核(滤波器)",charIndex:13},{level:3,title:"规则要求：",slug:"规则要求",normalizedTitle:"规则要求：",charIndex:26},{level:3,title:"概念",slug:"概念",normalizedTitle:"概念",charIndex:332},{level:2,title:"直方图",slug:"直方图",normalizedTitle:"直方图",charIndex:541},{level:2,title:"仿射变换",slug:"仿射变换",normalizedTitle:"仿射变换",charIndex:633},{level:2,title:"ncnn",slug:"ncnn",normalizedTitle:"ncnn",charIndex:796}],headersStr:"卷积核(滤波器) 规则要求： 概念 直方图 仿射变换 ncnn",content:"# 图像处理基础\n\n\n# 卷积核(滤波器)\n\n\n# 规则要求：\n\n 1. 滤波器的大小应该是奇数，这样它才有一个中心，例如3x3，5x5。有中心了，也有了半径的称呼，例如5x5大小的核的半径就是2。\n    * 保证锚点(卷积核的中心)刚好在中间，方便以模块中心为标准进行滑动卷积\n 2. 滤波器矩阵所有的元素之和应该要等于1，这是为了保证滤波前后图像的亮度保持不变。(非硬性要求)\n    * 如果滤波器矩阵所有元素之和大于1，那么滤波后的图像就会比原图像更亮，反之，如果小于1，那么得到的图像就会变暗。如果和为0，图像不会变黑，但也会非常暗。\n 3. 对于滤波后的结构，可能会出现负数或者大于255的数值。对这种情况，将他们直接截断到0和255之间.\n\n\n# 概念\n\n * 卷积核大小(Kernel Size)：步长（Stride） 填充（Padding）输入和输出通道数（Input & Output Channels）\n * 扩张卷积（Dilated Convolution）：\n   * 感受野（reception field）\n   * 扩张率(dilation rate): 指的是卷积核的点的间隔数量，比如常规的卷积操作dilatation rate为1。\n\n\n# 直方图\n\n直方图归一化（ Histogram Normalization ） ： 增加对比度 直方图均衡化（ Histogram Equalization ） ： 增加对比度\n\n\n# 仿射变换\n\nhttps://blog.csdn.net/momata/article/details/106943599\n\nhttps://github.com/gzr2017/ImageProcessing100Wen/blob/master/Question_51_60/answers/answer_58.py\n\n\n# ncnn\n\n模型可视化：https://lutzroeder.github.io/netron/\n\nncnn 在处理 dbnet 模型时：\n\n 1. 最长边 跟 内存、耗时 的关系密切\n 2. 测试中：最长边 5000 以内，可以控制到内存消耗在400M内, 普通的 2000 x 3000 的最大内存消耗在 100M 左右\n 3. 测试中：限制高宽比最大比例为20，跑了下拿到的测试数据，没有再出现异常",normalizedContent:"# 图像处理基础\n\n\n# 卷积核(滤波器)\n\n\n# 规则要求：\n\n 1. 滤波器的大小应该是奇数，这样它才有一个中心，例如3x3，5x5。有中心了，也有了半径的称呼，例如5x5大小的核的半径就是2。\n    * 保证锚点(卷积核的中心)刚好在中间，方便以模块中心为标准进行滑动卷积\n 2. 滤波器矩阵所有的元素之和应该要等于1，这是为了保证滤波前后图像的亮度保持不变。(非硬性要求)\n    * 如果滤波器矩阵所有元素之和大于1，那么滤波后的图像就会比原图像更亮，反之，如果小于1，那么得到的图像就会变暗。如果和为0，图像不会变黑，但也会非常暗。\n 3. 对于滤波后的结构，可能会出现负数或者大于255的数值。对这种情况，将他们直接截断到0和255之间.\n\n\n# 概念\n\n * 卷积核大小(kernel size)：步长（stride） 填充（padding）输入和输出通道数（input & output channels）\n * 扩张卷积（dilated convolution）：\n   * 感受野（reception field）\n   * 扩张率(dilation rate): 指的是卷积核的点的间隔数量，比如常规的卷积操作dilatation rate为1。\n\n\n# 直方图\n\n直方图归一化（ histogram normalization ） ： 增加对比度 直方图均衡化（ histogram equalization ） ： 增加对比度\n\n\n# 仿射变换\n\nhttps://blog.csdn.net/momata/article/details/106943599\n\nhttps://github.com/gzr2017/imageprocessing100wen/blob/master/question_51_60/answers/answer_58.py\n\n\n# ncnn\n\n模型可视化：https://lutzroeder.github.io/netron/\n\nncnn 在处理 dbnet 模型时：\n\n 1. 最长边 跟 内存、耗时 的关系密切\n 2. 测试中：最长边 5000 以内，可以控制到内存消耗在400m内, 普通的 2000 x 3000 的最大内存消耗在 100m 左右\n 3. 测试中：限制高宽比最大比例为20，跑了下拿到的测试数据，没有再出现异常",charsets:{cjk:!0}},{title:"PyTorch入门(快速、深度)",frontmatter:{title:"PyTorch入门(快速、深度)",date:"2021-02-18T00:00:00.000Z",description:"快速又有深度的 PyTorch 入门",categories:["pytorch"],tags:[null],permalink:null},regularPath:"/blog/skills/ai/pytorch_base.html",relativePath:"blog/skills/ai/pytorch_base.md",key:"v-cc5c4542",path:"/blog/skills/ai/pytorch_base.html",headers:[{level:2,title:"1 基础元素",slug:"_1-基础元素",normalizedTitle:"1 基础元素",charIndex:23},{level:3,title:"1.1 Tensor",slug:"_1-1-tensor",normalizedTitle:"1.1 tensor",charIndex:34},{level:3,title:"1.2 Autograd",slug:"_1-2-autograd",normalizedTitle:"1.2 autograd",charIndex:603},{level:3,title:"1.3 NN && Loss",slug:"_1-3-nn-loss",normalizedTitle:"1.3 nn &amp;&amp; loss",charIndex:null},{level:3,title:"1.4 Device",slug:"_1-4-device",normalizedTitle:"1.4 device",charIndex:1889},{level:2,title:"2 模型(Module)",slug:"_2-模型-module",normalizedTitle:"2 模型(module)",charIndex:3093},{level:3,title:"2.1 保存和加载",slug:"_2-1-保存和加载",normalizedTitle:"2.1 保存和加载",charIndex:3110},{level:3,title:"2.2 网络结构",slug:"_2-2-网络结构",normalizedTitle:"2.2 网络结构",charIndex:3957},{level:3,title:"2.3 成员",slug:"_2-3-成员",normalizedTitle:"2.3 成员",charIndex:4874},{level:3,title:"2.4 组成",slug:"_2-4-组成",normalizedTitle:"2.4 组成",charIndex:7683},{level:2,title:"3 数据变换操作",slug:"_3-数据变换操作",normalizedTitle:"3 数据变换操作",charIndex:8684},{level:3,title:"常用方法(共：5类22种)",slug:"常用方法-共-5类22种",normalizedTitle:"常用方法(共：5类22种)",charIndex:8804},{level:2,title:"4 数据加载",slug:"_4-数据加载",normalizedTitle:"4 数据加载",charIndex:10903},{level:3,title:"数据采样(划分)",slug:"数据采样-划分",normalizedTitle:"数据采样(划分)",charIndex:12528},{level:2,title:"5 损失函数",slug:"_5-损失函数",normalizedTitle:"5 损失函数",charIndex:13962},{level:2,title:"6 优化器",slug:"_6-优化器",normalizedTitle:"6 优化器",charIndex:15340},{level:2,title:"7 数据标注",slug:"_7-数据标注",normalizedTitle:"7 数据标注",charIndex:16730},{level:2,title:"To Be Continue ....",slug:"to-be-continue",normalizedTitle:"to be continue ....",charIndex:17347},{level:2,title:"Reference",slug:"reference",normalizedTitle:"reference",charIndex:17591}],headersStr:"1 基础元素 1.1 Tensor 1.2 Autograd 1.3 NN && Loss 1.4 Device 2 模型(Module) 2.1 保存和加载 2.2 网络结构 2.3 成员 2.4 组成 3 数据变换操作 常用方法(共：5类22种) 4 数据加载 数据采样(划分) 5 损失函数 6 优化器 7 数据标注 To Be Continue .... Reference",content:'# PyTorch入门: 快速、深度\n\n\n# 1 基础元素\n\n\n# 1.1 Tensor\n\nTensor的常见操作操作，包括换位、索引、切片、数学运算、线性算法和随机数等等。\n\n除了 CharTensor 之外，所有的 tensor 都可以很方便的在 CPU和GPU 运算之间相互转换:\n\n    tor = torch.ones(5)\n    if torch.cuda.is_available():\n        tor_cuda = tor.cuda()\n        tor_cpu = tor_cuda.cpu()\n\n\n1\n2\n3\n4\n\n\n这里强调下 Torch 的 Tensor 和 numpy 的 array 相互转换，GPU tensor 不能直接转为 numpy 数组，必须先转到 CPU tensor：\n\n    import numpy as np\n\n    a_np = np.ones(5)\n    a_tor = torch.ones(5)\n\n    b_np = a_tor.numpy()\n    b_tor = torch.from_numpy(a_np)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n还需要注意的是：Torch 的 Tensor 和 numpy 的 array 会共享他们的存储空间，修改一个会导致另外的一个也被修改。\n\nmore docs...\n\n\n# 1.2 Autograd\n\nautograd 包提供 Tensor 所有操作的自动求导方法。这是一个运行时定义的框架，这意味着你的反向传播是根据你代码运行的方式来定义的，因此每一轮迭代都可以各不相同。\n\nautograd 包中有两个非常重要的类：Variable 和 Function，二者相互联系并且构建了一个描述整个运算过程的无环图。\n\n其中，Function 实现了使用自动求导方法的前馈和后馈的定义。每个Variable的操作都会生成至少一个独立的Function节点，与生成了Variable的函数相连之后记录下操作历史。\n\nautograd.Variable 是这个包中最核心的类。它有三个常用属性：\n\n * data ： 用于访问原始的 tensor\n   * Variable 包装了一个 Tensor，并且几乎支持所有的定义在其上的操作。\n * creator ： 引用了一个创建 Variable 的 Function。(除了用户创建的 Variable 中的 creator 属性是 None)\n * grad ： 关于这一 Variable 的梯度则集中存储于此属性\n\n当通过 Variable 定义了完整计算后，可以调用计算结果的 .backward() 来自动计算出所有的梯度。当然，也可以指定 Variable 不计算梯度，如：指定 requires_grad=False。\n\n思考：如果 a = Variable(torch.randn(5, 5), requires_grad=True) + Variable(torch.randn(5, 5), requires_grad=False), 那个 a.requires_grad 是什么？\n\nmore docs...\n\n\n# 1.3 NN && Loss\n\n在 pytorch 中，可以使用 torch.nn 包进行神经网络的构建。nn.Module中包含着神经网络的层，同时forward(input)方法能够将output进行返回。\n\n一个典型的神经网络的训练过程是这样的：\n\n 1. 定义一个有着可学习的参数（或者权重）的神经网络\n 2. 对着一个输入的数据集进行迭代:\n    1. 用神经网络对输入进行处理\n    2. 计算代价值 (对输出值的修正到底有多少)\n    3. 通过 optimizer(优化器) 对损失函数进行梯度计算，并将梯度传播回神经网络的参数中\n    4. 更新网络中的权重\n    * 通常使用简单的更新规则: weight = weight + learning_rate * gradient\n\n在上述这个过程中，torch.nn.Module (神经网络模块) 是所有 网络的基础，可以独立用作一个网络，也可以通过组合各个网络层形成神经网络进行计算。模型的组合，可以通过以下方式形成：\n\n而 porch.optim 和 ptorch.nn.MSELoss等损失函数，则是在网络计算过程中进行迭代优化必不可少的部分。\n\ndocs...\n\n\n# 1.4 Device\n\n在 pytorch 中，我们可以选择将 tensor 运行在 cpu 或者 gpu 上，如上文所述的方式：tensor.cpu() 或 tensor.gpu() 就可以简单的实现 cpu 和 gpu 的选择或切换。\n\n有些时候，我们想在代码的全局位置上指定使用的设备类型，然后就可以不用修改的将代码跑在 gpu 或者 cpu 上，这也很容易实现：\n\nif gpu_id == -1:\n  device = torch.device("cpu")\nelse:\n  device = torch.device("cuda")\n  torch.cuda.set_device(gpu_id)\n  # torch.cuda.set_device("cuda:1,2") # 指定多张显卡\n\nones = tensor.ones(5).to(device)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n注意到，使用 cuda 时，我们指定了 gpu_id, 如果不显示的设置，默认使用 cuda:0，即系统的第一块显卡。\n\n如果在一个节点上有多块 gpu，分别跑同一个模型的不同参数，这时我们可以通过 set_device() 显示的将模型分配到某一个 cuda 上。还有其他方法可以实现吗？\n\n有，可以通过 CUDA_VISIBLE_DEVICES 环境变量来限制 CUDA 程序所能使用的 GPU 设备。CUDA 应用运行时，CUDA 将遍历当前可见的设备，并从零开始为可见设备编号。这样，就可以让我们的程序都认为自己看到的 gpu 是零号开始编号的设备。\n\n  CUDA_VISIBLE_DEVICES=0,2,3 ./cuda_executable\n\n\n1\n\n\n也就是说通过这个环境变量，可以使得系统中 GPU 设备的编号 和 CUDA应用看到的设备编号产生不一致。使用得当的话，可以通过灵活的配置 CUDA_VISIBLE_DEVICES 环境变量为 CUDA 应用分配需要的硬件资源。\n\n如果为 CUDA_VISIBLE_DEVICES 设置了不存在的设备，所有实际设备将被隐藏，CUDA 应用将无法使用 GPU 设备；如果设备序列是存在和不存在设备的混合，那么不存在设备前的所有存在设备将被重新编号，不存在设备之后的所有设备将被屏蔽。\n\n当然，对于在代码内通过代码修改可见设备的情况，只有在代码访问 GPU 设备之前设置 CUDA_VISIBLE_DEVICES 变量才有效。\n\n这里我们提到了多个 GPU 设备，自然会想到当训练迭代次数或者epoch足够大的时候希望用多个 GPU 来加速训练。一般我们会使用：net = torch.nn.DataParallel(net, device_ids=[0, 1]) 来实现使用多个 GPU 训练模型。更多关于多卡的内容...\n\n\n# 2 模型(Module)\n\n\n# 2.1 保存和加载\n\npytorch 中模型的存储和再加载都比较简单，一般有两种方式，示例代码如下：\n\n * 保存整个网络（信息全）\n   \n     torch.save(model, PATH) \n     model = torch.load(PATH)\n   \n   \n   1\n   2\n   \n * 保存网络中的参数（速度快，占空间少）\n   \n     # save\n     torch.save(model.state_dict(), PATH)\n     # load\n     model = MyModel(*args, **kwargs)\n     model.load_state_dict(torch.load(PATH), strict=True)\n     model.eval()\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   \n\nload_state_dict() 是 nn.Module 的一个API，利用模型文件反序列化后得到的 Dict 来初始化当前的模型。需要注意 strict 参数，默认值是 True。因此在初始化时候，该函数会严格比较源 Dict 和目标 Dict 的 key 是否完全一样。如果 strict=False，则将不会进行这样的严格检查，只有key一样的才会进行赋值。\n\n看到这里，是否好奇存储的模型文件(.pth)里都包含了什么信息？比如，模型的网络结构、model.state_dict 具体是什么内容呢... 接下来我们就看看 module 里都包含了什么吧。\n\n注意，使用 torch.nn.DataParallel 训练的模型要保存的话，最好使用 torch.save(model.module.state_dict(), PATH)。这样的话，在重新加载 pth模型文件 的时候，会有极大的灵活性，而不是出现一大堆 unexpected keys和missed keys\n\n\n# 2.2 网络结构\n\n# 模型\n\n我们先来看看 torch.load 网络后，得到的是什么内容：\n\n  for k in model.keys():\n    print(k)  \n\n\n1\n2\n\n\n发现加载后的模型有四个键值, 观察其中的内容，可以发现：\n\nKEY         TYPE          用途\nmodel       OrderedDict   相当于 model.state_dict() 的值,\n                          存储着所有的每一层的参数名称以及对应的参数值，需要注意的是，参数名称可能很长\noptimizer   dict          相当于 optimizer.state_dict() 的值, 用途：?\nscheduler   dict          ?\niteration   int           ?\n\n注意，这里看到的是通过 torch.load 加载模型文件后得到的 dict，需要转换为具体的 Model 对象才能被继续使用(继续训练 或 测试)\n\n# 结构\n\n一般我们要了解其网络结构，往往将其可视化是常用的方式。以常见的 pytorch 的 .pth 模型文件为例:\n\n * 使用 netron 可视化工具。\n   1. 安装netron：参考 github-Netron\n   2. 注意, 保存网络时要保存完整结构，不能只保存参数，否则不正常工作\n * 使用 tensorwatch (微软)\n   1. 安装、使用：参考 github-tensorwatch\n   2. 功能强大：TensorWatch is under heavy development with a goal of providing a platform for debugging machine learning in one easy to use, extensible, and hackable package.\n\n另外，还可以直接使用 print(model_obj) (依靠__repr__机制)打印出模型的相关信息，组合出网络信息。\n\n\n# 2.3 成员\n\n简单的了解 pytorch 后，我们知道，所有定义的网络结构都必须要继承：torch.nn.Module 类。例如，\n\n  class MyModel(nn.Module):\n    def __init__(self):\n      super(MyModel, self).__init__()\n      self.my_tensor = torch.randn(1) # 模型类成员变量\n      self.register_buffer(\'my_buffer\', torch.randn(1)) # 自定义 buffer\n      # 通过两种方式定义 paramter\n      self.p1 = nn.paramter.Paramter(torch.tensor(1.0))\n      print(self._parameters)\n      self.p2 = nn.Paramter(torch.tensor(2.0))\n      print(self._parameters)\n      \n    def forward(self, x):\n      return x\t\n\n  model = MyModel()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n查看 torch.nn.Module 类实现，会发现其包含了以下成员变量：\n\n名字                            类型            用途\n_modules                      OrderedDict   可以通过 model.state_dict() 得到其中的值\n_parameters                   OrderedDict   \n_buffers                      OrderedDict   \n_state_dict_hooks             OrderedDict   \n_load_state_dict_pre_hooks    OrderedDict   \n_forward_pre_hooks            OrderedDict   \n_forward_hooks                OrderedDict   \n_backward_hooks               OrderedDict   \n_non_persistent_buffers_set   set           \n\n# _parameters\n\n存储的值类型为：nn.parameter.Paramter，也就是模型中存储的参数。一般的，它就是训练过程中需要求解的参数，也就是说需要进行反向传播。所以，它有一个特点是：默认的 requires_grad=True。\n\n这里通过一个简单的 Module 来了解下 _parameters。例如，模型 torch.nn.Linear 通常由 weight和bias 参数组成：\n\n  # 定义一个 module\n  fc = torch.nn.Linear(2,2)\n\n  # 读取 _parameters: 方式a\n  fc._parameters\n  \n  # 读取 _parameters: 方式b\n  for n, p in fc.named_parameters():\n    pring(n, p)\n  \n  # 读取 _parameters: 方式c\n  for p in fc.parameters():\n    print(p)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n注意： 测试代码时，会发现 requires_grad 属性默认为 True。另外就是，推荐后边两种通过迭代器的方式进行读取，以避免参数非常多时，第一种方式占用过多资源。 这里提一下，weight(权重) 和 bias(偏置量) 的作用：weight 决定网络的形状，bias给网络增加平移(泛化)的能力\n\n如果运行了 MyModel 模型定义的代码，就会发现一个奇怪的现象，self.p1 和 self.p2 赋值后，模型的 _parameters 参数都会发生相应的变化(被加入到了_parameters中)，这是怎么回事呢？\n\n 1. 首先运行super(MyModel, self).init()，这样MyModel就初始化了_paramters等一系列的OrderDict，此时所有变量还都是空的。\n 2. self.p1 = nn.paramter.Paramter(torch.tensor(1.0)): 这行代码会触发 nn.Module 预定义好的 setattr 函数。源码片段如下：\n\n  def __setattr__(self, name, value):\n    ...\n    params = self.__dict__.get(\'_parameters\')\n    if isinstance(value, Parameter):\n      if params is None:\n        raise AttributeError(\n          "cannot assign parameters before Module.__init__() call")\n      remove_from(self.__dict__, self._buffers, self._modules)\n      self.register_parameter(name, value)\n    ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n发现 setattr 函数的作用，简单说就是检查定义的参数类型, 如果正确就继续调用 register_parameter 函数进行注册，这个函数就更简单了，我们目前关心的就是它做了下面这件事\n\n  def register_parameter(self,name,param):\n    ...\n    self._parameters[name]=param\n    ...\n\n\n1\n2\n3\n4\n\n\n另外， setattr 还可以处理 Module 类型，当 value 是 nn.Module 类型时，也会进行相应的处理动作。\n\n# _buffers\n\n和 _parameters 用于反向传播不同，一般用于存储需要持久化，但又不是网络(不需要参与反向传播的)参数，使用方式：self.register_buffer(\'my_buffer\', torch.randn(1))\n\n\n# 2.4 组成\n\n在构建新的模型时，可以通过多个小模型组合形成复杂的网络模型，如：\n\n  # 主动设置 name \n  from collections import OrderedDict\n  model = nn.Sequential(OrderedDict([ (\'conv1\', nn.Conv2d(1,20,5)), (\'relu1\', nn.ReLU())]))\n\n  # 自动设置 name: 以在 layers 中的索引为 name\n  layers = []\n  layers.append(nn.Conv2d(curr_dim, 3, kernel_size=7, stride=1, padding=3, bias=False))\n  layers.append(nn.Tanh())\n  model = nn.Sequential(*layers)\n\n  # 自动设置 name: 以在 layers 中的索引为 name\n  model = nn.ModuleList([nn.Conv2d(curr_dim, 3), nn.Tanh()]))\n\n  # 查看网络结构\n  print(model)\n\n  # 查看模型的参数列表\n  params=model.state_dict() \n  for k,v in params.items():\n    print(k, v)    #打印网络的变量名、param\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n通过上文，我们知道 model.state_dict 存储了网络模型的相关参数信息，这个信息存储在 OrderedDict 中，那么 key 和 value 又分别是什么呢？\n\n通过上述示例代码，我们可以查看 state_dict 的内容，这里主要说明下 key 的生成，其格式为：prefix + param_name_in_module + name + "." [ + ... ]，如果模型迭代，则继续这个格式直到最终的变量。其中，prefix 默认为 “”，name 如果没有主动声明，则默认为组合模型的 layers 中的索引.\n\n思考：如果向 layers 里添加 [nn.Conv2d(), nn.Conv2d()] 会怎么样？\n\n\n# 3 数据变换操作\n\n这里主要介绍下 Pytorch 中 torchvision.transforms 提供的几种数据增强函数的使用。在加载数据时，可以通过指定 transforms.Compose() 方便、高效的进行数据预处理。\n\n\n# 常用方法(共：5类22种)\n\n测试代码：\n\n  from torchvision import transforms\n  from PIL import Image\n  import torch\n  \n  img = Image.open("img_path")\n  transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.ToPILImage()\n    # ... more\n  ])\n  new_img = transform(img)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n# 基础操作\n\n# transforms.ToTensor()\n\n# transforms.Lambda()\n\n  lambd = lambda x: TF.rotate(x, 100)\n  transforms.Lambda(lambd)\n\n\n1\n2\n\n\nApply a user-defined lambda as a transform. 根据用户自定义的方式进行变换\n\n# transforms.ToPILImage()\n\n# transforms.Normalize(mean, std)\n\n# 随机应用\n\n# transforms.RandomApply(transforms, p=0.5)\n\n给定一定概率从一组 transformations 应用\n\n# transforms.RandomChoice(transforms)\n\nApply single transformation randomly picked from a list\n\n# transforms.RandomOrder\n\nApply a list of transformations in a random order\n\n# 剪裁、填充\n\n# transforms.Resize()\n\n# transforms.Pad()\n\npadding_mode：填充的模式：constant, edge（填充值为边缘）, reflect (从边缘往内一个像素开始做镜像) or symmetric（从边缘做镜像）\n\n# transforms.CenterCrop\n\nCrops the given PIL Image at the center\n\n# transforms.RandomCrop\n\nCrop the given PIL Image at a random location. 随机进行裁剪\n\n# transforms.RandomResizedCrop\n\nCrop the given PIL Image to random size and aspect ratio. 裁剪给定的 PIL 图像到随机的尺寸和长宽比。\n\n# transforms.FiveCrop\n\n将给定的 PIL 图像裁剪成四个角和中间的裁剪\n\n# transforms.TenCrop\n\n裁剪一张图片的 4 个角以及中间得到指定大小的图片，并且进行水平翻转 / 竖直翻转 共 10 张\n\n# 仿射变换\n\n# transforms.RandomHorizontalFlip(p=0.5) 、transforms.RandomVerticalFlip(p=0.5)\n\nHorizontally/Vertically flip the given PIL Image randomly with a given probability. 按一定概率进行水平 / 竖直翻转\n\n# transforms.RandomRotation\n\n一定角度旋转图像\n\n# transforms.RandomAffine\n\n保持图像中心不变的随机仿射变换，可以进行随心所欲的变化\n\n# transforms.RandomPerspective\n\n对给定的 PIL 图像以给定的概率随机进行透视变换\n\n# transforms.LinearTransformation()\n\n常应用于 白化，以去除输入数据的冗余信息。假设训练数据是图像，由于图像中相邻像素之间具有很强的相关性，所以用于训练时输入是冗余的；白化的目的就是降低输入的冗余性。\n\n# 颜色相关\n\n# transforms.ColorJitter\n\nRandomly change the brightness, contrast and saturation of an image. 随机改变图像的亮度、对比度和饱和度\n\n# transforms.Grayscale\n\n转换图像灰度。\n\n# transforms.RandomGrayscale\n\nRandomly convert image to grayscale with a probability of p (default 0.1). 以一定的概率对图像进行灰度化，转换后的图片还是 3 通道的\n\nmore docs...\n\n\n# 4 数据加载\n\npytorch 中对数据集合处理的方法集中在 torch.utils.data 包中，主要包含了以下方法：\n\nCLASS                                                      DESCRIPTION                       ADDITIONS\ntorch.utils.data.Dataset                                   一个抽象类， 所有其他类的数据集类都应该是它的子类         其子类必须重载两个重要的函数：len(提供数据集的大小）、getitem(支持整数索引)\ntorch.utils.data.TensorDataset                             封装成tensor的数据集，每一个样本都通过索引张量来获得     \ntorch.utils.data.ConcatDataset                             连接不同的数据集以构成更大的新数据集                \ntorch.utils.data.Subset(dataset, indices)                  获取指定一个索引序列对应的子数据集                 \ntorch.utils.data.DataLoader                                数据加载器, 组合了一个数据集和采样器，并提供关于数据的迭代器   \ntorch.utils.data.random_split(dataset, lengths)            按照给定的长度将数据集划分成没有重叠的新数据集组合         \n                                                                                             \ntorch.utils.data.Sampler(data_source)                      所有采样的器的基类                         每个采样器子类都需要提供 iter 方-法以方便迭代器进行索引 和一个 len方法 以方便返回迭代器的长度。\ntorch.utils.data.SequentialSampler                         顺序采样样本，始终按照同一个顺序                  \ntorch.utils.data.RandomSampler                             无放回地随机采样样本元素                      \ntorch.utils.data.SubsetRandomSampler                       无放回地按照给定的索引列表采样样本元素               \ntorch.utils.data.WeightedRandomSampler                     按照给定的概率来采样样本                      \ntorch.utils.data.BatchSampler(sampler, batch_size,         在一个batch中封装一个其他的采样器               \ndrop_last)\ntorch.utils.data.distributed.DistributedSampler(dataset,   采样器可以约束数据加载进数据集的子集                \nnum_replicas=None, rank=None)\n\n\n# 数据采样(划分)\n\n在进行训练时，常将用于训练的数据集分割成 8:2 两部分，一部分用于训练，另一部分用于每个 epoch 结束后的 test，以判断当前模型的收敛效果。\n\n借助上文中所述的方法，我们常用的分割方法如下：\n\n 1. random_split\n\ntrain_size = int(0.8 * len(full_dataset))\ntest_size = len(full_dataset) - train_size\ntrain_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n\n\n1\n2\n3\n\n\n这个过程的效果等同于：手动对数据索引进行shuffle后进行切分。\n\n 2. SubsetRandomSampler\n\n...\n\ndataset = MyCustomDataset(my_path)\nbatch_size = 16\nvalidation_split = .2\nshuffle_dataset = True\nrandom_seed= 42\n\n# Creating data indices for training and validation splits:\ndataset_size = len(dataset)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]\n\n# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\nvalidation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n\n# Usage Example:\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    # Train:   \n    for batch_index, (faces, labels) in enumerate(train_loader):\n        # ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\nmore docs...\n\n\n# 5 损失函数\n\npytorch 中常用的 loss 有：\n\nNAME                   DESCRIBE                   FEATURE                                                      NOTE\nL1 Loss                绝对值误差                      主要应用在回归任务                                                    \nMSE Loss(L2Loss)       均方误差                       主要应用在回归任务                                                    \nCrossEntropy Loss      交叉熵                        主要应用在多分类问题中(二分类也可以用)                                         实际上它是由nn.LogSoftmax()和nn.NLLLoss()组成\nBCE Loss               二分类的交叉熵(严格按照交叉熵的公式去算)      一般应用在单标签二分类和多标签二分类                                           \nBCEWithLogits Loss     把 Sigmoid 和 BCELoss 合成一步                                                                如果想用BCE损失，推荐这种，不需要自己写sigmoid那部分\nMultiLabelMarginLoss                              用于一个样本属于多个类别时的分类任务                                           \nNLLLoss                负对数似然损失                    主要应用在分类任务                                                    \nSmoothL1Loss           其实是L2Loss和L1Loss的结合        当预测值和ground truth差别较小的时候（绝对值差小于 beta）使用是L2；当差别大时，使用 L1 的平移   \nFocal Loss             主要是为了解决难易样本数量不平衡           只是针对二分类问题                                                    注意，有区别于正负样本数量不平衡, 难易程度即易分程度\nGHM Loss               Focal Loss 的升级版                                                                         \n\nmore docs...\n\n\n# 6 优化器\n\npytorch 中常用的 optimizer 有：\n\nNAME       DESCRIBE                                      GOOD                                                          BAD                    NOTE\nSGD        随机梯度下降                                        对梯度的要求很低（计算梯度快）。而对于引入的噪声，大量的理论和实践工作证明，只要噪声不是特别大，SGD都能很好地收敛。   1.SGD在随机选择梯度的同时会引入噪声   \n                                                                                                                       2.容易陷入局部最优解\nMomentum   SGD 的升级版，使用动量的SGD，主要思想是引入一个积攒历史梯度信息动量来加速SGD   动量主要解决SGD的两个问题:                                                                      效果上类似于小球向下滚动的时候带上了惯性\n                                                         1.随机梯度的方法（引入的噪声）\n                                                         2.解决了Hessian矩阵病态问题(可以理解为：SGD 在收敛过程中和正确梯度相比来回摆动比较大的问题)\nRMSProp    自适应学习率优化算法，Momentum的升级版                       相对于Adagrad，由于取了个加权平均，避免了学习率越来越低的的问题                                                  在经验上已经被证明是一种有效且实用的深度神经网络优化算法。目前它是深度学习从业者经常采用的优化方法之一。\nAdam       自适应学习率优化算法，RMSProp 的升级版                       相比于缺少修正因子导致二阶矩估计可能在训练初期具有很高偏置的RMSProp                                                通常被认为对超参数的选择相当鲁棒。一般比RMSProp要好一点。\n\n效果如下(图片来源于互联网)：\n\n * 曲面上\n   \n * 存在鞍点的曲面\n   \n\n注意到，两个动量优化器 Momentum 和 NAG 以及 SGD 都顺势进入了鞍点。但两个动量优化器在鞍点抖动了一会，但最终逃离了鞍点并迅速地下降，而 SGD 却始终停留在了鞍点。\n\n在实际应用中，选择哪种优化器应结合具体问题；同时，也优化器的选择也取决于使用者对优化器的熟悉程度（比如参数的调节等等）。\n\nmore docs...\n\n\n# 7 数据标注\n\n数据标注工具：\n\nhttps://github.com/topics/annotation-tool\nhttps://github.com/mingx9527/Data_Label_Tools\n  https://github.com/heartexlabs/label-studio\n  https://github.com/tzutalin/labelImg\n  https://github.com/jsbroks/coco-annotator\n  https://github.com/opencv/cvat\n  https://github.com/microsoft/VoTT\n  https://github.com/wkentaro/labelme\n  https://github.com/abreheret/PixelAnnotationTool\n  https://www.robots.ox.ac.uk/~vgg/software/via/\n  https://github.com/Labelbox/Labelbox\n  https://github.com/UniversalDataTool/universal-data-tool\n  https://github.com/DataTurks/DataTurks\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# To Be Continue ....\n\npytorch-lightning\n  https://pytorch-lightning.readthedocs.io/en/1.0.2/trainer.html\n  https://github.com/3017218062/Pytorch-Lightning-Learning\n  https://blog.csdn.net/weixin_46062098/article/details/109713240\n\n\n1\n2\n3\n4\n\n\n\n# Reference\n\n * github pytorch examples',normalizedContent:'# pytorch入门: 快速、深度\n\n\n# 1 基础元素\n\n\n# 1.1 tensor\n\ntensor的常见操作操作，包括换位、索引、切片、数学运算、线性算法和随机数等等。\n\n除了 chartensor 之外，所有的 tensor 都可以很方便的在 cpu和gpu 运算之间相互转换:\n\n    tor = torch.ones(5)\n    if torch.cuda.is_available():\n        tor_cuda = tor.cuda()\n        tor_cpu = tor_cuda.cpu()\n\n\n1\n2\n3\n4\n\n\n这里强调下 torch 的 tensor 和 numpy 的 array 相互转换，gpu tensor 不能直接转为 numpy 数组，必须先转到 cpu tensor：\n\n    import numpy as np\n\n    a_np = np.ones(5)\n    a_tor = torch.ones(5)\n\n    b_np = a_tor.numpy()\n    b_tor = torch.from_numpy(a_np)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n还需要注意的是：torch 的 tensor 和 numpy 的 array 会共享他们的存储空间，修改一个会导致另外的一个也被修改。\n\nmore docs...\n\n\n# 1.2 autograd\n\nautograd 包提供 tensor 所有操作的自动求导方法。这是一个运行时定义的框架，这意味着你的反向传播是根据你代码运行的方式来定义的，因此每一轮迭代都可以各不相同。\n\nautograd 包中有两个非常重要的类：variable 和 function，二者相互联系并且构建了一个描述整个运算过程的无环图。\n\n其中，function 实现了使用自动求导方法的前馈和后馈的定义。每个variable的操作都会生成至少一个独立的function节点，与生成了variable的函数相连之后记录下操作历史。\n\nautograd.variable 是这个包中最核心的类。它有三个常用属性：\n\n * data ： 用于访问原始的 tensor\n   * variable 包装了一个 tensor，并且几乎支持所有的定义在其上的操作。\n * creator ： 引用了一个创建 variable 的 function。(除了用户创建的 variable 中的 creator 属性是 none)\n * grad ： 关于这一 variable 的梯度则集中存储于此属性\n\n当通过 variable 定义了完整计算后，可以调用计算结果的 .backward() 来自动计算出所有的梯度。当然，也可以指定 variable 不计算梯度，如：指定 requires_grad=false。\n\n思考：如果 a = variable(torch.randn(5, 5), requires_grad=true) + variable(torch.randn(5, 5), requires_grad=false), 那个 a.requires_grad 是什么？\n\nmore docs...\n\n\n# 1.3 nn && loss\n\n在 pytorch 中，可以使用 torch.nn 包进行神经网络的构建。nn.module中包含着神经网络的层，同时forward(input)方法能够将output进行返回。\n\n一个典型的神经网络的训练过程是这样的：\n\n 1. 定义一个有着可学习的参数（或者权重）的神经网络\n 2. 对着一个输入的数据集进行迭代:\n    1. 用神经网络对输入进行处理\n    2. 计算代价值 (对输出值的修正到底有多少)\n    3. 通过 optimizer(优化器) 对损失函数进行梯度计算，并将梯度传播回神经网络的参数中\n    4. 更新网络中的权重\n    * 通常使用简单的更新规则: weight = weight + learning_rate * gradient\n\n在上述这个过程中，torch.nn.module (神经网络模块) 是所有 网络的基础，可以独立用作一个网络，也可以通过组合各个网络层形成神经网络进行计算。模型的组合，可以通过以下方式形成：\n\n而 porch.optim 和 ptorch.nn.mseloss等损失函数，则是在网络计算过程中进行迭代优化必不可少的部分。\n\ndocs...\n\n\n# 1.4 device\n\n在 pytorch 中，我们可以选择将 tensor 运行在 cpu 或者 gpu 上，如上文所述的方式：tensor.cpu() 或 tensor.gpu() 就可以简单的实现 cpu 和 gpu 的选择或切换。\n\n有些时候，我们想在代码的全局位置上指定使用的设备类型，然后就可以不用修改的将代码跑在 gpu 或者 cpu 上，这也很容易实现：\n\nif gpu_id == -1:\n  device = torch.device("cpu")\nelse:\n  device = torch.device("cuda")\n  torch.cuda.set_device(gpu_id)\n  # torch.cuda.set_device("cuda:1,2") # 指定多张显卡\n\nones = tensor.ones(5).to(device)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n注意到，使用 cuda 时，我们指定了 gpu_id, 如果不显示的设置，默认使用 cuda:0，即系统的第一块显卡。\n\n如果在一个节点上有多块 gpu，分别跑同一个模型的不同参数，这时我们可以通过 set_device() 显示的将模型分配到某一个 cuda 上。还有其他方法可以实现吗？\n\n有，可以通过 cuda_visible_devices 环境变量来限制 cuda 程序所能使用的 gpu 设备。cuda 应用运行时，cuda 将遍历当前可见的设备，并从零开始为可见设备编号。这样，就可以让我们的程序都认为自己看到的 gpu 是零号开始编号的设备。\n\n  cuda_visible_devices=0,2,3 ./cuda_executable\n\n\n1\n\n\n也就是说通过这个环境变量，可以使得系统中 gpu 设备的编号 和 cuda应用看到的设备编号产生不一致。使用得当的话，可以通过灵活的配置 cuda_visible_devices 环境变量为 cuda 应用分配需要的硬件资源。\n\n如果为 cuda_visible_devices 设置了不存在的设备，所有实际设备将被隐藏，cuda 应用将无法使用 gpu 设备；如果设备序列是存在和不存在设备的混合，那么不存在设备前的所有存在设备将被重新编号，不存在设备之后的所有设备将被屏蔽。\n\n当然，对于在代码内通过代码修改可见设备的情况，只有在代码访问 gpu 设备之前设置 cuda_visible_devices 变量才有效。\n\n这里我们提到了多个 gpu 设备，自然会想到当训练迭代次数或者epoch足够大的时候希望用多个 gpu 来加速训练。一般我们会使用：net = torch.nn.dataparallel(net, device_ids=[0, 1]) 来实现使用多个 gpu 训练模型。更多关于多卡的内容...\n\n\n# 2 模型(module)\n\n\n# 2.1 保存和加载\n\npytorch 中模型的存储和再加载都比较简单，一般有两种方式，示例代码如下：\n\n * 保存整个网络（信息全）\n   \n     torch.save(model, path) \n     model = torch.load(path)\n   \n   \n   1\n   2\n   \n * 保存网络中的参数（速度快，占空间少）\n   \n     # save\n     torch.save(model.state_dict(), path)\n     # load\n     model = mymodel(*args, **kwargs)\n     model.load_state_dict(torch.load(path), strict=true)\n     model.eval()\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   \n\nload_state_dict() 是 nn.module 的一个api，利用模型文件反序列化后得到的 dict 来初始化当前的模型。需要注意 strict 参数，默认值是 true。因此在初始化时候，该函数会严格比较源 dict 和目标 dict 的 key 是否完全一样。如果 strict=false，则将不会进行这样的严格检查，只有key一样的才会进行赋值。\n\n看到这里，是否好奇存储的模型文件(.pth)里都包含了什么信息？比如，模型的网络结构、model.state_dict 具体是什么内容呢... 接下来我们就看看 module 里都包含了什么吧。\n\n注意，使用 torch.nn.dataparallel 训练的模型要保存的话，最好使用 torch.save(model.module.state_dict(), path)。这样的话，在重新加载 pth模型文件 的时候，会有极大的灵活性，而不是出现一大堆 unexpected keys和missed keys\n\n\n# 2.2 网络结构\n\n# 模型\n\n我们先来看看 torch.load 网络后，得到的是什么内容：\n\n  for k in model.keys():\n    print(k)  \n\n\n1\n2\n\n\n发现加载后的模型有四个键值, 观察其中的内容，可以发现：\n\nkey         type          用途\nmodel       ordereddict   相当于 model.state_dict() 的值,\n                          存储着所有的每一层的参数名称以及对应的参数值，需要注意的是，参数名称可能很长\noptimizer   dict          相当于 optimizer.state_dict() 的值, 用途：?\nscheduler   dict          ?\niteration   int           ?\n\n注意，这里看到的是通过 torch.load 加载模型文件后得到的 dict，需要转换为具体的 model 对象才能被继续使用(继续训练 或 测试)\n\n# 结构\n\n一般我们要了解其网络结构，往往将其可视化是常用的方式。以常见的 pytorch 的 .pth 模型文件为例:\n\n * 使用 netron 可视化工具。\n   1. 安装netron：参考 github-netron\n   2. 注意, 保存网络时要保存完整结构，不能只保存参数，否则不正常工作\n * 使用 tensorwatch (微软)\n   1. 安装、使用：参考 github-tensorwatch\n   2. 功能强大：tensorwatch is under heavy development with a goal of providing a platform for debugging machine learning in one easy to use, extensible, and hackable package.\n\n另外，还可以直接使用 print(model_obj) (依靠__repr__机制)打印出模型的相关信息，组合出网络信息。\n\n\n# 2.3 成员\n\n简单的了解 pytorch 后，我们知道，所有定义的网络结构都必须要继承：torch.nn.module 类。例如，\n\n  class mymodel(nn.module):\n    def __init__(self):\n      super(mymodel, self).__init__()\n      self.my_tensor = torch.randn(1) # 模型类成员变量\n      self.register_buffer(\'my_buffer\', torch.randn(1)) # 自定义 buffer\n      # 通过两种方式定义 paramter\n      self.p1 = nn.paramter.paramter(torch.tensor(1.0))\n      print(self._parameters)\n      self.p2 = nn.paramter(torch.tensor(2.0))\n      print(self._parameters)\n      \n    def forward(self, x):\n      return x\t\n\n  model = mymodel()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n查看 torch.nn.module 类实现，会发现其包含了以下成员变量：\n\n名字                            类型            用途\n_modules                      ordereddict   可以通过 model.state_dict() 得到其中的值\n_parameters                   ordereddict   \n_buffers                      ordereddict   \n_state_dict_hooks             ordereddict   \n_load_state_dict_pre_hooks    ordereddict   \n_forward_pre_hooks            ordereddict   \n_forward_hooks                ordereddict   \n_backward_hooks               ordereddict   \n_non_persistent_buffers_set   set           \n\n# _parameters\n\n存储的值类型为：nn.parameter.paramter，也就是模型中存储的参数。一般的，它就是训练过程中需要求解的参数，也就是说需要进行反向传播。所以，它有一个特点是：默认的 requires_grad=true。\n\n这里通过一个简单的 module 来了解下 _parameters。例如，模型 torch.nn.linear 通常由 weight和bias 参数组成：\n\n  # 定义一个 module\n  fc = torch.nn.linear(2,2)\n\n  # 读取 _parameters: 方式a\n  fc._parameters\n  \n  # 读取 _parameters: 方式b\n  for n, p in fc.named_parameters():\n    pring(n, p)\n  \n  # 读取 _parameters: 方式c\n  for p in fc.parameters():\n    print(p)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n注意： 测试代码时，会发现 requires_grad 属性默认为 true。另外就是，推荐后边两种通过迭代器的方式进行读取，以避免参数非常多时，第一种方式占用过多资源。 这里提一下，weight(权重) 和 bias(偏置量) 的作用：weight 决定网络的形状，bias给网络增加平移(泛化)的能力\n\n如果运行了 mymodel 模型定义的代码，就会发现一个奇怪的现象，self.p1 和 self.p2 赋值后，模型的 _parameters 参数都会发生相应的变化(被加入到了_parameters中)，这是怎么回事呢？\n\n 1. 首先运行super(mymodel, self).init()，这样mymodel就初始化了_paramters等一系列的orderdict，此时所有变量还都是空的。\n 2. self.p1 = nn.paramter.paramter(torch.tensor(1.0)): 这行代码会触发 nn.module 预定义好的 setattr 函数。源码片段如下：\n\n  def __setattr__(self, name, value):\n    ...\n    params = self.__dict__.get(\'_parameters\')\n    if isinstance(value, parameter):\n      if params is none:\n        raise attributeerror(\n          "cannot assign parameters before module.__init__() call")\n      remove_from(self.__dict__, self._buffers, self._modules)\n      self.register_parameter(name, value)\n    ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n发现 setattr 函数的作用，简单说就是检查定义的参数类型, 如果正确就继续调用 register_parameter 函数进行注册，这个函数就更简单了，我们目前关心的就是它做了下面这件事\n\n  def register_parameter(self,name,param):\n    ...\n    self._parameters[name]=param\n    ...\n\n\n1\n2\n3\n4\n\n\n另外， setattr 还可以处理 module 类型，当 value 是 nn.module 类型时，也会进行相应的处理动作。\n\n# _buffers\n\n和 _parameters 用于反向传播不同，一般用于存储需要持久化，但又不是网络(不需要参与反向传播的)参数，使用方式：self.register_buffer(\'my_buffer\', torch.randn(1))\n\n\n# 2.4 组成\n\n在构建新的模型时，可以通过多个小模型组合形成复杂的网络模型，如：\n\n  # 主动设置 name \n  from collections import ordereddict\n  model = nn.sequential(ordereddict([ (\'conv1\', nn.conv2d(1,20,5)), (\'relu1\', nn.relu())]))\n\n  # 自动设置 name: 以在 layers 中的索引为 name\n  layers = []\n  layers.append(nn.conv2d(curr_dim, 3, kernel_size=7, stride=1, padding=3, bias=false))\n  layers.append(nn.tanh())\n  model = nn.sequential(*layers)\n\n  # 自动设置 name: 以在 layers 中的索引为 name\n  model = nn.modulelist([nn.conv2d(curr_dim, 3), nn.tanh()]))\n\n  # 查看网络结构\n  print(model)\n\n  # 查看模型的参数列表\n  params=model.state_dict() \n  for k,v in params.items():\n    print(k, v)    #打印网络的变量名、param\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n通过上文，我们知道 model.state_dict 存储了网络模型的相关参数信息，这个信息存储在 ordereddict 中，那么 key 和 value 又分别是什么呢？\n\n通过上述示例代码，我们可以查看 state_dict 的内容，这里主要说明下 key 的生成，其格式为：prefix + param_name_in_module + name + "." [ + ... ]，如果模型迭代，则继续这个格式直到最终的变量。其中，prefix 默认为 “”，name 如果没有主动声明，则默认为组合模型的 layers 中的索引.\n\n思考：如果向 layers 里添加 [nn.conv2d(), nn.conv2d()] 会怎么样？\n\n\n# 3 数据变换操作\n\n这里主要介绍下 pytorch 中 torchvision.transforms 提供的几种数据增强函数的使用。在加载数据时，可以通过指定 transforms.compose() 方便、高效的进行数据预处理。\n\n\n# 常用方法(共：5类22种)\n\n测试代码：\n\n  from torchvision import transforms\n  from pil import image\n  import torch\n  \n  img = image.open("img_path")\n  transform = transforms.compose([\n    transforms.totensor(),\n    transforms.topilimage()\n    # ... more\n  ])\n  new_img = transform(img)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n# 基础操作\n\n# transforms.totensor()\n\n# transforms.lambda()\n\n  lambd = lambda x: tf.rotate(x, 100)\n  transforms.lambda(lambd)\n\n\n1\n2\n\n\napply a user-defined lambda as a transform. 根据用户自定义的方式进行变换\n\n# transforms.topilimage()\n\n# transforms.normalize(mean, std)\n\n# 随机应用\n\n# transforms.randomapply(transforms, p=0.5)\n\n给定一定概率从一组 transformations 应用\n\n# transforms.randomchoice(transforms)\n\napply single transformation randomly picked from a list\n\n# transforms.randomorder\n\napply a list of transformations in a random order\n\n# 剪裁、填充\n\n# transforms.resize()\n\n# transforms.pad()\n\npadding_mode：填充的模式：constant, edge（填充值为边缘）, reflect (从边缘往内一个像素开始做镜像) or symmetric（从边缘做镜像）\n\n# transforms.centercrop\n\ncrops the given pil image at the center\n\n# transforms.randomcrop\n\ncrop the given pil image at a random location. 随机进行裁剪\n\n# transforms.randomresizedcrop\n\ncrop the given pil image to random size and aspect ratio. 裁剪给定的 pil 图像到随机的尺寸和长宽比。\n\n# transforms.fivecrop\n\n将给定的 pil 图像裁剪成四个角和中间的裁剪\n\n# transforms.tencrop\n\n裁剪一张图片的 4 个角以及中间得到指定大小的图片，并且进行水平翻转 / 竖直翻转 共 10 张\n\n# 仿射变换\n\n# transforms.randomhorizontalflip(p=0.5) 、transforms.randomverticalflip(p=0.5)\n\nhorizontally/vertically flip the given pil image randomly with a given probability. 按一定概率进行水平 / 竖直翻转\n\n# transforms.randomrotation\n\n一定角度旋转图像\n\n# transforms.randomaffine\n\n保持图像中心不变的随机仿射变换，可以进行随心所欲的变化\n\n# transforms.randomperspective\n\n对给定的 pil 图像以给定的概率随机进行透视变换\n\n# transforms.lineartransformation()\n\n常应用于 白化，以去除输入数据的冗余信息。假设训练数据是图像，由于图像中相邻像素之间具有很强的相关性，所以用于训练时输入是冗余的；白化的目的就是降低输入的冗余性。\n\n# 颜色相关\n\n# transforms.colorjitter\n\nrandomly change the brightness, contrast and saturation of an image. 随机改变图像的亮度、对比度和饱和度\n\n# transforms.grayscale\n\n转换图像灰度。\n\n# transforms.randomgrayscale\n\nrandomly convert image to grayscale with a probability of p (default 0.1). 以一定的概率对图像进行灰度化，转换后的图片还是 3 通道的\n\nmore docs...\n\n\n# 4 数据加载\n\npytorch 中对数据集合处理的方法集中在 torch.utils.data 包中，主要包含了以下方法：\n\nclass                                                      description                       additions\ntorch.utils.data.dataset                                   一个抽象类， 所有其他类的数据集类都应该是它的子类         其子类必须重载两个重要的函数：len(提供数据集的大小）、getitem(支持整数索引)\ntorch.utils.data.tensordataset                             封装成tensor的数据集，每一个样本都通过索引张量来获得     \ntorch.utils.data.concatdataset                             连接不同的数据集以构成更大的新数据集                \ntorch.utils.data.subset(dataset, indices)                  获取指定一个索引序列对应的子数据集                 \ntorch.utils.data.dataloader                                数据加载器, 组合了一个数据集和采样器，并提供关于数据的迭代器   \ntorch.utils.data.random_split(dataset, lengths)            按照给定的长度将数据集划分成没有重叠的新数据集组合         \n                                                                                             \ntorch.utils.data.sampler(data_source)                      所有采样的器的基类                         每个采样器子类都需要提供 iter 方-法以方便迭代器进行索引 和一个 len方法 以方便返回迭代器的长度。\ntorch.utils.data.sequentialsampler                         顺序采样样本，始终按照同一个顺序                  \ntorch.utils.data.randomsampler                             无放回地随机采样样本元素                      \ntorch.utils.data.subsetrandomsampler                       无放回地按照给定的索引列表采样样本元素               \ntorch.utils.data.weightedrandomsampler                     按照给定的概率来采样样本                      \ntorch.utils.data.batchsampler(sampler, batch_size,         在一个batch中封装一个其他的采样器               \ndrop_last)\ntorch.utils.data.distributed.distributedsampler(dataset,   采样器可以约束数据加载进数据集的子集                \nnum_replicas=none, rank=none)\n\n\n# 数据采样(划分)\n\n在进行训练时，常将用于训练的数据集分割成 8:2 两部分，一部分用于训练，另一部分用于每个 epoch 结束后的 test，以判断当前模型的收敛效果。\n\n借助上文中所述的方法，我们常用的分割方法如下：\n\n 1. random_split\n\ntrain_size = int(0.8 * len(full_dataset))\ntest_size = len(full_dataset) - train_size\ntrain_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n\n\n1\n2\n3\n\n\n这个过程的效果等同于：手动对数据索引进行shuffle后进行切分。\n\n 2. subsetrandomsampler\n\n...\n\ndataset = mycustomdataset(my_path)\nbatch_size = 16\nvalidation_split = .2\nshuffle_dataset = true\nrandom_seed= 42\n\n# creating data indices for training and validation splits:\ndataset_size = len(dataset)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]\n\n# creating pt data samplers and loaders:\ntrain_sampler = subsetrandomsampler(train_indices)\nvalid_sampler = subsetrandomsampler(val_indices)\n\ntrain_loader = torch.utils.data.dataloader(dataset, batch_size=batch_size, sampler=train_sampler)\nvalidation_loader = torch.utils.data.dataloader(dataset, batch_size=batch_size, sampler=valid_sampler)\n\n# usage example:\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    # train:   \n    for batch_index, (faces, labels) in enumerate(train_loader):\n        # ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\nmore docs...\n\n\n# 5 损失函数\n\npytorch 中常用的 loss 有：\n\nname                   describe                   feature                                                      note\nl1 loss                绝对值误差                      主要应用在回归任务                                                    \nmse loss(l2loss)       均方误差                       主要应用在回归任务                                                    \ncrossentropy loss      交叉熵                        主要应用在多分类问题中(二分类也可以用)                                         实际上它是由nn.logsoftmax()和nn.nllloss()组成\nbce loss               二分类的交叉熵(严格按照交叉熵的公式去算)      一般应用在单标签二分类和多标签二分类                                           \nbcewithlogits loss     把 sigmoid 和 bceloss 合成一步                                                                如果想用bce损失，推荐这种，不需要自己写sigmoid那部分\nmultilabelmarginloss                              用于一个样本属于多个类别时的分类任务                                           \nnllloss                负对数似然损失                    主要应用在分类任务                                                    \nsmoothl1loss           其实是l2loss和l1loss的结合        当预测值和ground truth差别较小的时候（绝对值差小于 beta）使用是l2；当差别大时，使用 l1 的平移   \nfocal loss             主要是为了解决难易样本数量不平衡           只是针对二分类问题                                                    注意，有区别于正负样本数量不平衡, 难易程度即易分程度\nghm loss               focal loss 的升级版                                                                         \n\nmore docs...\n\n\n# 6 优化器\n\npytorch 中常用的 optimizer 有：\n\nname       describe                                      good                                                          bad                    note\nsgd        随机梯度下降                                        对梯度的要求很低（计算梯度快）。而对于引入的噪声，大量的理论和实践工作证明，只要噪声不是特别大，sgd都能很好地收敛。   1.sgd在随机选择梯度的同时会引入噪声   \n                                                                                                                       2.容易陷入局部最优解\nmomentum   sgd 的升级版，使用动量的sgd，主要思想是引入一个积攒历史梯度信息动量来加速sgd   动量主要解决sgd的两个问题:                                                                      效果上类似于小球向下滚动的时候带上了惯性\n                                                         1.随机梯度的方法（引入的噪声）\n                                                         2.解决了hessian矩阵病态问题(可以理解为：sgd 在收敛过程中和正确梯度相比来回摆动比较大的问题)\nrmsprop    自适应学习率优化算法，momentum的升级版                       相对于adagrad，由于取了个加权平均，避免了学习率越来越低的的问题                                                  在经验上已经被证明是一种有效且实用的深度神经网络优化算法。目前它是深度学习从业者经常采用的优化方法之一。\nadam       自适应学习率优化算法，rmsprop 的升级版                       相比于缺少修正因子导致二阶矩估计可能在训练初期具有很高偏置的rmsprop                                                通常被认为对超参数的选择相当鲁棒。一般比rmsprop要好一点。\n\n效果如下(图片来源于互联网)：\n\n * 曲面上\n   \n * 存在鞍点的曲面\n   \n\n注意到，两个动量优化器 momentum 和 nag 以及 sgd 都顺势进入了鞍点。但两个动量优化器在鞍点抖动了一会，但最终逃离了鞍点并迅速地下降，而 sgd 却始终停留在了鞍点。\n\n在实际应用中，选择哪种优化器应结合具体问题；同时，也优化器的选择也取决于使用者对优化器的熟悉程度（比如参数的调节等等）。\n\nmore docs...\n\n\n# 7 数据标注\n\n数据标注工具：\n\nhttps://github.com/topics/annotation-tool\nhttps://github.com/mingx9527/data_label_tools\n  https://github.com/heartexlabs/label-studio\n  https://github.com/tzutalin/labelimg\n  https://github.com/jsbroks/coco-annotator\n  https://github.com/opencv/cvat\n  https://github.com/microsoft/vott\n  https://github.com/wkentaro/labelme\n  https://github.com/abreheret/pixelannotationtool\n  https://www.robots.ox.ac.uk/~vgg/software/via/\n  https://github.com/labelbox/labelbox\n  https://github.com/universaldatatool/universal-data-tool\n  https://github.com/dataturks/dataturks\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# to be continue ....\n\npytorch-lightning\n  https://pytorch-lightning.readthedocs.io/en/1.0.2/trainer.html\n  https://github.com/3017218062/pytorch-lightning-learning\n  https://blog.csdn.net/weixin_46062098/article/details/109713240\n\n\n1\n2\n3\n4\n\n\n\n# reference\n\n * github pytorch examples',charsets:{cjk:!0}},{title:"Single Image Super Resolution",frontmatter:{title:"Single Image Super Resolution",date:"2021-04-25T19:41:00.000Z",description:"超分辨率",categories:["imgproc"],tags:["SISR"],permalink:null},regularPath:"/blog/skills/ai/super_resolution.html",relativePath:"blog/skills/ai/super_resolution.md",key:"v-386d6b3f",path:"/blog/skills/ai/super_resolution.html",headers:[{level:2,title:"1. 调研",slug:"_1-调研",normalizedTitle:"1. 调研",charIndex:36},{level:2,title:"3. Reference",slug:"_3-reference",normalizedTitle:"3. reference",charIndex:1874}],headersStr:"1. 调研 3. Reference",content:"# Single Image Super Resolution\n\n\n# 1. 调研\n\ndone: 2021-04-25\n\nNAME      ATTR                                  PUBLISHED   NOTE                                                GITHUB\nvideo2x   x                                     x           只是应用框架，需要下述算法驱动                                     https://github.com/k4yt3x/video2x\nBSRGAN    x                                     2021        x                                                   https://github.com/cszn/BSRGAN\nReal-SR   相当慢，比USRNet慢很多                        2020        winner of CVPR NTIRE 2020 Challenge on Real-World   https://github.com/Tencent/Real-SR\n                                                            Super-Resolution\nUSRNet    小图片速度在秒级，效果比 RCAN 好，自测比 Real-SR 也要好   CVPR 2020   x                                                   https://github.com/cszn/USRNet\nwaifu2x   x                                     x           github 的 star 比较多                                   https://github.com/nagadomi/waifu2x/\nRCAN      x                                     ECCV 2018   x                                                   https://github.com/xinntao/BasicSR\nESRGAN    x                                     ECCV 2018   比 RCAN 更晚出现，虽然 PSNR 值比 RCAN 稍低，但视觉效果更高              https://github.com/xinntao/ESRGAN\nSRMD      x                                     x           CVPR 2018                                           https://github.com/cszn/KAIR\nAnime4K   x                                     x           non-machine-learning based                          https://github.com/bloc97/Anime4K\n\n针对模拟数据训练的SISR模型难以泛化到真实场景的问题，作者认为构建一个真实超分数据集很有必要性。通过对同一场景采用同一相机以不同的焦距采集数据的方法构建了一个真实的RealSR数据集\n\n还有很多其他的算法，比如 https://github.com/cszn/KAIR 和 https://github.com/xinntao/BasicSR 中都实现了很多其他算法...\n\n * image-super-resolution: https://github.com/idealo/image-super-resolution\n * 压缩：https://github.com/caoscott/SReC\n\n\n# 3. Reference\n\n * https://blog.csdn.net/gwplovekimi/article/details/83041627\n * https://zhuanlan.zhihu.com/p/143380729",normalizedContent:"# single image super resolution\n\n\n# 1. 调研\n\ndone: 2021-04-25\n\nname      attr                                  published   note                                                github\nvideo2x   x                                     x           只是应用框架，需要下述算法驱动                                     https://github.com/k4yt3x/video2x\nbsrgan    x                                     2021        x                                                   https://github.com/cszn/bsrgan\nreal-sr   相当慢，比usrnet慢很多                        2020        winner of cvpr ntire 2020 challenge on real-world   https://github.com/tencent/real-sr\n                                                            super-resolution\nusrnet    小图片速度在秒级，效果比 rcan 好，自测比 real-sr 也要好   cvpr 2020   x                                                   https://github.com/cszn/usrnet\nwaifu2x   x                                     x           github 的 star 比较多                                   https://github.com/nagadomi/waifu2x/\nrcan      x                                     eccv 2018   x                                                   https://github.com/xinntao/basicsr\nesrgan    x                                     eccv 2018   比 rcan 更晚出现，虽然 psnr 值比 rcan 稍低，但视觉效果更高              https://github.com/xinntao/esrgan\nsrmd      x                                     x           cvpr 2018                                           https://github.com/cszn/kair\nanime4k   x                                     x           non-machine-learning based                          https://github.com/bloc97/anime4k\n\n针对模拟数据训练的sisr模型难以泛化到真实场景的问题，作者认为构建一个真实超分数据集很有必要性。通过对同一场景采用同一相机以不同的焦距采集数据的方法构建了一个真实的realsr数据集\n\n还有很多其他的算法，比如 https://github.com/cszn/kair 和 https://github.com/xinntao/basicsr 中都实现了很多其他算法...\n\n * image-super-resolution: https://github.com/idealo/image-super-resolution\n * 压缩：https://github.com/caoscott/srec\n\n\n# 3. reference\n\n * https://blog.csdn.net/gwplovekimi/article/details/83041627\n * https://zhuanlan.zhihu.com/p/143380729",charsets:{cjk:!0}},{title:"docker 基础知识",frontmatter:{title:"docker 基础知识",date:"2019-12-18T00:00:00.000Z",lastmod:null,description:"docker 基础知识汇总，以及常见操作",categories:["skills","devops"],tags:[null],permalink:null},regularPath:"/blog/skills/devops/docker-base.html",relativePath:"blog/skills/devops/docker-base.md",key:"v-0e5e6773",path:"/blog/skills/devops/docker-base.html",headers:[{level:2,title:"配置源",slug:"配置源",normalizedTitle:"配置源",charIndex:67},{level:2,title:"dockerfile",slug:"dockerfile",normalizedTitle:"dockerfile",charIndex:278},{level:2,title:"多阶段构建",slug:"多阶段构建",normalizedTitle:"多阶段构建",charIndex:4153},{level:2,title:"数据管理",slug:"数据管理",normalizedTitle:"数据管理",charIndex:4163},{level:2,title:"Docker 三剑客",slug:"docker-三剑客",normalizedTitle:"docker 三剑客",charIndex:5263},{level:2,title:"Docker 底层实现",slug:"docker-底层实现",normalizedTitle:"docker 底层实现",charIndex:5850},{level:2,title:"operations",slug:"operations",normalizedTitle:"operations",charIndex:5898},{level:2,title:"容器",slug:"容器",normalizedTitle:"容器",charIndex:29}],headersStr:"配置源 dockerfile 多阶段构建 数据管理 Docker 三剑客 Docker 底层实现 operations 容器",content:'# Docker 基础使用指南\n\n镜像（ Image ）、容器 （ Container ）、仓库（ Repository ）\n\n\n# 配置源\n\n * 配置国内image 下载源\n   * vi /etc/docker/daemon.json\n   \n       {\n           "registry-mirrors": [\n               "https://registry.docker-cn.com"\n           ]\n       }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   \n\n\n# dockerfile\n\n * 常用命令\n   * COPY\n     * 格式: COPY [--chown=<user>:<group>] <源路径>... <目标路径>\n   * ADD\n     * ADD 和 COPY 的格式和性质基本一致，但是在 COPY 基础上增加了一些功能。\n     * 在 COPY 和 ADD 中选择时，可以遵循这样的原则：复制均使用 COPY，仅在需要自动解压的场合使用 ADD。\n     * 注意：ADD 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。\n     \n         ADD [--chown=<user>:<group>] <源路径>... <目标路径>\n     \n     \n     1\n     \n   * RUN\n     * 每一个 RUN 都是启动一个容器、执行命令、然后提交存储层文件变更\n   * CMD\n     * CMD 用于指定默认的容器主进程的启动命令，指令的格式和 RUN 相似，也是两种格式：\n       * shell 格式：CMD <命令>\n         * 这种格式下，实际的命令会被包装为 sh -c 的参数的形式进行执行。即，CMD [ "sh", "-c", <命令> ]\n       * exec 格式：CMD ["可执行文件", "参数1", "参数2"...]\n         * 这种格式下，当同时指定了 ENTRYPOINT 指令时，相当于将 CMD 的内容作为参数传给 ENTRYPOINT 指令\n     * docker run 执行时，跟在镜像名后面的是 command，运行时会替换 CMD 的默认值。\n     * 启动容器就是启动容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出。\n       \n           例如：dockerfile 中: CMD service nginx start 是起不到预期(真机中一样的)作用的。\n       \n           使用 service nginx start 命令，则是希望 upstart 来以后台守护进程形式启动 nginx 服务。然而实际执行的是：CMD [ "sh", "-c", "service nginx start"]，因此主进程实际上是 sh。那么当 service nginx start 命令结束后，sh 作为主进程退出了，容器自然就退出。\n       \n           正确的做法是直接执行 nginx 可执行文件，并且要求以前台形式运行。比如：CMD ["nginx", "-g", "daemon off;"]\n       \n       \n       1\n       2\n       3\n       4\n       5\n       \n   * ENTRYPOINT 入口点\n     * 目的和 CMD 一样，都是指定容器启动程序及参数。\n     * ENTRYPOINT 在运行时也可以替代，不过比 CMD 要略显繁琐，需要通过 docker run 的参数 --entrypoint 来指定\n     * 使用场景\n       * 让镜像变成像命令一样使用\n         * 需要 dockerfile 中指定的启动命令，能够像普通命令一样接收运行时指定的额外参数\n       * 应用运行前的准备工作\n         * 将预处理工作写成脚本，然后放入 ENTRYPOINT 中去执行，而这个脚本会将接到的参数(也就是 CMD)作为命令，在脚本最后执行。比如官方镜像 redis 中就是这么做的。\n     * reference:\n       * ENTRYPOINT 入口点\n   * ENV 设置环境变量\n     * 格式有两种：\n       \n           ENV <key> <value>\n           ENV <key1>=<value1> <key2>=<value2>...\n       \n       \n       1\n       2\n       \n   * WORKDIR 指定工作目录\n     * 格式: WORKDIR <工作目录路径>\n     * 作用\n       * 改变工作目录并影响以后的层\n   * USER 指定当前用户\n     * 格式: USER <用户名>[:<用户组>]\n     * 作用\n       * USER 和 WORKDIR 相似，都是改变环境状态并影响以后的层。WORKDIR 是改变工作目录，USER 则是改变之后层执行 RUN, CMD 以及 ENTRYPOINT 这类命令的身份\n   * ARG 构建参数\n     * 格式: ARG <参数名>[=<默认值>]\n   * VOLUME 定义匿名卷\n     * 会在运行时自动挂载为匿名卷, 格式为：\n       \n           VOLUME ["<路径1>", "<路径2>"...]\n           VOLUME <路径>\n       \n       \n       1\n       2\n       \n     * note\n       * 当自动挂载匿名卷时，会在宿主机的 /var/lib/docker/volumes/ 随机配置一个目录，映射到容器内(VOLUME声明)的挂载路径\n       * 运行时可以覆盖这个挂载设置:\n         \n         将宿主的 /tmp/data 映射到容器的 /data\n             docker run -d -v /tmp/data:/data xxxx\n         \n         \n         1\n         2\n         \n   * EXPOSE 声明端口\n     * 格式: EXPOSE <端口1> [<端口2>...]\n     * 此指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。\n     * 作用\n       * 在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。\n       * 例如：\n         \n         expose:\n             - "3000"        # 在启动容器时通过-P(注意是大写)，Docker主机会自动分配一个端口转发到指定的3000端口\n                             # 或者，使用 -p 则可以具体指定哪个本地端口映射过来。\n         \n         \n         1\n         2\n         3\n         \n   * PORTS\n     \n     ports:\n         - "8000:80"     # 绑定容器的80端口到主机的8000端口\n         - "443"         # 绑定容器的443端口到主机的任意端口，容器启动时随机分配绑定的主机端口号\n     \n     \n     1\n     2\n     3\n     \n   * HEALTHCHECK 健康检查\n     * 格式\n       \n           HEALTHCHECK [选项] CMD <命令>：设置检查容器健康状况的命令\n           HEALTHCHECK NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令\n       \n           HEALTHCHECK 支持下列选项：\n               --interval=<间隔>：两次健康检查的间隔，默认为 30 秒；\n               --timeout=<时长>：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒；\n               --retries=<次数>：当连续失败指定次数后，则将容器状态视为 unhealthy，默认 3 次。\n       \n       \n       1\n       2\n       3\n       4\n       5\n       6\n       7\n       \n     * 作用\n       * 当在一个镜像指定了 HEALTHCHECK 指令后，用其启动容器，初始状态会为 starting，在 HEALTHCHECK 指令检查成功后变为 healthy，如果连续一定次数失败，则会变为 unhealthy\n     * note\n       * 在 HEALTHCHECK [选项] CMD 后面的命令，格式和 ENTRYPOINT 一样，分为 shell 和 exec 格式。命令的返回值标识健康检查是否成功：0：成功；1：失败；2：保留，不要使用这个值。\n       * 和 CMD, ENTRYPOINT 一样，HEALTHCHECK 只可以出现一次，如果写了多个，只有最后一个生效。\n\n\n# 多阶段构建\n\n\n# 数据管理\n\n# 数据卷\n\n * 定义\n   * 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性:\n     * 数据卷 可以在容器之间共享和重用\n     * 对 数据卷 的修改会立马生效\n     * 对 数据卷 的更新，不会影响镜像\n     * 数据卷 默认会一直存在，即使容器被删除\n * 常用命令\n   \n       docker volume create my-vol\n       docker volume ls\n       docker volume inspect my-vol\n       docker volume rm my-vol\n       docker run -d -P --name web -v my-vol:/wepapp training/webapp python app.py\n       docker run -d -P --name web --mount source=my-vol,target=/webapp training/webapp python app.py\n       \n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   \n * 说明\n   * 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。\n   * 如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。\n   * 无主的数据卷可能会占据很多空间，要清理请使用以下命令: docker volume prune\n\n# 挂载主机目录\n\n * 使用 --mount 标记可以指定挂载一个本地主机的目录(必须是绝对路径)到容器中去\n * -v && --mount\n   * 使用 -v 参数时, 如果本地目录不存在 Docker 会自动为你创建一个文件夹\n   * 使用 --mount 参数时, 如果本地目录不存在，Docker 会报错\n * Docker 挂载主机目录的默认权限是 读写，用户也可以通过增加 readonly 指定为 只读\n   \n     -v /src/webapp:/opt/webapp:ro\n     --mount type=bind,source=/src/webapp,target=/opt/webapp,readonly \n   \n   \n   1\n   2\n   \n\n\n# Docker 三剑客\n\n# Docker Compose\n\n * 定位\n   * Compose 定位是 定义和运行多个 Docker 容器的应用。它允许用户通过一个单独的 docker-compose.yml 模板文件来定义一组相关联的应用容器为一个项目(project)\n   * Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理\n * Compose 中两个重要的概念：\n   * 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。\n   * 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。\n * 命令\n   * docker-compose\n\n# Docker Machine\n\n * 定位\n   * 负责在多种平台上快速安装 Docker 环境。Docker Machine 项目基于 Go 语言实现，目前在 Github 上进行维护。\n\n# Docker Swarm\n\n * 定位\n   * 提供 Docker 容器集群服务，是 Docker 官方对容器云生态进行支持的核心方案。\n   * 使用它，用户可以将多个 Docker 主机封装为单个大型的虚拟 Docker 主机，快速打造一套容器云平台。\n\n\n# Docker 底层实现\n\n * TODO\n * reference\n   * 底层实现\n\n\n# operations\n\n//> delete\ndocker rm $(docker ps -q -a) \ndocker rmi $(docker images -q) \n\n//> create and run container\ndocker run -itd --hostname [x] --name [x] [image_id] /bin/bash\n\n//> create and run container and mount shared directory\ndocker run -it --hostname [x] --name [x] -v [absolute path in host]:[absolute path in docker][:ro] [image] /bin/bash\n//> create and run container having shared directory based on \'--volumes-from\'\ndocker run -it --hostname [x] --name [x] --volumes-from [container_id with \'-v\'] [image] /bin/bash\n\n//> net\ndocker run -it -h centos.xxx.docker -v /home/centos:/shared -w /home/xxx --net host --name xxx  centos6.7 /bin/bash\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# 容器\n\n什么是容器？ 在介绍容器的具体概念之前，先简单回顾一下操作系统是如何管理进程的。\n\n首先，当我们登录到操作系统之后，可以通过 ps 等操作看到各式各样的进程，这些进程包括系统自带的服务和用户的应用进程。那么，这些进程都有什么样的特点？\n\n * 第一，这些进程可以相互看到、相互通信；\n * 第二，它们使用的是同一个文件系统，可以对同一个文件进行读写操作；\n * 第三，这些进程会使用相同的系统资源。\n\n这样的三个特点会带来什么问题呢？\n\n * 因为这些进程能够相互看到并且进行通信，高级权限的进程可以攻击其他进程；\n * 因为它们使用的是同一个文件系统，因此会带来两个问题：这些进程可以对于已有的数据进行增删改查，具有高级权限的进程可能会将其他进程的数据删除掉，破坏掉其他进程的正常运行；此外，进程与进程之间的依赖可能会存在冲突，如此一来就会给运维带来很大的压力；\n * 因为这些进程使用的是同一个宿主机的资源，应用之间可能会存在资源抢占的问题，当一个应用需要消耗大量 CPU 和内存资源的时候，就可能会破坏其他应用的运行，导致其他应用无法正常地提供服务。\n\n针对上述的三个问题，如何为进程提供一个独立的运行环境呢？\n\n * 针对不同进程使用同一个文件系统所造成的问题而言，Linux 和 Unix 操作系统可以通过 chroot 系统调用将子目录变成根目录，达到视图级别的隔离；进程在 chroot 的帮助下可以具有独立的文件系统，对于这样的文件系统进行增删改查不会影响到其他进程；\n * 因为进程之间相互可见并且可以相互通信，使用 Namespace 技术来实现进程在资源的视图上进行隔离。在 chroot 和 Namespace 的帮助下，进程就能够运行在一个独立的环境下了；\n * 但在独立的环境下，进程所使用的还是同一个操作系统的资源，一些进程可能会侵蚀掉整个系统的资源。为了减少进程彼此之间的影响，可以通过 Cgroup 来限制其资源使用率，设置其能够使用的 CPU 以及内存量。\n\n那么，应该如何定义这样的进程集合呢？\n\n其实，容器就是一个视图隔离、资源可限制、独立文件系统的进程集合。所谓“视图隔离”就是能够看到部分进程以及具有独立的主机名等；控制资源使用率则是可以对于内存大小以及 CPU 使用个数等进行限制。容器就是一个进程集合，它将系统的其他资源隔离开来，具有自己独立的资源视图。\n\n容器具有一个独立的文件系统，因为使用的是系统的资源，所以在独立的文件系统内不需要具备内核相关的代码或者工具，我们只需要提供容器所需的二进制文件、配置文件以及依赖即可。只要容器运行时所需的文件集合都能够具备，那么这个容器就能够运行起来。\n\n综上所述，我们将这些容器运行时所需要的所有的文件集合称之为容器镜像。',normalizedContent:'# docker 基础使用指南\n\n镜像（ image ）、容器 （ container ）、仓库（ repository ）\n\n\n# 配置源\n\n * 配置国内image 下载源\n   * vi /etc/docker/daemon.json\n   \n       {\n           "registry-mirrors": [\n               "https://registry.docker-cn.com"\n           ]\n       }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   \n\n\n# dockerfile\n\n * 常用命令\n   * copy\n     * 格式: copy [--chown=<user>:<group>] <源路径>... <目标路径>\n   * add\n     * add 和 copy 的格式和性质基本一致，但是在 copy 基础上增加了一些功能。\n     * 在 copy 和 add 中选择时，可以遵循这样的原则：复制均使用 copy，仅在需要自动解压的场合使用 add。\n     * 注意：add 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。\n     \n         add [--chown=<user>:<group>] <源路径>... <目标路径>\n     \n     \n     1\n     \n   * run\n     * 每一个 run 都是启动一个容器、执行命令、然后提交存储层文件变更\n   * cmd\n     * cmd 用于指定默认的容器主进程的启动命令，指令的格式和 run 相似，也是两种格式：\n       * shell 格式：cmd <命令>\n         * 这种格式下，实际的命令会被包装为 sh -c 的参数的形式进行执行。即，cmd [ "sh", "-c", <命令> ]\n       * exec 格式：cmd ["可执行文件", "参数1", "参数2"...]\n         * 这种格式下，当同时指定了 entrypoint 指令时，相当于将 cmd 的内容作为参数传给 entrypoint 指令\n     * docker run 执行时，跟在镜像名后面的是 command，运行时会替换 cmd 的默认值。\n     * 启动容器就是启动容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出。\n       \n           例如：dockerfile 中: cmd service nginx start 是起不到预期(真机中一样的)作用的。\n       \n           使用 service nginx start 命令，则是希望 upstart 来以后台守护进程形式启动 nginx 服务。然而实际执行的是：cmd [ "sh", "-c", "service nginx start"]，因此主进程实际上是 sh。那么当 service nginx start 命令结束后，sh 作为主进程退出了，容器自然就退出。\n       \n           正确的做法是直接执行 nginx 可执行文件，并且要求以前台形式运行。比如：cmd ["nginx", "-g", "daemon off;"]\n       \n       \n       1\n       2\n       3\n       4\n       5\n       \n   * entrypoint 入口点\n     * 目的和 cmd 一样，都是指定容器启动程序及参数。\n     * entrypoint 在运行时也可以替代，不过比 cmd 要略显繁琐，需要通过 docker run 的参数 --entrypoint 来指定\n     * 使用场景\n       * 让镜像变成像命令一样使用\n         * 需要 dockerfile 中指定的启动命令，能够像普通命令一样接收运行时指定的额外参数\n       * 应用运行前的准备工作\n         * 将预处理工作写成脚本，然后放入 entrypoint 中去执行，而这个脚本会将接到的参数(也就是 cmd)作为命令，在脚本最后执行。比如官方镜像 redis 中就是这么做的。\n     * reference:\n       * entrypoint 入口点\n   * env 设置环境变量\n     * 格式有两种：\n       \n           env <key> <value>\n           env <key1>=<value1> <key2>=<value2>...\n       \n       \n       1\n       2\n       \n   * workdir 指定工作目录\n     * 格式: workdir <工作目录路径>\n     * 作用\n       * 改变工作目录并影响以后的层\n   * user 指定当前用户\n     * 格式: user <用户名>[:<用户组>]\n     * 作用\n       * user 和 workdir 相似，都是改变环境状态并影响以后的层。workdir 是改变工作目录，user 则是改变之后层执行 run, cmd 以及 entrypoint 这类命令的身份\n   * arg 构建参数\n     * 格式: arg <参数名>[=<默认值>]\n   * volume 定义匿名卷\n     * 会在运行时自动挂载为匿名卷, 格式为：\n       \n           volume ["<路径1>", "<路径2>"...]\n           volume <路径>\n       \n       \n       1\n       2\n       \n     * note\n       * 当自动挂载匿名卷时，会在宿主机的 /var/lib/docker/volumes/ 随机配置一个目录，映射到容器内(volume声明)的挂载路径\n       * 运行时可以覆盖这个挂载设置:\n         \n         将宿主的 /tmp/data 映射到容器的 /data\n             docker run -d -v /tmp/data:/data xxxx\n         \n         \n         1\n         2\n         \n   * expose 声明端口\n     * 格式: expose <端口1> [<端口2>...]\n     * 此指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。\n     * 作用\n       * 在运行时使用随机端口映射时，也就是 docker run -p 时，会自动随机映射 expose 的端口。\n       * 例如：\n         \n         expose:\n             - "3000"        # 在启动容器时通过-p(注意是大写)，docker主机会自动分配一个端口转发到指定的3000端口\n                             # 或者，使用 -p 则可以具体指定哪个本地端口映射过来。\n         \n         \n         1\n         2\n         3\n         \n   * ports\n     \n     ports:\n         - "8000:80"     # 绑定容器的80端口到主机的8000端口\n         - "443"         # 绑定容器的443端口到主机的任意端口，容器启动时随机分配绑定的主机端口号\n     \n     \n     1\n     2\n     3\n     \n   * healthcheck 健康检查\n     * 格式\n       \n           healthcheck [选项] cmd <命令>：设置检查容器健康状况的命令\n           healthcheck none：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令\n       \n           healthcheck 支持下列选项：\n               --interval=<间隔>：两次健康检查的间隔，默认为 30 秒；\n               --timeout=<时长>：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒；\n               --retries=<次数>：当连续失败指定次数后，则将容器状态视为 unhealthy，默认 3 次。\n       \n       \n       1\n       2\n       3\n       4\n       5\n       6\n       7\n       \n     * 作用\n       * 当在一个镜像指定了 healthcheck 指令后，用其启动容器，初始状态会为 starting，在 healthcheck 指令检查成功后变为 healthy，如果连续一定次数失败，则会变为 unhealthy\n     * note\n       * 在 healthcheck [选项] cmd 后面的命令，格式和 entrypoint 一样，分为 shell 和 exec 格式。命令的返回值标识健康检查是否成功：0：成功；1：失败；2：保留，不要使用这个值。\n       * 和 cmd, entrypoint 一样，healthcheck 只可以出现一次，如果写了多个，只有最后一个生效。\n\n\n# 多阶段构建\n\n\n# 数据管理\n\n# 数据卷\n\n * 定义\n   * 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 ufs，可以提供很多有用的特性:\n     * 数据卷 可以在容器之间共享和重用\n     * 对 数据卷 的修改会立马生效\n     * 对 数据卷 的更新，不会影响镜像\n     * 数据卷 默认会一直存在，即使容器被删除\n * 常用命令\n   \n       docker volume create my-vol\n       docker volume ls\n       docker volume inspect my-vol\n       docker volume rm my-vol\n       docker run -d -p --name web -v my-vol:/wepapp training/webapp python app.py\n       docker run -d -p --name web --mount source=my-vol,target=/webapp training/webapp python app.py\n       \n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   \n * 说明\n   * 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。\n   * 如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。\n   * 无主的数据卷可能会占据很多空间，要清理请使用以下命令: docker volume prune\n\n# 挂载主机目录\n\n * 使用 --mount 标记可以指定挂载一个本地主机的目录(必须是绝对路径)到容器中去\n * -v && --mount\n   * 使用 -v 参数时, 如果本地目录不存在 docker 会自动为你创建一个文件夹\n   * 使用 --mount 参数时, 如果本地目录不存在，docker 会报错\n * docker 挂载主机目录的默认权限是 读写，用户也可以通过增加 readonly 指定为 只读\n   \n     -v /src/webapp:/opt/webapp:ro\n     --mount type=bind,source=/src/webapp,target=/opt/webapp,readonly \n   \n   \n   1\n   2\n   \n\n\n# docker 三剑客\n\n# docker compose\n\n * 定位\n   * compose 定位是 定义和运行多个 docker 容器的应用。它允许用户通过一个单独的 docker-compose.yml 模板文件来定义一组相关联的应用容器为一个项目(project)\n   * compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理\n * compose 中两个重要的概念：\n   * 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。\n   * 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。\n * 命令\n   * docker-compose\n\n# docker machine\n\n * 定位\n   * 负责在多种平台上快速安装 docker 环境。docker machine 项目基于 go 语言实现，目前在 github 上进行维护。\n\n# docker swarm\n\n * 定位\n   * 提供 docker 容器集群服务，是 docker 官方对容器云生态进行支持的核心方案。\n   * 使用它，用户可以将多个 docker 主机封装为单个大型的虚拟 docker 主机，快速打造一套容器云平台。\n\n\n# docker 底层实现\n\n * todo\n * reference\n   * 底层实现\n\n\n# operations\n\n//> delete\ndocker rm $(docker ps -q -a) \ndocker rmi $(docker images -q) \n\n//> create and run container\ndocker run -itd --hostname [x] --name [x] [image_id] /bin/bash\n\n//> create and run container and mount shared directory\ndocker run -it --hostname [x] --name [x] -v [absolute path in host]:[absolute path in docker][:ro] [image] /bin/bash\n//> create and run container having shared directory based on \'--volumes-from\'\ndocker run -it --hostname [x] --name [x] --volumes-from [container_id with \'-v\'] [image] /bin/bash\n\n//> net\ndocker run -it -h centos.xxx.docker -v /home/centos:/shared -w /home/xxx --net host --name xxx  centos6.7 /bin/bash\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# 容器\n\n什么是容器？ 在介绍容器的具体概念之前，先简单回顾一下操作系统是如何管理进程的。\n\n首先，当我们登录到操作系统之后，可以通过 ps 等操作看到各式各样的进程，这些进程包括系统自带的服务和用户的应用进程。那么，这些进程都有什么样的特点？\n\n * 第一，这些进程可以相互看到、相互通信；\n * 第二，它们使用的是同一个文件系统，可以对同一个文件进行读写操作；\n * 第三，这些进程会使用相同的系统资源。\n\n这样的三个特点会带来什么问题呢？\n\n * 因为这些进程能够相互看到并且进行通信，高级权限的进程可以攻击其他进程；\n * 因为它们使用的是同一个文件系统，因此会带来两个问题：这些进程可以对于已有的数据进行增删改查，具有高级权限的进程可能会将其他进程的数据删除掉，破坏掉其他进程的正常运行；此外，进程与进程之间的依赖可能会存在冲突，如此一来就会给运维带来很大的压力；\n * 因为这些进程使用的是同一个宿主机的资源，应用之间可能会存在资源抢占的问题，当一个应用需要消耗大量 cpu 和内存资源的时候，就可能会破坏其他应用的运行，导致其他应用无法正常地提供服务。\n\n针对上述的三个问题，如何为进程提供一个独立的运行环境呢？\n\n * 针对不同进程使用同一个文件系统所造成的问题而言，linux 和 unix 操作系统可以通过 chroot 系统调用将子目录变成根目录，达到视图级别的隔离；进程在 chroot 的帮助下可以具有独立的文件系统，对于这样的文件系统进行增删改查不会影响到其他进程；\n * 因为进程之间相互可见并且可以相互通信，使用 namespace 技术来实现进程在资源的视图上进行隔离。在 chroot 和 namespace 的帮助下，进程就能够运行在一个独立的环境下了；\n * 但在独立的环境下，进程所使用的还是同一个操作系统的资源，一些进程可能会侵蚀掉整个系统的资源。为了减少进程彼此之间的影响，可以通过 cgroup 来限制其资源使用率，设置其能够使用的 cpu 以及内存量。\n\n那么，应该如何定义这样的进程集合呢？\n\n其实，容器就是一个视图隔离、资源可限制、独立文件系统的进程集合。所谓“视图隔离”就是能够看到部分进程以及具有独立的主机名等；控制资源使用率则是可以对于内存大小以及 cpu 使用个数等进行限制。容器就是一个进程集合，它将系统的其他资源隔离开来，具有自己独立的资源视图。\n\n容器具有一个独立的文件系统，因为使用的是系统的资源，所以在独立的文件系统内不需要具备内核相关的代码或者工具，我们只需要提供容器所需的二进制文件、配置文件以及依赖即可。只要容器运行时所需的文件集合都能够具备，那么这个容器就能够运行起来。\n\n综上所述，我们将这些容器运行时所需要的所有的文件集合称之为容器镜像。',charsets:{cjk:!0}},{title:"k8s-ipvs连接保持",frontmatter:{title:"k8s-ipvs连接保持",date:"2019-10-15T00:00:00.000Z",description:"k8s ipvs recorder",categories:["skills","devops"],tags:[null],permalink:null},regularPath:"/blog/skills/devops/ipvs_in_k8s.html",relativePath:"blog/skills/devops/ipvs_in_k8s.md",key:"v-35163721",path:"/blog/skills/devops/ipvs_in_k8s.html",headers:[{level:2,title:"IPVS 在 k8s 中连接保持引发的问题：",slug:"ipvs-在-k8s-中连接保持引发的问题",normalizedTitle:"ipvs 在 k8s 中连接保持引发的问题：",charIndex:2},{level:3,title:"起因",slug:"起因",normalizedTitle:"起因",charIndex:29},{level:3,title:"初步确认",slug:"初步确认",normalizedTitle:"初步确认",charIndex:264},{level:3,title:"知识点准备",slug:"知识点准备",normalizedTitle:"知识点准备",charIndex:446},{level:3,title:"关键点",slug:"关键点",normalizedTitle:"关键点",charIndex:2414},{level:3,title:"扩展",slug:"扩展",normalizedTitle:"扩展",charIndex:3008}],headersStr:"IPVS 在 k8s 中连接保持引发的问题： 起因 初步确认 知识点准备 关键点 扩展",content:"# IPVS 在 k8s 中连接保持引发的问题：\n\n\n# 起因\n\n在将业务(小部分长连接)迁移至k8s集群时, 项目能够平稳运行, 但是在测试环境发布时却经常遇到：刚刚发布成功后的1分钟左右，websocket连接出现：504 bad handshake。\n\n这一错误引起了我们的注意：因为在做k8s部署时是通过配置 readiness 来保证服务正常可访问。同时, 遇到问题的这一服务 svcA 是单实例部署。\n\nk8s 版本大于 1.8 时，默认采用的 ipvs。我们的集群 k8s 的底层负载采用的是 ipvs。\n\n\n# 初步确认\n\n遇到问题后, 先确认了通过lb访问、在集群内通过nodeport访问 以及 直接cluster ip访问是否正常。经确认，集群内通过nodeport不能正常访问, 直接cluster ip正常。此时可以将问题缩小到 ipvs 路由相关的内容。\n\n经腾讯运维同学提醒，我们注意到 ipvs 的一个配置参数：persistence_timeout\n\n\n# 知识点准备\n\n * ipvs 工作模型\n   * LVS DR原理详解图\n     * \n   * LVS FULLNAT模式\n     * \n   * LVS NAT原理详解图\n     * \n   * LVS TUN原理\n     * \n * 连接保持：\n   * lvs-persistent-connection\n * ipvs:\n   * ipvs 通过ipvsadm命令和LVS内核打交道\n   * 参数配置：\n     \n         配置全局参数，位于目录/proc/sys/net/ipv4/vs/下:\n         获取统计信息，位于目录/proc/net/下:\n     \n     \n     1\n     2\n     \n     * /proc/net/ip_vs\n       * 获取当前LVS内核配置，包括VS和RS相关信息；同ipvsadm -ln；\n       \n           IP Virtual Server version 1.2.1 (size=1048576) - 这里size是指连接hash表大小；\n           Prot LocalAddress:Port Scheduler Flags\n               -> RemoteAddress:Port Forward Weight ActiveConn InActConn\n           TCP 0ADC0108:0050 rr - vs信息，vip和vport 16进制，调度算法rr；\n               -> C0A8010B:0050 Route 1 0 0 - rs信息，rip和rport 16进制，权值为1，\n               -> C0A8010A:0050 Route 1 0 0 \n       \n           - ActiveConn是指established状态的连接个数；\n           - InActConn是指非established状态的连接个数；\n       \n       \n       1\n       2\n       3\n       4\n       5\n       6\n       7\n       8\n       9\n       \n     * /proc/net/ip_vs_conn\n       * 获取所有连接信息，建议不要用该命令，因为连接数很多时，CPU开销会很大；\n       \n           Pro FromIP FPrt ToIP TPrt DestIP DPrt State Expires\n           - 用户ip和port vs ip和port rs ip和port tcp状态机状态 连接超时剩余的时间\n       \n       \n       1\n       2\n       \n     * /proc/net/ip_vs_stats\n     * /proc/sys/net/ipv4/vs/expire_nodest_conn\n       * 默认值为0，当LVS转发数据包，发现目的RS无效（删除）时，会丢弃该数据包，但不删除相应连接；这样设计的考虑是，RS恢复时，如果Client和RS socket还没有超时，则 可以继续通讯;\n       * 如果将该参数置1，则马上释放相应 连接；个人建议采用默认值，配置为0；\n     * /proc/sys/net/ipv4/vs/expire_quiescent_template\n       * 默认值为0，当RS的weight值=0（如，健康检测失败，应用程序将RS weight置0）时，会话保持的新建连接 还会继续调度到该RS上；\n       * 如果配置为1，则马上将 会话保持的连接模板 置为无效，重新调度新的RS；如果有会话保持的业务，建议该值 配置为1；\n     * /proc/sys/net/ipv4/vs/nat_icmp_send\n       * 默认值为0；建议采用默认值，为0；\n       * 如果置为1，当LVS收到RS发送出来的数据包，但没有找到相应连接时，则发送目的不可达（端口不可达）的ICMP给RS；\n     * /proc/sys/net/ipv4/vs/sync_threshold\n       * 默认值为 3 50；\n       * 这个参数和连接同步相关，LVS收到3个包后，开始启动同步；之后，每收到50个包，启动一次同步；可以根据LVS的流量，可以调整连接同步的频率，从而控制同步的系统开销；\n\n\n# 关键点\n\n在问题发生时，通过 ipvsadm -Ln | grep 10.111.103.161 -A3 查看ipvs路由表发现，已经无效的pod的rip依然存在，只不过weight=0。\n\n联系上述的相关配置会发现，当服务发布时，先将新pod创建并注册rip到ipvs，再将旧pod删除，，但是但是，，旧pod删除时不是应该把对应的rip删除掉吗？\n\n当旧pod删除时，已有连接被断开，客户端触发重连机制，但因为ipvs的连接保持特性，会依然路由到旧pod对应的rip(虽然此时weight为0)。这就是问题的根源~\n\n持久连接（Persistence）的问题。持久连接使一个客户端在超时时间内（ipvsadmin -p参数指定，keepalived的配置文件persistence_timeout指令）会持续连接到同一台后端服务器\n\n深究发现：1.12 的kube-proxy更改了实现：ipvs 下如果有 conn 存在就不删除 rip，只是将其权重设置为0\n\n * 解决方案\n   \n   * 将参数 /proc/sys/net/ipv4/vs/expire_quiescent_template 设置为 1\n\n * 注意\n   \n   * 之所以不调整 persistence_timeout 是因为，ftp 以及 ssl 等会依赖此特性，详见：persistence\n\n\n# 扩展\n\n * k8s 中的 ipvs 是 NAT 模式\n   * ipvs 是一个内核态的四层负载均衡，支持NAT、Gateway以及IPIP隧道模式，Gateway模式性能最好，但LB和RS不能跨子网，IPIP性能次之，通过ipip隧道解决跨网段传输问题，因此能够支持跨子网。而NAT模式没有限制，这也是唯一一种支持端口映射的模式。\n   * 由于 Kubernetes Service 需要使用端口映射功能，因此kube-proxy必然只能使用ipvs的NAT模式。\n * k8s 中为了流量能原路返回：\n   * 由于 ipvs 的 NAT 模式是 dnat，不做snat，所以需要跟iptables配合，增加snat\n     \n         -A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000\n     \n     \n     1\n     \n   * k8s 的 snat 是在 mangle 表的 POSTROUTING 链上进行的，一般来说，需要开启以下参数，才能实现这一功能：\n     \n         sysctl net.ipv4.vs.conntrack=1\n     \n     \n     1\n     \n * ipvs是dnat，不做snat，所以如果单纯使用ipvs，会话负载均衡是可以的; 但是，k8s使用ipvs，必须跟iptables配合，还得加多个snat，这样对于ipvs来说，所有的来源ip就变成一样的了，使用会话负载均衡是否就有问题了呢？ + 不会，因为，ipvs 工作在 PREROUTING 上，而 snat 发生在 POSTROUTING 链上\n * svc有个参数 ExternalTrafficPolicy 设置为 local 时，可以避免 k8s 的跨节点路由",normalizedContent:"# ipvs 在 k8s 中连接保持引发的问题：\n\n\n# 起因\n\n在将业务(小部分长连接)迁移至k8s集群时, 项目能够平稳运行, 但是在测试环境发布时却经常遇到：刚刚发布成功后的1分钟左右，websocket连接出现：504 bad handshake。\n\n这一错误引起了我们的注意：因为在做k8s部署时是通过配置 readiness 来保证服务正常可访问。同时, 遇到问题的这一服务 svca 是单实例部署。\n\nk8s 版本大于 1.8 时，默认采用的 ipvs。我们的集群 k8s 的底层负载采用的是 ipvs。\n\n\n# 初步确认\n\n遇到问题后, 先确认了通过lb访问、在集群内通过nodeport访问 以及 直接cluster ip访问是否正常。经确认，集群内通过nodeport不能正常访问, 直接cluster ip正常。此时可以将问题缩小到 ipvs 路由相关的内容。\n\n经腾讯运维同学提醒，我们注意到 ipvs 的一个配置参数：persistence_timeout\n\n\n# 知识点准备\n\n * ipvs 工作模型\n   * lvs dr原理详解图\n     * \n   * lvs fullnat模式\n     * \n   * lvs nat原理详解图\n     * \n   * lvs tun原理\n     * \n * 连接保持：\n   * lvs-persistent-connection\n * ipvs:\n   * ipvs 通过ipvsadm命令和lvs内核打交道\n   * 参数配置：\n     \n         配置全局参数，位于目录/proc/sys/net/ipv4/vs/下:\n         获取统计信息，位于目录/proc/net/下:\n     \n     \n     1\n     2\n     \n     * /proc/net/ip_vs\n       * 获取当前lvs内核配置，包括vs和rs相关信息；同ipvsadm -ln；\n       \n           ip virtual server version 1.2.1 (size=1048576) - 这里size是指连接hash表大小；\n           prot localaddress:port scheduler flags\n               -> remoteaddress:port forward weight activeconn inactconn\n           tcp 0adc0108:0050 rr - vs信息，vip和vport 16进制，调度算法rr；\n               -> c0a8010b:0050 route 1 0 0 - rs信息，rip和rport 16进制，权值为1，\n               -> c0a8010a:0050 route 1 0 0 \n       \n           - activeconn是指established状态的连接个数；\n           - inactconn是指非established状态的连接个数；\n       \n       \n       1\n       2\n       3\n       4\n       5\n       6\n       7\n       8\n       9\n       \n     * /proc/net/ip_vs_conn\n       * 获取所有连接信息，建议不要用该命令，因为连接数很多时，cpu开销会很大；\n       \n           pro fromip fprt toip tprt destip dprt state expires\n           - 用户ip和port vs ip和port rs ip和port tcp状态机状态 连接超时剩余的时间\n       \n       \n       1\n       2\n       \n     * /proc/net/ip_vs_stats\n     * /proc/sys/net/ipv4/vs/expire_nodest_conn\n       * 默认值为0，当lvs转发数据包，发现目的rs无效（删除）时，会丢弃该数据包，但不删除相应连接；这样设计的考虑是，rs恢复时，如果client和rs socket还没有超时，则 可以继续通讯;\n       * 如果将该参数置1，则马上释放相应 连接；个人建议采用默认值，配置为0；\n     * /proc/sys/net/ipv4/vs/expire_quiescent_template\n       * 默认值为0，当rs的weight值=0（如，健康检测失败，应用程序将rs weight置0）时，会话保持的新建连接 还会继续调度到该rs上；\n       * 如果配置为1，则马上将 会话保持的连接模板 置为无效，重新调度新的rs；如果有会话保持的业务，建议该值 配置为1；\n     * /proc/sys/net/ipv4/vs/nat_icmp_send\n       * 默认值为0；建议采用默认值，为0；\n       * 如果置为1，当lvs收到rs发送出来的数据包，但没有找到相应连接时，则发送目的不可达（端口不可达）的icmp给rs；\n     * /proc/sys/net/ipv4/vs/sync_threshold\n       * 默认值为 3 50；\n       * 这个参数和连接同步相关，lvs收到3个包后，开始启动同步；之后，每收到50个包，启动一次同步；可以根据lvs的流量，可以调整连接同步的频率，从而控制同步的系统开销；\n\n\n# 关键点\n\n在问题发生时，通过 ipvsadm -ln | grep 10.111.103.161 -a3 查看ipvs路由表发现，已经无效的pod的rip依然存在，只不过weight=0。\n\n联系上述的相关配置会发现，当服务发布时，先将新pod创建并注册rip到ipvs，再将旧pod删除，，但是但是，，旧pod删除时不是应该把对应的rip删除掉吗？\n\n当旧pod删除时，已有连接被断开，客户端触发重连机制，但因为ipvs的连接保持特性，会依然路由到旧pod对应的rip(虽然此时weight为0)。这就是问题的根源~\n\n持久连接（persistence）的问题。持久连接使一个客户端在超时时间内（ipvsadmin -p参数指定，keepalived的配置文件persistence_timeout指令）会持续连接到同一台后端服务器\n\n深究发现：1.12 的kube-proxy更改了实现：ipvs 下如果有 conn 存在就不删除 rip，只是将其权重设置为0\n\n * 解决方案\n   \n   * 将参数 /proc/sys/net/ipv4/vs/expire_quiescent_template 设置为 1\n\n * 注意\n   \n   * 之所以不调整 persistence_timeout 是因为，ftp 以及 ssl 等会依赖此特性，详见：persistence\n\n\n# 扩展\n\n * k8s 中的 ipvs 是 nat 模式\n   * ipvs 是一个内核态的四层负载均衡，支持nat、gateway以及ipip隧道模式，gateway模式性能最好，但lb和rs不能跨子网，ipip性能次之，通过ipip隧道解决跨网段传输问题，因此能够支持跨子网。而nat模式没有限制，这也是唯一一种支持端口映射的模式。\n   * 由于 kubernetes service 需要使用端口映射功能，因此kube-proxy必然只能使用ipvs的nat模式。\n * k8s 中为了流量能原路返回：\n   * 由于 ipvs 的 nat 模式是 dnat，不做snat，所以需要跟iptables配合，增加snat\n     \n         -a kube-mark-masq -j mark --set-xmark 0x4000/0x4000\n     \n     \n     1\n     \n   * k8s 的 snat 是在 mangle 表的 postrouting 链上进行的，一般来说，需要开启以下参数，才能实现这一功能：\n     \n         sysctl net.ipv4.vs.conntrack=1\n     \n     \n     1\n     \n * ipvs是dnat，不做snat，所以如果单纯使用ipvs，会话负载均衡是可以的; 但是，k8s使用ipvs，必须跟iptables配合，还得加多个snat，这样对于ipvs来说，所有的来源ip就变成一样的了，使用会话负载均衡是否就有问题了呢？ + 不会，因为，ipvs 工作在 prerouting 上，而 snat 发生在 postrouting 链上\n * svc有个参数 externaltrafficpolicy 设置为 local 时，可以避免 k8s 的跨节点路由",charsets:{cjk:!0}},{title:"kubernetes 简述",frontmatter:{title:"kubernetes 简述",date:"2019-12-18T00:00:00.000Z",categories:["kubernetes","istio","envoy","mesh services"],keywords:["envoy","k8s","istio","mesh services"],description:"kubernetes 基础知识汇总，以及mesh services---后 Kubernetes 时代的微服务",tags:[null],permalink:null},regularPath:"/blog/skills/devops/k8s_base.html",relativePath:"blog/skills/devops/k8s_base.md",key:"v-75c42f42",path:"/blog/skills/devops/k8s_base.html",headers:[{level:2,title:"summary",slug:"summary",normalizedTitle:"summary",charIndex:17},{level:2,title:"Network",slug:"network",normalizedTitle:"network",charIndex:1028},{level:2,title:"kubernetes details",slug:"kubernetes-details",normalizedTitle:"kubernetes details",charIndex:1587},{level:2,title:"istio summary",slug:"istio-summary",normalizedTitle:"istio summary",charIndex:2567},{level:2,title:"reference",slug:"reference",normalizedTitle:"reference",charIndex:1802}],headersStr:"summary Network kubernetes details istio summary reference",content:'# Kubernetes\n\n\n# summary\n\n * 本质：\n   \n   * Kubernetes 的本质是应用的生命周期管理，具体来说就是部署和管理（扩缩容、自动恢复、发布）。为微服务提供了可扩展、高弹性的部署和管理平台。\n   \n       At its core, k8s is a database(etcd). With "watchers" & "controllers" that react to changes in the DB. \n       The controllers are what make it Kubernetes. \n       This pluggability and extensibility is part of its "secret sauce"\n   \n   \n   1\n   2\n   3\n   \n\n * xDS：\n   \n   * xDS 协议控制了 Istio Service Mesh 中所有流量的具体行为，可以进行更加完善、精准的管理流量\n\n * k8s架构如下:\n   \n   * \n\n * 各个模块之间的工作流：\n   \n   * \n\n总的来说，k8s 由以下几部分组成：\n\n * kube-apiserver ::: 提供统一接口\n * kube-controller-manager ::: 负责资源管理同步\n   * Replication Controller\n   * Service Controller\n   * ResourceQuota Controller\n   * Namespace Controller\n   * Node Controller\n   * .etc\n * kube-scheduler ::: 负载资源与pod的匹配\n * kube-proxy ::: 负责k8s中的网络配置\n * kubelet ::: 管理pod的生命周期\n\n其中，常见的资源类型有：\n\n * Config Maps、Daemon Sets、Deployments、Events、Endpoints、Ingress、Jobs、Nodes、Namespaces、Pods、Persistent Volume、Replic Sets、Secrets、Services、Service Accounts、Stateful Sets, and more...\n\n\n# Network\n\n * 网络架构\n   \n   * 架构图\n   * 优缺点\n   * istio\n\n * 网络架构分层学习优缺点\n\n * 定制网络\n\n * 问题定位\n\n * CRI(container runtime interface)\n   \n   * CRI integrations\n     * containerd(with cri-containerd)\n     * cri-o\n     * docker\n     * frakti\n     * rktlet\n   * cri-containerd\n     * a containerd based implementation of CRI\n\n * CNI(container network interface)\n   \n   * notes\n     * kubernetes 使用 CNI 组件容器网络\n     * 当 POD 创建和销毁时，kubernetes 将调用 CNI 插件接口生成网络配置\n     * CNI 插件将生成虚拟NIC，将其挂载在主机的网络上，并和 POD 的 namespace 关联\n   * Calico\n     * 基于三层路由(BGP路由协议)，不依赖二层软件\n   * Flannel\n\n\n# kubernetes details\n\n * k8s pause容器:\n   * 在pod中担任Linux命名空间共享的基础；\n     * 每个Pod里运行着一个特殊的被称之为Pause的容器，其他容器则为业务容器，这些业务容器共享Pause容器的网络栈和Volume挂载卷，因此他们之间通信和数据交换更为高效\n   * 启用pid命名空间，开启init进程\n     * 是同一个pod中，其他容器1号进程的父进程\n   * reference: almighty-pause-container\n * k8s externalIPs:\n   * LoadBalancer 这种访问集群内的方式，会自动创建 externalIPs (需要云服务商提供相应支持)\n   * reference: service-discovery\n * k8s kubeproxy:\n   * Service 实现负载均衡（Load Balance）功能，自动把请求流量分布到后端所有的服务上，这一功能的关键，就是 kube-proxy。\n     * kube-proxy 运行在每个节点上，监听 API Server 中服务对象的变化，通过管理 iptables 来实现网络的转发。\n   * kube-proxy 有两种实现 service 的方案：userspace 和 iptables\n     * userspace 是在用户空间监听一个端口，所有的 service 都转发到这个端口，然后 kube-proxy 在内部应用层对其进行转发。因为是在用户空间进行转发，所以效率也不高\n     * iptables 完全实现 iptables 来实现 service，是目前默认的方式，也是推荐的方式，效率很高（只有内核中 netfilter 一些损耗）。\n   * 问题：k8s kubeproxy 在 istio 中是否有用？有的话，能发挥什么样的作用\n * 不常用的重要命令\n\n    kubectl api-resources -o wide: limit:  >= 1.11.0\n    kubectl explain: eg. kubectl explain replicaset --api-version apps/v1\t\n\n\n1\n2\n\n\n\n# istio summary\n\n * envoy 的4种DS(discovery Service):Discovery Service就是部署在控制面的，在istio中，是Pilot。\n   1. listener，也即envoy既然是proxy，专门做转发，就得监听一个端口，接入请求，然后才能够根据策略转发，这个监听的端口称为listener\n   2. endpoint，是目标的ip地址和端口，这个是proxy最终将请求转发到的地方。\n   3. cluster，一个cluster是具有完全相同行为的多个endpoint，也即如果有三个容器在运行，就会有三个IP和端口，但是部署的是完全相同的三个服务，他们组成一个Cluster，从cluster到endpoint的过程称为负载均衡，可以轮询等。\n   4. route，有时候多个cluster具有类似的功能，但是是不同的版本号，可以通过route规则，选择将请求路由到某一个版本号，也即某一个cluster。\n\n\n# reference\n\n * istio-handbook\n * ibm-opentech-ma\n\nhttps://kubernetes.feisky.xyz/ https://sookocheff.com/post/kubernetes/understanding-kubernetes-networking-model/\n\n重启 k8s deployment 的方式： kubectl rollout restart deployment your_deployment_name 更改 deployment 文件(更改label、image等有效部分)，并重新 apply\n\nconntrack',normalizedContent:'# kubernetes\n\n\n# summary\n\n * 本质：\n   \n   * kubernetes 的本质是应用的生命周期管理，具体来说就是部署和管理（扩缩容、自动恢复、发布）。为微服务提供了可扩展、高弹性的部署和管理平台。\n   \n       at its core, k8s is a database(etcd). with "watchers" & "controllers" that react to changes in the db. \n       the controllers are what make it kubernetes. \n       this pluggability and extensibility is part of its "secret sauce"\n   \n   \n   1\n   2\n   3\n   \n\n * xds：\n   \n   * xds 协议控制了 istio service mesh 中所有流量的具体行为，可以进行更加完善、精准的管理流量\n\n * k8s架构如下:\n   \n   * \n\n * 各个模块之间的工作流：\n   \n   * \n\n总的来说，k8s 由以下几部分组成：\n\n * kube-apiserver ::: 提供统一接口\n * kube-controller-manager ::: 负责资源管理同步\n   * replication controller\n   * service controller\n   * resourcequota controller\n   * namespace controller\n   * node controller\n   * .etc\n * kube-scheduler ::: 负载资源与pod的匹配\n * kube-proxy ::: 负责k8s中的网络配置\n * kubelet ::: 管理pod的生命周期\n\n其中，常见的资源类型有：\n\n * config maps、daemon sets、deployments、events、endpoints、ingress、jobs、nodes、namespaces、pods、persistent volume、replic sets、secrets、services、service accounts、stateful sets, and more...\n\n\n# network\n\n * 网络架构\n   \n   * 架构图\n   * 优缺点\n   * istio\n\n * 网络架构分层学习优缺点\n\n * 定制网络\n\n * 问题定位\n\n * cri(container runtime interface)\n   \n   * cri integrations\n     * containerd(with cri-containerd)\n     * cri-o\n     * docker\n     * frakti\n     * rktlet\n   * cri-containerd\n     * a containerd based implementation of cri\n\n * cni(container network interface)\n   \n   * notes\n     * kubernetes 使用 cni 组件容器网络\n     * 当 pod 创建和销毁时，kubernetes 将调用 cni 插件接口生成网络配置\n     * cni 插件将生成虚拟nic，将其挂载在主机的网络上，并和 pod 的 namespace 关联\n   * calico\n     * 基于三层路由(bgp路由协议)，不依赖二层软件\n   * flannel\n\n\n# kubernetes details\n\n * k8s pause容器:\n   * 在pod中担任linux命名空间共享的基础；\n     * 每个pod里运行着一个特殊的被称之为pause的容器，其他容器则为业务容器，这些业务容器共享pause容器的网络栈和volume挂载卷，因此他们之间通信和数据交换更为高效\n   * 启用pid命名空间，开启init进程\n     * 是同一个pod中，其他容器1号进程的父进程\n   * reference: almighty-pause-container\n * k8s externalips:\n   * loadbalancer 这种访问集群内的方式，会自动创建 externalips (需要云服务商提供相应支持)\n   * reference: service-discovery\n * k8s kubeproxy:\n   * service 实现负载均衡（load balance）功能，自动把请求流量分布到后端所有的服务上，这一功能的关键，就是 kube-proxy。\n     * kube-proxy 运行在每个节点上，监听 api server 中服务对象的变化，通过管理 iptables 来实现网络的转发。\n   * kube-proxy 有两种实现 service 的方案：userspace 和 iptables\n     * userspace 是在用户空间监听一个端口，所有的 service 都转发到这个端口，然后 kube-proxy 在内部应用层对其进行转发。因为是在用户空间进行转发，所以效率也不高\n     * iptables 完全实现 iptables 来实现 service，是目前默认的方式，也是推荐的方式，效率很高（只有内核中 netfilter 一些损耗）。\n   * 问题：k8s kubeproxy 在 istio 中是否有用？有的话，能发挥什么样的作用\n * 不常用的重要命令\n\n    kubectl api-resources -o wide: limit:  >= 1.11.0\n    kubectl explain: eg. kubectl explain replicaset --api-version apps/v1\t\n\n\n1\n2\n\n\n\n# istio summary\n\n * envoy 的4种ds(discovery service):discovery service就是部署在控制面的，在istio中，是pilot。\n   1. listener，也即envoy既然是proxy，专门做转发，就得监听一个端口，接入请求，然后才能够根据策略转发，这个监听的端口称为listener\n   2. endpoint，是目标的ip地址和端口，这个是proxy最终将请求转发到的地方。\n   3. cluster，一个cluster是具有完全相同行为的多个endpoint，也即如果有三个容器在运行，就会有三个ip和端口，但是部署的是完全相同的三个服务，他们组成一个cluster，从cluster到endpoint的过程称为负载均衡，可以轮询等。\n   4. route，有时候多个cluster具有类似的功能，但是是不同的版本号，可以通过route规则，选择将请求路由到某一个版本号，也即某一个cluster。\n\n\n# reference\n\n * istio-handbook\n * ibm-opentech-ma\n\nhttps://kubernetes.feisky.xyz/ https://sookocheff.com/post/kubernetes/understanding-kubernetes-networking-model/\n\n重启 k8s deployment 的方式： kubectl rollout restart deployment your_deployment_name 更改 deployment 文件(更改label、image等有效部分)，并重新 apply\n\nconntrack',charsets:{cjk:!0}},{title:"K8S网络之集群外访问service的方式",frontmatter:{title:"K8S网络之集群外访问service的方式",date:"2019-12-18T00:00:00.000Z",description:"K8S网络之集群外访问service的方式",categories:["skills","devops"],tags:[null],permalink:null},regularPath:"/blog/skills/devops/k8s_net_expose.html",relativePath:"blog/skills/devops/k8s_net_expose.md",key:"v-897ab682",path:"/blog/skills/devops/k8s_net_expose.html",headers:[{level:2,title:"NodePort",slug:"nodeport",normalizedTitle:"nodeport",charIndex:110},{level:2,title:"LoadBalancer:",slug:"loadbalancer",normalizedTitle:"loadbalancer:",charIndex:462},{level:2,title:"Ingress",slug:"ingress",normalizedTitle:"ingress",charIndex:122}],headersStr:"NodePort LoadBalancer: Ingress",content:"# K8S网络之集群外访问service的方式\n\nk8s service 的 cluster ip 只能供集群内部访问使用，如果想将 service 暴露给外部该怎么办？\n\nk8s 提供了以下几种方式来实现这个\n\n * NodePort\n * Ingress\n * LoadBalancer\n\n\n# NodePort\n\nNodePort 服务是引导外部流量到 k8s 服务的最基础的方式。\n\n正如 NodePort 这个名字所示，在所有 k8s 节点上开放一个特定端口，任何发送到该端口的流量都被转发到对应服务。这个端口可以自己指定，如果不指定的话，系统将选择一个随机端口。\n\n\n\n这种方法有许多缺点：\n\n * 每个端口只能是一种服务\n * 端口(默认)范围只能是 30000-32767\n * 如果节点的 IP 地址发生变化(集群扩/缩容)，我们需要能处理这种情况。\n\n基于以上原因，不建议在生产环境上用这种方式暴露服务。但是对 demo 应用等临时应用使用这种方式，无疑是很方便的，不需要申请额外的昂贵的资源。\n\n\n# LoadBalancer:\n\nLoadBalancer 是暴露 k8s service 到 internet 的标准方式。这种方式的实现，需要依赖 云提供商 的支持。通过这种方式，来自外部负载均衡器的流量将直接打到 backend pod 上，不过实际它们是如何工作的，这要依赖于云提供商。\n\nLoadBalancer 的工作方式，是在集群外创建一个 lb (拥有独立的 ip 地址)，并且所有经过 lb 的流量转发到指定 port，经过这个 port 后流量会被转发到指定的 k8s 服务。这个过程中，没有过滤、没有路由..., 同时, 由于它工作在 Layer 4，所以几乎可以处理任意流量类型，如：HTTP, TCP, UDP, Websockets, gRPC, or whatever\n\nLoadBalancer 方式的最大不足是，每个需要暴露给 internet 的服务都要一个拥有独立 ip 地址的 lb，并且需要为此支付费用。\n\n\n\n\n# Ingress\n\nIngress 不同于上文的 NodePort、LoadBalancer，它事实上不是一种服务类型, 而是一种资源类型，是一个 Ingress Controller 的规则集合。而 Ingress Controller 实际上就是一个解析 Ingress 规则的集群内 service。\n\n注意，Ingress 是规则，Ingress Controller 进行规则解析、执行，他们都没有涉及如何暴露自己到 internet，这个还是需要 Ingress Controller 借助前文讲到的 NodePort 或者 LoadBalancer 来实现。\n\nService Type 示例:\n\n\n    Type=ClusterIP\n    Type=NodePort\n    Type=LoadBalancer\n\n\n1\n2\n3\n4\n\n\nIngress 示例\n\n    apiVersion: networking.k8s.io/v1beta1\n    kind: Ingress\n    metadata:\n    name: test-ingress\n    annotations:\n        nginx.ingress.kubernetes.io/rewrite-target: /\n    spec:\n    rules:\n    - http:\n        paths:\n        - path: /testpath\n            pathType: Prefix\n            backend:\n            serviceName: test\n            servicePort: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\n在 k8s 集群中最常见的 ingress controller 就是 nginx，此时 Ingress Controller 的作用就是监听 Ingress 规则的变化，并解析成对应的 nginx 规则，并写入 nginx 配置(/etc/nginx.conf)。\n\n通过使用 Ingress，我们可以做很多不同的事情，因为有很多不同类型的 Ingress controller 拥有各种各样的能力。默认的 GKE ingress controller 会为服务创建一个 HTTP(S) Load Balancer。 这就允许用基于 path 和 subdomain 的方式路由到后端服务。例如，可以通过 foo.yourdomain.com 到达 foo service，在 yourdomain.com/bar/ 下的路径路由到 bar service.\n\nIngress 可能是功能最强大的暴露服务的方式，但是也是最复杂的。有各种各样的 Ingress controller 的实现方式，如 the Google Cloud Load Balancer, Nginx, Contour, Istio, and more. 也有很多 Ingress controllers 的插件，如 the cert-manager 可以自动进行 SSL 认证。\n\nIngress 是用同一个 ip 暴露多个服务(可以通过过 L7 协议进行路由)的最有用的方式。这样的话，只需要支付一个 load balancer 的费用。同时，Ingress 附带了很多有用的特性，如：SSL、Auth、Routing, etc\n\n\n# 思考\n\n * 如果我们是云厂商的话，会怎么来实现 LoadBalancer ? 对负载均衡、源ip保留等问题如何处理\n\n\n# reference\n\n * services-networking-ingress\n * create-external-load-balancer\n * ingress-vs-load-balancer",normalizedContent:"# k8s网络之集群外访问service的方式\n\nk8s service 的 cluster ip 只能供集群内部访问使用，如果想将 service 暴露给外部该怎么办？\n\nk8s 提供了以下几种方式来实现这个\n\n * nodeport\n * ingress\n * loadbalancer\n\n\n# nodeport\n\nnodeport 服务是引导外部流量到 k8s 服务的最基础的方式。\n\n正如 nodeport 这个名字所示，在所有 k8s 节点上开放一个特定端口，任何发送到该端口的流量都被转发到对应服务。这个端口可以自己指定，如果不指定的话，系统将选择一个随机端口。\n\n\n\n这种方法有许多缺点：\n\n * 每个端口只能是一种服务\n * 端口(默认)范围只能是 30000-32767\n * 如果节点的 ip 地址发生变化(集群扩/缩容)，我们需要能处理这种情况。\n\n基于以上原因，不建议在生产环境上用这种方式暴露服务。但是对 demo 应用等临时应用使用这种方式，无疑是很方便的，不需要申请额外的昂贵的资源。\n\n\n# loadbalancer:\n\nloadbalancer 是暴露 k8s service 到 internet 的标准方式。这种方式的实现，需要依赖 云提供商 的支持。通过这种方式，来自外部负载均衡器的流量将直接打到 backend pod 上，不过实际它们是如何工作的，这要依赖于云提供商。\n\nloadbalancer 的工作方式，是在集群外创建一个 lb (拥有独立的 ip 地址)，并且所有经过 lb 的流量转发到指定 port，经过这个 port 后流量会被转发到指定的 k8s 服务。这个过程中，没有过滤、没有路由..., 同时, 由于它工作在 layer 4，所以几乎可以处理任意流量类型，如：http, tcp, udp, websockets, grpc, or whatever\n\nloadbalancer 方式的最大不足是，每个需要暴露给 internet 的服务都要一个拥有独立 ip 地址的 lb，并且需要为此支付费用。\n\n\n\n\n# ingress\n\ningress 不同于上文的 nodeport、loadbalancer，它事实上不是一种服务类型, 而是一种资源类型，是一个 ingress controller 的规则集合。而 ingress controller 实际上就是一个解析 ingress 规则的集群内 service。\n\n注意，ingress 是规则，ingress controller 进行规则解析、执行，他们都没有涉及如何暴露自己到 internet，这个还是需要 ingress controller 借助前文讲到的 nodeport 或者 loadbalancer 来实现。\n\nservice type 示例:\n\n\n    type=clusterip\n    type=nodeport\n    type=loadbalancer\n\n\n1\n2\n3\n4\n\n\ningress 示例\n\n    apiversion: networking.k8s.io/v1beta1\n    kind: ingress\n    metadata:\n    name: test-ingress\n    annotations:\n        nginx.ingress.kubernetes.io/rewrite-target: /\n    spec:\n    rules:\n    - http:\n        paths:\n        - path: /testpath\n            pathtype: prefix\n            backend:\n            servicename: test\n            serviceport: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\n在 k8s 集群中最常见的 ingress controller 就是 nginx，此时 ingress controller 的作用就是监听 ingress 规则的变化，并解析成对应的 nginx 规则，并写入 nginx 配置(/etc/nginx.conf)。\n\n通过使用 ingress，我们可以做很多不同的事情，因为有很多不同类型的 ingress controller 拥有各种各样的能力。默认的 gke ingress controller 会为服务创建一个 http(s) load balancer。 这就允许用基于 path 和 subdomain 的方式路由到后端服务。例如，可以通过 foo.yourdomain.com 到达 foo service，在 yourdomain.com/bar/ 下的路径路由到 bar service.\n\ningress 可能是功能最强大的暴露服务的方式，但是也是最复杂的。有各种各样的 ingress controller 的实现方式，如 the google cloud load balancer, nginx, contour, istio, and more. 也有很多 ingress controllers 的插件，如 the cert-manager 可以自动进行 ssl 认证。\n\ningress 是用同一个 ip 暴露多个服务(可以通过过 l7 协议进行路由)的最有用的方式。这样的话，只需要支付一个 load balancer 的费用。同时，ingress 附带了很多有用的特性，如：ssl、auth、routing, etc\n\n\n# 思考\n\n * 如果我们是云厂商的话，会怎么来实现 loadbalancer ? 对负载均衡、源ip保留等问题如何处理\n\n\n# reference\n\n * services-networking-ingress\n * create-external-load-balancer\n * ingress-vs-load-balancer",charsets:{cjk:!0}},{title:"K8S网络之网络框架",frontmatter:{title:"K8S网络之网络框架",date:"2019-12-18T00:00:00.000Z",description:"K8S网络之网络框架",categories:["skills","devops"],tags:[null],permalink:null},regularPath:"/blog/skills/devops/k8s_net_mode.html",relativePath:"blog/skills/devops/k8s_net_mode.md",key:"v-41809442",path:"/blog/skills/devops/k8s_net_mode.html",headers:[{level:2,title:"模型",slug:"模型",normalizedTitle:"模型",charIndex:383},{level:2,title:"方案",slug:"方案",normalizedTitle:"方案",charIndex:778},{level:3,title:"准备",slug:"准备",normalizedTitle:"准备",charIndex:785},{level:3,title:"CNI 简介",slug:"cni-简介",normalizedTitle:"cni 简介",charIndex:2386},{level:3,title:"实现",slug:"实现",normalizedTitle:"实现",charIndex:1092}],headersStr:"模型 方案 准备 CNI 简介 实现",content:"# K8S网络之网络框架\n\n网络是 k8s 的一个核心部分，但是精准的了解其预期的工作方式可能会比较困难。总的来说，有四个不同的网络问题需要解决：\n\n * Highly-coupled container-to-container communications\n * Pod-to-Pod communications\n * Pod-to-Service communications: this is covered by services.\n * External-to-Service communications\n\n其中，高度耦合的容器到容器通信，可以通过 pod 机制：同一个 pod 中的容器 共享 pause 容器的 network namespace，来解决。\n\n本文主要关注 pod-to-pod 的通信，另外两个问题，后续系列再来介绍。\n\n\n# 模型\n\n假定大家已经对 k8s 的基础元素比较熟悉了。在 k8s 的网络构建过程中，对容器网络是做出了一些限制，也就是 k8s 的容器网络模型。\n\n这些限制如下：\n\n * 任意 pod 之间可以直接通信，无需经过地址转换(NAT)\n * 任意 pod 与其宿主 node 之间是可以直接通信的，无需经过地址转换(NAT)\n * 每个 pod 都拥有一个独立 ip 地址，pod 内所有容器共享一个网络命名空间\n\n可以看出，k8s 将集群内所有 pod 都放在一个直接连通的扁平网络中，pod 之间可以通过 ip 直接访问。在一个 pod 中的应用在 选择端口、服务发现、应用配置等操作时，可以表现的像 VMs 或者 物理机 一样。\n\n通过这样设计，k8s 网络可以很容易做到，将一个 K8s 系统为外部世界提供服务的时候，从网络的角度很容易弄清楚，外部数据怎么连接到容器内的应用。\n\n\n# 方案\n\n\n# 准备\n\n# docker 网络概述\n\n我们知道，在启动 docker 后，docker engine 会在宿主机里新增一个网络设备：docker0 网桥(Bridge)，而创建的 docker 容器的网络默认情况下会被分配在一个以 docker0 为网关的虚拟子网中，通过 veth对 连接 docker0 和 容器内部。\n\n总体来说，就是 docker 通过 network namespace 做了容器和宿主机的网络隔离, 再用 veth对 将容器和宿主机两个 network namespace 连接起来，并将 veth 的一端连接到 docker0 (网桥, 在node的root namespace内)，实现 容器间、和宿主机的网络互通。\n\n# k8s 的网络状况\n\n对于 k8s 系统来说，支持多种 container runtime 是一件非常重要的事情，当然，Docker 只是其中之一。\n\n而配置网络环境只是 container runtime 的一个方面。所以，当人们问“k8s 是否会支持 CNM”的时候，其实是在问“k8s 是否会在 Docker runtime 中支持 CNM drivers”。确实，k8s 尚未在 Docker runtime 中采用 CNM/libnetwork。而是对 CoreOS 提出的 Container Network Interface (CNI) 模型很感兴趣。\n\n这里对 CNM 做个简单说明:\n    CNM 是由 docker 提出的网络协议，它要解决的问题和 CNI 是重合的。目前 CNM 只能使用在 docker 中，而 CNI 可以使用在任何容器运行时。CNM 主要用来实现 docker 自身的网络问题，也就是 docker network 子命令提供的功能。 \n\n\n1\n2\n\n\n为什么不用 CNM 呢？why-kubernetes-doesnt-use-libnetwork里有较为详细的介绍，本文只做个简单的描述。\n\n 1. Docker 的 “local”(bridge) driver 概念 在 k8s 集群中，一般由少则 3~5 台，多则 100+ 节点组成。如果网络设计，依然像 docker 那样以 docker0 为网关就会出现问题：docker 网络是为同一台宿主机的容器通信设计的，而根据上文 k8s 的网络要求，pod 需要能跨主机与其他 pod 直接通信。\n\n 2. Docker 的 “global”(overlay) driver 概念 依赖于 libkv 这一非常底层的 key-value 存储抽象，要在 k8s 中支持 Docker’s overlay driver, 就需要支持这一存储抽象，这会造成 k8s 本来是想通过Docker networking 来简化事情，但是却明显的更加复杂化了。\n\n 3. CNI 在设计哲学上与 k8s 保持一致(It follows the UNIX philosophy of doing one thing well)。且比 CNM 简单得多，不需要守护程序，并且可以跨平台\n\n所以为了满足 k8s 的网络设计要求，就需要一种 CNI 插件，它实现了让不同 node 上的 pod 实现无需经过显式的地址转换(NAT)进行通信的机制。同时，由于是通过 ip 直接通信，所以 ip 不能重复，这就还需要一种 为 pod 统一分配 ip 的机制。\n\n满足 k8s 网络设计要求的插件已经有很多，有兴趣的话，在官方文档上可以看看有哪些网络插件可以使用：https://kubernetes.io/docs/concepts/cluster-administration/networking/#how-to-achieve-this\n\n\n1\n\n\n\n# CNI 简介\n\nCNI(Conteinre Network Interface) 是 google 和 CoreOS 主导制定的容器网络标准，它本身并不是实现或者代码，只是一个标准(可以理解成一个协议)。它综合考虑了灵活性、扩展性、ip 分配、多网卡等因素，旨在为容器平台提供网络的标准化。\n\n目前存在网络方案 flannel、calico、openvswitch、weave、ipvlan 等，这些方案接口和使用方法都不尽相同，而不同的容器平台都需要网络功能，它们之间的适配如果没有统一的标准，会有很大的工作量和重复劳动。而 CNI 的出现，就是为了解决这样的问题，使得不同的容器平台(比如 kubernetes、mesos 和 rkt)能够通过相同的接口调用不同的网络组件。\n\n这个协议连接了两个组件：容器管理系统(如 rkt 或 k8s)和网络插件。它们之间通过 JSON 格式的文件进行通信，实现容器的网络功能。具体的事情都是插件来实现的，包括：创建容器网络空间(network namespace)、把网络接口(interface)放到对应的网络空间、给网络接口分配 IP 等等。\n\n\n\n# CNI 设计考量\n\nCNI设计的时候考虑了以下问题：\n\n * 容器运行时必须在调用任何插件之前为容器创建一个新的网络命名空间\n * 容器运行时必须确定这个容器应属于哪个网络，并为每个网络确定哪些插件必须被执行\n * 网络配置采用JSON格式\n * 容器运行时必须按顺序为每个网络执行相应的插件，将容器添加到每个网络中\n * 在完成容器生命周期后，运行时必须以相反的顺序执行插件（相对于执行添加容器的顺序）以将容器与网络断开连接\n * 容器运行时不能为同一容器调用并行操作，但可以为不同的容器调用并行操作\n * 容器运行时必须为容器订阅ADD和DEL操作，这样ADD后面总是跟着相应的DEL。 DEL可能跟着额外的DEL，但是，插件应该允许处理多个DEL（即插件DEL应该是幂等的）。\n * 容器必须由 ContainerID 唯一标识。存储状态的插件应该使用（网络名称，容器ID）的主键来完成。\n * 运行时不能调用同一个网络名称或容器ID执行两次ADD（没有相应的DEL）。换句话说，给定的容器ID必须只能添加到特定的网络一次。\n\nCNI插件\n\n * CNI插件必须实现一个可执行文件，这个文件可以被容器管理系统调用\n * CNI插件负责将网络接口插入容器网络命名空间（例如，veth对的一端），并在主机上进行任何必要的改变（例如将veth的另一端连接到网桥）。然后将IP分配给接口，并通过调用适当的IPAM(IP Address Management)插件来设置与“IP地址管理”部分一致的路由。\n\n\n# 实现\n\n# 容器创建\n\n接下来，我们跟随 pod 创建过程，看看 pod 的网络构建。k8s pod 的网络是这样创建的：\n\n 1. 首先 kubelet 创建基础容器 pause 生成对应的 network namespace\n 2. 然后 kubelet 调用网络 CNI driver，由它根据配置调用具体的 CNI 插件\n 3. 然后 CNI 插件给基础容器配置网络\n 4. 最后创建 pod 中其他容器共享使用基础容器的网络\n\n常见的 CNI 插件实现方案有：\n\n * 隧道方案\n   * 隧道方案在IaaS层的网络中应用也比较多，将pod分布在一个大二层的网络规模下。网络拓扑简单，但随着节点规模的增长复杂度会提升。\n   * 如：\n     * Weave：UDP广播，本机建立新的BR，通过PCAP互通\n     * Open vSwitch（OVS）：基于VxLan和GRE协议，但是性能方面损失比较严重\n     * Flannel：UDP广播，VxLan\n * 路由方案\n   * 路由方案一般是从3层或者2层实现隔离和跨主机容器互通的，出了问题也很容易排查。\n   * 如\n     * Calico：基于BGP协议的路由方案，支持很细致的ACL控制，对混合云亲和度比较高。\n     * Macvlan：从逻辑和Kernel层来看隔离性和性能最优的方案，基于二层隔离，所以需要二层路由器支持，大多数云服务商不支持，所以混合云上比较难以实现。\n\n这些插件各有优势，也在互相借鉴学习优点。这里介绍下常见的 flannel、calico：\n\n# Flannel\n\nflannel 是由 CoreOS 开发的一个比较简单的 overlay 网络，可能是目前最受欢迎的 CNI 插件了。一般来说，flannel 已经能够满足大多数的使用场景了，并且性能也比较好，所以，一般来说，只有在 flannel 不能满足需要的时候，才考虑使用其他的 CNI 插件。\n\nflannel 的工作流程大致如下：\n\n * 首先在启动 K8S Controller Manager 时，需要指定集群的 pod ip 范围：--cluster-cidr=172.16.0.0/16, 并开启为 node 分配 ip 选项：--allocate-node-cidrs=true\n * Controller Manager会把为每个node分配的IP范围保存到 etcd 中 (flannel 也会使用 etcd 来存储它的状态信息)\n * 新建 pod 时，flannel 会从 etcd 中取出属于该 node 的 ip 分配给 pod，再在 etcd 中记录下这个 pod 的 ip\n * 这样 etcd 中就会存有一张 node ip 与 pod id 对应的“路由表”\n\nflannel 的路由流程：\n\n * 当 pod 在同一个 node 之内通信时，通过 docker bridge 即可\n * 当 pod 需要跨 node 通信时，数据包经过 node 中的路由会到 flannel(flanneld) 中，flannel 通过 etcd 查询到目的 pod ip 的 node ip，使用flannel的Backends对数据包进行分装，发送给目的node处理。目的node拿到数据包后解开封装，拿到原始数据包，再通过node的路由送到相应的pod。\n\nflannel 有多种不同的 Backends (如 udp，VxLan、host-gw)来进行 封包和路由，默认的也是推荐的方式是：VxLan，相对于其他的实现，它提供了较好的性能和需要较少的人工干预。\n\n\n\n# Calico\n\nCalico 是一个纯三层的数据中心网络方案（不需要Overlay），并且与OpenStack、Kubernetes、AWS、GCE等IaaS和容器平台都有良好的集成。它为每个容器会分配一个可路由的IP，由于通信时不需要解包和封包，网络性能损耗小，易于排查。\n\nCalico在每一个节点利用 Linux Kernel 实现了一个高效的 vRouter 来负责数据转发，而每个 vRouter 通过 BGP 协议负责把自己上运行的 workload 的路由信息向整个 Calico 网络内传播。\n\n小规模部署的 Calico 网络可以直接互联，大规模下可通过指定的 BGP route reflector 来完成。 这样保证最终所有的 workload 之间的数据流量都是通过 IP 路由的方式完成互联的。Calico节点组网可以直接利用数据中心的网络结构(无论是L2或者L3)，不需要额外的NAT，隧道或者Overlay Network。\n\n\n\nCalico主要由 Felix、etcd、BGP client 以及 BGP Route Reflector 组成\n\n * Felix：Calico Agent，每个节点都需要运行，主要负责配置路由、配置ACLs、报告状态，确保Endpoint的连通状态\n * BGP Client: 主要负责把 Felix 写入 Kernel 的路由信息分发到当前 Calico 网络其他节点，确保 Workload 间的通信的有效性\n * Etcd: 分布式键值存储，主要负责存储网络信息，确保 Calico 网络状态的准确性\n * BGP Route Reflector: 大规模部署时使用，作为BGP client的中心连接点, 摒弃所有节点互联的 mesh 模式，避免每个节点互联, 通过一个或者多个BGP Route Reflector来完成集中式的路由分发\n\nCalico的不足\n\n * 不支持多租户网络的隔离功能，在多租户场景下会有网络安全问题\n * Calico控制平面的设计要求物理网络得是L2 Fabric，这样vRouter间都是直接可达的\n\n\n# 问题\n\n * docker0、cni0、kube-ipvs0 的区别\n\n\n# reference\n\n * Cluster Networking\n * network design-proposals\n * CNI (Container Network Interface)\n * CNM (Container Network Model)\n * understanding-kubernetes-networking-model",normalizedContent:"# k8s网络之网络框架\n\n网络是 k8s 的一个核心部分，但是精准的了解其预期的工作方式可能会比较困难。总的来说，有四个不同的网络问题需要解决：\n\n * highly-coupled container-to-container communications\n * pod-to-pod communications\n * pod-to-service communications: this is covered by services.\n * external-to-service communications\n\n其中，高度耦合的容器到容器通信，可以通过 pod 机制：同一个 pod 中的容器 共享 pause 容器的 network namespace，来解决。\n\n本文主要关注 pod-to-pod 的通信，另外两个问题，后续系列再来介绍。\n\n\n# 模型\n\n假定大家已经对 k8s 的基础元素比较熟悉了。在 k8s 的网络构建过程中，对容器网络是做出了一些限制，也就是 k8s 的容器网络模型。\n\n这些限制如下：\n\n * 任意 pod 之间可以直接通信，无需经过地址转换(nat)\n * 任意 pod 与其宿主 node 之间是可以直接通信的，无需经过地址转换(nat)\n * 每个 pod 都拥有一个独立 ip 地址，pod 内所有容器共享一个网络命名空间\n\n可以看出，k8s 将集群内所有 pod 都放在一个直接连通的扁平网络中，pod 之间可以通过 ip 直接访问。在一个 pod 中的应用在 选择端口、服务发现、应用配置等操作时，可以表现的像 vms 或者 物理机 一样。\n\n通过这样设计，k8s 网络可以很容易做到，将一个 k8s 系统为外部世界提供服务的时候，从网络的角度很容易弄清楚，外部数据怎么连接到容器内的应用。\n\n\n# 方案\n\n\n# 准备\n\n# docker 网络概述\n\n我们知道，在启动 docker 后，docker engine 会在宿主机里新增一个网络设备：docker0 网桥(bridge)，而创建的 docker 容器的网络默认情况下会被分配在一个以 docker0 为网关的虚拟子网中，通过 veth对 连接 docker0 和 容器内部。\n\n总体来说，就是 docker 通过 network namespace 做了容器和宿主机的网络隔离, 再用 veth对 将容器和宿主机两个 network namespace 连接起来，并将 veth 的一端连接到 docker0 (网桥, 在node的root namespace内)，实现 容器间、和宿主机的网络互通。\n\n# k8s 的网络状况\n\n对于 k8s 系统来说，支持多种 container runtime 是一件非常重要的事情，当然，docker 只是其中之一。\n\n而配置网络环境只是 container runtime 的一个方面。所以，当人们问“k8s 是否会支持 cnm”的时候，其实是在问“k8s 是否会在 docker runtime 中支持 cnm drivers”。确实，k8s 尚未在 docker runtime 中采用 cnm/libnetwork。而是对 coreos 提出的 container network interface (cni) 模型很感兴趣。\n\n这里对 cnm 做个简单说明:\n    cnm 是由 docker 提出的网络协议，它要解决的问题和 cni 是重合的。目前 cnm 只能使用在 docker 中，而 cni 可以使用在任何容器运行时。cnm 主要用来实现 docker 自身的网络问题，也就是 docker network 子命令提供的功能。 \n\n\n1\n2\n\n\n为什么不用 cnm 呢？why-kubernetes-doesnt-use-libnetwork里有较为详细的介绍，本文只做个简单的描述。\n\n 1. docker 的 “local”(bridge) driver 概念 在 k8s 集群中，一般由少则 3~5 台，多则 100+ 节点组成。如果网络设计，依然像 docker 那样以 docker0 为网关就会出现问题：docker 网络是为同一台宿主机的容器通信设计的，而根据上文 k8s 的网络要求，pod 需要能跨主机与其他 pod 直接通信。\n\n 2. docker 的 “global”(overlay) driver 概念 依赖于 libkv 这一非常底层的 key-value 存储抽象，要在 k8s 中支持 docker’s overlay driver, 就需要支持这一存储抽象，这会造成 k8s 本来是想通过docker networking 来简化事情，但是却明显的更加复杂化了。\n\n 3. cni 在设计哲学上与 k8s 保持一致(it follows the unix philosophy of doing one thing well)。且比 cnm 简单得多，不需要守护程序，并且可以跨平台\n\n所以为了满足 k8s 的网络设计要求，就需要一种 cni 插件，它实现了让不同 node 上的 pod 实现无需经过显式的地址转换(nat)进行通信的机制。同时，由于是通过 ip 直接通信，所以 ip 不能重复，这就还需要一种 为 pod 统一分配 ip 的机制。\n\n满足 k8s 网络设计要求的插件已经有很多，有兴趣的话，在官方文档上可以看看有哪些网络插件可以使用：https://kubernetes.io/docs/concepts/cluster-administration/networking/#how-to-achieve-this\n\n\n1\n\n\n\n# cni 简介\n\ncni(conteinre network interface) 是 google 和 coreos 主导制定的容器网络标准，它本身并不是实现或者代码，只是一个标准(可以理解成一个协议)。它综合考虑了灵活性、扩展性、ip 分配、多网卡等因素，旨在为容器平台提供网络的标准化。\n\n目前存在网络方案 flannel、calico、openvswitch、weave、ipvlan 等，这些方案接口和使用方法都不尽相同，而不同的容器平台都需要网络功能，它们之间的适配如果没有统一的标准，会有很大的工作量和重复劳动。而 cni 的出现，就是为了解决这样的问题，使得不同的容器平台(比如 kubernetes、mesos 和 rkt)能够通过相同的接口调用不同的网络组件。\n\n这个协议连接了两个组件：容器管理系统(如 rkt 或 k8s)和网络插件。它们之间通过 json 格式的文件进行通信，实现容器的网络功能。具体的事情都是插件来实现的，包括：创建容器网络空间(network namespace)、把网络接口(interface)放到对应的网络空间、给网络接口分配 ip 等等。\n\n\n\n# cni 设计考量\n\ncni设计的时候考虑了以下问题：\n\n * 容器运行时必须在调用任何插件之前为容器创建一个新的网络命名空间\n * 容器运行时必须确定这个容器应属于哪个网络，并为每个网络确定哪些插件必须被执行\n * 网络配置采用json格式\n * 容器运行时必须按顺序为每个网络执行相应的插件，将容器添加到每个网络中\n * 在完成容器生命周期后，运行时必须以相反的顺序执行插件（相对于执行添加容器的顺序）以将容器与网络断开连接\n * 容器运行时不能为同一容器调用并行操作，但可以为不同的容器调用并行操作\n * 容器运行时必须为容器订阅add和del操作，这样add后面总是跟着相应的del。 del可能跟着额外的del，但是，插件应该允许处理多个del（即插件del应该是幂等的）。\n * 容器必须由 containerid 唯一标识。存储状态的插件应该使用（网络名称，容器id）的主键来完成。\n * 运行时不能调用同一个网络名称或容器id执行两次add（没有相应的del）。换句话说，给定的容器id必须只能添加到特定的网络一次。\n\ncni插件\n\n * cni插件必须实现一个可执行文件，这个文件可以被容器管理系统调用\n * cni插件负责将网络接口插入容器网络命名空间（例如，veth对的一端），并在主机上进行任何必要的改变（例如将veth的另一端连接到网桥）。然后将ip分配给接口，并通过调用适当的ipam(ip address management)插件来设置与“ip地址管理”部分一致的路由。\n\n\n# 实现\n\n# 容器创建\n\n接下来，我们跟随 pod 创建过程，看看 pod 的网络构建。k8s pod 的网络是这样创建的：\n\n 1. 首先 kubelet 创建基础容器 pause 生成对应的 network namespace\n 2. 然后 kubelet 调用网络 cni driver，由它根据配置调用具体的 cni 插件\n 3. 然后 cni 插件给基础容器配置网络\n 4. 最后创建 pod 中其他容器共享使用基础容器的网络\n\n常见的 cni 插件实现方案有：\n\n * 隧道方案\n   * 隧道方案在iaas层的网络中应用也比较多，将pod分布在一个大二层的网络规模下。网络拓扑简单，但随着节点规模的增长复杂度会提升。\n   * 如：\n     * weave：udp广播，本机建立新的br，通过pcap互通\n     * open vswitch（ovs）：基于vxlan和gre协议，但是性能方面损失比较严重\n     * flannel：udp广播，vxlan\n * 路由方案\n   * 路由方案一般是从3层或者2层实现隔离和跨主机容器互通的，出了问题也很容易排查。\n   * 如\n     * calico：基于bgp协议的路由方案，支持很细致的acl控制，对混合云亲和度比较高。\n     * macvlan：从逻辑和kernel层来看隔离性和性能最优的方案，基于二层隔离，所以需要二层路由器支持，大多数云服务商不支持，所以混合云上比较难以实现。\n\n这些插件各有优势，也在互相借鉴学习优点。这里介绍下常见的 flannel、calico：\n\n# flannel\n\nflannel 是由 coreos 开发的一个比较简单的 overlay 网络，可能是目前最受欢迎的 cni 插件了。一般来说，flannel 已经能够满足大多数的使用场景了，并且性能也比较好，所以，一般来说，只有在 flannel 不能满足需要的时候，才考虑使用其他的 cni 插件。\n\nflannel 的工作流程大致如下：\n\n * 首先在启动 k8s controller manager 时，需要指定集群的 pod ip 范围：--cluster-cidr=172.16.0.0/16, 并开启为 node 分配 ip 选项：--allocate-node-cidrs=true\n * controller manager会把为每个node分配的ip范围保存到 etcd 中 (flannel 也会使用 etcd 来存储它的状态信息)\n * 新建 pod 时，flannel 会从 etcd 中取出属于该 node 的 ip 分配给 pod，再在 etcd 中记录下这个 pod 的 ip\n * 这样 etcd 中就会存有一张 node ip 与 pod id 对应的“路由表”\n\nflannel 的路由流程：\n\n * 当 pod 在同一个 node 之内通信时，通过 docker bridge 即可\n * 当 pod 需要跨 node 通信时，数据包经过 node 中的路由会到 flannel(flanneld) 中，flannel 通过 etcd 查询到目的 pod ip 的 node ip，使用flannel的backends对数据包进行分装，发送给目的node处理。目的node拿到数据包后解开封装，拿到原始数据包，再通过node的路由送到相应的pod。\n\nflannel 有多种不同的 backends (如 udp，vxlan、host-gw)来进行 封包和路由，默认的也是推荐的方式是：vxlan，相对于其他的实现，它提供了较好的性能和需要较少的人工干预。\n\n\n\n# calico\n\ncalico 是一个纯三层的数据中心网络方案（不需要overlay），并且与openstack、kubernetes、aws、gce等iaas和容器平台都有良好的集成。它为每个容器会分配一个可路由的ip，由于通信时不需要解包和封包，网络性能损耗小，易于排查。\n\ncalico在每一个节点利用 linux kernel 实现了一个高效的 vrouter 来负责数据转发，而每个 vrouter 通过 bgp 协议负责把自己上运行的 workload 的路由信息向整个 calico 网络内传播。\n\n小规模部署的 calico 网络可以直接互联，大规模下可通过指定的 bgp route reflector 来完成。 这样保证最终所有的 workload 之间的数据流量都是通过 ip 路由的方式完成互联的。calico节点组网可以直接利用数据中心的网络结构(无论是l2或者l3)，不需要额外的nat，隧道或者overlay network。\n\n\n\ncalico主要由 felix、etcd、bgp client 以及 bgp route reflector 组成\n\n * felix：calico agent，每个节点都需要运行，主要负责配置路由、配置acls、报告状态，确保endpoint的连通状态\n * bgp client: 主要负责把 felix 写入 kernel 的路由信息分发到当前 calico 网络其他节点，确保 workload 间的通信的有效性\n * etcd: 分布式键值存储，主要负责存储网络信息，确保 calico 网络状态的准确性\n * bgp route reflector: 大规模部署时使用，作为bgp client的中心连接点, 摒弃所有节点互联的 mesh 模式，避免每个节点互联, 通过一个或者多个bgp route reflector来完成集中式的路由分发\n\ncalico的不足\n\n * 不支持多租户网络的隔离功能，在多租户场景下会有网络安全问题\n * calico控制平面的设计要求物理网络得是l2 fabric，这样vrouter间都是直接可达的\n\n\n# 问题\n\n * docker0、cni0、kube-ipvs0 的区别\n\n\n# reference\n\n * cluster networking\n * network design-proposals\n * cni (container network interface)\n * cnm (container network model)\n * understanding-kubernetes-networking-model",charsets:{cjk:!0}},{title:"K8S网络之service间的通信",frontmatter:{title:"K8S网络之service间的通信",date:"2021-01-05T21:36:12.000Z",description:"K8S网络之service间的通信",categories:["skills","devops"],tags:[null],permalink:null},regularPath:"/blog/skills/devops/k8s_net_srv.html",relativePath:"blog/skills/devops/k8s_net_srv.md",key:"v-66696d37",path:"/blog/skills/devops/k8s_net_srv.html",headers:[{level:2,title:"ipvs 的特点",slug:"ipvs-的特点",normalizedTitle:"ipvs 的特点",charIndex:115},{level:2,title:"正文",slug:"正文",normalizedTitle:"正文",charIndex:742},{level:2,title:"实践",slug:"实践",normalizedTitle:"实践",charIndex:5580},{level:2,title:"思考",slug:"思考",normalizedTitle:"思考",charIndex:5765},{level:2,title:"说明",slug:"说明",normalizedTitle:"说明",charIndex:5862},{level:2,title:"reference",slug:"reference",normalizedTitle:"reference",charIndex:2276}],headersStr:"ipvs 的特点 正文 实践 思考 说明 reference",content:"# K8S网络之service间的通信\n\n从 k8s 1.8 开始，kube-proxy 组件在 iptables模式和用户模式 之外增加了 ipvs模式的支持。从 k8s 1.12 开始，ipvs模式成为默认操作模式。\n\n\n# ipvs 的特点\n\nipvs模式 与 iptables模式 的不同之处在于：\n\n 1. ipvs 在大型集群下提供了更好的扩展性 和 性能\n    \n    一个例子，在5000节点集群中使用 NodePort 服务，如果我们有2000个服务并且每个服务有10个 pod，这将在每个工作节点上至少产生20000个 iptable 记录，这可能使内核非常繁忙。\n\n 2. ipvs 提供了更加优雅和丰富的负载均衡算法\n    \n    例如，least load, least connections, locality, weighted, etc.\n\n 3. ipvs 支持 server 的健康检查 和 连接重试 等等\n\nipvs模式也会使用 IPTABLES， 以处理 packet filtering, SNAT, masquerade. 确切的说是，ipvs模式会使用 ipset 存储需要需要 DROP 或 masquared 的流量的源或目标地址, 以确保 IPTABLES 规则数保持稳定, 无论集群里有多少 service。\n\n另外，ipvs 需要对vs(虚拟服务也就是vip)进行管理，由于 ipvs 的 DNAT 钩子挂在 INPUT 链上，因此必须要让内核识别 VIP(cluster-ip) 是本机的 IP。k8s 通过设置将 service cluster ip 绑定到虚拟网卡 kube-ipvs0 来实现这一点。\n\n\n# 正文\n\n假定集群有两个服务：gate(1 pod)、srv_a(3 pods), 从 gate 的 pod 发起请求 到 srv 的 cluster ip。我们来看看，整个链路的状态吧。\n\n首先，获取到两个服务和相关pod的ip地址：\n\n * cluster ： kubectl get service --all-namespaces\n * pod：kubectl get pod --all-namespaces | grep '[service name]'\n\n在我的测试集群，ip 信息如下：\n\nservice:\n    srv_a                     NodePort       10.105.159.33    <none>           8000:32502/TCP     7d\n    gate                      NodePort       10.105.159.203   <none>           8000:30610/TCP     7d\npod:\n    gate-747d45c4bd-tmk62                1/1       Running            0          6d     10.105.130.70    xx.xx.xx.xx\n\n    srv_a-64c7ddc54d-48hsd               1/1       Running            0          23h    10.105.130.151   xx.xx.xx.xx\n    srv_a-64c7ddc54d-fc87r               1/1       Running            0          23h    10.105.130.153   xx.xx.xx.xx\n    srv_a-64c7ddc54d-qbs95               1/1       Running            0          23h    10.105.130.152   xx.xx.xx.xx\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n从 pod 出来的数据包会从 docker 容器内通过 veth pair 设备进入宿主 Node 的 network namespace。通过 宿主Node 的路由转发功能，数据先进入到了 iptable 的 PREROUTING chain 中，我们查看这个chain：\n\niptables -nL -t nat | grep PREROUTING -A5\n\n#:\n    Chain PREROUTING (policy ACCEPT)\n    target     prot opt source               destination\n    KUBE-SERVICES  all  --  0.0.0.0/0            0.0.0.0/0            /* kubernetes service portals */\n\n\n1\n2\n3\n4\n5\n6\n\n\n此时，数据包源ip 为 pod ip，源端口为随机端口，目标ip 为 cluster ip，目标port 为指定 port。\n\n据这个chain，数据包会进入到 KUBE-SERVICES 中。\n\niptables -nL -t nat | grep 'KUBE-SERVICES' -A5\n\n#:\n    Chain KUBE-SERVICES (2 references)\n    target     prot opt source               destination\n    KUBE-MARK-MASQ  all  --  0.0.0.0/0            0.0.0.0/0            match-set KUBE-CLUSTER-IP dst,dst\n    KUBE-MARK-MASQ  all  --  0.0.0.0/0            0.0.0.0/0            match-set KUBE-LOAD-BALANCER-MASQ dst,dst\n    KUBE-MARK-MASQ  tcp  --  0.0.0.0/0            0.0.0.0/0            tcp match-set KUBE-NODE-PORT-TCP dst\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n这里需要注意下，会根据 ipset 的不同，KUBE-SERVICES 有多条规则。这个需要根据，具体的访问方式，来决定具体使用哪个规则。\n\n在这里，我们使用的是集群内 cluster ip 访问服务的方式，所以，数据包会匹配ipset KUBE-CLUSTER-IP。在这里匹配了这个ipset之后进入了 KUBE-MARK-MASQ 这个规则链。(ipset是linux的内核数据结构，可以存储一些ip和端口的信息，ipvs模式的集群通过在iptable中匹配ipset，这样减少了iptable中的entry数量)\n\n可以通过查看 KUBE-CLUSTER-IP 这个 ipset 来验证下 match-set 匹配规则：\n\n// srv-a 的 cluster ip: 10.105.159.33\nipset list KUBE-CLUSTER-IP | grep '10.105.159.33' \n\n#:\n    10.105.159.33,tcp:8000\n\n\n1\n2\n3\n4\n5\n\n\n回到 KUBE-MARK-MASQ 这个 iptable 链，看看它做了什么。\n\niptables -nL -t nat | grep 'Chain KUBE-MARK-MASQ' -A5\n\n#:\n    Chain KUBE-MARK-MASQ (3 references)\n    target     prot opt source               destination\n    MARK       all  --  0.0.0.0/0            0.0.0.0/0            MARK or 0x4000\n\n\n1\n2\n3\n4\n5\n6\n\n\nKUBE-MARK-MASQ 对所有的 items 做了 mark 标记 0x4000 !!!\n\n以上是发生在 PREROUTING chain 过程中，接下来数据包会来到 INPUT chain 还是 FORWARD chain 呢？正如上文提到的，ipvs 工作在 INPUT chain，所以需要将数据包引入 INPUT chain，这个是通过：k8s 通过设置将 service cluster ip 绑定到虚拟网卡 kube-ipvs0 来实现的。完成绑定之后，内核就会识别 VIP(cluster-ip) 为本机的 IP, 使得数据包得到进一步处理。通过 ip addr | grep kube 很容易确认这个绑定。\n\n到这里，数据包已经到了 ipvs。我们来看看 ipvs 对路由的控制：\n\nipvsadm -L | grep '10.105.159.33' -A4\n\n#：\n    TCP  10.105.159.33:irdmi rr\n        -> 10.105.130.151:irdmi         Masq    1      0          0\n        -> 10.105.130.152:irdmi         Masq    1      0          0\n        -> 10.105.130.153:irdmi         Masq    1      0          0\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n可以看到，ipvs 将 vip 映射成3个 endpoints ，并且使用round robin的分配方式，分配权重为1，也就是均匀的实现负载均衡。ipvs 根据这个配置在 INPUT chain 完成这个 DNAT 操作。这时, 源ip 为 pod ip，源端口为随机端口，目标ip 为映射选择的 pod ip，目标 port 为映射选择的 port。\n\n然后，将数据送入 POSTROUTING chain， 而这个 chain 直接转发到 KUBE-POSTROUTING 中：\n\niptables -nL -t nat | grep 'Chain POSTROUTING' -A5\n\n#:\n    Chain POSTROUTING (policy ACCEPT)\n    target     prot opt source               destination\n    KUBE-POSTROUTING  all  --  0.0.0.0/0            0.0.0.0/0            /* kubernetes postrouting rules */\n    IP-MASQ-AGENT  all  --  0.0.0.0/0            0.0.0.0/0            /* ip-masq-agent: ensure nat POSTROUTING directs all non-LOCAL destination traffic to our custom IP-MASQ-AGENT chain */ ADDRTYPE match dst-type !LOCAL\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们来看看 KUBE-POSTROUTING:\n\niptables -nL -t nat | grep 'Chain KUBE-POSTROUTING' -A5\n\n#:\n    Chain KUBE-POSTROUTING (1 references)\n    target     prot opt source               destination\n    MASQUERADE  all  --  0.0.0.0/0            0.0.0.0/0            /* kubernetes service traffic requiring SNAT */ mark match 0x4000/0x4000\n    MASQUERADE  all  --  0.0.0.0/0            0.0.0.0/0            match-set KUBE-LOOP-BACK dst,dst,src\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n匹配到在 KUBE-MARK-MASQ 中做的标记 0x4000 时，对数据包做 MASQUERADE 伪装，也就是做个做 SNAT 操作：把源地址替换成这台宿主机上的 CNI 网桥地址。到这里我们的数据包源ip为下一跳路由所使用网路设备的ip，目标 ip为 ipvs 映射到的 real ip，然后根据 host network namespace 的路由表做下一跳路由选择。\n\n此时，包的目标地址已经到了具体的pod，会通过 k8s 的底层网络(flannel 等)，到达目的地。\n\n为什么只对 标记 0x4000 的包进行 SNAT 处理呢？这是为了避免误操作，只有打了标记的包，才是 k8s 内部的数据。\n\n\n# 实践\n\n最后，我们通过 tcpdump 抓包看看 tcp sync 包的流向：\n\ntcpdump -i any '((host 10.105.159.33 and port 8000) or (host 10.105.130.70 and not port 8000))' | grep '\\[S\\]'\n\n\n1\n\n\n可以看到数据包的源、目标 ip 的变化过程。\n\n\n# 思考\n\n * 为什么 k8s 中需要使用 ipvs 的 nat 模式，可以使用其他模式吗？\n * 通过 node_ip:node_port 方式访问 service 的过程是怎么样的？\n\n\n# 说明\n\n * 10.105.159.33:irdmi 中的 irdmi\n   * irdmi 是端口所对应的服务，具体可以查看：/etc/services 文件 (包含网络服务和它们映射端口的列表)\n\n\n# reference\n\n * k8s ipvs",normalizedContent:"# k8s网络之service间的通信\n\n从 k8s 1.8 开始，kube-proxy 组件在 iptables模式和用户模式 之外增加了 ipvs模式的支持。从 k8s 1.12 开始，ipvs模式成为默认操作模式。\n\n\n# ipvs 的特点\n\nipvs模式 与 iptables模式 的不同之处在于：\n\n 1. ipvs 在大型集群下提供了更好的扩展性 和 性能\n    \n    一个例子，在5000节点集群中使用 nodeport 服务，如果我们有2000个服务并且每个服务有10个 pod，这将在每个工作节点上至少产生20000个 iptable 记录，这可能使内核非常繁忙。\n\n 2. ipvs 提供了更加优雅和丰富的负载均衡算法\n    \n    例如，least load, least connections, locality, weighted, etc.\n\n 3. ipvs 支持 server 的健康检查 和 连接重试 等等\n\nipvs模式也会使用 iptables， 以处理 packet filtering, snat, masquerade. 确切的说是，ipvs模式会使用 ipset 存储需要需要 drop 或 masquared 的流量的源或目标地址, 以确保 iptables 规则数保持稳定, 无论集群里有多少 service。\n\n另外，ipvs 需要对vs(虚拟服务也就是vip)进行管理，由于 ipvs 的 dnat 钩子挂在 input 链上，因此必须要让内核识别 vip(cluster-ip) 是本机的 ip。k8s 通过设置将 service cluster ip 绑定到虚拟网卡 kube-ipvs0 来实现这一点。\n\n\n# 正文\n\n假定集群有两个服务：gate(1 pod)、srv_a(3 pods), 从 gate 的 pod 发起请求 到 srv 的 cluster ip。我们来看看，整个链路的状态吧。\n\n首先，获取到两个服务和相关pod的ip地址：\n\n * cluster ： kubectl get service --all-namespaces\n * pod：kubectl get pod --all-namespaces | grep '[service name]'\n\n在我的测试集群，ip 信息如下：\n\nservice:\n    srv_a                     nodeport       10.105.159.33    <none>           8000:32502/tcp     7d\n    gate                      nodeport       10.105.159.203   <none>           8000:30610/tcp     7d\npod:\n    gate-747d45c4bd-tmk62                1/1       running            0          6d     10.105.130.70    xx.xx.xx.xx\n\n    srv_a-64c7ddc54d-48hsd               1/1       running            0          23h    10.105.130.151   xx.xx.xx.xx\n    srv_a-64c7ddc54d-fc87r               1/1       running            0          23h    10.105.130.153   xx.xx.xx.xx\n    srv_a-64c7ddc54d-qbs95               1/1       running            0          23h    10.105.130.152   xx.xx.xx.xx\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n从 pod 出来的数据包会从 docker 容器内通过 veth pair 设备进入宿主 node 的 network namespace。通过 宿主node 的路由转发功能，数据先进入到了 iptable 的 prerouting chain 中，我们查看这个chain：\n\niptables -nl -t nat | grep prerouting -a5\n\n#:\n    chain prerouting (policy accept)\n    target     prot opt source               destination\n    kube-services  all  --  0.0.0.0/0            0.0.0.0/0            /* kubernetes service portals */\n\n\n1\n2\n3\n4\n5\n6\n\n\n此时，数据包源ip 为 pod ip，源端口为随机端口，目标ip 为 cluster ip，目标port 为指定 port。\n\n据这个chain，数据包会进入到 kube-services 中。\n\niptables -nl -t nat | grep 'kube-services' -a5\n\n#:\n    chain kube-services (2 references)\n    target     prot opt source               destination\n    kube-mark-masq  all  --  0.0.0.0/0            0.0.0.0/0            match-set kube-cluster-ip dst,dst\n    kube-mark-masq  all  --  0.0.0.0/0            0.0.0.0/0            match-set kube-load-balancer-masq dst,dst\n    kube-mark-masq  tcp  --  0.0.0.0/0            0.0.0.0/0            tcp match-set kube-node-port-tcp dst\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n这里需要注意下，会根据 ipset 的不同，kube-services 有多条规则。这个需要根据，具体的访问方式，来决定具体使用哪个规则。\n\n在这里，我们使用的是集群内 cluster ip 访问服务的方式，所以，数据包会匹配ipset kube-cluster-ip。在这里匹配了这个ipset之后进入了 kube-mark-masq 这个规则链。(ipset是linux的内核数据结构，可以存储一些ip和端口的信息，ipvs模式的集群通过在iptable中匹配ipset，这样减少了iptable中的entry数量)\n\n可以通过查看 kube-cluster-ip 这个 ipset 来验证下 match-set 匹配规则：\n\n// srv-a 的 cluster ip: 10.105.159.33\nipset list kube-cluster-ip | grep '10.105.159.33' \n\n#:\n    10.105.159.33,tcp:8000\n\n\n1\n2\n3\n4\n5\n\n\n回到 kube-mark-masq 这个 iptable 链，看看它做了什么。\n\niptables -nl -t nat | grep 'chain kube-mark-masq' -a5\n\n#:\n    chain kube-mark-masq (3 references)\n    target     prot opt source               destination\n    mark       all  --  0.0.0.0/0            0.0.0.0/0            mark or 0x4000\n\n\n1\n2\n3\n4\n5\n6\n\n\nkube-mark-masq 对所有的 items 做了 mark 标记 0x4000 !!!\n\n以上是发生在 prerouting chain 过程中，接下来数据包会来到 input chain 还是 forward chain 呢？正如上文提到的，ipvs 工作在 input chain，所以需要将数据包引入 input chain，这个是通过：k8s 通过设置将 service cluster ip 绑定到虚拟网卡 kube-ipvs0 来实现的。完成绑定之后，内核就会识别 vip(cluster-ip) 为本机的 ip, 使得数据包得到进一步处理。通过 ip addr | grep kube 很容易确认这个绑定。\n\n到这里，数据包已经到了 ipvs。我们来看看 ipvs 对路由的控制：\n\nipvsadm -l | grep '10.105.159.33' -a4\n\n#：\n    tcp  10.105.159.33:irdmi rr\n        -> 10.105.130.151:irdmi         masq    1      0          0\n        -> 10.105.130.152:irdmi         masq    1      0          0\n        -> 10.105.130.153:irdmi         masq    1      0          0\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n可以看到，ipvs 将 vip 映射成3个 endpoints ，并且使用round robin的分配方式，分配权重为1，也就是均匀的实现负载均衡。ipvs 根据这个配置在 input chain 完成这个 dnat 操作。这时, 源ip 为 pod ip，源端口为随机端口，目标ip 为映射选择的 pod ip，目标 port 为映射选择的 port。\n\n然后，将数据送入 postrouting chain， 而这个 chain 直接转发到 kube-postrouting 中：\n\niptables -nl -t nat | grep 'chain postrouting' -a5\n\n#:\n    chain postrouting (policy accept)\n    target     prot opt source               destination\n    kube-postrouting  all  --  0.0.0.0/0            0.0.0.0/0            /* kubernetes postrouting rules */\n    ip-masq-agent  all  --  0.0.0.0/0            0.0.0.0/0            /* ip-masq-agent: ensure nat postrouting directs all non-local destination traffic to our custom ip-masq-agent chain */ addrtype match dst-type !local\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们来看看 kube-postrouting:\n\niptables -nl -t nat | grep 'chain kube-postrouting' -a5\n\n#:\n    chain kube-postrouting (1 references)\n    target     prot opt source               destination\n    masquerade  all  --  0.0.0.0/0            0.0.0.0/0            /* kubernetes service traffic requiring snat */ mark match 0x4000/0x4000\n    masquerade  all  --  0.0.0.0/0            0.0.0.0/0            match-set kube-loop-back dst,dst,src\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n匹配到在 kube-mark-masq 中做的标记 0x4000 时，对数据包做 masquerade 伪装，也就是做个做 snat 操作：把源地址替换成这台宿主机上的 cni 网桥地址。到这里我们的数据包源ip为下一跳路由所使用网路设备的ip，目标 ip为 ipvs 映射到的 real ip，然后根据 host network namespace 的路由表做下一跳路由选择。\n\n此时，包的目标地址已经到了具体的pod，会通过 k8s 的底层网络(flannel 等)，到达目的地。\n\n为什么只对 标记 0x4000 的包进行 snat 处理呢？这是为了避免误操作，只有打了标记的包，才是 k8s 内部的数据。\n\n\n# 实践\n\n最后，我们通过 tcpdump 抓包看看 tcp sync 包的流向：\n\ntcpdump -i any '((host 10.105.159.33 and port 8000) or (host 10.105.130.70 and not port 8000))' | grep '\\[s\\]'\n\n\n1\n\n\n可以看到数据包的源、目标 ip 的变化过程。\n\n\n# 思考\n\n * 为什么 k8s 中需要使用 ipvs 的 nat 模式，可以使用其他模式吗？\n * 通过 node_ip:node_port 方式访问 service 的过程是怎么样的？\n\n\n# 说明\n\n * 10.105.159.33:irdmi 中的 irdmi\n   * irdmi 是端口所对应的服务，具体可以查看：/etc/services 文件 (包含网络服务和它们映射端口的列表)\n\n\n# reference\n\n * k8s ipvs",charsets:{cjk:!0}},{title:"K8S 的 rolling update",frontmatter:{title:"K8S 的 rolling update",date:"2020-06-05T00:00:00.000Z",description:"k8s rolling update",categories:["skills","devops"],tags:[null],permalink:null},regularPath:"/blog/skills/devops/k8s_rolling_update.html",relativePath:"blog/skills/devops/k8s_rolling_update.md",key:"v-71519a9f",path:"/blog/skills/devops/k8s_rolling_update.html",headers:[{level:2,title:"测试",slug:"测试",normalizedTitle:"测试",charIndex:337},{level:2,title:"结果",slug:"结果",normalizedTitle:"结果",charIndex:879},{level:2,title:"结论",slug:"结论",normalizedTitle:"结论",charIndex:2713},{level:2,title:"附",slug:"附",normalizedTitle:"附",charIndex:2815}],headersStr:"测试 结果 结论 附",content:"# K8S 之 rolling update\n\n最近一个重要业务在接入了反向代理后，在服务发布时出现请求 502 的问题，以此为契机，想了解下 k8s 的滚动升级过程中发生了什么。\n\n原来我以为，在指定以下参数时(假定集群资源充足)，并且我们自己的服务可以做到 gracefull terminate 的话，整个系统理论上可以做到完美过渡迁移\n\nstrategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n\nterminationGracePeriodSeconds: 30\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n但是，实际上会有微弱的过渡期(在测试集群150ms左右)。\n\n\n# 测试\n\n我的测试服务：在资源充足的 k8s 集群内，部署两个服务：同时，在集群外以 qps=100 的速度持续请求 gateway:\n\ngateway\n    功能：反向代理到后端服务(serv)\n    实例：1 pod\nserv\n    功能：简单的查询功能\n    实例：1 pod\n\n\n1\n2\n3\n4\n5\n6\n\n\n通过测试脚本(见文末)触发 rolling update, 并使用 tcpdump 抓取切换过程中的 tcp 包状况，还可以通过下述 shell 观察 ipvs 中路由变化情况：\n\nwhile [ True ];do\n    kubectl get pods -o wide --namespace=test | grep $serv_name\n    ipvsadm -Ln | grep $serv_cluster_ip -A4\n    sleep 0.1s\n    echo \"================>\"\ndone\n\n\n1\n2\n3\n4\n5\n6\n\n\n这里对为什么使用脚本进行操作做个说明，因为在滚动升级过程中，新旧 pod 的 ip 共存的时间很短，所以想通过脚本，自动捕获后相关 ip 后，进行监控。\n\n\n# 结果\n\n先看路由变化情况\n\n================>\n+ kubectl get pods -o wide --namespace=test | grep serv\nserv-7989c475cd-qpdvn                    0/1       Running            0          8s        10.102.102.176   10.46.xxx.xxx\nserv-7bdc4d8476-zk9wc                    1/1       Running            0          2m        10.102.102.199   10.46.xxx.xxx\n+ ipvsadm -Ln | grep 10.101.102.33 -A4\nTCP  10.101.102.33:8000 rr\n  -> 10.102.102.199:8000          Masq    1      0          1871\n+ sleep 0.1s\n\n================>\n+ '[' True ']'\n+ kubectl get pods -o wide --namespace=test | grep serv\nserv-7989c475cd-qpdvn                    1/1       Running            0          8s        10.102.102.176   10.46.xxx.xxx\nserv-7bdc4d8476-zk9wc                    1/1       Terminating        0          2m        10.102.102.199   10.46.xxx.xxx\n+ ipvsadm -Ln\n+ grep 10.101.102.33 -A4\nTCP  10.101.102.33:8000 rr\n  -> 10.102.102.176:8000          Masq    1      0          11\n  -> 10.102.102.199:8000          Masq    1      0          1896\n+ sleep 0.1s\n\n================>\n+ '[' True ']'\n+ kubectl get pods -o wide --namespace=test\n+ grep serv\nserv-7989c475cd-qpdvn                    1/1       Running            0          9s        10.102.102.176   10.46.xxx.xxx\nserv-7bdc4d8476-zk9wc                    1/1       Terminating        0          2m        10.102.102.199   10.46.xxx.xxx\n+ ipvsadm -Ln\n+ grep 10.101.102.33 -A4\nTCP  10.101.102.33:8000 rr\n  -> 10.102.102.176:8000          Masq    1      2          53\n+ sleep 0.1s\n\n================>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n\n\n再来看看 tcpdump 的抓包状况(内容太长就不放具体内容了，有兴趣的可以自行测试)：\n\n可以看到，\n1. 目标为 ip 10.102.102.199 的请求会出现 100ms 左右的，有发出 sync 但没有目标 ip 的确认包\n2. 目标为 ip 10.102.102.199 或 ip 10.102.102.176 的请求共存，大概持续 40ms\n3. 只剩下目标为 ip 10.102.102.176 的请求\n\n\n1\n2\n3\n4\n\n\n\n# 结论\n\n总体来看，在服务能够优雅退出的情况下，k8s 可以做到几乎完美的 rolling update，在大多数情况下完全能够满足我们的需要。如果有其他需要的话，可以自行根据业务进行适当的调整。\n\n\n# 附\n\n * 测试脚本\n\n    # ! /bin/bash\n    set +x\n\n    namespace='test'\n    gate_name='test-gateway'\n    serv_name='test-serv'\n    serv_pod_cnt=2\n\n    gate_cluster_ip=`kubectl get service $gate_name --namespace=$namespace | grep $gate_name | awk '{print($3)}'`\n    serv_cluster_ip=`kubectl get service $serv_name --namespace=$namespace | grep $serv_name | awk '{print($3)}'`\n\n    `kubectl apply -f $serv_name.yaml  --namespace=test`\n\n    while [ True ]; do\n        ipstr=`kubectl get pods -o wide --namespace=$namespace | grep $serv_name | awk '{print($6)}'`\n        if [[ $ipstr == *\"none\"* ]]; then \n            continue\n        fi\n        iparr=(${ipstr// /})\n        if [ ${#iparr[@]} -eq $serv_pod_cnt ]; then\n            break\n        fi \n        sleep 0.1s\n    done\n\n    echo ${iparr[@]}\n\n    hosts=\"(host $gate_cluster_ip) or (host $serv_cluster_ip)\"\n    for (( i=0;i<${#iparr[@]};i++ )); do \n        hosts=$hosts\" or (host  ${iparr[i]})\"\n    done\n\n    cmd_tcpdump=\"tcpdump -i any '($hosts)' | grep '\\[S\\]' > a.txt\"\n    `$cmd_tcpdump`\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n",normalizedContent:"# k8s 之 rolling update\n\n最近一个重要业务在接入了反向代理后，在服务发布时出现请求 502 的问题，以此为契机，想了解下 k8s 的滚动升级过程中发生了什么。\n\n原来我以为，在指定以下参数时(假定集群资源充足)，并且我们自己的服务可以做到 gracefull terminate 的话，整个系统理论上可以做到完美过渡迁移\n\nstrategy:\n    rollingupdate:\n      maxsurge: 1\n      maxunavailable: 0\n    type: rollingupdate\n\nterminationgraceperiodseconds: 30\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n但是，实际上会有微弱的过渡期(在测试集群150ms左右)。\n\n\n# 测试\n\n我的测试服务：在资源充足的 k8s 集群内，部署两个服务：同时，在集群外以 qps=100 的速度持续请求 gateway:\n\ngateway\n    功能：反向代理到后端服务(serv)\n    实例：1 pod\nserv\n    功能：简单的查询功能\n    实例：1 pod\n\n\n1\n2\n3\n4\n5\n6\n\n\n通过测试脚本(见文末)触发 rolling update, 并使用 tcpdump 抓取切换过程中的 tcp 包状况，还可以通过下述 shell 观察 ipvs 中路由变化情况：\n\nwhile [ true ];do\n    kubectl get pods -o wide --namespace=test | grep $serv_name\n    ipvsadm -ln | grep $serv_cluster_ip -a4\n    sleep 0.1s\n    echo \"================>\"\ndone\n\n\n1\n2\n3\n4\n5\n6\n\n\n这里对为什么使用脚本进行操作做个说明，因为在滚动升级过程中，新旧 pod 的 ip 共存的时间很短，所以想通过脚本，自动捕获后相关 ip 后，进行监控。\n\n\n# 结果\n\n先看路由变化情况\n\n================>\n+ kubectl get pods -o wide --namespace=test | grep serv\nserv-7989c475cd-qpdvn                    0/1       running            0          8s        10.102.102.176   10.46.xxx.xxx\nserv-7bdc4d8476-zk9wc                    1/1       running            0          2m        10.102.102.199   10.46.xxx.xxx\n+ ipvsadm -ln | grep 10.101.102.33 -a4\ntcp  10.101.102.33:8000 rr\n  -> 10.102.102.199:8000          masq    1      0          1871\n+ sleep 0.1s\n\n================>\n+ '[' true ']'\n+ kubectl get pods -o wide --namespace=test | grep serv\nserv-7989c475cd-qpdvn                    1/1       running            0          8s        10.102.102.176   10.46.xxx.xxx\nserv-7bdc4d8476-zk9wc                    1/1       terminating        0          2m        10.102.102.199   10.46.xxx.xxx\n+ ipvsadm -ln\n+ grep 10.101.102.33 -a4\ntcp  10.101.102.33:8000 rr\n  -> 10.102.102.176:8000          masq    1      0          11\n  -> 10.102.102.199:8000          masq    1      0          1896\n+ sleep 0.1s\n\n================>\n+ '[' true ']'\n+ kubectl get pods -o wide --namespace=test\n+ grep serv\nserv-7989c475cd-qpdvn                    1/1       running            0          9s        10.102.102.176   10.46.xxx.xxx\nserv-7bdc4d8476-zk9wc                    1/1       terminating        0          2m        10.102.102.199   10.46.xxx.xxx\n+ ipvsadm -ln\n+ grep 10.101.102.33 -a4\ntcp  10.101.102.33:8000 rr\n  -> 10.102.102.176:8000          masq    1      2          53\n+ sleep 0.1s\n\n================>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n\n\n再来看看 tcpdump 的抓包状况(内容太长就不放具体内容了，有兴趣的可以自行测试)：\n\n可以看到，\n1. 目标为 ip 10.102.102.199 的请求会出现 100ms 左右的，有发出 sync 但没有目标 ip 的确认包\n2. 目标为 ip 10.102.102.199 或 ip 10.102.102.176 的请求共存，大概持续 40ms\n3. 只剩下目标为 ip 10.102.102.176 的请求\n\n\n1\n2\n3\n4\n\n\n\n# 结论\n\n总体来看，在服务能够优雅退出的情况下，k8s 可以做到几乎完美的 rolling update，在大多数情况下完全能够满足我们的需要。如果有其他需要的话，可以自行根据业务进行适当的调整。\n\n\n# 附\n\n * 测试脚本\n\n    # ! /bin/bash\n    set +x\n\n    namespace='test'\n    gate_name='test-gateway'\n    serv_name='test-serv'\n    serv_pod_cnt=2\n\n    gate_cluster_ip=`kubectl get service $gate_name --namespace=$namespace | grep $gate_name | awk '{print($3)}'`\n    serv_cluster_ip=`kubectl get service $serv_name --namespace=$namespace | grep $serv_name | awk '{print($3)}'`\n\n    `kubectl apply -f $serv_name.yaml  --namespace=test`\n\n    while [ true ]; do\n        ipstr=`kubectl get pods -o wide --namespace=$namespace | grep $serv_name | awk '{print($6)}'`\n        if [[ $ipstr == *\"none\"* ]]; then \n            continue\n        fi\n        iparr=(${ipstr// /})\n        if [ ${#iparr[@]} -eq $serv_pod_cnt ]; then\n            break\n        fi \n        sleep 0.1s\n    done\n\n    echo ${iparr[@]}\n\n    hosts=\"(host $gate_cluster_ip) or (host $serv_cluster_ip)\"\n    for (( i=0;i<${#iparr[@]};i++ )); do \n        hosts=$hosts\" or (host  ${iparr[i]})\"\n    done\n\n    cmd_tcpdump=\"tcpdump -i any '($hosts)' | grep '\\[s\\]' > a.txt\"\n    `$cmd_tcpdump`\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n",charsets:{cjk:!0}},{title:"OpenTracing 简介",frontmatter:{title:"OpenTracing 简介",date:"2020-04-13T00:00:00.000Z",description:"OpenTracing 简介",permalink:null,categories:["blog","skills","devops"],tags:[null]},regularPath:"/blog/skills/devops/opentracing_overview.html",relativePath:"blog/skills/devops/opentracing_overview.md",key:"v-6ca7651f",path:"/blog/skills/devops/opentracing_overview.html",headers:[{level:2,title:"OpenTracing 简介",slug:"opentracing-简介",normalizedTitle:"opentracing 简介",charIndex:2},{level:3,title:"opentracing 关键词",slug:"opentracing-关键词",normalizedTitle:"opentracing 关键词",charIndex:148},{level:3,title:"opentracing 实现对比",slug:"opentracing-实现对比",normalizedTitle:"opentracing 实现对比",charIndex:1033},{level:3,title:"jaeger",slug:"jaeger",normalizedTitle:"jaeger",charIndex:1229},{level:3,title:"zipkin",slug:"zipkin",normalizedTitle:"zipkin",charIndex:1439}],headersStr:"OpenTracing 简介 opentracing 关键词 opentracing 实现对比 jaeger zipkin",content:'# OpenTracing 简介\n\n * reference\n   * The OpenTracing Semantic Specification\n   * OpenTracing API for Go\n   * 从Zipkin到Jaeger，Uber的分布式追踪之道tchannel\n\n\n# opentracing 关键词\n\n * 基本方法：Inject, Extract, 和 Carriers Span 可以包含很多的tags、logs和baggage，但是始终需要一个高度概括的operation name\n * 名词解释\n   * Trace : 一个 trace 代表了一个事务或者流程在分布式系统中的执行过程\n   * Span : 一个 span 代表在分布式系统中完成的单个工作单元。也包含其他 span 的"引用"，这允许将多个 spans 组合成一个完整的 Trace\n     \n         每个 span 根据 OpenTracing 规范封装以下内容：\n             操作名称\n             开始时间和结束时间\n             span Tags key:value \n             span Logs key:value \n             SpanContext\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     \n     * Tags : Span tags(跨度标签)可以理解为用户自定义的 Span 注释。便于查询、过滤和理解跟踪数据\n     * Logs : Span logs(跨度日志)可以记录 Span 内特定时间或事件的日志信息。主要用于捕获特定 Span 的日志信息以及应用程序本身的其他信息输出\n     * SpanContext : SpanContext 代表跨越进程边界，传递到子级 Span 的状态。常用做在跨域API边界时的上下文传递。\n   * Baggage Items : Baggage Items 可以理解为 trace 全局运行中额外传输的数据集合\n * 实现\n   * grpc : 通过附加 tracer 的信息到 context 来实现跨越边界传递\n   * http : 通过附加 tracer 的信息到 header 来实现跨越边界传递\n\n\n# opentracing 实现对比\n\n产品名称         厂商        开发语言   OPENTRACING标准   侵入性    时效性                                                       决策支持                                    可视化            低消耗     延展性\njaeger       uber      go     完全              部分侵入   时效性高， UDP协议传输数据(在Uber任意给定的一个Jaeger安装可以很容易地每天处理几十亿spans)   决策支持较好，并且底层支持metrics指标                  报表不丰富，UI比较简单   消耗低     jaeger比较复杂，使用框架较多。但经过uber大规模使用，延展性好\nzipkin       twitter   java   部分              侵入性强   时效性好                                                      决策一般(功能单一，监控维度和监控信息不够丰富。没有告警功能)         数据报表丰富         系统开销小   延展性好\nskywalking   华为        java   完全              侵入性低   时效性好                                                      虽然调用链路更细化，但作者在性能和追踪细粒度之间保持了比较好的平衡。决策好   数据报表丰富         消耗较低    延展性非常好，水平理论上无限扩展\n\n\n# jaeger\n\n\n\n * 核心组件\n   * Jaeger核心后端组件：jaeger-agent、jaeger-collector、jaeger-query\n   * 其中 jaeger-agent、jaeger-collector 都可以通过分布式部署 配合 LB 很容易做到横向扩展，所以对于业务体量较大的场景很有优势\n * 持久化\n   * Collectors require a persistent storage backend. Cassandra 3.x (default) and ElasticSearch are the primary supported storage backends. There is ongoing work to add support for MySQL and ScyllaDB.\n * 采样方式\n   * 固定采样、随机采样、限流采样等，采样方式丰富\n * 部署\n   * all in one\n     \n     (不适合生产环境)\n         docker run -d -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 -p 5775:5775/udp -p 6831:6831/udp -p 6832:6832/udp -p 5778:5778 -p 16686:16686 -p 14268:14268 -p 9411:9411 jaegertracing/all-in-one:latest \n     \n     \n     1\n     2\n     \n   * 独立部署\n     \n         docker run -d --rm -p 14268:14268 -p 9411:9411 jaegertracing/jaeger-collector /go/bin/collector-linux --es.server-urls=http://localhost:9200\n     \n         docker run -d --rm -p 5775:5775/udp -p 6831:6831/udp -p 6832:6832/udp -p 5778:5778/tcp jaegertracing/jaeger-agent /go/bin/agent-linux --collector.host-port=jaeger-collector.jaeger-infra.svc:14267\n     \n         docker run -d --rm -p 16686:16686 jaegertracing/jaeger-query /go/bin/query-linux -es.server-urls=http://localhost:9200\n     \n     \n     1\n     2\n     3\n     4\n     5\n     \n   * 端口说明\n     \n         端口\t协议\t所属模块\t     功能\n         5775\tUDP\tagent\t     通过兼容性Thrift协议，接收Zipkin thrift类型数据\n         6831\tUDP\tagent\t     通过兼容性Thrift协议，接收Jaeger thrift类型数据\n         6832\tUDP\tagent\t     通过二进制Thrift协议，接收Jaeger thrift类型数据\n         5778\tHTTP\tagent\t     配置控制服务接口\n         16686\tHTTP\tquery\t     客户端前端界面展示端口\n         14268\tHTTP\tcollector    接收客户端Zipkin thrift类型数据\n         14267\tHTTP\tcollector    接收客户端Jaeger thrift类型数据\n         9411\tHTTP\tcollector    Zipkin兼容endpoint\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     \n * reference\n   * jaegertracing docs\n\n\n# zipkin\n\n\n\n * 持久化\n   * Cassandra、ElasticSearch和MySQL\n * 采样方式\n   * 随机概率采样\n * zikpin 使用示例(可以自己实现grpc.StatsHandler来定制化功能)：\n   \n       import (\n           zipkin "github.com/openzipkin/zipkin-go"\n           zipkingrpc "github.com/openzipkin/zipkin-go/middleware/grpc"\n           zipkinrephttp "github.com/openzipkin/zipkin-go/reporter/http"\n       )\n   \n       func client() {\n           opts := []grpc.DialOption{\n               grpc.WithInsecure(),\n               func() grpc.DialOption {\n                   tracer, _ := zipkin.NewTracer(zipkinrephttp.NewReporter("http://127.0.0.1:9411/api/v2/spans"),  zipkin.WithSampler(zipkin.AlwaysSample))\n                   return grpc.WithStatsHandler(zipkingrpc.NewClientHandler(tracer))\n               }()\n           }\n           conn, err := grpc.Dial(fmt.Sprintf("%v:%v", svcData.Address, svcData.Port), opts ...)\n           ...\n       } \n   \n       func server() {\n           tracer, _ := zipkin.NewTracer(zipkinrephttp.NewReporter("http://127.0.0.1:9411/api/v2/spans"), zipkin.WithSampler(zipkin.AlwaysSample))\n           opt = append(opt, grpc.StatsHandler(zipkingrpc.NewServerHandler(tracer)))\n           ...\n           wserver.Server = grpc.NewServer(opt...)\n       } \n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   19\n   20\n   21\n   22\n   23\n   24\n   ',normalizedContent:'# opentracing 简介\n\n * reference\n   * the opentracing semantic specification\n   * opentracing api for go\n   * 从zipkin到jaeger，uber的分布式追踪之道tchannel\n\n\n# opentracing 关键词\n\n * 基本方法：inject, extract, 和 carriers span 可以包含很多的tags、logs和baggage，但是始终需要一个高度概括的operation name\n * 名词解释\n   * trace : 一个 trace 代表了一个事务或者流程在分布式系统中的执行过程\n   * span : 一个 span 代表在分布式系统中完成的单个工作单元。也包含其他 span 的"引用"，这允许将多个 spans 组合成一个完整的 trace\n     \n         每个 span 根据 opentracing 规范封装以下内容：\n             操作名称\n             开始时间和结束时间\n             span tags key:value \n             span logs key:value \n             spancontext\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     \n     * tags : span tags(跨度标签)可以理解为用户自定义的 span 注释。便于查询、过滤和理解跟踪数据\n     * logs : span logs(跨度日志)可以记录 span 内特定时间或事件的日志信息。主要用于捕获特定 span 的日志信息以及应用程序本身的其他信息输出\n     * spancontext : spancontext 代表跨越进程边界，传递到子级 span 的状态。常用做在跨域api边界时的上下文传递。\n   * baggage items : baggage items 可以理解为 trace 全局运行中额外传输的数据集合\n * 实现\n   * grpc : 通过附加 tracer 的信息到 context 来实现跨越边界传递\n   * http : 通过附加 tracer 的信息到 header 来实现跨越边界传递\n\n\n# opentracing 实现对比\n\n产品名称         厂商        开发语言   opentracing标准   侵入性    时效性                                                       决策支持                                    可视化            低消耗     延展性\njaeger       uber      go     完全              部分侵入   时效性高， udp协议传输数据(在uber任意给定的一个jaeger安装可以很容易地每天处理几十亿spans)   决策支持较好，并且底层支持metrics指标                  报表不丰富，ui比较简单   消耗低     jaeger比较复杂，使用框架较多。但经过uber大规模使用，延展性好\nzipkin       twitter   java   部分              侵入性强   时效性好                                                      决策一般(功能单一，监控维度和监控信息不够丰富。没有告警功能)         数据报表丰富         系统开销小   延展性好\nskywalking   华为        java   完全              侵入性低   时效性好                                                      虽然调用链路更细化，但作者在性能和追踪细粒度之间保持了比较好的平衡。决策好   数据报表丰富         消耗较低    延展性非常好，水平理论上无限扩展\n\n\n# jaeger\n\n\n\n * 核心组件\n   * jaeger核心后端组件：jaeger-agent、jaeger-collector、jaeger-query\n   * 其中 jaeger-agent、jaeger-collector 都可以通过分布式部署 配合 lb 很容易做到横向扩展，所以对于业务体量较大的场景很有优势\n * 持久化\n   * collectors require a persistent storage backend. cassandra 3.x (default) and elasticsearch are the primary supported storage backends. there is ongoing work to add support for mysql and scylladb.\n * 采样方式\n   * 固定采样、随机采样、限流采样等，采样方式丰富\n * 部署\n   * all in one\n     \n     (不适合生产环境)\n         docker run -d -e collector_zipkin_http_port=9411 -p 5775:5775/udp -p 6831:6831/udp -p 6832:6832/udp -p 5778:5778 -p 16686:16686 -p 14268:14268 -p 9411:9411 jaegertracing/all-in-one:latest \n     \n     \n     1\n     2\n     \n   * 独立部署\n     \n         docker run -d --rm -p 14268:14268 -p 9411:9411 jaegertracing/jaeger-collector /go/bin/collector-linux --es.server-urls=http://localhost:9200\n     \n         docker run -d --rm -p 5775:5775/udp -p 6831:6831/udp -p 6832:6832/udp -p 5778:5778/tcp jaegertracing/jaeger-agent /go/bin/agent-linux --collector.host-port=jaeger-collector.jaeger-infra.svc:14267\n     \n         docker run -d --rm -p 16686:16686 jaegertracing/jaeger-query /go/bin/query-linux -es.server-urls=http://localhost:9200\n     \n     \n     1\n     2\n     3\n     4\n     5\n     \n   * 端口说明\n     \n         端口\t协议\t所属模块\t     功能\n         5775\tudp\tagent\t     通过兼容性thrift协议，接收zipkin thrift类型数据\n         6831\tudp\tagent\t     通过兼容性thrift协议，接收jaeger thrift类型数据\n         6832\tudp\tagent\t     通过二进制thrift协议，接收jaeger thrift类型数据\n         5778\thttp\tagent\t     配置控制服务接口\n         16686\thttp\tquery\t     客户端前端界面展示端口\n         14268\thttp\tcollector    接收客户端zipkin thrift类型数据\n         14267\thttp\tcollector    接收客户端jaeger thrift类型数据\n         9411\thttp\tcollector    zipkin兼容endpoint\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     \n * reference\n   * jaegertracing docs\n\n\n# zipkin\n\n\n\n * 持久化\n   * cassandra、elasticsearch和mysql\n * 采样方式\n   * 随机概率采样\n * zikpin 使用示例(可以自己实现grpc.statshandler来定制化功能)：\n   \n       import (\n           zipkin "github.com/openzipkin/zipkin-go"\n           zipkingrpc "github.com/openzipkin/zipkin-go/middleware/grpc"\n           zipkinrephttp "github.com/openzipkin/zipkin-go/reporter/http"\n       )\n   \n       func client() {\n           opts := []grpc.dialoption{\n               grpc.withinsecure(),\n               func() grpc.dialoption {\n                   tracer, _ := zipkin.newtracer(zipkinrephttp.newreporter("http://127.0.0.1:9411/api/v2/spans"),  zipkin.withsampler(zipkin.alwayssample))\n                   return grpc.withstatshandler(zipkingrpc.newclienthandler(tracer))\n               }()\n           }\n           conn, err := grpc.dial(fmt.sprintf("%v:%v", svcdata.address, svcdata.port), opts ...)\n           ...\n       } \n   \n       func server() {\n           tracer, _ := zipkin.newtracer(zipkinrephttp.newreporter("http://127.0.0.1:9411/api/v2/spans"), zipkin.withsampler(zipkin.alwayssample))\n           opt = append(opt, grpc.statshandler(zipkingrpc.newserverhandler(tracer)))\n           ...\n           wserver.server = grpc.newserver(opt...)\n       } \n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   19\n   20\n   21\n   22\n   23\n   24\n   ',charsets:{cjk:!0}},{title:"MS Shell Link 格式简析",frontmatter:{title:"MS Shell Link 格式简析",date:"2021-11-11T19:32:00.000Z",lastmod:null,description:"MS Shell Link 格式解析",categories:["skills"],tags:["ole","ms shell link"],permalink:null},regularPath:"/blog/skills/office/ms_shellink.html",relativePath:"blog/skills/office/ms_shellink.md",key:"v-15864453",path:"/blog/skills/office/ms_shellink.html",headers:[{level:2,title:"Shell Link Binary File Format",slug:"shell-link-binary-file-format",normalizedTitle:"shell link binary file format",charIndex:150},{level:3,title:"ShellLinkHeader",slug:"shelllinkheader",normalizedTitle:"shelllinkheader",charIndex:434},{level:3,title:"LinkTargetIDList",slug:"linktargetidlist",normalizedTitle:"linktargetidlist",charIndex:517},{level:2,title:"Reference",slug:"reference",normalizedTitle:"reference",charIndex:1181}],headersStr:"Shell Link Binary File Format ShellLinkHeader LinkTargetIDList Reference",content:'# MS-SHLLINK\n\n对于 window 下的 "快捷方式" 功能，大家应该都比较熟悉了。它主要用于快速访问另一个位置（或路径）。在UNIX系统中，称为符号链接，而在Windows中，这样的文件被称为 "shell link"。Shell-Link 的文件名后缀为".LNK"，文件内容是按照 Shell Link Binary File Format 的规范，定义的二进制数据对象，其中包含了可用于访问另一个数据对象的信息。\n\nShell link通常用于支持应用程序启动和链接方案，例如对象链接和嵌入（OLE）。\n\n\n# Shell Link Binary File Format\n\nLNK 文件格式可以表达如下：SHELL_LINK = SHELL_LINK_HEADER [LINKTARGET_IDLIST] [LINKINFO] [STRING_DATA] *EXTRA_DATA, 其中\n\n * SHELL_LINK_HEADER：\n   * 一个ShellLinkHeader结构，包含了确认信息，时间戳，以及指明一些可选结构是否存在的flags\n * LINKTARGET_IDLIST：\n   * 一个可选的LinkTargetIDList结构，指定了link的target\n * LINKINFO\n   * 一个可选的LinkInfo结构，指明了处理link target必需的信息\n * STRING_DATA\n   * 0个或多个StringData结构，用于传递用户接口和路径标识信息\n * EXTRA_DATA\n   * 0个或多个和ExtraData结构\n\n需要注意的是，若无特殊说明，MS-SHLLINK 文档中定义的数据结构的字节序都是 little-endian.\n\n\n# ShellLinkHeader\n\n在 [MS-SHLLINK]: Shell Link (.LNK) Binary File Format 中有详细说明，这里不再赘述。\n\n\n# LinkTargetIDList\n\n在 [MS-SHLLINK]: Shell Link (.LNK) Binary File Format 中说明如下：\n\n+ LinkTargetIDList\n    + IDListSize (2 bytes)\n    + IDList (variable)\n        + ItemIDList (variable)\n            + ItemIDSize (2 bytes)\n            + Data (variable)\n        + TerminalID (2 bytes)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n可以看到，Data 字段没有更加细节的说明，这里对其做进一步补充。\n\n\n# Reference\n\n * [MS-SHLLINK]: Shell Link (.LNK) Binary File Format\n * CVE-2020-0729：Windows LNK远程代码执行漏洞分析',normalizedContent:'# ms-shllink\n\n对于 window 下的 "快捷方式" 功能，大家应该都比较熟悉了。它主要用于快速访问另一个位置（或路径）。在unix系统中，称为符号链接，而在windows中，这样的文件被称为 "shell link"。shell-link 的文件名后缀为".lnk"，文件内容是按照 shell link binary file format 的规范，定义的二进制数据对象，其中包含了可用于访问另一个数据对象的信息。\n\nshell link通常用于支持应用程序启动和链接方案，例如对象链接和嵌入（ole）。\n\n\n# shell link binary file format\n\nlnk 文件格式可以表达如下：shell_link = shell_link_header [linktarget_idlist] [linkinfo] [string_data] *extra_data, 其中\n\n * shell_link_header：\n   * 一个shelllinkheader结构，包含了确认信息，时间戳，以及指明一些可选结构是否存在的flags\n * linktarget_idlist：\n   * 一个可选的linktargetidlist结构，指定了link的target\n * linkinfo\n   * 一个可选的linkinfo结构，指明了处理link target必需的信息\n * string_data\n   * 0个或多个stringdata结构，用于传递用户接口和路径标识信息\n * extra_data\n   * 0个或多个和extradata结构\n\n需要注意的是，若无特殊说明，ms-shllink 文档中定义的数据结构的字节序都是 little-endian.\n\n\n# shelllinkheader\n\n在 [ms-shllink]: shell link (.lnk) binary file format 中有详细说明，这里不再赘述。\n\n\n# linktargetidlist\n\n在 [ms-shllink]: shell link (.lnk) binary file format 中说明如下：\n\n+ linktargetidlist\n    + idlistsize (2 bytes)\n    + idlist (variable)\n        + itemidlist (variable)\n            + itemidsize (2 bytes)\n            + data (variable)\n        + terminalid (2 bytes)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n可以看到，data 字段没有更加细节的说明，这里对其做进一步补充。\n\n\n# reference\n\n * [ms-shllink]: shell link (.lnk) binary file format\n * cve-2020-0729：windows lnk远程代码执行漏洞分析',charsets:{cjk:!0}},{title:"Office 格式简析",frontmatter:{title:"Office 格式简析",date:"2021-06-18T13:50:00.000Z",lastmod:null,description:"Office 格式简析，查找 宏 以进行病毒检测",categories:["skills"],tags:["ole","ms-cfb","office"],permalink:null},regularPath:"/blog/skills/office/ole_office.html",relativePath:"blog/skills/office/ole_office.md",key:"v-a254d0c2",path:"/blog/skills/office/ole_office.html",headers:[{level:2,title:"一、Malware",slug:"一、malware",normalizedTitle:"一、malware",charIndex:922},{level:3,title:"1.1 漏洞",slug:"_1-1-漏洞",normalizedTitle:"1.1 漏洞",charIndex:1029},{level:3,title:"1.2 宏病毒",slug:"_1-2-宏病毒",normalizedTitle:"1.2 宏病毒",charIndex:1202},{level:3,title:"1.3 Embedded",slug:"_1-3-embedded",normalizedTitle:"1.3 embedded",charIndex:2797},{level:2,title:"二、MS-CFB",slug:"二、ms-cfb",normalizedTitle:"二、ms-cfb",charIndex:2937},{level:2,title:"OLE",slug:"ole",normalizedTitle:"ole",charIndex:119},{level:3,title:"OLE 格式",slug:"ole-格式",normalizedTitle:"ole 格式",charIndex:5058},{level:3,title:"VBA Project 格式",slug:"vba-project-格式",normalizedTitle:"vba project 格式",charIndex:8015},{level:3,title:"Microsoft Office Excel 4.0",slug:"microsoft-office-excel-4-0",normalizedTitle:"microsoft office excel 4.0",charIndex:11043},{level:3,title:"DOC",slug:"doc",normalizedTitle:"doc",charIndex:15056},{level:3,title:"PPT",slug:"ppt",normalizedTitle:"ppt",charIndex:603},{level:3,title:"XLS",slug:"xls",normalizedTitle:"xls",charIndex:2439},{level:2,title:"OOXML",slug:"ooxml",normalizedTitle:"ooxml",charIndex:153},{level:3,title:"1. Name Representation",slug:"_1-name-representation",normalizedTitle:"1. name representation",charIndex:20827},{level:3,title:"2. Cell References & Name",slug:"_2-cell-references-name",normalizedTitle:"2. cell references &amp; name",charIndex:null},{level:3,title:"3. Formulas and expressions",slug:"_3-formulas-and-expressions",normalizedTitle:"3. formulas and expressions",charIndex:22310},{level:2,title:"MS-Office 的其他形式",slug:"ms-office-的其他形式",normalizedTitle:"ms-office 的其他形式",charIndex:23232},{level:2,title:"RTF",slug:"rtf",normalizedTitle:"rtf",charIndex:23830},{level:3,title:"检出",slug:"检出",normalizedTitle:"检出",charIndex:23946},{level:3,title:"清理",slug:"清理",normalizedTitle:"清理",charIndex:24354},{level:2,title:"Reference",slug:"reference",normalizedTitle:"reference",charIndex:2701}],headersStr:"一、Malware 1.1 漏洞 1.2 宏病毒 1.3 Embedded 二、MS-CFB OLE OLE 格式 VBA Project 格式 Microsoft Office Excel 4.0 DOC PPT XLS OOXML 1. Name Representation 2. Cell References & Name 3. Formulas and expressions MS-Office 的其他形式 RTF 检出 清理 Reference",content:'# Office 格式简析\n\n目前常见的 Microsoft Office 格式主要分为 97 ~ 2003 和 2007 ~ 两种格式。Microsoft Office 97 ~ 2003 的文件格式都是由 MS-CFB 结构来表示的 OLE 文件。Microsoft Office 2007 ~则是由 OOXML 格式的文件结构压缩而成的 zip 包来存储。\n\n而 OOXML 又是以 XML 文件为基础的，所以，概括的说，Office文档主要基于 ole、xml、ooxml 这三种文件格式构建起来的。\n\n常见的文件扩展名以及用途如下：\n\nEXTENSIONS       USAGE                                          REMARK\ndoc、xls、ppt      属于 97-2003 版 Office                            \ndocx、xlsx、pptx   属于 2007 ~ 版 Office 文档，但没有启用宏                   \ndocm、xlsm、pptm   属于启用了宏的 2007 ~ 版 Office 文档，可以存储 Visual Basic   \n                 Applications（VBA）宏代码\nppsx             是 2007 的 PPT 的一种格式，打开就是幻灯片播放模式                 \n\n按照我们常规的认知，一个文档应当包含以下几个部分：\n\n 1. 文档内容\n    * 可能涉及对 embedded objects 或 external objects 的引用\n    * 文档的展示相关：字体、页面大小、打印方式等等\n 2. 文档工具\n    * 为了更好、更方便的操作文档内容进行编辑、展示、提示以及其他功能，而提供的一些跟文档相关的组件，如 vba、formula、animation 等等\n 3. 文档属性\n    * 如，创作时间、作者、最后修改时间等等\n 4. 保护措施\n    * 签名\n    * 读(打开)、写 保护\n\n\n# 一、Malware\n\n由于 ms-office 文件的广泛使用，恶意软件作者对其进行了充分的挖掘、利用，催生出了一系列针对这些文档的病毒，期中常常被用于恶意目的的组件或者方式有：宏病毒、漏洞利用、嵌入文件\n\n\n# 1.1 漏洞\n\n漏洞利用是指软件自身缺陷被攻击者利用来执行高危动作，如利用 ole 的特点调用第三方组件并执行；栈溢出造成的任意代码执行漏洞(CVE-2017-11882) 等等，常见的漏洞有：\n\n * CVE-2017-11882\n * CVE-2018-0802\n * CVE-2019-0801\n * CVE-2021-40444\n\n\n# 1.2 宏病毒\n\n宏（Macro）是 ms-office 提供的一种利用一系列独立的 office 命令来实现任务执行的自动化，以简化日常工作的工具。当前的 ms-office 是使用 Visual Basic for Applications（VBA）编写的，它是 Microsoft 的 Visual Basic 编程语言专门为 Office 服务的一种变体。VBA 可在大多数 Office 程序中使用，例如 Access，Excel，Outlook，PowerPoint，Project，Publisher，Visio 和 Word 等等。\n\n宏病毒主要是利用 宏 来进行感染和传播。它利用宏语言的功能寄存在文档或模板中，一旦带有宏病毒的文档被打开，宏就可能会执行，而宏病毒就会被激活。\n\n它的主要感染路径大致如下：单个Office文档 => Office文档模板 => 多个Office文档。\n\n常见的宏主要存在于以下两种形式(vba && xlm)：\n\n此外，还有一种攻击方式被称为「模板注入」，实际上还是上述两种 macros 的利用，不过内容可能会随时发生变化\n\n * \n\n此外，宏病毒常常用以下方式保护、隐藏自己：\n\n 1. 禁止提示信息\n\nOn Error Resume Next                     \'如果发生错误，不弹出出错窗口，继续执行下面语句\nApplication.DisplayAlerts = wdAlertsNone \'不弹出警告窗口\nApplication.DisplayStatusBar = False     \'不显示状态栏，以免显示宏的运行状态\nOptions.VirusProtection = False          \'关闭病毒保护功能，运行前如果包含宏，不提示\n\n\n1\n2\n3\n4\n\n 2. 屏蔽命令菜单，不许查看宏\n\n\' Disable或者删除特定菜单项，用来使“工具—宏”菜单失效的语句：\nCommandBars(“Tools”).Controls(16).Enabled = False\n\n\n1\n2\n\n 3. 隐藏宏的真实代码\n\n * 在“自动宏”中，不包括任何感染或破坏的代码，但包含了创建、执行和删除新宏（实际进行感染和破坏的宏）的代码；将宏代码字体颜色设置成与背景一样的白色等\n * “自动宏” 是指利用 AutoExec、AutoNew、AutoOpen、AutoClose、AutoExit 自动触发执行的宏\n\n 4. 文档密码保护\n\n * 打开文档时需要密码 或者 查看vba脚本时需要密码\n\n另外，病毒作者常用密码逃逸手段以增加检测难度，事实上也很有效。这种方法的全称是：VelvetSweatshop Default Password Ploy。\n\n * 对象：Excel 4.0 xls 97 ~ files with a compromised macro\n * 表现：XLS files appear password protected but aren’t, opening automatically to install malware from compromised macros.\n * 原因：Excel 会首先尝试使用默认密码 \'VelvetSweatshop\' 以 read-only 模式打开文件，如果失败时，再向用户要求输入密码。(This read-only technique has been known about for over 10 years.)\n * Reference\n   * https://threatpost.com/hackers-update-age-old-excel-4-0-macro-attack/154898/\n\n\n# 1.3 Embedded\n\n利用复合文档可以内嵌其它文档的特性，可以嵌套如：\n\n * images、video、audio\n * other streams, eg. rtf、pdf、docx ... (rtf、docx等复合文档又可以继续嵌套... MY GOD ~)\n\n\n# 二、MS-CFB\n\n经常被称为 OLE(Object Linking and Embedded)，实际上 OLE (是一种面向对象的技术)包含的内容更多，是 COM 技术的基础，而 CFB 只是 OLE 中关于文件格式的一种描述。\n\n复合文档的物理结构比较简单：\n\n * \n\n注意：Compound File Header (512 bytes)也会独占一个 sector, 没有用到的地方填充 0.\n\n这里是逻辑结构：\n\n * \n\n文档中的内容都以 stream 来保持具体内容，storage 来组织 stream 的结构。而这些内容在文件中的位置、查找方式、解读方式，就由 Directory Entry Array 来表达。\n\n复合文档的结构非常类似 FAT 文件系统，storage 相当于 directory，stream 相当于 file。为了文件的快速定位，我们需要相应的分区索引表(DiFat 和 Fat)。在 复合文档中，为了节省空间，会将 sector 划分成等长的 short-sector 用于小对象(short-stream)的存储，而它的索引需要 Mini-Fat。\n\n由于 CFB 文件由 sectors 组成，这里统一称呼为：\n\n * msat (master sector allocation table)，又名 DiFat\n * sat (sector allocation table)，又名 Fat\n * ssat (short-sector allocation table)\n * stream\n * short_stream\n\n他们的功能如下：\n\n * msat 表包含了用于构造 sat 表的 sectors 的 sid\n * sat 表包含了很多 sid 链(有特定的 sid 标识链条结束)\n   * 每个 sid 链上的 sectors 联合构成了一个完整的 object (如，stream、storage、directory entry array、ssat ...)的物理存储。\n * ssat 表包含了很多 ssid 链(有特定的 ssid 标识链条结束)\n   * 每个 ssid 链上的 short-sectors 联合构成了一个完整的 short-stream\n\n到这里，我们大概可以想到为了解析 CFB 结构，需要知道以下几个内容：\n\n 1. Directory Entry 的结构 和 存放位置\n 2. msat 表在文件中的位置\n 3. stream 和 short-stream 的切割点：什么情况下用 stream 什么时候用 short-stream\n 4. short-sector 存储于哪些 sector 中\n 5. ssid 存储于哪些 sector 中\n\n这些内容就存放在 Compound File Header 和 Directory Entry Root 中。\n\n\n# OLE\n\nOLE, Object Linking and Embedded。\n\n微软在 1991 年制定的 OLE1.0 规范，主要解决多个应用程序之间的通信和消息传递问题，微软希望第三方开发商能够遵守这个规范，以使在当时的Windows平台上的应用程序能够相互协调工作，更大的提高工作效率。然而事与愿违，只有很少的软件开发商支持它。为此，微软于1993 年发布了新的规范 OLE2.0，它在原有的基础上完善并增强了以下各方面的性能：\n\n 1. OLE自动化：一个程序有计划地控制另一个程序的能力。\n 2. OLE控件：小型的组件程序，可嵌入到另外的程序，提供自己的专有功能。\n 3. OLE文档：完善了早期的混合文档功能，不仅支持简单链接和嵌入，还支持在位激活、拖放等功能。\n\n强大的功能使得很多的开发商开始支持新的 OLE 技术，因为微软在 OLE2.0 中建立了 COM（Component Object Model即组件对象模式）规范。\n\nOLE 相关的基础概念有：\n\n * 容器：\n   * 容器是一个客户程序，它具有申请并使用其它COM组件通过接口为其它程序实现的功能；\n * 服务器：\n   * 服务器通过特定的接口将自己完成的一些功能，提供给使用自己的应用程序（例如画笔程序是一个文档服务器，它提供创建并编辑BMP 图像的功能）。当打开Word，选择【插入】菜单下的【对象...】项，您可以看到在您的系统中存在哪些文档服务器，此时的Word以文档容器的身份出现。\n * 在位激活：\n   * 当您双击插入的对象后发现Word的菜单有些改变成文档服务器程序的菜单，可以在当前的环境下编辑对象，这称为在位激活。\n\n简单的说，OLE 是一种可以用来创建复杂文档的技术，这些复杂文档可以包含来自不同渠道（数据源）的信息，并保留其原始属性。例如，一个支持 OLE 的文档（例如word）能够支持嵌入的表格对象，并且嵌入的文档会保留所有原来的属性。如果用户打算编辑嵌入的数据，windows 操作系统会激活原来的应用程序（如excel）并载入这个嵌入的文档。\n\n\n# OLE 格式\n\nOLE 文件的 Property Sets 通过以下两个 stream 存储:\n\n * "\\005SummaryInformation"\n * "\\005DocumentSummaryInformation"\n\n这两个 stream 都以 PropertySetStream 结构(见 MS-OSHARED 的 section3.2.1 )开头。\n\nOLE文件中包含的常见内容主要有：\n\n# 1. linked or embedded object\n\n包含嵌入、链接对象的容器文档的逻辑布局如下图：\n\n * OLEStream\n   * OLE2.0 中，由复合文档的以 "\\1Ole" 为名的 stream object 包含。OLEStream structure 表述了存储对象是用于 linked object 还是 embedded object。当此结构是为 linked object 指定 storage object 时，它还指定了对此链接对象的引用。\n * CompObjStream\n   * OLE2.0 中，名为 "\\1CompObj" 的流，主要用于描述 Clipboard Format、用于显示的linked object 或 embedded object 的名字。\n * Embedded Object Native Data\n   * OLE1.0 中，其由 EmbeddedObject structure 的 NativeData field 指定。\n   * OLE2.0 中，Native Data 的指定方式有以下两种，可以互换使用：\n     * 由复合文档的以 "\\1Ole10Native" 为名的 stream object 包含。如 OLENativeStream structure 的 NativeData field 所指定。\n     * 由 creating application 创建的 stream objects 可以包含 native data。此类流对象是 creating application 的私有对象，未在文档中说明。\n       * creating application: An application whose data is stored in or referenced by documents from other applications.\n * Embedded Object Presentation Data\n   * 用于指定如何在 container application 中显示 linked or embedded object 对象\n   * OLE1.0 中，其由 EmbeddedObject structure 的 Presentation field 指定\n   * OLE2.0 中，由复合文档的以 "\\2OlePres" 为前缀(后跟着3个十进制数字，并且最多只能有999个Presentations)的 stream objects 指定。每一个 stream 都包含一个 OLEPresentationStream structure。\n\n# 2. 宏\n\n常见的 宏 有两种：vba 和 ms-excel4.0, 它们出现的主要位置有：\n\n * vba project\n   * office97 ~ 2003: vba project storage\n   * office2007 ~ : vbaProject.bin\n * microsoft office excel 4.0\n   * office97 ~ 2003: book\\workbook stream\n     * 注：主要通过 BIFF 格式保存了 formula、drawing group 等内容\n   * office2007 ~ : macrosheets\n     * Microsoft 365 新增 LAMBDA function\n * macro template\n   * office2007 ~ : /[xx]/_rels/settings.xml.rels 中引用外部(远程)模板文件\n * VbaProjectStg\n   * binary powerpoint document 中用于指定一个用于 VBA project 的结构化存储\n\n# 3. officeart\n\n * office97 ~ 2003:\n   * worddocument、book\\workbook、\'powerpoint document\' stream\n     * Office Drawing Binary File Format (MS-ODRAW)，This file format is also known as OfficeArt.\n * office2007 ~ :\n   * TODO\n\n# 4. encryption and obfuscation\n\n详见 Office 格式简析 - Crypto\n\n这里需要注意的是 vba project 的保护(待确认)：\n\n * vba project\n   * 可以对其中的 stream 设置独立的密码 (未确认)\n     * VBA uses a reversible encryption algorithm for selected data.\n   * PROJECT Stream: ProjectProtectionState\n     * ProjectProtectionState: "CMG="0705D8E3D8EDDBF1DBF1DBF1DBF1"" specifies no sources are restricted access to the VBA project. The value is obfuscated by Data Encryption (section 2.4.3).\n     * ProjectPassword (section 2.3.1.16): "DPB="0E0CD1ECDFF4E7F5E7F5E7"" specifies the VBA project has no password. The value is obfuscated by Data Encryption (section 2.4.3).\n     * ProjectVisibilityState (section 2.3.1.17): "GC="1517CAF1D6F9D7F9D706"" specifies the VBA project is visible. The value is obfuscated by Data Encryption (section 2.4.3).\n     * LibName: "VBE" specifies a built in name for the VBA Automation type library.\n\n\n# VBA Project 格式\n\nVBA project 是由一系列 records 组成的结构。其中每个 record 都定义了 project 的三要素之一的部分内容。每个 record 都是以结构开头：ID(2 bytes) + Size(4 bytes) + ...\n\nproject 的三要素有：project information, project references, and project items.\n\n# 1. project information\n\nole 中 VBA 存储(storage)结构如下：\n\n\n\n其中 Project Root Storage 是一个独立的 storage。例如，OLE 文件中的 Macros storage。\n\n * VBA Storage\n   * sub-structure\n     * _VBA_PROJECT Stream\n       * MUST\n       * 包含了 VBA project 的基础信息，如，版本号(用于加载此结构的剩余内容) 等\n     * dir Stream\n       * MUST\n       * 指明 VBA project properties, project references, 和 module properties\n       * The entire stream MUST be compressed as specified in Compression\n     * "Module Stream"\n       * VBA project 中的每个 module 必须拥有一个 Module Stream\n       * VBA project 中 modules 的源码。此 stream 的名字由 MODULESTREAMNAME 指定。\n     * SRP Streams\n       * Optional\n       * 指定 特定实现和版本相关 的性能缓存的流。必须是读取时忽略。写入时不得出现。\n * PROJECT Stream\n   * MUST\n   * VBA Project Properties, 如 工程的目录结构、脚本类型、module的可编辑窗口的信息等等, 以及一些 VBA project 的附加信息，如：ProjectPassword、ProjectVisibilityState 等 注：[MS-OVBA] - v20200219 的 2.3.1.3 ProjectModule 有脚本类型的相关说明\n * PROJECTwm Stream\n   * Optional\n   * 包含了用于 module name 在 multibyte character set (MBCS) 和 UTF-16 之间互相映射的信息\n * PROJECTlk Stream\n   * Optional\n   * 包含了 VBA project 中的 ActiveX controls 的 license 信息\n * Designer Storages\n   * Optional\n   * 每个 vba project 中的 designer module 都必定有一个与之对应的 designer storage ，此 storage 的名字由 dir stream 中相关 module 中的 MODULESTREAMNAME record 指定。\n   * 每个 designer storage 必定有一个 VBFrame Stream\n     * VBFrame Stream，用于描述 designer module 的属性信息，此 stream 的名字必须是以 UTF-16 character 0x0003 开头紧接着是 UTF-16 的 "VBFrame"。\n   * 如果此 designer 是一个 Office Form ActiveX control, 那么此 storage 必定包含 [MS-OFORMS] section 2中描述的必须 storages 和 streams。\n\n# 2. project references\n\ndir Stream 中的 records 包含了 VBA project 对外部资源引用的信息。主要有三类：REFERENCECONTROL、REFERENCEREGISTERED、REFERENCEPROJECT。\n\n# 3. project items\n\nVBA project 包含一系列用于嵌入 macros 的 project items。而 project item 是由多个 records 组合定义。主要有以下 5 种 project item(详见 MS-OVBA 文档): project package, document modules, procedural modules, class modules 和 designer modules。\n\n# 4. pcode\n\n它并不广为人知，一般来说 VBA 编写的宏以三种不同的可执行形式存在，每种形式都可以是在运行时实际执行的内容，具体取决于具体情况. 它们是：\n\n * source code\n   * 这是最为我们熟知的形式。但大多数情况下，office 会完全忽略源代码。\n   * 事实上，删除源代码是可能的，但宏仍然可以毫无问题地执行(从 pcode)\n     * 这种威胁利用技术被称为 VBA Stomping\n * p-code\n   * 当每行 vba 脚本被输入到 vba 编辑器中时，它会立即被编译成 pcode 并存储到模块流中。 pcode 正是大部分时间被执行的代码。\n   * 事实上，即使在 vba 编辑器中打开宏模块的源码，显示的也不是解压后的源码，而是反编译成源码的 pcode。\n   * 只有在使用与创建文档时使用的 vba 版本不同的 office 版本下打开文档时，才会将存储的压缩源代码重新编译为 pcode，然后执行该 pcode\n   * 这使得可以在支持 vba 的任何版本的 office 上打开包含 vba 的文档，并使内部的宏保持可执行，尽管不同版本的 vba 使用不同(不兼容)的 pcode 指令。\n * dxecodes\n   * 当 pcode 至少被执行过一次后，它会以进一步标记化形式存储在文档的其他地方(在流中，其名称以 _SRP 开头，后跟一个数字)。从那里它可以执行得更快。\n   * 但是 execode 的格式极其复杂，并且特定于创建它们的特定 Office 版本(不是 VBA 版本)。这使得它们的通用性很差。\n   * 此外，它们的存在不是必需的 --- 它们可以被删除并且宏将运行得很好(从 pcode)\n\n综上，我们可以知道：\n\n * source 的通用性最好，但只有在 pcode 不能使用时，才会被使用\n * execodes 的通用性最差，但执行得最快\n * p-code 则是执行速度和通用性的折中，也是用的比较广泛的形式\n\n因此，我们有必要解析 pcode，具体可以参考：github.com/bontchev/pcodedmp\n\n\n# Microsoft Office Excel 4.0\n\nMicrosoft Office Excel 4.0, 主要存在于 MS-XLS 的 book\\workbook stream 中。此 stream 以 BIFF8(Binary Interchange File Format) 格式组织各个细节。\n\nStream 由以下几部分组成：\n\n * Globals Substream\n   * 描述 workbook 中的全局属性和数据\n     * 注意 Lbl、ShrFmla 数据\n * Chart Sheet Substream\n * Dialog Sheet Substream\n * Macro Sheet Substream\n * Worksheet Substream\n\n使用 Excel 4 Macros 的一些细节：\n\n * 使用 relative named range 时，函数主体和结果之间的单元格距离必须都相同，否则可能会计算出错误的结果。\n * Office 2007 ~ 中，任何带有 Excel 4 Macro 的文件都必须另存为启用宏的工作簿 (.xlsm)，尝试另存为标准 Excel 文件将触发以下错误消息:\n * 任何包含数组的函数，例如 GET.WORKSPACE(37) 或 NAMES() 都应该包含在 INDEX 函数中: 如，=INDEX(GET.WORKSPACE(37),!A1)，在这个例子中，A1 包含应该检索的数组中的数字，例如如果 A1 包含值 2，它将返回 GET.WORKSPACE(37) 数组中的第二项。\n * 使用 Macro Worksheet 时，工作表设置为显示公式，而不是公式的结果。可以使用 Ctrl + | 在公式视图和结果视图之间切换。\n\n# PtgExp、ShrFmla、Array\n\nPtgExp 一般会出现在 formula 的第一个 rgce 元素。此时，它表示当前单元格是 array formula 或 shared formula 的一部分。\n\nPtgExp.row 和 PtgExp.col 指定了一个在当前 sheet 中的 cell\n\n * 这个 cell 也是 array formula 或 shared formula 的一部分\n   * 也就是说必定有一个 formula record 的 row == PtgExp.row && col == PtgExp.col\n     * 紧跟着这个 formula record 的必定是一个 ShrFmla record 或者 Array record\n     * 也就是说这个 PtgExp 指向了使用此 array formula 或 shared formula 的区域中的 the first cell\n       * 隐含：拥有 PtgExp 的 formula record 满足：record.row == PtgExp.row && record.col == PtgExp.col 时，它后边一定跟着 ShrFmla record 或 Array record\n   * 这个 formula record 定义了区域中使用 array formula 或 shared formula 的 the first cell\n\nShrFmla(shared formula record)\n\n * 此 record 前必定有一个 formula record，这个 formula record 指定了使用此 shared formula 的区域中的 the first cell\n * 其它使用了此 shared formula 的 formula records 后续会出现，但不一定是连续的\n * 使用了此 shared formula 的 formula records 会有 Formula.fShrFmla bit 被置位，同时 Formula.cell 必定位于 ShrFmla.ref 指定的区域内\n\nArray(array formula record)\n\n * 此 record 前必定有一个 Formula record，这个 formula record 指定了使用此 array formula 的区域中的 the first cell\n * 其它使用了此 array formula 的 formula records 后续会出现，但不一定是连续的\n * 使用了此 array formula 的 formula records 必定有 Formula.cell 位于 Array.ref 指定的区域内，同时这些使用 array formula 的 formula 的 rgce 必定以 PtgExp 开头。\n\n# 解析过程中遇到的问题\n\n * RgceLoc 可以按照 RgceLocRel 来解析，以简化解析流程。\n * 解析 formula 的过程中，会遇到 "is part of a revision or not" 的分支流程，这里涉及以下三个概念：\n   * UserBView Record:\n     * fPersonalView : MUST be 0 if this is not a shared workbook.\n   * Revision Stream\n     * An instance of the Revision Stream specifies the revision logs (section 2.2.11.2) and revision records (section 2.2.11.3) for a shared workbook (section 2.2.11).\n     * The name of this stream MUST be "Revision Log". A file MUST contain at most one Revision Stream. The Revision Stream MUST exist if the workbook is a shared workbook.\n   * Revision Records\n     * a series of records. 详情可以参考 [MS-XLS] 文档。\n * external references：\n   * Supporting Link 包含了 Self-Referencing、Same-Sheet Referencing、External Workbook Referencing 等等类型。\n * name manager:\n   * LblRecord : (关联 name 和 sheet)\n     * 内置名字的索引，可能由 1 或 2 字节表示\n     * NameParsedFormula 可能出现 ptgRef3d 的 ixti == 0xFFFF，此时，此时的结构未被文档记录：\n       * we can reproduce it: make a macro sheet in ooxml and export it to xls.\n       \n         \t\tuint8_t ptg = uint8_t(data[cce_offset] & 0x7f);\n         \t\tif (ptg == ptgRef3d || ptg == ptgRef3dA || ptg == ptgRef3dV) {\n         \t\t\tuint16_t ixti = *(uint16_t*)(data + cce_offset + 1);\n         \t\t\tif (ixti > 0xFF00 && record->cce >= 15 + 3) {\n         \t\t\t\tassert(record->itab == 0 || record->itab == 1);\n             uint16_t iscope_1base = (record->itab == 1) ? record->reserved1 : record->itab;\n         \t\t\t\tuint16_t isheet_0base_a = *(uint16_t*)(data + cce_offset + 11);\n         \t\t\t\tuint16_t isheet_0base_b = *(uint16_t*)(data + cce_offset + 13);\n         \t\t\t\tassert(isheet_0base_a == isheet_0base_b);\n         \t\t\t\tauto row = *(uint16_t*)(data + cce_offset + 15);\n         \t\t\t\tauto col = (uint16_t)*(uint8_t*)(data + cce_offset + 17);\n         \t\t\t}\n         \t\t}\n         \t}\n       \n       \n       1\n       2\n       3\n       4\n       5\n       6\n       7\n       8\n       9\n       10\n       11\n       12\n       13\n       14\n       \n * Rgce 的 ACTUAL_PTG_SIZE 跟实际情况不符合\n\n\n# DOC\n\n一个 doc 文档应当由以下几个部分组成：\n\n 1. WordDocument stream\n    * 有一个 FIB structure 在流的起始位置\n 2. Table stream\n    * 1Table 或者 0Table 流必定存在。当二者同时存在时，base.fWhichTblStm 指定的为有效流，忽略其他即可。\n    * 如果文档被加密的话，会有一个 EncryptionHeader 结构在流的起始位置。反之，如果文档没有加密，则此流没有预定义的结构。\n    * 存储了文档的文本信息\n 3. Data stream\n    * 没有预定义的结构，也不是必定存在。它包含的是 FIB 或 文件的其它部分的引用数据，也就是说如果没有引用数据的话，这个流没有存在的必要\n 4. ObjectPool storage\n    * Object Pool storage 包含一些用于持久化 embedded OLE objects 的 storages。如果文档没有 embedded OLE objects 时，是不会出现此 storage 的。\n    * 每一个位于 ObjectPool storage 中的 storage 都有一个 ObjInfo Stream (名为 "\\003ObjInfo")，这个流里存放着用于描述 embedded OLE object 信息的 ODT structure。\n      * embedded OLE object 相关的其他流的描述可以参考 Embedded Object Native Data 相关内容\n    * 每个 sub-storage 都存储了一个用户嵌入(embedded)的文件。并且，每个 sub-storage 都是以: 下划线"_" + 10个digits 组成，如 _1557814583\n      * 关联引用的关键词：sprmCFOle2、sprmCPicLocation\n 5. Summary Information\n    * Summary Information stream\n    * Document Summary Information stream\n    * Encrypt stream\n      * 名为 encryption 的流，只有当以下两个条件同时满足才会出现：文档被 RC4 CryptoAPI 加密， 并且，EncryptionHeader.Flags 的 fDocProps 标记被置位\n 6. Macros stream\n    * vba project\n 7. Signature\n    * 参考 MS-OFFCRYPTO 中的说明。\n 8. Protected Content\n\n * 由 IRMDS 描述的方式进行保护的内容, 在 MS-OFFCRYPTO 有描述。\n\n\n# PPT\n\n按照 [MS-PPT] - v20210817 ：pageno 28 中 Part 1 ~ 11 的描述，即可解出完整的 ppt 文档内容。\n\n注意：the UserEditAtom record closest to the end of the PointPower Document stream\n\n其中，所有用于 presentation 的文本都存储在 "PowerPoint Document" stream 中；所有用于 presentation 的 images 都存储在Pictures stream 中；不过，Embedded files 没有存储在独立的 storages，而是被融合到 "PowerPoint Document" stream 中，此外，这些 embedded files 在存储时，有些会被压缩有些却不会。\n\n# External Objects\n\nSlides 可以包含连接到外部的 objects。播放 ppt 的人可以在幻灯片放映期间激活链接对象以访问外部资源。External Objects 的例子有 embedded and linked audio, linked video, embedded and linked OLE objects, 以及 hyperlinks。\n\n也就是说 Embedded or Linked Object 在 ppt 中的存在形式就是 External Objects。\n\n有关有 External Objects 的记录，请参阅 [MS-PPT] External Object Types (section 2.10) 相关内容。简单的说，为了解析出 External Objects，我们需要关注：\n\n * ExternalOleObjectStg 0x1011 , 用于对象存储(如果有n个则会有n个此类型的 record)\n * DocumentContainer 0x03E8 , 用于描述文档对象\n   * DocInfoListContainer 0x07D0\n     * VBAInfoContainer 0x03FF\n       * VBAInfoAtom 0x0400\n   * ExObjListContainer 0x0409\n     * storage for compressed/uncompressed OLE/VBA/ActiveX control data, 如 VbaProjectStg\n   * SoundCollectionContainer\n   * DrawingGroupContainer\n\n也就是说要首先找到 DocumentContainer：\n\n1. 构造 PersistDirectory\n  Current User Stream\n    CurrentUserAtom Record\n      offsetToCurrentEdit field\n  |--\x3ePowerPoint Document Stream\n  |\t\tUserEditAtom\n  |\t\t\toffsetPersistDirectory field\n  |\t\tPersistDirectoryAtom\n  UserEditAtom.offsetLastEdit (Repeat until offsetLastEdit is 0x000000)\n\n2. 定位 DocumentContainer\n  UserEditAtom.docPersistIdRef\n    DocumentContainer Record\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n关于鉴别 embedded OLE object 对象的具体步骤可以参考 [MS-PPT] 2.1.2 PowerPoint Document Stream part 9 相关内容\n\n关于鉴别 linked OLE object 对象的具体步骤可以参考 [MS-PPT] 2.1.2 PowerPoint Document Stream part 10 相关内容\n\n\n# XLS\n\n一个 xls 文件最多只能一个 Component Object Stream。 一个 xls 文件最多只能一个 OLE Stream。 一个 xls 文件最多只能一个 Control Stream。\n\nWorkBook stream 中存储了 excel 中所有的 text 和 formulas。\n\n# Embedded or Linked Object\n\n在 Excel 的 workbook 中嵌入一个文件的话，这些文件会被存储在名为 "MBD + 随机的8个十六进制数字" 的 Embedding Storages 中。\n\n每个 Embedding Storage 都表示了一个基于 storage-based 持久化的 embedded OLE object 或 ActiveX control 对象。同时，持久化在 Embedding Storage 的对象必定有一个相关联的 Obj record 在 worksheet substream、macro sheet substream 或 dialog sheet substream 中，并且 cmo.ot == 8，pictFlags.fPrstm == pictFlags.fDde == 0。\n\n不过不同类型的文件在 Embedding Storage 中的形式有些不一样，如：\n\n 1. 如果 embedded file 是另外一个 binary Office document, 那么这个 embedded file 中的 storages 和 streams 会被当成对应的节点原样存储在 MDB storage 中\n 2. 如果 embedded file 是一个 Open XML document, 那么这个 embedded file 会被完整存储在名为 "Package" 的 stream 中\n\n一个 Link Storage 指定一个 linked OLE object 和任意其他的默认数据或表示为其建立的缓存。它的名字必定是由："LNK" + 8个十六进制数字 标识。持久化在 Link Storage 的对象必定有一个相关联的 Obj record (Obj.pictFmla.lPosInCtlStm)在 worksheet substream、macro sheet substream 或 dialog sheet substream 中，并且 cmo.ot == 8，pictFlags.fPrstm == pictFlags.fDde == 0。\n\n\n# OOXML\n\nOOXML(Office Open XML File Formats), 简单来说，OOXML 是一个基于 XML 的文档格式标准，最早是微软 Office2007 的产品开发技术规范，先是成为 Ecma(ECMA-376) 的标准，最后改进推广成为了 ISO 和 IEC (as ISO/IEC 29500) 的国际文档格式标准。也就是说，通过 OOXML 标准，我们能够在不依赖 Office 产品的情况下，在任何平台读写Office Word，PPT 和 Excel 文件。\n\nOOXML 的主要目录结构如下所示：\n\nOOXML\n├── [Content_Types].xml // 描述文档各个部分的ContentType，协助解析文档\n│           \n├─ docProps        // ms-office 需要此内容以打开文件，而 wps 不需要\n│   ├── app.xml    //程序级别的文档属性，如：页数、文本行数、程序版本等\n│   └── core.xml   //用户填写的文档属性，如：标题、主题、作者等\n│\n├─ _rels\n│   └── .rels      //描述各个部分之间的关系\n│\n└─ word / xl / ppt\n    ├── document.xml     //word\n    ├── fontTable.xml    //word，页脚\n    │\n    ├── workbook.xml     // xl\n    ├── worksheets       // xl\n    │    └── sheet1.xml\n    ├── macrosheets      // xl, microsoft excel 4.0 macros\n    │      ├── _rels\n    │      │   └── sheet1.xml.rels\n    │      └── sheet1.xml\n    |\n    |── presentation.xml // ppt\n    |\n    |── embeddings       //all, optional, 存放 embedded files\n    |     ├── a\n    |     └── b\n    │\n    |── vbaData.xml      //all, vba属性，是否auoopen，是否加密\n    |── vbaProject.bin   //all, 记录 vba project 信息, ole 格式\n    |\n    ├─ theme             //all, 记录样式，颜色编号，字体大小等等\n    │    └── theme1.xml\n    │\n    ├─ _rels             //all, relationships\n    |    ├── settings.xml.rels   // 指定 模板 引用\n    │    ├── document.xml.rels   // 使用 ID 和 URL 来定义文档各零件\n    |    ├── workbook.xml.rels   // 使用 ID 和 URL 来定义文档各零件\n    │    └── vbaProject.bin.rels // vba\n    │ \n    ├── printerSettings //all, Reference to Printer Settings Data\n    │....└── printerSettings1.bin\n    │\n    └─ styles.xml       //all\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n\n\n\n# 1. Name Representation\n\n无论是 definedNames 中定义的，还是表格显示的名字，这些需要展示的名字都应当在 docProps\\app.xml 中作为 Application-Defined File Properties 部分被定义，如下：\n\n<TitlesOfParts>\n <vt:vector size="[0-9]+" baseType="lpstr">\n  <vt:lpstr>Sheet1</vt:lpstr>\n  <vt:lpstr>Sheet2</vt:lpstr>\n  <vt:lpstr>Sheet3</vt:lpstr>\n  <vt:lpstr>value1</vt:lpstr>\n  <vt:lpstr>value2</vt:lpstr>\n </vt:vector>\n</TitlesOfParts>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 2. Cell References & Name\n\nexcel中可以给 函数、cell、sheet、甚至任意一段文本或图形等定义名字(也被称为 bookmark)，并通过名字来引用对应的内容，引用方式参考\n\n * ECMA-376-Fifth-Edition-Part-1 --- 18.17.2.3 Cell References\n * ECMA-376-Fifth-Edition-Part-1 --- 18.17.2.5 Names\n\nname 的组成形式：\n\nname = [ workbook-name, "!" ], [letter | "_" | "\\"], [ letter | decimal-digit | "_" | "." ] ;\n\n\n1\n\n\n其中 name 不能包含以下几种格形式：\n\n * TRUE or FALSE\n * user-defined-function-name\n * cell-reference\n\nfunction-name 的组成形式：\n\nfunction-name= prefixed-function-name | predefined-function-name | user-defined-function-name ;\n\npredefined-function-name= "ABS" | "ACOS" | "ACOSH" | ( any of the other functions defined in §18.17.7) ;\nprefixed-function-name= "ISO.", predefined-function-name | "ECMA.", predefined-function-name ; \nuser-defined-function-name= letter, [ letter | decimal-digit | "." ] ;\n\n\n1\n2\n3\n4\n5\n\n\n其中 function-name 不能包含以下几种格形式：\n\n * TRUE or FALSE\n * name\n * cell-reference\n\nCell Reference 的形式有两种：R1C1-Style 和 A1-Style\n\noperator 有以下几种格式：\n\n":" | comma | space | "^" | "*" | "/" | "+" | "-" | "&" | "=" | "<>" | "<" | "<=" | ">" | ">=" | "%" ;\n\n\n1\n\n\n\n# 3. Formulas and expressions\n\n * ECMA-376-Fifth-Edition-Part-1 --- 17.16.3 Formulas and expressions\n\nA field instruction can involve a calculation via a formula, which is simply an expression that is an arbitrary complex arithmetic expression，如：\n\n<sheetData>\n\t\t<row r="2" spans="4:4" x14ac:dyDescent="0.25">\n\t\t\t<c r="D2" s="1" t="b">\n\t\t\t\t<f>FORMULA()=FORMULA()=FORMULA(\'Buk1\'!E11,\'Buk2\'!B12)=FORMULA(\'Buk2\'!H5,\'Buk3\'!H3)=FORMULA(\'Buk3\'!C9,\'Buk4\'!C2)=FORMULA(\'Buk4\'!I8,\'Buk5\'!F2)=FORMULA(\'Buk5\'!B12,\'Buk6\'!B10)=FORMULA(\'Buk6\'!G3,\'Buk7\'!I2)=FORMULA(\'Buk7\'!D13,\'Buk1\'!A3)=FORMULA(\'Buk3\'!H3&amp;\'Ss1\'!O6&amp;\'Ss1\'!D16&amp;\'Ss1\'!K13&amp;\'Ss1\'!R12&amp;\'Ss1\'!R14,D3)=FORMULA(\'Buk3\'!H3&amp;\'Buk7\'!I2&amp;\'Buk4\'!C2&amp;\'Buk5\'!F2&amp;\'Buk5\'!F2&amp;Ss1br2!B3&amp;\'Buk1\'!A3&amp;Ss1br2!D5&amp;\'Buk6\'!B10&amp;Ss1br2!G3&amp;\'Buk7\'!I2&amp;\'Buk7\'!I2&amp;Ss1br2!B9,D17)</f>\n\t\t\t\t<v>1</v>\n\t\t\t</c>\n\t\t</row>\n\t</sheetData>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# MS-Office 的其他形式\n\n使用 MS-Office 软件可以将 office 文件通过"另存为"保存为 xml、mhtml、html 等格式的文本文件，并且，可以再次通过 MS-Office 软件打开、编辑。\n\n另外，这些转换而成的文本类型的文档，被加密后，是一个 ole 文件。\n\n被转换而成的 xml 文件，在结构上保持了跟 binary 形式的 office 文件一致，并且一一对应。如，contentType 为 "application/vnd.ms-office.vbaProject" 的 binaryData 数据, 就是二进制形式的 vbaProject 内容 base64 后的结果。\n\n这里要注意的是，在解析 binData 类型的数据时，可能会遇到 mso(ActiveMine) 文件。这是一种文件名为 *.mso 同时 MIME Types 为 application/x-mso 的结构未公开的文件格式(参考 activemime-format )。\n\nMSO文件是将Microsoft Office文档保存为网页时创建的宏引用文件。它包含有关原始文件中包含的宏和OLE（对象链接和嵌入）对象的信息，并且可以被创建的网页作为样式表引用。MSO文件可以用文本编辑器查看，但由于内容是编码的，因此无法读取。大多数用户只会将MSO文件作为电子邮件的附件。\n\n\n# RTF\n\n富文本格式（Rtf，rich text tormat）是微软的文本和图像信息交换指定的格式。Rtf文件可以划分为文件头和文档区两个部分组成。文件头和文档区由文本、控制字和控制符组成，同时利用{…}来表明层级关系。\n\n\n# 检出\n\n * hash (忽略大小写、空字符)\n   * function\n   * stream\n * 模糊匹配\n   * 简单的模式匹配\n   * eg.\n     * 搜索到 ：VirtualProtectEx、WriteProcessMemory、CreateRemoteThread、VirtualAllocEx\n     * Shell Environ$("comspec") & " /c attrib -S -h """ & Application.StartupPath & "\\K4.XLS""", vbMinimizedFocus\n     * Shell ("\\jdq\\cc$\\b.exe")\n     * If .Lines(1, 1) = "APMP" & .Lines(1, 2) <> "KILL" Then ........ End If\n     * 混淆的文件：熵 ？\n\n\n# 清理\n\n * 抹除\n   * function\n     * 替换函数内容为空格\n   * stream :\n     * 将 stream 的 size 置 0，同时抹除第一个扇区内容，断开内容扇区链\n     * 一般来说，只修改 size 就可以让 office 软件无法读取相关内容。但其他杀软可能会继续报毒，毕竟 stream 的其他信息依然有效，可以在容错情况下还原出来 malicious 内容。\n     * 注意：其它部分对 macro 的引用，如：\n       * doc 中 fcCmds 会通过 macro names 引用对应的宏，所以\n         1. 根据需要将 document 流中的 fcCmds 和 lcbCmds 所引用的数据\n         2. 粗暴的将 document 流中的 fcCmds 和 lcbCmds 都置空\n * 还原\n   * 还原被加密破坏的文件内容\n     * 病毒感染时是有机会操作原有的正常 vba 脚本的，比如，加密（目前还没见到此类样本）。\n\n\n# Reference\n\n * MS-Office-Extensions\n\n * MS-Office File Formats\n\n * [MS-OVBA] - v20210817\n\n * [MS-OFFCRYPTO] - v20210817\n\n * [MS-XLS] - v20210817\n\n * [MS-DOC] - v20210817\n\n * [MS-PPT] - v20210817\n\n * [MS-OLEDS] - v20210625\n\n * Introducing the Office (2007) Open XML File Formats\n\n * Microsoft Office Excel 97 - 2007 Binary File Format (.xls) Specification\n\n * OLE1.0 and OLE2.0 Formats\n\n * Microsoft Office Word 2003\n   \n   * Microsoft Office Word 2003 Preview\n   * The XML Files: XML in Microsoft Office Word 2003\n\n * [翻译]攻击互通性-以OLE为例\n   \n   * Attacking Interoperability: An OLE Edition\n\n * 宏病毒常用的一些trick\n\n * Old school: evil Excel 4.0 macros (XLM)\n\n * oletools\n\n * DidierStevens\n   \n   * oledump-py\n   * oledump.py\n   * msoffcrypto-crack.py\n\n * 0xevilc0de\n   \n   * Maldoc uses template injection for macro execution\n   * Excel 4 Macros – Get.Workspace Reference\n   * Removing Passwords from VBA Projects\n   * Maldoc uses RC4 to hide PowerShell script, retrieves payload from DNS TXT record\n   * Maldoc uses Windows API to perform process hollowing\n\n * jstrosch\n   \n   * malware-samples\n\n * spiderlabs\n   \n   * spiderlabs-blog\n\n * Template Injection\n   \n   * malware-samples: Word Doc uses Template Injection\n\n * 复合文档文件格式研究\n\n * VelvetSweatshop: Default Passwords Can Still Make a Difference\n\n * REMnux: Analyze Documents',normalizedContent:'# office 格式简析\n\n目前常见的 microsoft office 格式主要分为 97 ~ 2003 和 2007 ~ 两种格式。microsoft office 97 ~ 2003 的文件格式都是由 ms-cfb 结构来表示的 ole 文件。microsoft office 2007 ~则是由 ooxml 格式的文件结构压缩而成的 zip 包来存储。\n\n而 ooxml 又是以 xml 文件为基础的，所以，概括的说，office文档主要基于 ole、xml、ooxml 这三种文件格式构建起来的。\n\n常见的文件扩展名以及用途如下：\n\nextensions       usage                                          remark\ndoc、xls、ppt      属于 97-2003 版 office                            \ndocx、xlsx、pptx   属于 2007 ~ 版 office 文档，但没有启用宏                   \ndocm、xlsm、pptm   属于启用了宏的 2007 ~ 版 office 文档，可以存储 visual basic   \n                 applications（vba）宏代码\nppsx             是 2007 的 ppt 的一种格式，打开就是幻灯片播放模式                 \n\n按照我们常规的认知，一个文档应当包含以下几个部分：\n\n 1. 文档内容\n    * 可能涉及对 embedded objects 或 external objects 的引用\n    * 文档的展示相关：字体、页面大小、打印方式等等\n 2. 文档工具\n    * 为了更好、更方便的操作文档内容进行编辑、展示、提示以及其他功能，而提供的一些跟文档相关的组件，如 vba、formula、animation 等等\n 3. 文档属性\n    * 如，创作时间、作者、最后修改时间等等\n 4. 保护措施\n    * 签名\n    * 读(打开)、写 保护\n\n\n# 一、malware\n\n由于 ms-office 文件的广泛使用，恶意软件作者对其进行了充分的挖掘、利用，催生出了一系列针对这些文档的病毒，期中常常被用于恶意目的的组件或者方式有：宏病毒、漏洞利用、嵌入文件\n\n\n# 1.1 漏洞\n\n漏洞利用是指软件自身缺陷被攻击者利用来执行高危动作，如利用 ole 的特点调用第三方组件并执行；栈溢出造成的任意代码执行漏洞(cve-2017-11882) 等等，常见的漏洞有：\n\n * cve-2017-11882\n * cve-2018-0802\n * cve-2019-0801\n * cve-2021-40444\n\n\n# 1.2 宏病毒\n\n宏（macro）是 ms-office 提供的一种利用一系列独立的 office 命令来实现任务执行的自动化，以简化日常工作的工具。当前的 ms-office 是使用 visual basic for applications（vba）编写的，它是 microsoft 的 visual basic 编程语言专门为 office 服务的一种变体。vba 可在大多数 office 程序中使用，例如 access，excel，outlook，powerpoint，project，publisher，visio 和 word 等等。\n\n宏病毒主要是利用 宏 来进行感染和传播。它利用宏语言的功能寄存在文档或模板中，一旦带有宏病毒的文档被打开，宏就可能会执行，而宏病毒就会被激活。\n\n它的主要感染路径大致如下：单个office文档 => office文档模板 => 多个office文档。\n\n常见的宏主要存在于以下两种形式(vba && xlm)：\n\n此外，还有一种攻击方式被称为「模板注入」，实际上还是上述两种 macros 的利用，不过内容可能会随时发生变化\n\n * \n\n此外，宏病毒常常用以下方式保护、隐藏自己：\n\n 1. 禁止提示信息\n\non error resume next                     \'如果发生错误，不弹出出错窗口，继续执行下面语句\napplication.displayalerts = wdalertsnone \'不弹出警告窗口\napplication.displaystatusbar = false     \'不显示状态栏，以免显示宏的运行状态\noptions.virusprotection = false          \'关闭病毒保护功能，运行前如果包含宏，不提示\n\n\n1\n2\n3\n4\n\n 2. 屏蔽命令菜单，不许查看宏\n\n\' disable或者删除特定菜单项，用来使“工具—宏”菜单失效的语句：\ncommandbars(“tools”).controls(16).enabled = false\n\n\n1\n2\n\n 3. 隐藏宏的真实代码\n\n * 在“自动宏”中，不包括任何感染或破坏的代码，但包含了创建、执行和删除新宏（实际进行感染和破坏的宏）的代码；将宏代码字体颜色设置成与背景一样的白色等\n * “自动宏” 是指利用 autoexec、autonew、autoopen、autoclose、autoexit 自动触发执行的宏\n\n 4. 文档密码保护\n\n * 打开文档时需要密码 或者 查看vba脚本时需要密码\n\n另外，病毒作者常用密码逃逸手段以增加检测难度，事实上也很有效。这种方法的全称是：velvetsweatshop default password ploy。\n\n * 对象：excel 4.0 xls 97 ~ files with a compromised macro\n * 表现：xls files appear password protected but aren’t, opening automatically to install malware from compromised macros.\n * 原因：excel 会首先尝试使用默认密码 \'velvetsweatshop\' 以 read-only 模式打开文件，如果失败时，再向用户要求输入密码。(this read-only technique has been known about for over 10 years.)\n * reference\n   * https://threatpost.com/hackers-update-age-old-excel-4-0-macro-attack/154898/\n\n\n# 1.3 embedded\n\n利用复合文档可以内嵌其它文档的特性，可以嵌套如：\n\n * images、video、audio\n * other streams, eg. rtf、pdf、docx ... (rtf、docx等复合文档又可以继续嵌套... my god ~)\n\n\n# 二、ms-cfb\n\n经常被称为 ole(object linking and embedded)，实际上 ole (是一种面向对象的技术)包含的内容更多，是 com 技术的基础，而 cfb 只是 ole 中关于文件格式的一种描述。\n\n复合文档的物理结构比较简单：\n\n * \n\n注意：compound file header (512 bytes)也会独占一个 sector, 没有用到的地方填充 0.\n\n这里是逻辑结构：\n\n * \n\n文档中的内容都以 stream 来保持具体内容，storage 来组织 stream 的结构。而这些内容在文件中的位置、查找方式、解读方式，就由 directory entry array 来表达。\n\n复合文档的结构非常类似 fat 文件系统，storage 相当于 directory，stream 相当于 file。为了文件的快速定位，我们需要相应的分区索引表(difat 和 fat)。在 复合文档中，为了节省空间，会将 sector 划分成等长的 short-sector 用于小对象(short-stream)的存储，而它的索引需要 mini-fat。\n\n由于 cfb 文件由 sectors 组成，这里统一称呼为：\n\n * msat (master sector allocation table)，又名 difat\n * sat (sector allocation table)，又名 fat\n * ssat (short-sector allocation table)\n * stream\n * short_stream\n\n他们的功能如下：\n\n * msat 表包含了用于构造 sat 表的 sectors 的 sid\n * sat 表包含了很多 sid 链(有特定的 sid 标识链条结束)\n   * 每个 sid 链上的 sectors 联合构成了一个完整的 object (如，stream、storage、directory entry array、ssat ...)的物理存储。\n * ssat 表包含了很多 ssid 链(有特定的 ssid 标识链条结束)\n   * 每个 ssid 链上的 short-sectors 联合构成了一个完整的 short-stream\n\n到这里，我们大概可以想到为了解析 cfb 结构，需要知道以下几个内容：\n\n 1. directory entry 的结构 和 存放位置\n 2. msat 表在文件中的位置\n 3. stream 和 short-stream 的切割点：什么情况下用 stream 什么时候用 short-stream\n 4. short-sector 存储于哪些 sector 中\n 5. ssid 存储于哪些 sector 中\n\n这些内容就存放在 compound file header 和 directory entry root 中。\n\n\n# ole\n\nole, object linking and embedded。\n\n微软在 1991 年制定的 ole1.0 规范，主要解决多个应用程序之间的通信和消息传递问题，微软希望第三方开发商能够遵守这个规范，以使在当时的windows平台上的应用程序能够相互协调工作，更大的提高工作效率。然而事与愿违，只有很少的软件开发商支持它。为此，微软于1993 年发布了新的规范 ole2.0，它在原有的基础上完善并增强了以下各方面的性能：\n\n 1. ole自动化：一个程序有计划地控制另一个程序的能力。\n 2. ole控件：小型的组件程序，可嵌入到另外的程序，提供自己的专有功能。\n 3. ole文档：完善了早期的混合文档功能，不仅支持简单链接和嵌入，还支持在位激活、拖放等功能。\n\n强大的功能使得很多的开发商开始支持新的 ole 技术，因为微软在 ole2.0 中建立了 com（component object model即组件对象模式）规范。\n\nole 相关的基础概念有：\n\n * 容器：\n   * 容器是一个客户程序，它具有申请并使用其它com组件通过接口为其它程序实现的功能；\n * 服务器：\n   * 服务器通过特定的接口将自己完成的一些功能，提供给使用自己的应用程序（例如画笔程序是一个文档服务器，它提供创建并编辑bmp 图像的功能）。当打开word，选择【插入】菜单下的【对象...】项，您可以看到在您的系统中存在哪些文档服务器，此时的word以文档容器的身份出现。\n * 在位激活：\n   * 当您双击插入的对象后发现word的菜单有些改变成文档服务器程序的菜单，可以在当前的环境下编辑对象，这称为在位激活。\n\n简单的说，ole 是一种可以用来创建复杂文档的技术，这些复杂文档可以包含来自不同渠道（数据源）的信息，并保留其原始属性。例如，一个支持 ole 的文档（例如word）能够支持嵌入的表格对象，并且嵌入的文档会保留所有原来的属性。如果用户打算编辑嵌入的数据，windows 操作系统会激活原来的应用程序（如excel）并载入这个嵌入的文档。\n\n\n# ole 格式\n\nole 文件的 property sets 通过以下两个 stream 存储:\n\n * "\\005summaryinformation"\n * "\\005documentsummaryinformation"\n\n这两个 stream 都以 propertysetstream 结构(见 ms-oshared 的 section3.2.1 )开头。\n\nole文件中包含的常见内容主要有：\n\n# 1. linked or embedded object\n\n包含嵌入、链接对象的容器文档的逻辑布局如下图：\n\n * olestream\n   * ole2.0 中，由复合文档的以 "\\1ole" 为名的 stream object 包含。olestream structure 表述了存储对象是用于 linked object 还是 embedded object。当此结构是为 linked object 指定 storage object 时，它还指定了对此链接对象的引用。\n * compobjstream\n   * ole2.0 中，名为 "\\1compobj" 的流，主要用于描述 clipboard format、用于显示的linked object 或 embedded object 的名字。\n * embedded object native data\n   * ole1.0 中，其由 embeddedobject structure 的 nativedata field 指定。\n   * ole2.0 中，native data 的指定方式有以下两种，可以互换使用：\n     * 由复合文档的以 "\\1ole10native" 为名的 stream object 包含。如 olenativestream structure 的 nativedata field 所指定。\n     * 由 creating application 创建的 stream objects 可以包含 native data。此类流对象是 creating application 的私有对象，未在文档中说明。\n       * creating application: an application whose data is stored in or referenced by documents from other applications.\n * embedded object presentation data\n   * 用于指定如何在 container application 中显示 linked or embedded object 对象\n   * ole1.0 中，其由 embeddedobject structure 的 presentation field 指定\n   * ole2.0 中，由复合文档的以 "\\2olepres" 为前缀(后跟着3个十进制数字，并且最多只能有999个presentations)的 stream objects 指定。每一个 stream 都包含一个 olepresentationstream structure。\n\n# 2. 宏\n\n常见的 宏 有两种：vba 和 ms-excel4.0, 它们出现的主要位置有：\n\n * vba project\n   * office97 ~ 2003: vba project storage\n   * office2007 ~ : vbaproject.bin\n * microsoft office excel 4.0\n   * office97 ~ 2003: book\\workbook stream\n     * 注：主要通过 biff 格式保存了 formula、drawing group 等内容\n   * office2007 ~ : macrosheets\n     * microsoft 365 新增 lambda function\n * macro template\n   * office2007 ~ : /[xx]/_rels/settings.xml.rels 中引用外部(远程)模板文件\n * vbaprojectstg\n   * binary powerpoint document 中用于指定一个用于 vba project 的结构化存储\n\n# 3. officeart\n\n * office97 ~ 2003:\n   * worddocument、book\\workbook、\'powerpoint document\' stream\n     * office drawing binary file format (ms-odraw)，this file format is also known as officeart.\n * office2007 ~ :\n   * todo\n\n# 4. encryption and obfuscation\n\n详见 office 格式简析 - crypto\n\n这里需要注意的是 vba project 的保护(待确认)：\n\n * vba project\n   * 可以对其中的 stream 设置独立的密码 (未确认)\n     * vba uses a reversible encryption algorithm for selected data.\n   * project stream: projectprotectionstate\n     * projectprotectionstate: "cmg="0705d8e3d8eddbf1dbf1dbf1dbf1"" specifies no sources are restricted access to the vba project. the value is obfuscated by data encryption (section 2.4.3).\n     * projectpassword (section 2.3.1.16): "dpb="0e0cd1ecdff4e7f5e7f5e7"" specifies the vba project has no password. the value is obfuscated by data encryption (section 2.4.3).\n     * projectvisibilitystate (section 2.3.1.17): "gc="1517caf1d6f9d7f9d706"" specifies the vba project is visible. the value is obfuscated by data encryption (section 2.4.3).\n     * libname: "vbe" specifies a built in name for the vba automation type library.\n\n\n# vba project 格式\n\nvba project 是由一系列 records 组成的结构。其中每个 record 都定义了 project 的三要素之一的部分内容。每个 record 都是以结构开头：id(2 bytes) + size(4 bytes) + ...\n\nproject 的三要素有：project information, project references, and project items.\n\n# 1. project information\n\nole 中 vba 存储(storage)结构如下：\n\n\n\n其中 project root storage 是一个独立的 storage。例如，ole 文件中的 macros storage。\n\n * vba storage\n   * sub-structure\n     * _vba_project stream\n       * must\n       * 包含了 vba project 的基础信息，如，版本号(用于加载此结构的剩余内容) 等\n     * dir stream\n       * must\n       * 指明 vba project properties, project references, 和 module properties\n       * the entire stream must be compressed as specified in compression\n     * "module stream"\n       * vba project 中的每个 module 必须拥有一个 module stream\n       * vba project 中 modules 的源码。此 stream 的名字由 modulestreamname 指定。\n     * srp streams\n       * optional\n       * 指定 特定实现和版本相关 的性能缓存的流。必须是读取时忽略。写入时不得出现。\n * project stream\n   * must\n   * vba project properties, 如 工程的目录结构、脚本类型、module的可编辑窗口的信息等等, 以及一些 vba project 的附加信息，如：projectpassword、projectvisibilitystate 等 注：[ms-ovba] - v20200219 的 2.3.1.3 projectmodule 有脚本类型的相关说明\n * projectwm stream\n   * optional\n   * 包含了用于 module name 在 multibyte character set (mbcs) 和 utf-16 之间互相映射的信息\n * projectlk stream\n   * optional\n   * 包含了 vba project 中的 activex controls 的 license 信息\n * designer storages\n   * optional\n   * 每个 vba project 中的 designer module 都必定有一个与之对应的 designer storage ，此 storage 的名字由 dir stream 中相关 module 中的 modulestreamname record 指定。\n   * 每个 designer storage 必定有一个 vbframe stream\n     * vbframe stream，用于描述 designer module 的属性信息，此 stream 的名字必须是以 utf-16 character 0x0003 开头紧接着是 utf-16 的 "vbframe"。\n   * 如果此 designer 是一个 office form activex control, 那么此 storage 必定包含 [ms-oforms] section 2中描述的必须 storages 和 streams。\n\n# 2. project references\n\ndir stream 中的 records 包含了 vba project 对外部资源引用的信息。主要有三类：referencecontrol、referenceregistered、referenceproject。\n\n# 3. project items\n\nvba project 包含一系列用于嵌入 macros 的 project items。而 project item 是由多个 records 组合定义。主要有以下 5 种 project item(详见 ms-ovba 文档): project package, document modules, procedural modules, class modules 和 designer modules。\n\n# 4. pcode\n\n它并不广为人知，一般来说 vba 编写的宏以三种不同的可执行形式存在，每种形式都可以是在运行时实际执行的内容，具体取决于具体情况. 它们是：\n\n * source code\n   * 这是最为我们熟知的形式。但大多数情况下，office 会完全忽略源代码。\n   * 事实上，删除源代码是可能的，但宏仍然可以毫无问题地执行(从 pcode)\n     * 这种威胁利用技术被称为 vba stomping\n * p-code\n   * 当每行 vba 脚本被输入到 vba 编辑器中时，它会立即被编译成 pcode 并存储到模块流中。 pcode 正是大部分时间被执行的代码。\n   * 事实上，即使在 vba 编辑器中打开宏模块的源码，显示的也不是解压后的源码，而是反编译成源码的 pcode。\n   * 只有在使用与创建文档时使用的 vba 版本不同的 office 版本下打开文档时，才会将存储的压缩源代码重新编译为 pcode，然后执行该 pcode\n   * 这使得可以在支持 vba 的任何版本的 office 上打开包含 vba 的文档，并使内部的宏保持可执行，尽管不同版本的 vba 使用不同(不兼容)的 pcode 指令。\n * dxecodes\n   * 当 pcode 至少被执行过一次后，它会以进一步标记化形式存储在文档的其他地方(在流中，其名称以 _srp 开头，后跟一个数字)。从那里它可以执行得更快。\n   * 但是 execode 的格式极其复杂，并且特定于创建它们的特定 office 版本(不是 vba 版本)。这使得它们的通用性很差。\n   * 此外，它们的存在不是必需的 --- 它们可以被删除并且宏将运行得很好(从 pcode)\n\n综上，我们可以知道：\n\n * source 的通用性最好，但只有在 pcode 不能使用时，才会被使用\n * execodes 的通用性最差，但执行得最快\n * p-code 则是执行速度和通用性的折中，也是用的比较广泛的形式\n\n因此，我们有必要解析 pcode，具体可以参考：github.com/bontchev/pcodedmp\n\n\n# microsoft office excel 4.0\n\nmicrosoft office excel 4.0, 主要存在于 ms-xls 的 book\\workbook stream 中。此 stream 以 biff8(binary interchange file format) 格式组织各个细节。\n\nstream 由以下几部分组成：\n\n * globals substream\n   * 描述 workbook 中的全局属性和数据\n     * 注意 lbl、shrfmla 数据\n * chart sheet substream\n * dialog sheet substream\n * macro sheet substream\n * worksheet substream\n\n使用 excel 4 macros 的一些细节：\n\n * 使用 relative named range 时，函数主体和结果之间的单元格距离必须都相同，否则可能会计算出错误的结果。\n * office 2007 ~ 中，任何带有 excel 4 macro 的文件都必须另存为启用宏的工作簿 (.xlsm)，尝试另存为标准 excel 文件将触发以下错误消息:\n * 任何包含数组的函数，例如 get.workspace(37) 或 names() 都应该包含在 index 函数中: 如，=index(get.workspace(37),!a1)，在这个例子中，a1 包含应该检索的数组中的数字，例如如果 a1 包含值 2，它将返回 get.workspace(37) 数组中的第二项。\n * 使用 macro worksheet 时，工作表设置为显示公式，而不是公式的结果。可以使用 ctrl + | 在公式视图和结果视图之间切换。\n\n# ptgexp、shrfmla、array\n\nptgexp 一般会出现在 formula 的第一个 rgce 元素。此时，它表示当前单元格是 array formula 或 shared formula 的一部分。\n\nptgexp.row 和 ptgexp.col 指定了一个在当前 sheet 中的 cell\n\n * 这个 cell 也是 array formula 或 shared formula 的一部分\n   * 也就是说必定有一个 formula record 的 row == ptgexp.row && col == ptgexp.col\n     * 紧跟着这个 formula record 的必定是一个 shrfmla record 或者 array record\n     * 也就是说这个 ptgexp 指向了使用此 array formula 或 shared formula 的区域中的 the first cell\n       * 隐含：拥有 ptgexp 的 formula record 满足：record.row == ptgexp.row && record.col == ptgexp.col 时，它后边一定跟着 shrfmla record 或 array record\n   * 这个 formula record 定义了区域中使用 array formula 或 shared formula 的 the first cell\n\nshrfmla(shared formula record)\n\n * 此 record 前必定有一个 formula record，这个 formula record 指定了使用此 shared formula 的区域中的 the first cell\n * 其它使用了此 shared formula 的 formula records 后续会出现，但不一定是连续的\n * 使用了此 shared formula 的 formula records 会有 formula.fshrfmla bit 被置位，同时 formula.cell 必定位于 shrfmla.ref 指定的区域内\n\narray(array formula record)\n\n * 此 record 前必定有一个 formula record，这个 formula record 指定了使用此 array formula 的区域中的 the first cell\n * 其它使用了此 array formula 的 formula records 后续会出现，但不一定是连续的\n * 使用了此 array formula 的 formula records 必定有 formula.cell 位于 array.ref 指定的区域内，同时这些使用 array formula 的 formula 的 rgce 必定以 ptgexp 开头。\n\n# 解析过程中遇到的问题\n\n * rgceloc 可以按照 rgcelocrel 来解析，以简化解析流程。\n * 解析 formula 的过程中，会遇到 "is part of a revision or not" 的分支流程，这里涉及以下三个概念：\n   * userbview record:\n     * fpersonalview : must be 0 if this is not a shared workbook.\n   * revision stream\n     * an instance of the revision stream specifies the revision logs (section 2.2.11.2) and revision records (section 2.2.11.3) for a shared workbook (section 2.2.11).\n     * the name of this stream must be "revision log". a file must contain at most one revision stream. the revision stream must exist if the workbook is a shared workbook.\n   * revision records\n     * a series of records. 详情可以参考 [ms-xls] 文档。\n * external references：\n   * supporting link 包含了 self-referencing、same-sheet referencing、external workbook referencing 等等类型。\n * name manager:\n   * lblrecord : (关联 name 和 sheet)\n     * 内置名字的索引，可能由 1 或 2 字节表示\n     * nameparsedformula 可能出现 ptgref3d 的 ixti == 0xffff，此时，此时的结构未被文档记录：\n       * we can reproduce it: make a macro sheet in ooxml and export it to xls.\n       \n         \t\tuint8_t ptg = uint8_t(data[cce_offset] & 0x7f);\n         \t\tif (ptg == ptgref3d || ptg == ptgref3da || ptg == ptgref3dv) {\n         \t\t\tuint16_t ixti = *(uint16_t*)(data + cce_offset + 1);\n         \t\t\tif (ixti > 0xff00 && record->cce >= 15 + 3) {\n         \t\t\t\tassert(record->itab == 0 || record->itab == 1);\n             uint16_t iscope_1base = (record->itab == 1) ? record->reserved1 : record->itab;\n         \t\t\t\tuint16_t isheet_0base_a = *(uint16_t*)(data + cce_offset + 11);\n         \t\t\t\tuint16_t isheet_0base_b = *(uint16_t*)(data + cce_offset + 13);\n         \t\t\t\tassert(isheet_0base_a == isheet_0base_b);\n         \t\t\t\tauto row = *(uint16_t*)(data + cce_offset + 15);\n         \t\t\t\tauto col = (uint16_t)*(uint8_t*)(data + cce_offset + 17);\n         \t\t\t}\n         \t\t}\n         \t}\n       \n       \n       1\n       2\n       3\n       4\n       5\n       6\n       7\n       8\n       9\n       10\n       11\n       12\n       13\n       14\n       \n * rgce 的 actual_ptg_size 跟实际情况不符合\n\n\n# doc\n\n一个 doc 文档应当由以下几个部分组成：\n\n 1. worddocument stream\n    * 有一个 fib structure 在流的起始位置\n 2. table stream\n    * 1table 或者 0table 流必定存在。当二者同时存在时，base.fwhichtblstm 指定的为有效流，忽略其他即可。\n    * 如果文档被加密的话，会有一个 encryptionheader 结构在流的起始位置。反之，如果文档没有加密，则此流没有预定义的结构。\n    * 存储了文档的文本信息\n 3. data stream\n    * 没有预定义的结构，也不是必定存在。它包含的是 fib 或 文件的其它部分的引用数据，也就是说如果没有引用数据的话，这个流没有存在的必要\n 4. objectpool storage\n    * object pool storage 包含一些用于持久化 embedded ole objects 的 storages。如果文档没有 embedded ole objects 时，是不会出现此 storage 的。\n    * 每一个位于 objectpool storage 中的 storage 都有一个 objinfo stream (名为 "\\003objinfo")，这个流里存放着用于描述 embedded ole object 信息的 odt structure。\n      * embedded ole object 相关的其他流的描述可以参考 embedded object native data 相关内容\n    * 每个 sub-storage 都存储了一个用户嵌入(embedded)的文件。并且，每个 sub-storage 都是以: 下划线"_" + 10个digits 组成，如 _1557814583\n      * 关联引用的关键词：sprmcfole2、sprmcpiclocation\n 5. summary information\n    * summary information stream\n    * document summary information stream\n    * encrypt stream\n      * 名为 encryption 的流，只有当以下两个条件同时满足才会出现：文档被 rc4 cryptoapi 加密， 并且，encryptionheader.flags 的 fdocprops 标记被置位\n 6. macros stream\n    * vba project\n 7. signature\n    * 参考 ms-offcrypto 中的说明。\n 8. protected content\n\n * 由 irmds 描述的方式进行保护的内容, 在 ms-offcrypto 有描述。\n\n\n# ppt\n\n按照 [ms-ppt] - v20210817 ：pageno 28 中 part 1 ~ 11 的描述，即可解出完整的 ppt 文档内容。\n\n注意：the usereditatom record closest to the end of the pointpower document stream\n\n其中，所有用于 presentation 的文本都存储在 "powerpoint document" stream 中；所有用于 presentation 的 images 都存储在pictures stream 中；不过，embedded files 没有存储在独立的 storages，而是被融合到 "powerpoint document" stream 中，此外，这些 embedded files 在存储时，有些会被压缩有些却不会。\n\n# external objects\n\nslides 可以包含连接到外部的 objects。播放 ppt 的人可以在幻灯片放映期间激活链接对象以访问外部资源。external objects 的例子有 embedded and linked audio, linked video, embedded and linked ole objects, 以及 hyperlinks。\n\n也就是说 embedded or linked object 在 ppt 中的存在形式就是 external objects。\n\n有关有 external objects 的记录，请参阅 [ms-ppt] external object types (section 2.10) 相关内容。简单的说，为了解析出 external objects，我们需要关注：\n\n * externaloleobjectstg 0x1011 , 用于对象存储(如果有n个则会有n个此类型的 record)\n * documentcontainer 0x03e8 , 用于描述文档对象\n   * docinfolistcontainer 0x07d0\n     * vbainfocontainer 0x03ff\n       * vbainfoatom 0x0400\n   * exobjlistcontainer 0x0409\n     * storage for compressed/uncompressed ole/vba/activex control data, 如 vbaprojectstg\n   * soundcollectioncontainer\n   * drawinggroupcontainer\n\n也就是说要首先找到 documentcontainer：\n\n1. 构造 persistdirectory\n  current user stream\n    currentuseratom record\n      offsettocurrentedit field\n  |--\x3epowerpoint document stream\n  |\t\tusereditatom\n  |\t\t\toffsetpersistdirectory field\n  |\t\tpersistdirectoryatom\n  usereditatom.offsetlastedit (repeat until offsetlastedit is 0x000000)\n\n2. 定位 documentcontainer\n  usereditatom.docpersistidref\n    documentcontainer record\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n关于鉴别 embedded ole object 对象的具体步骤可以参考 [ms-ppt] 2.1.2 powerpoint document stream part 9 相关内容\n\n关于鉴别 linked ole object 对象的具体步骤可以参考 [ms-ppt] 2.1.2 powerpoint document stream part 10 相关内容\n\n\n# xls\n\n一个 xls 文件最多只能一个 component object stream。 一个 xls 文件最多只能一个 ole stream。 一个 xls 文件最多只能一个 control stream。\n\nworkbook stream 中存储了 excel 中所有的 text 和 formulas。\n\n# embedded or linked object\n\n在 excel 的 workbook 中嵌入一个文件的话，这些文件会被存储在名为 "mbd + 随机的8个十六进制数字" 的 embedding storages 中。\n\n每个 embedding storage 都表示了一个基于 storage-based 持久化的 embedded ole object 或 activex control 对象。同时，持久化在 embedding storage 的对象必定有一个相关联的 obj record 在 worksheet substream、macro sheet substream 或 dialog sheet substream 中，并且 cmo.ot == 8，pictflags.fprstm == pictflags.fdde == 0。\n\n不过不同类型的文件在 embedding storage 中的形式有些不一样，如：\n\n 1. 如果 embedded file 是另外一个 binary office document, 那么这个 embedded file 中的 storages 和 streams 会被当成对应的节点原样存储在 mdb storage 中\n 2. 如果 embedded file 是一个 open xml document, 那么这个 embedded file 会被完整存储在名为 "package" 的 stream 中\n\n一个 link storage 指定一个 linked ole object 和任意其他的默认数据或表示为其建立的缓存。它的名字必定是由："lnk" + 8个十六进制数字 标识。持久化在 link storage 的对象必定有一个相关联的 obj record (obj.pictfmla.lposinctlstm)在 worksheet substream、macro sheet substream 或 dialog sheet substream 中，并且 cmo.ot == 8，pictflags.fprstm == pictflags.fdde == 0。\n\n\n# ooxml\n\nooxml(office open xml file formats), 简单来说，ooxml 是一个基于 xml 的文档格式标准，最早是微软 office2007 的产品开发技术规范，先是成为 ecma(ecma-376) 的标准，最后改进推广成为了 iso 和 iec (as iso/iec 29500) 的国际文档格式标准。也就是说，通过 ooxml 标准，我们能够在不依赖 office 产品的情况下，在任何平台读写office word，ppt 和 excel 文件。\n\nooxml 的主要目录结构如下所示：\n\nooxml\n├── [content_types].xml // 描述文档各个部分的contenttype，协助解析文档\n│           \n├─ docprops        // ms-office 需要此内容以打开文件，而 wps 不需要\n│   ├── app.xml    //程序级别的文档属性，如：页数、文本行数、程序版本等\n│   └── core.xml   //用户填写的文档属性，如：标题、主题、作者等\n│\n├─ _rels\n│   └── .rels      //描述各个部分之间的关系\n│\n└─ word / xl / ppt\n    ├── document.xml     //word\n    ├── fonttable.xml    //word，页脚\n    │\n    ├── workbook.xml     // xl\n    ├── worksheets       // xl\n    │    └── sheet1.xml\n    ├── macrosheets      // xl, microsoft excel 4.0 macros\n    │      ├── _rels\n    │      │   └── sheet1.xml.rels\n    │      └── sheet1.xml\n    |\n    |── presentation.xml // ppt\n    |\n    |── embeddings       //all, optional, 存放 embedded files\n    |     ├── a\n    |     └── b\n    │\n    |── vbadata.xml      //all, vba属性，是否auoopen，是否加密\n    |── vbaproject.bin   //all, 记录 vba project 信息, ole 格式\n    |\n    ├─ theme             //all, 记录样式，颜色编号，字体大小等等\n    │    └── theme1.xml\n    │\n    ├─ _rels             //all, relationships\n    |    ├── settings.xml.rels   // 指定 模板 引用\n    │    ├── document.xml.rels   // 使用 id 和 url 来定义文档各零件\n    |    ├── workbook.xml.rels   // 使用 id 和 url 来定义文档各零件\n    │    └── vbaproject.bin.rels // vba\n    │ \n    ├── printersettings //all, reference to printer settings data\n    │....└── printersettings1.bin\n    │\n    └─ styles.xml       //all\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n\n\n\n# 1. name representation\n\n无论是 definednames 中定义的，还是表格显示的名字，这些需要展示的名字都应当在 docprops\\app.xml 中作为 application-defined file properties 部分被定义，如下：\n\n<titlesofparts>\n <vt:vector size="[0-9]+" basetype="lpstr">\n  <vt:lpstr>sheet1</vt:lpstr>\n  <vt:lpstr>sheet2</vt:lpstr>\n  <vt:lpstr>sheet3</vt:lpstr>\n  <vt:lpstr>value1</vt:lpstr>\n  <vt:lpstr>value2</vt:lpstr>\n </vt:vector>\n</titlesofparts>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 2. cell references & name\n\nexcel中可以给 函数、cell、sheet、甚至任意一段文本或图形等定义名字(也被称为 bookmark)，并通过名字来引用对应的内容，引用方式参考\n\n * ecma-376-fifth-edition-part-1 --- 18.17.2.3 cell references\n * ecma-376-fifth-edition-part-1 --- 18.17.2.5 names\n\nname 的组成形式：\n\nname = [ workbook-name, "!" ], [letter | "_" | "\\"], [ letter | decimal-digit | "_" | "." ] ;\n\n\n1\n\n\n其中 name 不能包含以下几种格形式：\n\n * true or false\n * user-defined-function-name\n * cell-reference\n\nfunction-name 的组成形式：\n\nfunction-name= prefixed-function-name | predefined-function-name | user-defined-function-name ;\n\npredefined-function-name= "abs" | "acos" | "acosh" | ( any of the other functions defined in §18.17.7) ;\nprefixed-function-name= "iso.", predefined-function-name | "ecma.", predefined-function-name ; \nuser-defined-function-name= letter, [ letter | decimal-digit | "." ] ;\n\n\n1\n2\n3\n4\n5\n\n\n其中 function-name 不能包含以下几种格形式：\n\n * true or false\n * name\n * cell-reference\n\ncell reference 的形式有两种：r1c1-style 和 a1-style\n\noperator 有以下几种格式：\n\n":" | comma | space | "^" | "*" | "/" | "+" | "-" | "&" | "=" | "<>" | "<" | "<=" | ">" | ">=" | "%" ;\n\n\n1\n\n\n\n# 3. formulas and expressions\n\n * ecma-376-fifth-edition-part-1 --- 17.16.3 formulas and expressions\n\na field instruction can involve a calculation via a formula, which is simply an expression that is an arbitrary complex arithmetic expression，如：\n\n<sheetdata>\n\t\t<row r="2" spans="4:4" x14ac:dydescent="0.25">\n\t\t\t<c r="d2" s="1" t="b">\n\t\t\t\t<f>formula()=formula()=formula(\'buk1\'!e11,\'buk2\'!b12)=formula(\'buk2\'!h5,\'buk3\'!h3)=formula(\'buk3\'!c9,\'buk4\'!c2)=formula(\'buk4\'!i8,\'buk5\'!f2)=formula(\'buk5\'!b12,\'buk6\'!b10)=formula(\'buk6\'!g3,\'buk7\'!i2)=formula(\'buk7\'!d13,\'buk1\'!a3)=formula(\'buk3\'!h3&amp;\'ss1\'!o6&amp;\'ss1\'!d16&amp;\'ss1\'!k13&amp;\'ss1\'!r12&amp;\'ss1\'!r14,d3)=formula(\'buk3\'!h3&amp;\'buk7\'!i2&amp;\'buk4\'!c2&amp;\'buk5\'!f2&amp;\'buk5\'!f2&amp;ss1br2!b3&amp;\'buk1\'!a3&amp;ss1br2!d5&amp;\'buk6\'!b10&amp;ss1br2!g3&amp;\'buk7\'!i2&amp;\'buk7\'!i2&amp;ss1br2!b9,d17)</f>\n\t\t\t\t<v>1</v>\n\t\t\t</c>\n\t\t</row>\n\t</sheetdata>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# ms-office 的其他形式\n\n使用 ms-office 软件可以将 office 文件通过"另存为"保存为 xml、mhtml、html 等格式的文本文件，并且，可以再次通过 ms-office 软件打开、编辑。\n\n另外，这些转换而成的文本类型的文档，被加密后，是一个 ole 文件。\n\n被转换而成的 xml 文件，在结构上保持了跟 binary 形式的 office 文件一致，并且一一对应。如，contenttype 为 "application/vnd.ms-office.vbaproject" 的 binarydata 数据, 就是二进制形式的 vbaproject 内容 base64 后的结果。\n\n这里要注意的是，在解析 bindata 类型的数据时，可能会遇到 mso(activemine) 文件。这是一种文件名为 *.mso 同时 mime types 为 application/x-mso 的结构未公开的文件格式(参考 activemime-format )。\n\nmso文件是将microsoft office文档保存为网页时创建的宏引用文件。它包含有关原始文件中包含的宏和ole（对象链接和嵌入）对象的信息，并且可以被创建的网页作为样式表引用。mso文件可以用文本编辑器查看，但由于内容是编码的，因此无法读取。大多数用户只会将mso文件作为电子邮件的附件。\n\n\n# rtf\n\n富文本格式（rtf，rich text tormat）是微软的文本和图像信息交换指定的格式。rtf文件可以划分为文件头和文档区两个部分组成。文件头和文档区由文本、控制字和控制符组成，同时利用{…}来表明层级关系。\n\n\n# 检出\n\n * hash (忽略大小写、空字符)\n   * function\n   * stream\n * 模糊匹配\n   * 简单的模式匹配\n   * eg.\n     * 搜索到 ：virtualprotectex、writeprocessmemory、createremotethread、virtualallocex\n     * shell environ$("comspec") & " /c attrib -s -h """ & application.startuppath & "\\k4.xls""", vbminimizedfocus\n     * shell ("\\jdq\\cc$\\b.exe")\n     * if .lines(1, 1) = "apmp" & .lines(1, 2) <> "kill" then ........ end if\n     * 混淆的文件：熵 ？\n\n\n# 清理\n\n * 抹除\n   * function\n     * 替换函数内容为空格\n   * stream :\n     * 将 stream 的 size 置 0，同时抹除第一个扇区内容，断开内容扇区链\n     * 一般来说，只修改 size 就可以让 office 软件无法读取相关内容。但其他杀软可能会继续报毒，毕竟 stream 的其他信息依然有效，可以在容错情况下还原出来 malicious 内容。\n     * 注意：其它部分对 macro 的引用，如：\n       * doc 中 fccmds 会通过 macro names 引用对应的宏，所以\n         1. 根据需要将 document 流中的 fccmds 和 lcbcmds 所引用的数据\n         2. 粗暴的将 document 流中的 fccmds 和 lcbcmds 都置空\n * 还原\n   * 还原被加密破坏的文件内容\n     * 病毒感染时是有机会操作原有的正常 vba 脚本的，比如，加密（目前还没见到此类样本）。\n\n\n# reference\n\n * ms-office-extensions\n\n * ms-office file formats\n\n * [ms-ovba] - v20210817\n\n * [ms-offcrypto] - v20210817\n\n * [ms-xls] - v20210817\n\n * [ms-doc] - v20210817\n\n * [ms-ppt] - v20210817\n\n * [ms-oleds] - v20210625\n\n * introducing the office (2007) open xml file formats\n\n * microsoft office excel 97 - 2007 binary file format (.xls) specification\n\n * ole1.0 and ole2.0 formats\n\n * microsoft office word 2003\n   \n   * microsoft office word 2003 preview\n   * the xml files: xml in microsoft office word 2003\n\n * [翻译]攻击互通性-以ole为例\n   \n   * attacking interoperability: an ole edition\n\n * 宏病毒常用的一些trick\n\n * old school: evil excel 4.0 macros (xlm)\n\n * oletools\n\n * didierstevens\n   \n   * oledump-py\n   * oledump.py\n   * msoffcrypto-crack.py\n\n * 0xevilc0de\n   \n   * maldoc uses template injection for macro execution\n   * excel 4 macros – get.workspace reference\n   * removing passwords from vba projects\n   * maldoc uses rc4 to hide powershell script, retrieves payload from dns txt record\n   * maldoc uses windows api to perform process hollowing\n\n * jstrosch\n   \n   * malware-samples\n\n * spiderlabs\n   \n   * spiderlabs-blog\n\n * template injection\n   \n   * malware-samples: word doc uses template injection\n\n * 复合文档文件格式研究\n\n * velvetsweatshop: default passwords can still make a difference\n\n * remnux: analyze documents',charsets:{cjk:!0}},{title:"Office 格式简析 - Crypto",frontmatter:{title:"Office 格式简析 - Crypto",date:"2021-06-18T13:50:00.000Z",lastmod:null,description:"Office 格式简析，查找 宏 以进行病毒检测",categories:["skills"],tags:["ole","ms-cfb","office"],permalink:null},regularPath:"/blog/skills/office/ole_office_msoffcrypto.html",relativePath:"blog/skills/office/ole_office_msoffcrypto.md",key:"v-76ece9bf",path:"/blog/skills/office/ole_office_msoffcrypto.html",headers:[{level:2,title:"一、Data Spaces",slug:"一、data-spaces",normalizedTitle:"一、data spaces",charIndex:220},{level:3,title:"Information Rights Management Data Space(IRMDS)",slug:"information-rights-management-data-space-irmds",normalizedTitle:"information rights management data space(irmds)",charIndex:610},{level:3,title:"Protected Content Stream",slug:"protected-content-stream",normalizedTitle:"protected content stream",charIndex:3336},{level:3,title:"Encryption and Obfuscation",slug:"encryption-and-obfuscation",normalizedTitle:"encryption and obfuscation",charIndex:3655},{level:3,title:"Write Protection",slug:"write-protection",normalizedTitle:"write protection",charIndex:6586},{level:3,title:"Digital Signatures",slug:"digital-signatures",normalizedTitle:"digital signatures",charIndex:7590},{level:2,title:"二、XLS",slug:"二、xls",normalizedTitle:"二、xls",charIndex:8105},{level:3,title:"2.1 Password Verifier Algorithm",slug:"_2-1-password-verifier-algorithm",normalizedTitle:"2.1 password verifier algorithm",charIndex:8135},{level:3,title:"2.2 Encryption (Password to Open)",slug:"_2-2-encryption-password-to-open",normalizedTitle:"2.2 encryption (password to open)",charIndex:9104},{level:3,title:"2.3 XorArrayIndex",slug:"_2-3-xorarrayindex",normalizedTitle:"2.3 xorarrayindex",charIndex:9965},{level:2,title:"三、DOC",slug:"三、doc",normalizedTitle:"三、doc",charIndex:10293},{level:3,title:"3.1 Encryption and Obfuscation (Password to Open)",slug:"_3-1-encryption-and-obfuscation-password-to-open",normalizedTitle:"3.1 encryption and obfuscation (password to open)",charIndex:10303},{level:2,title:"四、PPT",slug:"四、ppt",normalizedTitle:"四、ppt",charIndex:13362},{level:3,title:"Encryption",slug:"encryption",normalizedTitle:"encryption",charIndex:391},{level:2,title:"Reference",slug:"reference",normalizedTitle:"reference",charIndex:1086}],headersStr:"一、Data Spaces Information Rights Management Data Space(IRMDS) Protected Content Stream Encryption and Obfuscation Write Protection Digital Signatures 二、XLS 2.1 Password Verifier Algorithm 2.2 Encryption (Password to Open) 2.3 XorArrayIndex 三、DOC 3.1 Encryption and Obfuscation (Password to Open) 四、PPT Encryption Reference",content:'# MS-OFFCRYPTO\n\nMS-OFFCRYPTO 只对 windows office 生效，所以有一些常见的规则约定：\n\n * ole 中用于指定 storages 和 streams 位置的路径使用 backslash() 作为分隔符\n * 以 backslash() 开始的路径是指 ole compound file 的 root storage\n * Byte Ordering 默认是 little-endian\n\n\n# 一、Data Spaces\n\ndata spaces 结构描述了一种存储经过某种方式转换(transformed)后的 OLE 复合文件的一致性方法。所以，该结构需要存储受保护的内容(protected content)和应用于内容的转换信息(information about the transforms)。例如，下文的 IRMDS 和 Encryption 等都是基于 data spaces 结构进行的。\n\ndata spaces 结构允许客户端应用程序描述一个或多个任意转换。每个变换表示要对原始文档内容中的一组 storages 或 streams 执行的单个任意操作。一个或多个转换可以被组合到一个 data space 的定义中，然后这个定义可以被应用到存在于 data space map 中的原始文档的任意 storages 或 streams 中。\n\n\n# Information Rights Management Data Space(IRMDS)\n\nIRMDS 主要应用于强化文档的权限管理策略。当对使用了权限管理策略的文档进行读、写、创建操作时，需要使用到 IRMDS structure。\n\nIRMDS 可以被应用于以下两种类型的文档:\n\n * Office binary documents\n * ECMA-376 documents\n\n\n\nECMA, European Computer Manufacturers Association； ECMA376 协议代指 Office Open XML 格式\n\n具体的差别如下：\n\n# "\\0x06DataSpaces\\DataSpaceMap" Stream\n\n 1. Office binary document\n\n * 至少有一个 DataSpaceMapEntry 结构\n * 必须有一个 DataSpaceMapEntry 结构的 DataSpaceName 字段为 "\\009DRMDataSpace"\n   * 此结构中，有且只有一个 ReferenceComponents 结构，表示一个名为 "\\009DRMContent" 的 stream\n * 第二种 DataSpaceMapEntry 结构的 DataSpaceName 字段必须为 "\\009LZXDRMDataSpace"\n   * 此结构中，有且只有一个 ReferenceComponents 结构，表示一个名为 "\\009DRMViewerContent" 的 stream\n\n 2. ECMA-376 document\n\n * 有且只有一个 DataSpaceMapEntry 结构，这个结构的 DataSpaceName 字段为 "DRMEncryptedDataSpace"\n   * 此结构中，有且只有一个 ReferenceComponents 结构，表示一个名为 "EncryptedPackage" 的 stream\n\n# "\\0x06DataSpaces\\DataSpaceInfo" Storage\n\n 1. Office binary document\n\n * 必须包含一个名为 "\\009DRMDataSpace" 的 stream\n   * 流中必须包含一个 DataSpaceDefinition 结构，此结构有且仅有一个名为 "\\009DRMTransform" 的 TransformReferences\n * 可能会包含一个名为 "\\009LZXDRMDataSpace" 的 stream\n   * 流中必须包含一个这样的 DataSpaceDefinition 结构：有且仅有两个 TransformReferences 条目，"\\009DRMTransform" 和 "\\009LZXTransform"\n\n 2. ECMA-376 document\n\n * 必须包含一个名为 "DRMEncryptedDataSpace" 的 stream\n   * 流中必须含有一个 DataSpaceDefinition 结构，此结构有且仅有一个名为 "DRMEncryptedTransform" 的 TransformReferences 条目\n\n# "\\0x06DataSpaces\\TransformInfo" Storage\n\n 1. Office binary document\n\n * 必须包含一个名为 "\\009DRMTransform" 的 storage，其下必须包含一个名为 "\\006Primary" 的 stream (完整路径为："0x09DRMTransform\\0x06Primary")。\n   * 此 stream 必定包含 IRMDSTransformInfo 结构，其内容如下：\n     * TransformInfoHeader.TransformID MUST be "{C73DFACD-061F-43B0-8B64-0C620D2A8B50}"\n     * TransformInfoHeader.TransformName MUST be "Microsoft.Metadata.DRMTransform"\n   * "\\009DRMTransform" storage 同时必须包含一个或多个 end-user license streams\n * 可能包含一个名为 "\\009LZXTransform" 的 storage。如果此 storage 存在，则其下必须存在一个名为 "\\006Primary" 的 stream\n   * 此 stream 必定包含 TransformInfoHeader 结构，其内容如下：\n     * TransformType MUST be 0x00000001\n     * TransformID MUST be "{86DE7F2B-DDCE-486d-B016-405BBE82B8BC}"\n     * TransformName MUST be "Microsoft.Metadata.CompressionTransform"\n\n 2. ECMA-376 document\n\n * 必须包含一个名为 "DRMEncryptedTransform" 的 storage，此 storage 下必须包含一个名为 "\\006Primary" 的 stream\n   * 此 stream 必定包含 IRMDSTransformInfo 结构，其内容如下：\n     * TransformInfoHeader.TransformID MUST be ""{C73DFACD-061F-43B0-8B64-0C620D2A8B50}"\n     * TransformInfoHeader.TransformName MUST be "Microsoft.Metadata.DRMTransform"\n   * "DRMEncryptedTransform" storage 同时必须包含一个或多个 end-user license streams\n\n上文中涉及到的 End-User License Stream，其中包含了缓存的 licenses 信息。这些 end-user license stream 的命名必须以 "EUL-" 为前缀，为："EUL-" + "一个 base-32-encoded 的GUID"。\n\n\n# Protected Content Stream\n\nprotected content stream 必须是在 root storage 中。如果原始文档是 ECMA-376 时，流的名字必定是 "EncryptedPackage"；原始文档是任意其他格式时, 流的名字一定是 "\\0x09DRMContent"。\n\n而这个受保护的流由: Length(8 bytes) + Contents(variable) 组成。\n\n其中 Contents 是使用对称密钥，AES-128 算法, 16-byte block size, electronic codebook (ECB) mode 以及 全 0 的初始向量进行加解密的。\n\n\n# Encryption and Obfuscation\n\n应用于 ms-office 的加密和混淆的共有四种不同的技术：\n\n 1. XOR Obfuscation\n\n * 对象：[MS-XLS] and [MS-DOC]\n * 方法：对 Office Binary Document 的部分(storage 或 stream)执行就地混淆\n * 细节：包含两种方法：Method 1 和 Method 2\n   * Method 1 应用于 Excel Binary File Format (.xls) 的 structures 和 procedures\n   * Method 2 应用于 Word Binary File Format (.doc) 的 structures 和 procedures\n\n 2. 40-bit RC4 Encryption\n\n * 对象：[MS-XLS] and [MS-DOC]\n * 方法：对 Office Binary Document 的部分(storage 或 stream)执行就地加密\n * 细节：\n   * 算法中的 hash 函数为 MD5\n   * 除非特殊说明，否则，最大密码长度为：255 Unicode characters\n\n 3. RC4 CryptoAPI Encryption\n\n * 对象：[MS-XLS], [MS-DOC], and [MS-PPT]\n * 方法：可能会有一个 Encrypted Summary Stream 被创建，也能对其他 stream 执行就地加密\n * 细节：\n   * 除非特殊说明，否则，最大密码长度为：255 Unicode characters\n   * SHA-1 hash 是 160 bits, 而 RC4 的 key 最大长度是 128 bits; 因此, key 必定少于或等于 128 bits。\n     * 如果 key 只有 40 bits，说明这是一个非常老的版本，此时加密算法必须创建一个由 Hfinal 的前 40 bits 和 88 bits 的 0 拼接而成的 128-bit 的 key\n\n 4. ECMA-376 Document Encryption\n\n * 对象：[ECMA-376]\n * 方法：利用 data spaces 功能将 [ECMA-376] 文档加密成了 ole 中的一个 stream\n * 细节：一共有三种方法，\n   * Standard encryption:\n     * 利用二进制(binary)类型的 EncryptionInfo 结构存储加密信息，使用 AES 作为加密算法，SHA-1 作为散列(hash)算法\n   * Agile encryption:\n     * 利用 XML 存放加密信息。加密和散列算法在结构中指定，可以使用主机支持的任何加密算法。还支持数据完整性校验。\n   * Extensible encryption:\n     * 此方法使用可扩展的机制来允许使用任意的第三方加密扩展模块\n\n注：ECMA-376 和 RC4 CryptoAPI 加密算法都使用到了 EncryptionHeader 结构\n\n# ECMA-376 Document Encryption\n\n 1. "\\0x06DataSpaces\\DataSpaceMap" Stream\n\n * 必须包含一个 DataSpaceMap 结构，其中有且只有一个 DataSpaceMapEntry 结构\n   * 此结构的 DataSpaceName 字段为 "StrongEncryptionDataSpace"\n   * 此结构中，有且只有一个 ReferenceComponents 结构，表示一个名为 "EncryptedPackage" 的 stream\n\n 2. "\\0x06DataSpaces\\TransformInfo" Storage\n\n * 必须包含一个名为 "StrongEncryptionTransform" 的 storage，其下必须包含一个名为 "\\006Primary" 的 stream\n   * 这个流必须包含一个 IRMDSTransformInfo 结构，其内容如下：\n     * TransformInfoHeader.TransformType MUST be 0x00000001\n     * TransformInfoHeader.TransformID MUST be "{FF9A3F03-56EF-4613-BDD5-5A41C1D07246}"\n     * TransformInfoHeader.TransformName MUST be "Microsoft.Container.EncryptionTransform".\n   * 紧跟着 IRMDSTransformInfo 的是一个 EncryptionTransformInfo 结构\n     * 如果 EncryptionInfo 和 EncryptionTransformInfo 中的算法不一致时，认为 EncryptionInfo 中的更加权威。\n     * 如果使用 agile encryption 时，EncryptionTransformInfo 的 EncryptionName 字段必须为空字符串(0x00000000)\n\n 3. "\\EncryptedPackage" Stream\n\n * 是一个加密的 stream，它包含了完整的(压缩后的) ECMA376 原文件\n   * 由 StreamSize(8 bytes) + EncryptedData(variable) 组成\n   * StreamSize 指明 EncryptedData 的字节数。另外，StreamSize 的大小实际上可能会与流的大小有出入，这依赖于所用加密算法的 block size\n\n 4. "\\EncryptionInfo" Stream\n\n * Standard Encryption\n   * 包含用于初始化用于加密 "\\EncryptedPackage" 流的密码学详细信息\n * Agile Encryption\n   * 包含用于初始化用于加密 "\\EncryptedPackage" 流的密码学详细信息\n * Extensible Encryption\n   * ECMA-376 文档可以选择使用用户提供的自定义（可扩展）加密模块。当使用可扩展加密时，\\EncryptionInfo 流的结构描述不同于标准模式，详细可以参考文档[MS-OFFCRYPTO]\n\n# Office Binary Document Encryption\n\nXOR、RC4 以及 RC4 CryptoAPI 都可以应用于 Office Binary Document 文件。\n\n详细信息见本文档关于 [xls]、[doc]、 [ppt] 的描述。\n\n\n# Write Protection\n\n# ECMA-376 Document Write Protection\n\nECMA-376 文档的 write protection 在 [ECMA-376] 文档的 Part 4 中的 Sections 2.15.1.28, 2.15.1.94, 3.2.12, 和 4.3.1.17 中有详细描述。\n\n# Binary Document Write Protection\n\n二进制类型 office 文档的基于 password 的 Write Protection 根据文件格式的不同具有不同的细节, 大致如下：\n\n * .xls\n   * 密码被转换成了一个 16-bit 的 password verifier, 并将其依 [MS-XLS] 文档进行存储, 同时，文档会被加密。如果用户未提供加密密码，会使用一个固定密码。\n     * 默认密码是：\\x56\\x65\\x6C\\x76\\x65\\x74\\x53\\x77\\x65\\x61\\x74\\x73\\x68\\x6F\\x70(也可以表示为：VelvetSweatshop)\n   * 使用 Write Protection 的同时，依然可以按照 Encryption 的描述进行加密\n   * 详细内容参考 [MS-XLS] section 2.2.9\n * .doc\n   * 密码以明文形式存储，并且文档内容未被加密。\n   * 详细内容参考 [MS-DOC] section 2.9.276\n * .ppt\n   * 密码以明文形式存储，并且文档可以被加密。如果文档被加密，但用户未提供加密密码时，会使用一个固定密码。\n     * 默认密码是：\\x2f\\x30\\x31\\x48\\x61\\x6e\\x6e\\x65\\x73\\x20\\x52\\x75\\x65\\x73\\x63\\x68\\x65\\x72\\x2f\\x30\\x31(也可以表示为：/01Hannes Ruescher/01)\n   * 使用 Write Protection 的同时，不应该(SHOULD NOT)再按照 Encryption 中描述的算法进行加密\n   * 详细内容参考 [MS-PPT] section 2.4.7\n\n另外还有 ISO Write Protection Method， 其旨在与 ISO/IEC 29500 兼容\n\n\n# Digital Signatures\n\n# ECMA-376 Document Digital Signatures\n\n用于 ECMA-376 documents 的 xmldsig 数字签名 和 用于 Office binary documents 的 xmldsig 数字签名非常相似。详细内容参考 [ECMA-376] Part 2 Section 12.2.4。\n\n# Binary Document Digital Signatures\n\n二进制类型 office 文档可以使用下述方法中的任意一种进行签名：\n\n 1. CryptoAPI digital signature\n    * 以二进制形式存储在 _signatures storage 中\n    * 详细内容参考 [MS-OFFCRYPTO] Section 2.5.1\n 2. xmldsig digital signature\n\n * 以 XML-Signature 语法和处理方式(详见[XMLDSig])存储在 _xmlsignatures storage 中\n * 详细内容参考 [MS-OFFCRYPTO] Section 2.5.2\n\n\n# 二、XLS\n\n这里主要关注 Encryption。\n\n\n# 2.1 Password Verifier Algorithm\n\n一些 records (Password, FileSharing, Prot4RevPass, FeatProtection, 和 FilePass) 会利用 password verifier 来锁定或解锁对 workbook 部分内容的查看或编辑。这个 password verifier 的设计主要是为了防止意外编辑，而不是安全特性。\n\nIt is possible to remove the passwords by removing the records containing the verifier values.\n\n这个 verifier 的值由两个阶段计算:\n\n * 将 Unicode 的 password 转换为当前系统的 ANSI 字符编码\n   * 任何不能被转换为 ANSI 字符编码的 Unicode 字符用 0x3F 替换。\n   * 这个替换动作在验证 hash 时将生成正数哈希值匹配。在某些语言环境中，这些字符可能是日常字符集的重要组成部分。\n * 使用 [MS-OFFCRYPTO] 中指定的 XOR obfuscation 算法(Binary Document Password Verifier Derivation Method 1)计算出16-bit 的 password verifier 值\n\n# Password record\n\nPassword record 为 sheet or workbook 指定了 password verifier。如果 record 结构中的 wPassword 值为 0，则表示没有密码。\n\n如果此 record 存在于 Globals Substream, 那么它是整个 workbook 的密码. 如果此 record 存在于 worksheet substream, chart sheet substream, macro sheet substream, or dialog sheet substream, 那么它仅仅适用于那个 sheet。\n\n此外，workbook 中必定存在此 record，而 sheet 则当且仅当有密码时才存在此 record。\n\n\n# 2.2 Encryption (Password to Open)\n\n其 obfuscation or encryption 信息存放于 workbook 流的 FilePass Record 中。\n\n如果使用的是 RC4 CryptoAPI 加密方式的话，某些 storages 和 streams 被存储在 Encryption Stream(详见 [MS-OFFCRYPTO] section 2.3.5.3)。这些 storages 和 streams 是否被加密等信息见下表(reference)：\n\n * \n\n其中带 (*) 标记的，表示这个 stream 或者 storage 中有 stream 包含 BIFF records 结构。当混淆或加密这些流中的 BIFF 记录时，有以下内容需要注意：\n\n * record type 和 record size 一定不得混淆或加密。\n * 以下这些 record 一定不能被混淆或加密：\n   * BOF、FilePass、UsrExcl、FileLock、InterfaceHdr、RRDInfo 和 RRDHead\n * BoundSheet8 record 的 lbPlyPos 字段一定不能被加密或混淆\n\n注意：上图可以看出，不止 Workbook Stream 可以包含 BIFF，User Names Stream、Revision Stream 也可以\n\n其中带 (**) 标记的，表示这个流当且仅当 EncryptionHeader.flags 的 0x08 bit 为 0 时，必须按照指定方式加密。(EncryptionHeader 见 [MS-OFFCRYPTO] section 2.3.5.1)。\n\n在使用 RC4、RC4 CAPI 算法加密时，需要以 1024-byte 的块来进行。从每个 BIFF record stream 的第一个字节开始，block number 置为 0，后续每 1024-byte 增加 1。\n\n\n# 2.3 XorArrayIndex\n\n当使用了 XOR 算法时，XorArrayIndex 的值的计算方法：XorArrayIndex = (WorkbookStreamOffset + Data.Length) % 16\n\n上文中的变量 WorkbookStreamOffset 是在 record 中的每个字节在 Workbook stream 中的偏移。在写入过程中此变量会每字节递增，所以计算出首字节的 XorArrayIndex 后，即可通过递增得到后续字节的 index 值。\n\nReference : XLS XOR Data Transformation Method 1\n\n此外，用于 XOR 算法的密码长度不能超过15个字符。\n\n\n# 三、DOC\n\n\n# 3.1 Encryption and Obfuscation (Password to Open)\n\n二进制格式的 word 文件可以通过以下三种方式进行密码保护：XOR obfuscation、 RC4 encryption 以及 RC4 CryptoAPI encryption。\n\n当 FibBase.fEncrypted 和 FibBase.fObfuscated 都为 1 时, 文件被使用 XOR obfuscation 方式进行了混淆。\n\n当 FibBase.fEncrypted 和 FibBase.fObfuscated 都为 0 时, 文件被使用 XOR obfuscation 或 RC4 encryption 方式进行了加密。此时 EncryptionHeader 结构被存放在 Table stream 的头部 FibBase.lKey 个字节中。而具体使用哪种加密方式，则由 EncryptionHeader.EncryptionVersionInfo 结构决定。\n\n其中，Table stream 可以是 1Table 或 0Table，判定方法如下：\n\n * 当 Fib.base.fWhichTblStm == 1 时，为 1Table stream\n * 当 Fib.base.fWhichTblStm == 0 时，为 0Table stream\n\n另外，如果文档使用了 obfuscation 或 encryption 时, ObjectPool storage, Macros storage, Custom XML Data storage, XML Signatures storage, 和 Signatures stream 必定不能被加密或混淆。\n\n# XOR Obfuscation\n\n文档的 WordDocument stream、Table stream 以及 Data stream 必须使用 [MS-OFFCRYPTO] 中的 XOR Data Transformation Method 2 进行混淆，所有其他的 streams 和 storages 必须不能(MUST NOT)被混淆。另外，用于密码验证的 password verifier 必定存储在 FibBase.lKey 中。\n\n根据 [[MS-DOC] 2.2.6.1 XOR Obfuscation] 的说明，对 WordDocument stream 转换必须从流的第一个字节开始进行，但最初的 68 bytes 必须用原始的未转换的值。\n\n此外，用于 XOR 算法的密码长度不能超过15个字符。所以，需要将 unicode 的密码转换成 single-byte 字符，这里有以下两种方式：\n\n * 使用 language code identifier (LCID) 将 unicode 转换为 ANSI 并截断\n * 对每个 unicode 字符，如果低字节为 0x00，则拷贝高字节到 single-byte; 否则，拷贝低字节到 single-byte。对结果进行截断，只保留 15 个字符\n\n对于写操作来说，应该使用第二种方式。不过，如果是读文件的话，应当尝试以上两种方式，任意一种能够匹配即可认为密码正确。\n\n# Office Binary Document RC4 Encryption\n\nTable stream 的头部 FibBase.lKey 个字节中以未加密未混淆的方式存储了 EncryptionHeader 结构。Table stream 的剩余部分, WordDocument stream 的超出最初的 68 bytes 的部分, 以及 Data stream 的全部，必须被加密。所有其他的 streams 和 storages 必须不能(MUST NOT)被加密。\n\n被加密的三个流的数据必须(MUST)以 512-byte 的 blocks 的形式被加密。在流的起始位置，block number 必须被设置为 0，在每个 512-byte 边界处递增。注意，加密算法必须在流的第一个字节开始被执行，尽管一些字节是以未加密的形式被写入文件的。\n\n# Office Binary Document RC4 CryptoAPI Encryption\n\nTable stream 的头部 FibBase.lKey 个字节中以未加密未混淆的方式存储了 EncryptionHeader 结构。Table stream 的剩余部分, WordDocument stream 的超出最初的 68 bytes 的部分, 以及 Data stream 的全部，必须被加密。\n\n被加密的三个流的数据必须(MUST)以 512-byte 的 blocks 的形式被加密。在流的起始位置，block number 必须被设置为 0，在每个 512-byte 边界处递增。注意，加密算法必须在流的第一个字节开始被执行，尽管一些字节是以未加密的形式被写入文件的。\n\n此外，ObjectPool storage 必定不会出现。如果文件包含有 OLE objects 的话，用于 OLE objects 的 storage objects 必定(像 sprmCPicLocation 描述的那样)被存储在 Data stream 中。\n\n如果 EncryptionHeader.Flags 中的 fDocProps 被置位，那么 Encryption Stream 必定存在，Summary Information stream 必定不存在，一个被用作占位符的 Document Summary Information stream 必定存在。这些信息在 [MS-OFFCRYPTO] section 2.3.5.4 中有详细描述。\n\n如果 EncryptionHeader.Flags 中的 fDocProps 没被置位，那么 Document Summary Information stream 和 Summary Information stream 必定没有被加密。\n\n所有其他的 streams 和 storages 必须不能(MUST NOT)被加密。\n\n相关名词说明：\n\n * ObjectPool storage\n   * 包含多个用于 embedded OLE objects 的 storages，storages 中的每一个都一定包含一个名为 "\\003ObjInfo" 的流，其中有一个用于描述 embedded OLE objects 的 ODT 结构\n * OLE object\n   * 支持 Object Linking and Embedding (OLE) 协议的对象\n * Encryption Stream\n   * 一个名为 encryption 的 stream\n   * 当以下两个条件同时满足时，它必定存在，反之，当它们不能同时满足时，这个 stream 必定不会(MUST NOT)出现：\n     1. 文档被使用 Office Binary Document RC4 CryptoAPI Encryption 方法加密\n     2. EncryptionHeader.Flags 中的 fDocProps 被置位\n\n\n# 四、PPT\n\n只支持 RC4 CryptoAPI 加密方式。PPT 的加密信息存储在 CryptSession10Container record 中\n\n对于加密的 ppt 文档，必定满足以下条件：\n\n * Current User Stream\n   * 必定不能被加密\n   * CurrentUserAtom record 的 headerToken 字段应该为 0xF3D1C4DF\n     * 注意 PowerPoint 2002 会使用 0xE391C05F 来标记是否加密\n     * 无论如何，当文档被加密时，UserEditAtom.encryptSessionPersistIdRef 一定存在并且不为 0 (PersistIdRef 为 0 时表示空引用)\n * PowerPoint Document Stream\n   * UserEditAtom record 和 PersistDirectoryAtom record 必定不能被加密\n   * CryptSession10Container record 的 rh 字段必定不能被加密\n   * CryptSession10Container record 的其他字段被按照 [MSOFFCRYPTO] section 2.3.5.1 进行了解释\n   * stream 的其它部分必定被加密\n   * stream 必定有且只有一个 UserEditAtom record\n   * UserEditAtom record 的 encryptSessionPersistIdRef 字段必定存在，它指向一个含有 CryptSession10Container record 的 persist object.\n     * PowerPoint 97 and PowerPoint 2000 会忽略 UserEditAtom.encryptSessionPersistIdRef 字段，因为他们不支持文档的 opening 或 creating 加密\n * Pictures Stream\n   * 如果存在的话，必定被加密\n * Summary Info Stream 和 Document Summary Info Stream\n   * CryptSession10Container.data.EncryptionHeader.Flags 的 fDocProps == 0：\n     * Summary Info Stream (名为 "\\005SummaryInformation")必定不存在\n     * Encrypted Summary Info Stream (名为 "EncryptedSummary")必定存在\n     * Document Summary Info Stream (名为 "\\005DocumentSummaryInformation")应该存在，但是空的\n   * CryptSession10Container.data.EncryptionHeader.Flags 的 fDocProps == 1：\n     * Summary Info Stream 和 Document Summary Info Stream 必定没被加密\n\n解密 encrypted document 的被解密部分，需要依照下面的规则：\n\n * For each block number the derived encryption key MUST be generated from the password hash and the block number as specified in [MS-OFFCRYPTO] section 2.3.5.2.\n\nPowerPoint Document Stream 中的 persist object 依照下述规则被加密：\n\n * 对于一个 persist object, 用于 derived encryption key 的 block number 就是 persist object 的 identifier\n * 用于 persist object 的 derived encryption key 必须通过 password hash 和 persist object 的 identifier 生成\n * 对于一个 persist object, 必须使用 derived encryption key 进行解密的字节由下述指定：\n   * 在 PowerPoint Document Stream section 中描述的 persist object 的文件偏移\n   * length in bytes == 8 + (文件偏移处的) RecordHeader 的 recLen 字段\n * 解密后，字节长度范围符合 [MS-OFFCRYPTO] 文档规定\n\nPictures Stream 中的 picture (也就是说，OfficeArtBStoreContainerFileBlock record 的每个字段)依照下述规则解密:\n\n * derived encryption key 必须通过 password hash 和 block number 为 0 产生\n * 字段的长度必须通过 derived encryption key 进行解密\n\n\n# Encryption\n\nppt 文档中可能有一个名字为 "EncryptedSummary" 的可选流，它只在被加密的文档中存在。当这个流存在时，也必定存在一个名为 "\\0x05DocumentSummaryInformation" 的流，而名为 "\\0x05SummaryInformation" 则必定不能存在。\n\n关于 "EncryptedSummary" 这个 Encrypted Summary Stream 的详细描述见 [MS-OFFCRYPTO] section 2.3.5.4。\n\n\n# Reference\n\n * [MS-Office File Formats]\n * [MS-XLS] - v20210817\n * [MS-OFFCRYPTO] - v20210817',normalizedContent:'# ms-offcrypto\n\nms-offcrypto 只对 windows office 生效，所以有一些常见的规则约定：\n\n * ole 中用于指定 storages 和 streams 位置的路径使用 backslash() 作为分隔符\n * 以 backslash() 开始的路径是指 ole compound file 的 root storage\n * byte ordering 默认是 little-endian\n\n\n# 一、data spaces\n\ndata spaces 结构描述了一种存储经过某种方式转换(transformed)后的 ole 复合文件的一致性方法。所以，该结构需要存储受保护的内容(protected content)和应用于内容的转换信息(information about the transforms)。例如，下文的 irmds 和 encryption 等都是基于 data spaces 结构进行的。\n\ndata spaces 结构允许客户端应用程序描述一个或多个任意转换。每个变换表示要对原始文档内容中的一组 storages 或 streams 执行的单个任意操作。一个或多个转换可以被组合到一个 data space 的定义中，然后这个定义可以被应用到存在于 data space map 中的原始文档的任意 storages 或 streams 中。\n\n\n# information rights management data space(irmds)\n\nirmds 主要应用于强化文档的权限管理策略。当对使用了权限管理策略的文档进行读、写、创建操作时，需要使用到 irmds structure。\n\nirmds 可以被应用于以下两种类型的文档:\n\n * office binary documents\n * ecma-376 documents\n\n\n\necma, european computer manufacturers association； ecma376 协议代指 office open xml 格式\n\n具体的差别如下：\n\n# "\\0x06dataspaces\\dataspacemap" stream\n\n 1. office binary document\n\n * 至少有一个 dataspacemapentry 结构\n * 必须有一个 dataspacemapentry 结构的 dataspacename 字段为 "\\009drmdataspace"\n   * 此结构中，有且只有一个 referencecomponents 结构，表示一个名为 "\\009drmcontent" 的 stream\n * 第二种 dataspacemapentry 结构的 dataspacename 字段必须为 "\\009lzxdrmdataspace"\n   * 此结构中，有且只有一个 referencecomponents 结构，表示一个名为 "\\009drmviewercontent" 的 stream\n\n 2. ecma-376 document\n\n * 有且只有一个 dataspacemapentry 结构，这个结构的 dataspacename 字段为 "drmencrypteddataspace"\n   * 此结构中，有且只有一个 referencecomponents 结构，表示一个名为 "encryptedpackage" 的 stream\n\n# "\\0x06dataspaces\\dataspaceinfo" storage\n\n 1. office binary document\n\n * 必须包含一个名为 "\\009drmdataspace" 的 stream\n   * 流中必须包含一个 dataspacedefinition 结构，此结构有且仅有一个名为 "\\009drmtransform" 的 transformreferences\n * 可能会包含一个名为 "\\009lzxdrmdataspace" 的 stream\n   * 流中必须包含一个这样的 dataspacedefinition 结构：有且仅有两个 transformreferences 条目，"\\009drmtransform" 和 "\\009lzxtransform"\n\n 2. ecma-376 document\n\n * 必须包含一个名为 "drmencrypteddataspace" 的 stream\n   * 流中必须含有一个 dataspacedefinition 结构，此结构有且仅有一个名为 "drmencryptedtransform" 的 transformreferences 条目\n\n# "\\0x06dataspaces\\transforminfo" storage\n\n 1. office binary document\n\n * 必须包含一个名为 "\\009drmtransform" 的 storage，其下必须包含一个名为 "\\006primary" 的 stream (完整路径为："0x09drmtransform\\0x06primary")。\n   * 此 stream 必定包含 irmdstransforminfo 结构，其内容如下：\n     * transforminfoheader.transformid must be "{c73dfacd-061f-43b0-8b64-0c620d2a8b50}"\n     * transforminfoheader.transformname must be "microsoft.metadata.drmtransform"\n   * "\\009drmtransform" storage 同时必须包含一个或多个 end-user license streams\n * 可能包含一个名为 "\\009lzxtransform" 的 storage。如果此 storage 存在，则其下必须存在一个名为 "\\006primary" 的 stream\n   * 此 stream 必定包含 transforminfoheader 结构，其内容如下：\n     * transformtype must be 0x00000001\n     * transformid must be "{86de7f2b-ddce-486d-b016-405bbe82b8bc}"\n     * transformname must be "microsoft.metadata.compressiontransform"\n\n 2. ecma-376 document\n\n * 必须包含一个名为 "drmencryptedtransform" 的 storage，此 storage 下必须包含一个名为 "\\006primary" 的 stream\n   * 此 stream 必定包含 irmdstransforminfo 结构，其内容如下：\n     * transforminfoheader.transformid must be ""{c73dfacd-061f-43b0-8b64-0c620d2a8b50}"\n     * transforminfoheader.transformname must be "microsoft.metadata.drmtransform"\n   * "drmencryptedtransform" storage 同时必须包含一个或多个 end-user license streams\n\n上文中涉及到的 end-user license stream，其中包含了缓存的 licenses 信息。这些 end-user license stream 的命名必须以 "eul-" 为前缀，为："eul-" + "一个 base-32-encoded 的guid"。\n\n\n# protected content stream\n\nprotected content stream 必须是在 root storage 中。如果原始文档是 ecma-376 时，流的名字必定是 "encryptedpackage"；原始文档是任意其他格式时, 流的名字一定是 "\\0x09drmcontent"。\n\n而这个受保护的流由: length(8 bytes) + contents(variable) 组成。\n\n其中 contents 是使用对称密钥，aes-128 算法, 16-byte block size, electronic codebook (ecb) mode 以及 全 0 的初始向量进行加解密的。\n\n\n# encryption and obfuscation\n\n应用于 ms-office 的加密和混淆的共有四种不同的技术：\n\n 1. xor obfuscation\n\n * 对象：[ms-xls] and [ms-doc]\n * 方法：对 office binary document 的部分(storage 或 stream)执行就地混淆\n * 细节：包含两种方法：method 1 和 method 2\n   * method 1 应用于 excel binary file format (.xls) 的 structures 和 procedures\n   * method 2 应用于 word binary file format (.doc) 的 structures 和 procedures\n\n 2. 40-bit rc4 encryption\n\n * 对象：[ms-xls] and [ms-doc]\n * 方法：对 office binary document 的部分(storage 或 stream)执行就地加密\n * 细节：\n   * 算法中的 hash 函数为 md5\n   * 除非特殊说明，否则，最大密码长度为：255 unicode characters\n\n 3. rc4 cryptoapi encryption\n\n * 对象：[ms-xls], [ms-doc], and [ms-ppt]\n * 方法：可能会有一个 encrypted summary stream 被创建，也能对其他 stream 执行就地加密\n * 细节：\n   * 除非特殊说明，否则，最大密码长度为：255 unicode characters\n   * sha-1 hash 是 160 bits, 而 rc4 的 key 最大长度是 128 bits; 因此, key 必定少于或等于 128 bits。\n     * 如果 key 只有 40 bits，说明这是一个非常老的版本，此时加密算法必须创建一个由 hfinal 的前 40 bits 和 88 bits 的 0 拼接而成的 128-bit 的 key\n\n 4. ecma-376 document encryption\n\n * 对象：[ecma-376]\n * 方法：利用 data spaces 功能将 [ecma-376] 文档加密成了 ole 中的一个 stream\n * 细节：一共有三种方法，\n   * standard encryption:\n     * 利用二进制(binary)类型的 encryptioninfo 结构存储加密信息，使用 aes 作为加密算法，sha-1 作为散列(hash)算法\n   * agile encryption:\n     * 利用 xml 存放加密信息。加密和散列算法在结构中指定，可以使用主机支持的任何加密算法。还支持数据完整性校验。\n   * extensible encryption:\n     * 此方法使用可扩展的机制来允许使用任意的第三方加密扩展模块\n\n注：ecma-376 和 rc4 cryptoapi 加密算法都使用到了 encryptionheader 结构\n\n# ecma-376 document encryption\n\n 1. "\\0x06dataspaces\\dataspacemap" stream\n\n * 必须包含一个 dataspacemap 结构，其中有且只有一个 dataspacemapentry 结构\n   * 此结构的 dataspacename 字段为 "strongencryptiondataspace"\n   * 此结构中，有且只有一个 referencecomponents 结构，表示一个名为 "encryptedpackage" 的 stream\n\n 2. "\\0x06dataspaces\\transforminfo" storage\n\n * 必须包含一个名为 "strongencryptiontransform" 的 storage，其下必须包含一个名为 "\\006primary" 的 stream\n   * 这个流必须包含一个 irmdstransforminfo 结构，其内容如下：\n     * transforminfoheader.transformtype must be 0x00000001\n     * transforminfoheader.transformid must be "{ff9a3f03-56ef-4613-bdd5-5a41c1d07246}"\n     * transforminfoheader.transformname must be "microsoft.container.encryptiontransform".\n   * 紧跟着 irmdstransforminfo 的是一个 encryptiontransforminfo 结构\n     * 如果 encryptioninfo 和 encryptiontransforminfo 中的算法不一致时，认为 encryptioninfo 中的更加权威。\n     * 如果使用 agile encryption 时，encryptiontransforminfo 的 encryptionname 字段必须为空字符串(0x00000000)\n\n 3. "\\encryptedpackage" stream\n\n * 是一个加密的 stream，它包含了完整的(压缩后的) ecma376 原文件\n   * 由 streamsize(8 bytes) + encrypteddata(variable) 组成\n   * streamsize 指明 encrypteddata 的字节数。另外，streamsize 的大小实际上可能会与流的大小有出入，这依赖于所用加密算法的 block size\n\n 4. "\\encryptioninfo" stream\n\n * standard encryption\n   * 包含用于初始化用于加密 "\\encryptedpackage" 流的密码学详细信息\n * agile encryption\n   * 包含用于初始化用于加密 "\\encryptedpackage" 流的密码学详细信息\n * extensible encryption\n   * ecma-376 文档可以选择使用用户提供的自定义（可扩展）加密模块。当使用可扩展加密时，\\encryptioninfo 流的结构描述不同于标准模式，详细可以参考文档[ms-offcrypto]\n\n# office binary document encryption\n\nxor、rc4 以及 rc4 cryptoapi 都可以应用于 office binary document 文件。\n\n详细信息见本文档关于 [xls]、[doc]、 [ppt] 的描述。\n\n\n# write protection\n\n# ecma-376 document write protection\n\necma-376 文档的 write protection 在 [ecma-376] 文档的 part 4 中的 sections 2.15.1.28, 2.15.1.94, 3.2.12, 和 4.3.1.17 中有详细描述。\n\n# binary document write protection\n\n二进制类型 office 文档的基于 password 的 write protection 根据文件格式的不同具有不同的细节, 大致如下：\n\n * .xls\n   * 密码被转换成了一个 16-bit 的 password verifier, 并将其依 [ms-xls] 文档进行存储, 同时，文档会被加密。如果用户未提供加密密码，会使用一个固定密码。\n     * 默认密码是：\\x56\\x65\\x6c\\x76\\x65\\x74\\x53\\x77\\x65\\x61\\x74\\x73\\x68\\x6f\\x70(也可以表示为：velvetsweatshop)\n   * 使用 write protection 的同时，依然可以按照 encryption 的描述进行加密\n   * 详细内容参考 [ms-xls] section 2.2.9\n * .doc\n   * 密码以明文形式存储，并且文档内容未被加密。\n   * 详细内容参考 [ms-doc] section 2.9.276\n * .ppt\n   * 密码以明文形式存储，并且文档可以被加密。如果文档被加密，但用户未提供加密密码时，会使用一个固定密码。\n     * 默认密码是：\\x2f\\x30\\x31\\x48\\x61\\x6e\\x6e\\x65\\x73\\x20\\x52\\x75\\x65\\x73\\x63\\x68\\x65\\x72\\x2f\\x30\\x31(也可以表示为：/01hannes ruescher/01)\n   * 使用 write protection 的同时，不应该(should not)再按照 encryption 中描述的算法进行加密\n   * 详细内容参考 [ms-ppt] section 2.4.7\n\n另外还有 iso write protection method， 其旨在与 iso/iec 29500 兼容\n\n\n# digital signatures\n\n# ecma-376 document digital signatures\n\n用于 ecma-376 documents 的 xmldsig 数字签名 和 用于 office binary documents 的 xmldsig 数字签名非常相似。详细内容参考 [ecma-376] part 2 section 12.2.4。\n\n# binary document digital signatures\n\n二进制类型 office 文档可以使用下述方法中的任意一种进行签名：\n\n 1. cryptoapi digital signature\n    * 以二进制形式存储在 _signatures storage 中\n    * 详细内容参考 [ms-offcrypto] section 2.5.1\n 2. xmldsig digital signature\n\n * 以 xml-signature 语法和处理方式(详见[xmldsig])存储在 _xmlsignatures storage 中\n * 详细内容参考 [ms-offcrypto] section 2.5.2\n\n\n# 二、xls\n\n这里主要关注 encryption。\n\n\n# 2.1 password verifier algorithm\n\n一些 records (password, filesharing, prot4revpass, featprotection, 和 filepass) 会利用 password verifier 来锁定或解锁对 workbook 部分内容的查看或编辑。这个 password verifier 的设计主要是为了防止意外编辑，而不是安全特性。\n\nit is possible to remove the passwords by removing the records containing the verifier values.\n\n这个 verifier 的值由两个阶段计算:\n\n * 将 unicode 的 password 转换为当前系统的 ansi 字符编码\n   * 任何不能被转换为 ansi 字符编码的 unicode 字符用 0x3f 替换。\n   * 这个替换动作在验证 hash 时将生成正数哈希值匹配。在某些语言环境中，这些字符可能是日常字符集的重要组成部分。\n * 使用 [ms-offcrypto] 中指定的 xor obfuscation 算法(binary document password verifier derivation method 1)计算出16-bit 的 password verifier 值\n\n# password record\n\npassword record 为 sheet or workbook 指定了 password verifier。如果 record 结构中的 wpassword 值为 0，则表示没有密码。\n\n如果此 record 存在于 globals substream, 那么它是整个 workbook 的密码. 如果此 record 存在于 worksheet substream, chart sheet substream, macro sheet substream, or dialog sheet substream, 那么它仅仅适用于那个 sheet。\n\n此外，workbook 中必定存在此 record，而 sheet 则当且仅当有密码时才存在此 record。\n\n\n# 2.2 encryption (password to open)\n\n其 obfuscation or encryption 信息存放于 workbook 流的 filepass record 中。\n\n如果使用的是 rc4 cryptoapi 加密方式的话，某些 storages 和 streams 被存储在 encryption stream(详见 [ms-offcrypto] section 2.3.5.3)。这些 storages 和 streams 是否被加密等信息见下表(reference)：\n\n * \n\n其中带 (*) 标记的，表示这个 stream 或者 storage 中有 stream 包含 biff records 结构。当混淆或加密这些流中的 biff 记录时，有以下内容需要注意：\n\n * record type 和 record size 一定不得混淆或加密。\n * 以下这些 record 一定不能被混淆或加密：\n   * bof、filepass、usrexcl、filelock、interfacehdr、rrdinfo 和 rrdhead\n * boundsheet8 record 的 lbplypos 字段一定不能被加密或混淆\n\n注意：上图可以看出，不止 workbook stream 可以包含 biff，user names stream、revision stream 也可以\n\n其中带 (**) 标记的，表示这个流当且仅当 encryptionheader.flags 的 0x08 bit 为 0 时，必须按照指定方式加密。(encryptionheader 见 [ms-offcrypto] section 2.3.5.1)。\n\n在使用 rc4、rc4 capi 算法加密时，需要以 1024-byte 的块来进行。从每个 biff record stream 的第一个字节开始，block number 置为 0，后续每 1024-byte 增加 1。\n\n\n# 2.3 xorarrayindex\n\n当使用了 xor 算法时，xorarrayindex 的值的计算方法：xorarrayindex = (workbookstreamoffset + data.length) % 16\n\n上文中的变量 workbookstreamoffset 是在 record 中的每个字节在 workbook stream 中的偏移。在写入过程中此变量会每字节递增，所以计算出首字节的 xorarrayindex 后，即可通过递增得到后续字节的 index 值。\n\nreference : xls xor data transformation method 1\n\n此外，用于 xor 算法的密码长度不能超过15个字符。\n\n\n# 三、doc\n\n\n# 3.1 encryption and obfuscation (password to open)\n\n二进制格式的 word 文件可以通过以下三种方式进行密码保护：xor obfuscation、 rc4 encryption 以及 rc4 cryptoapi encryption。\n\n当 fibbase.fencrypted 和 fibbase.fobfuscated 都为 1 时, 文件被使用 xor obfuscation 方式进行了混淆。\n\n当 fibbase.fencrypted 和 fibbase.fobfuscated 都为 0 时, 文件被使用 xor obfuscation 或 rc4 encryption 方式进行了加密。此时 encryptionheader 结构被存放在 table stream 的头部 fibbase.lkey 个字节中。而具体使用哪种加密方式，则由 encryptionheader.encryptionversioninfo 结构决定。\n\n其中，table stream 可以是 1table 或 0table，判定方法如下：\n\n * 当 fib.base.fwhichtblstm == 1 时，为 1table stream\n * 当 fib.base.fwhichtblstm == 0 时，为 0table stream\n\n另外，如果文档使用了 obfuscation 或 encryption 时, objectpool storage, macros storage, custom xml data storage, xml signatures storage, 和 signatures stream 必定不能被加密或混淆。\n\n# xor obfuscation\n\n文档的 worddocument stream、table stream 以及 data stream 必须使用 [ms-offcrypto] 中的 xor data transformation method 2 进行混淆，所有其他的 streams 和 storages 必须不能(must not)被混淆。另外，用于密码验证的 password verifier 必定存储在 fibbase.lkey 中。\n\n根据 [[ms-doc] 2.2.6.1 xor obfuscation] 的说明，对 worddocument stream 转换必须从流的第一个字节开始进行，但最初的 68 bytes 必须用原始的未转换的值。\n\n此外，用于 xor 算法的密码长度不能超过15个字符。所以，需要将 unicode 的密码转换成 single-byte 字符，这里有以下两种方式：\n\n * 使用 language code identifier (lcid) 将 unicode 转换为 ansi 并截断\n * 对每个 unicode 字符，如果低字节为 0x00，则拷贝高字节到 single-byte; 否则，拷贝低字节到 single-byte。对结果进行截断，只保留 15 个字符\n\n对于写操作来说，应该使用第二种方式。不过，如果是读文件的话，应当尝试以上两种方式，任意一种能够匹配即可认为密码正确。\n\n# office binary document rc4 encryption\n\ntable stream 的头部 fibbase.lkey 个字节中以未加密未混淆的方式存储了 encryptionheader 结构。table stream 的剩余部分, worddocument stream 的超出最初的 68 bytes 的部分, 以及 data stream 的全部，必须被加密。所有其他的 streams 和 storages 必须不能(must not)被加密。\n\n被加密的三个流的数据必须(must)以 512-byte 的 blocks 的形式被加密。在流的起始位置，block number 必须被设置为 0，在每个 512-byte 边界处递增。注意，加密算法必须在流的第一个字节开始被执行，尽管一些字节是以未加密的形式被写入文件的。\n\n# office binary document rc4 cryptoapi encryption\n\ntable stream 的头部 fibbase.lkey 个字节中以未加密未混淆的方式存储了 encryptionheader 结构。table stream 的剩余部分, worddocument stream 的超出最初的 68 bytes 的部分, 以及 data stream 的全部，必须被加密。\n\n被加密的三个流的数据必须(must)以 512-byte 的 blocks 的形式被加密。在流的起始位置，block number 必须被设置为 0，在每个 512-byte 边界处递增。注意，加密算法必须在流的第一个字节开始被执行，尽管一些字节是以未加密的形式被写入文件的。\n\n此外，objectpool storage 必定不会出现。如果文件包含有 ole objects 的话，用于 ole objects 的 storage objects 必定(像 sprmcpiclocation 描述的那样)被存储在 data stream 中。\n\n如果 encryptionheader.flags 中的 fdocprops 被置位，那么 encryption stream 必定存在，summary information stream 必定不存在，一个被用作占位符的 document summary information stream 必定存在。这些信息在 [ms-offcrypto] section 2.3.5.4 中有详细描述。\n\n如果 encryptionheader.flags 中的 fdocprops 没被置位，那么 document summary information stream 和 summary information stream 必定没有被加密。\n\n所有其他的 streams 和 storages 必须不能(must not)被加密。\n\n相关名词说明：\n\n * objectpool storage\n   * 包含多个用于 embedded ole objects 的 storages，storages 中的每一个都一定包含一个名为 "\\003objinfo" 的流，其中有一个用于描述 embedded ole objects 的 odt 结构\n * ole object\n   * 支持 object linking and embedding (ole) 协议的对象\n * encryption stream\n   * 一个名为 encryption 的 stream\n   * 当以下两个条件同时满足时，它必定存在，反之，当它们不能同时满足时，这个 stream 必定不会(must not)出现：\n     1. 文档被使用 office binary document rc4 cryptoapi encryption 方法加密\n     2. encryptionheader.flags 中的 fdocprops 被置位\n\n\n# 四、ppt\n\n只支持 rc4 cryptoapi 加密方式。ppt 的加密信息存储在 cryptsession10container record 中\n\n对于加密的 ppt 文档，必定满足以下条件：\n\n * current user stream\n   * 必定不能被加密\n   * currentuseratom record 的 headertoken 字段应该为 0xf3d1c4df\n     * 注意 powerpoint 2002 会使用 0xe391c05f 来标记是否加密\n     * 无论如何，当文档被加密时，usereditatom.encryptsessionpersistidref 一定存在并且不为 0 (persistidref 为 0 时表示空引用)\n * powerpoint document stream\n   * usereditatom record 和 persistdirectoryatom record 必定不能被加密\n   * cryptsession10container record 的 rh 字段必定不能被加密\n   * cryptsession10container record 的其他字段被按照 [msoffcrypto] section 2.3.5.1 进行了解释\n   * stream 的其它部分必定被加密\n   * stream 必定有且只有一个 usereditatom record\n   * usereditatom record 的 encryptsessionpersistidref 字段必定存在，它指向一个含有 cryptsession10container record 的 persist object.\n     * powerpoint 97 and powerpoint 2000 会忽略 usereditatom.encryptsessionpersistidref 字段，因为他们不支持文档的 opening 或 creating 加密\n * pictures stream\n   * 如果存在的话，必定被加密\n * summary info stream 和 document summary info stream\n   * cryptsession10container.data.encryptionheader.flags 的 fdocprops == 0：\n     * summary info stream (名为 "\\005summaryinformation")必定不存在\n     * encrypted summary info stream (名为 "encryptedsummary")必定存在\n     * document summary info stream (名为 "\\005documentsummaryinformation")应该存在，但是空的\n   * cryptsession10container.data.encryptionheader.flags 的 fdocprops == 1：\n     * summary info stream 和 document summary info stream 必定没被加密\n\n解密 encrypted document 的被解密部分，需要依照下面的规则：\n\n * for each block number the derived encryption key must be generated from the password hash and the block number as specified in [ms-offcrypto] section 2.3.5.2.\n\npowerpoint document stream 中的 persist object 依照下述规则被加密：\n\n * 对于一个 persist object, 用于 derived encryption key 的 block number 就是 persist object 的 identifier\n * 用于 persist object 的 derived encryption key 必须通过 password hash 和 persist object 的 identifier 生成\n * 对于一个 persist object, 必须使用 derived encryption key 进行解密的字节由下述指定：\n   * 在 powerpoint document stream section 中描述的 persist object 的文件偏移\n   * length in bytes == 8 + (文件偏移处的) recordheader 的 reclen 字段\n * 解密后，字节长度范围符合 [ms-offcrypto] 文档规定\n\npictures stream 中的 picture (也就是说，officeartbstorecontainerfileblock record 的每个字段)依照下述规则解密:\n\n * derived encryption key 必须通过 password hash 和 block number 为 0 产生\n * 字段的长度必须通过 derived encryption key 进行解密\n\n\n# encryption\n\nppt 文档中可能有一个名字为 "encryptedsummary" 的可选流，它只在被加密的文档中存在。当这个流存在时，也必定存在一个名为 "\\0x05documentsummaryinformation" 的流，而名为 "\\0x05summaryinformation" 则必定不能存在。\n\n关于 "encryptedsummary" 这个 encrypted summary stream 的详细描述见 [ms-offcrypto] section 2.3.5.4。\n\n\n# reference\n\n * [ms-office file formats]\n * [ms-xls] - v20210817\n * [ms-offcrypto] - v20210817',charsets:{cjk:!0}},{title:"PDF 格式简析",frontmatter:{title:"PDF 格式简析",date:"2021-06-18T13:50:00.000Z",lastmod:null,description:"PDF格式解析，深入PDF内部结构",categories:["skills","devops"],tags:[null],permalink:null},regularPath:"/blog/skills/pdf/pdf_struct.html",relativePath:"blog/skills/pdf/pdf_struct.md",key:"v-34bb950d",path:"/blog/skills/pdf/pdf_struct.html",headers:[{level:2,title:"1. Introduce",slug:"_1-introduce",normalizedTitle:"1. introduce",charIndex:15},{level:2,title:"2. File Structure",slug:"_2-file-structure",normalizedTitle:"2. file structure",charIndex:852},{level:3,title:"2.1 Header",slug:"_2-1-header",normalizedTitle:"2.1 header",charIndex:2559},{level:3,title:"2.2 Trailer",slug:"_2-2-trailer",normalizedTitle:"2.2 trailer",charIndex:3170},{level:3,title:"2.3 Cross-Reference Table",slug:"_2-3-cross-reference-table",normalizedTitle:"2.3 cross-reference table",charIndex:4100},{level:3,title:"2.4 Body",slug:"_2-4-body",normalizedTitle:"2.4 body",charIndex:5627},{level:3,title:"2.5 Increamental update",slug:"_2-5-increamental-update",normalizedTitle:"2.5 increamental update",charIndex:8742},{level:2,title:"4. Fix Pdf Structure",slug:"_4-fix-pdf-structure",normalizedTitle:"4. fix pdf structure",charIndex:9040},{level:2,title:"5 Document structure",slug:"_5-document-structure",normalizedTitle:"5 document structure",charIndex:9611},{level:3,title:"5.1 Catalog",slug:"_5-1-catalog",normalizedTitle:"5.1 catalog",charIndex:9638},{level:3,title:"5.2 Common Data Structures",slug:"_5-2-common-data-structures",normalizedTitle:"5.2 common data structures",charIndex:10077},{level:3,title:"5.3 PageLabel",slug:"_5-3-pagelabel",normalizedTitle:"5.3 pagelabel",charIndex:12890},{level:3,title:"5.4 Outlines",slug:"_5-4-outlines",normalizedTitle:"5.4 outlines",charIndex:13308},{level:3,title:"5.5 Action",slug:"_5-5-action",normalizedTitle:"5.5 action",charIndex:15069},{level:3,title:"5.6 Destinations",slug:"_5-6-destinations",normalizedTitle:"5.6 destinations",charIndex:16757},{level:3,title:"5.7 Article thread",slug:"_5-7-article-thread",normalizedTitle:"5.7 article thread",charIndex:17216},{level:3,title:"5.8 Interactive Forms",slug:"_5-8-interactive-forms",normalizedTitle:"5.8 interactive forms",charIndex:17708},{level:3,title:"5.9 Forms Data Format",slug:"_5-9-forms-data-format",normalizedTitle:"5.9 forms data format",charIndex:19069},{level:3,title:"5.10 XFA",slug:"_5-10-xfa",normalizedTitle:"5.10 xfa",charIndex:20772},{level:2,title:"6 Graphics",slug:"_6-graphics",normalizedTitle:"6 graphics",charIndex:21316},{level:3,title:"6.1 Graphics Objects",slug:"_6-1-graphics-objects",normalizedTitle:"6.1 graphics objects",charIndex:21333},{level:3,title:"6.2 Coordinate Systems",slug:"_6-2-coordinate-systems",normalizedTitle:"6.2 coordinate systems",charIndex:21820},{level:2,title:"Reference",slug:"reference",normalizedTitle:"reference",charIndex:1146}],headersStr:"1. Introduce 2. File Structure 2.1 Header 2.2 Trailer 2.3 Cross-Reference Table 2.4 Body 2.5 Increamental update 4. Fix Pdf Structure 5 Document structure 5.1 Catalog 5.2 Common Data Structures 5.3 PageLabel 5.4 Outlines 5.5 Action 5.6 Destinations 5.7 Article thread 5.8 Interactive Forms 5.9 Forms Data Format 5.10 XFA 6 Graphics 6.1 Graphics Objects 6.2 Coordinate Systems Reference",content:'# PDF 格式简析\n\n\n# 1. Introduce\n\nPortable Document Format (PDF), 由Adobe System Incorporated 公司在1992年发明的一种编程形式的文档格式，它所有显示的内容，都是通过相应的操作符进行绘制的。\n\n基于 PDF 的组织结构和展示形式，可以知道 PDF 有以下优点:\n\n * 一致性：\n   * 在不同的设备上打开 PDF 文档，展示效果是完全一致的，不会出现段落错乱、文字乱码这些排版问题。尤其是文档中可以嵌入字体文件，避免了客户端没有对应字体，而导致文字显示不一致的问题。所以，在印刷行业，绝大多数用的都是PDF格式。\n * 不易修改：\n   * PDF 格式复杂，对已经保存的PDF文件，想要进行重新排版比较复杂，这就保证了 PDF 文件不容易被篡改。\n * 安全性：\n   * PDF文档可以进行加密，包括以下几种加密形式：文档打开密码，文档权限(如，复制操作等)密码，文档证书密码，加密的方法包括：RC4，AES，通过加密这种形式，可以达到资料防扩散等目的。\n * 不失真：\n   * PDF文件中使用了矢量图，无论放大多少倍，都不会导致使用矢量图绘制的文字、图案失真。\n * 支持多种压缩方式：\n   * 为了减少PDF文件的size，PDF格式支持各种压缩方式：asciihex，ascii85，lzw，runlength，ccitt，jbig2，jpeg(DCT)，jpeg2000(jpx)\n * 支持多种印刷标准：\n   * 支持 PDF-A，PDF-X 等\n\n为了了解 PDF 这些特性的实现原理，我们需要对其结构有一定了解。一般来说，PDF 结构分为物理结构(File structure)和逻辑结构(Document structure)。物理结构用于根据 PDF 文件格式的约定从文件中读取各个对象；逻辑结构用于根据读取的文件结构、对象构建对象树，以按照对象的空间结构显示出 PDF 文件。\n\n\n# 2. File Structure\n\n标准的PDF文档一般包括四个部分：\n\n结构                作用                                                    备注\nHeader            存储PDF版本                                               一般是在首行 %PDF-XXX\nBody              存储间接对象                                                这是构成PDF比重最大的内容\nCross-Reference   保存各个间接对象在文件中的起始地址                                     \nTrailer           存储交叉索引表的起始位置, 根对象（Root），加密对象（Encrypt），文档信息对象（Info）等   包含 startxref 和 %%EOF\n\n解析 pdf 文件一般以下步骤进行：\n\n 1. 检查 Header 确认是否 pdf 格式 以及 版本\n 2. 从文件尾部读取 %%EOF，再查找 startxref 位置，并读取 Cross-Reference 的偏移\n 3. 读取 trailer 段(在 startxref 前，一般来说二者临近 )，从中读取文档的元信息\n 4. 从 Cross-Reference 中解析 indirect-object 的 objid、genid、offset 等信息\n 5. 从 indirect-object 中解析 pdf 内容、布局相关的详细信息\n\n当然，以上步骤只是简单的描述流程，其中还有很多细节需要处理，比如：Linearized PDF、Incremental Updates、object streams(标记为 /Type /ObjStm) 等等...\n\n一个 PDF 文件，可以在结构上形成一棵对象树，这些对象可以分为 8 种类型：\n\n * Boolean values\n   * representing true or false\n * Integers and Real numbers\n * Strings\n   * enclosed within parentheses ((...)). Strings may contain 8-bit characters.\n * Names, starting with a forward slash (/)\n   * name 被定义为字节流，但是现实中经常被用作可以阅读的text，这时规定以 utf-8 编码方式表示\n * Arrays\n   * ordered collections of objects enclosed within square brackets ([...])\n * Dictionaries\n   * collections of objects indexed by names enclosed within double angle brackets (<<...>>)\n * Streams\n   * usually containing large amounts of optionally compressed binary data, preceded by a dictionary and enclosed between the stream and endstream keywords.\n * The null object\n\n另外，PDF 中可以存在注释，它是以 % 符号开始。PDF 中的 object 可以分为 direct (embedded in another object) 和 indirect。Indirect objects 使用 objid 和 genid 进行编号，并且如果驻留在文档根中，则会在 obj 和 endobj 关键字之间定义。\n\n\n# 2.1 Header\n\n一般情况下，文件头，即，PDF文件的第一行，它用来定义PDF的版本，从而确定该PDF遵循的哪个版本的PDF规范。PDF版本是向下兼容的，即高版本的规范，兼容低版本的规范。\n\n正常情况下，%PDF 标记会出现在文件首行、首部。但是现实中，为了兼容异常做得更健壮，会在文件首部的 N 个字节内搜索这个标记，并完成 头部、版本号 的判断。如果文件头部，没有找到此标记，可以认为不是 PDF 文件。\n\n如果 %PDF 标记不是出现在文件的首行首部，那么 PDF 文件中的 startxref、cross-reference table 等中偏移地址是相对于文件第一个字节还是 %PDF 标记首部的呢？\n\n答案是相对于 %PDF 标记首部的偏移。根据 PDF 的 ISO 文档，%PDF应当出现在文件的首行首部，在保证文档完整性的同时，在文件首部或尾部增加内容，并不会改变 PDF 文件内部的内容(包含相对偏移)。所以，解析 PDF 文件时，首个 %PDF 和 最后一个 %%EOF 标记的位置很重要。\n\n一般的，%PDF 标记后跟随的 1.x 就是 PDF 文件的版本号。\n\n从 PDF 1.4 开始，支持将版本号放置于 trailer 中 Root 对象的 category 字典的 Version 属性中。这里的版本号是可选的，如果存在时(通常是在PDF增量更新时用到)，应当以此版本号为准。\n\n\n# 2.2 Trailer\n\nTrailer 部分包含了 trailer 段、startxref 段、%%EOF 标记 三部分。结构如下:\n\ntrailer\n    << /Size 642\n       /Root 1 0 R /Info 2 0 R\n       /Encrypt << ... >>\n       /ID [ <7919a5d3c67dca9aa6777b99d4a0214d>\n          <b8e48d9b43300bb87f6ff6c528d13fc2> ]\n       /Prev 2027\n    >>\nstartxref\nbyte_offset_of_the_last_cross-reference_section\n%%EOF\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\ntrailer 段用于存储交叉索引表的起始位置，根对象（Root），加密对象（Encrypt），文档信息对象（Info）等。例如，Info 中包含以下属性信息：\n\nOBJECT NAME    DESCRIPTION\nTitle          文档标题\nAuthor         创建文件的作者\nSubject        文档主题\nKeywords       文档关键字\nCreator        如果PDF是由其他格式转换而来的，Creator是创建原始文档的应用程序名\nProducer       如果PDF是由其他格式转换而来的，Producer是创建PDF文件的应用程序名\nCreationDate   文档创建的时间\nModDate        文档上一次修改的时间\n\nstartxref 所在行应该在 trailer 结构之后，并且 startxref、byte_offset_of_the_last_cross-reference_section、%%EOF 按顺序每个各占一行。\n\n由于 PDF 的 Increment Update 模式的存在，文件中的 Trailer 结构可能并不唯一。\n\n注意，在某些情况下会缺失 %%EOF 标记，并且大多 PDF 阅读器能够宽容的处理这种情况。\n\n\n# 2.3 Cross-Reference Table\n\n交叉索引表是PDF文件的重要部分，主要用途是保存各个间接对象在文件中的起始地址。\n\n那么交叉引用表的位置在什么地方呢？其实很简单，trailer 段的 startxref 指示了交叉索引表的具体偏移位置。根据这个偏移，可以很容易读取到 xref 标记以及其后的内容。\n\nxref 段的结构如下：\n\nxref \n0 3\n0000000004 65535 f \n0022826162 00000 n \n0022826184 00000 n \n6 2\n0022826260 00000 n \n0000000006 00007 f\n0022829428 00000 n \n0000000088 00001 f \n0000000000 00001 f  \n...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n首先，以包含关键字 xref 的一行为起点。紧接着这一行，就是一个或者多个 cross-reference subsections(交叉索引表子段，没有顺序)。每个交叉索引表子段包含一行或多行内容，每行包含一个 indirect object 的入口信息：偏移地址(10-digit)、修订号、n/f标记(in use/free)。\n\n交叉索引表的第一个条目，应该都是 object number 0、free、generation number = 65535，这标识着 free 对象链表的头。链表的尾部重新指向 object number 0 的对象。需要注意的是，一个 free 的 entry 的偏移地址表示下一个 free 对象在交叉索引表中的索引，它可以不在交叉索引表中的索引中，这表示下一个对象不存；它也可以是 0，这表示这个对象已经被删除。\n\n此外，交叉索引表在文件中可以存在单个，也可以存在多个。多个交叉引用表通常出现在两个情况：一、增量保存，二、线性化。\n\n当存在多个交叉索引表时，需要注意以下问题：\n\n 1. 交叉索引表的查找\n\n * 通常在交叉引用表之后的 trailer 字典中会保存 /Prev 对象，该 key 对应的值就是上一个交叉引用表的位置。\n\n 2. 同一个间接对象存在不同的引用表中\n\n * 一个文件中出现多个交叉引用表时，可能出现同一个间接对象存在不同的引用表中，这时，要以出现在文件最后位置的那个为准，前面的忽略，这种情况，通常是由于修改了PDF文件，导致其中的一个或多个对象发生了变化，PDF生成器根据输出要求，进行增加输出，只输出修改的对象，然后在文件末尾加上更新的交叉引用表。\n\n在 PDF 1.5 版本之前，交叉引用表总是采用 ASCII 格式，用 xref 关键字标记，并跟随由间接对象组成的主体。 1.5 版引入了 cross-reference streams ，它们具有标准流对象的形式，可能应用了过滤器。 这样的流可以用来代替 ASCII 格式的交叉引用表，并包含二进制格式的偏移量和其他信息。 该格式很灵活，因为它允许指定整数宽度（使用 /W 数组），因此例如，大小不超过 64 KiB 的文档可能仅将 2 个字节用于对象偏移。\n\n当使用 cross-reference streams 方式来表达交叉引用表时，关键字 xref 和 trailer 应该不会再出现。此时 startxref 指示的偏移地址上就是 cross-reference streams 流对象。结构如下（通过对象 /Type /XRef 标记）：\n\n关于 cross-reference streams 的解析流程可以参考官方文档。\n\n\n# 2.4 Body\n\n由 indirect objects 组成的文件内容主体。单个对象的格式如下：\n\nobjid genid obj\n...\nendobj\n\n\n1\n2\n3\n\n\n# 2.4.1 Encryption\n\nPDF 中的加密，主要是针对内容的处理，这也就说明了为什么 PDF 的加密主要应用在 strings 和 streams 对象。总有例外，如：\n\n * The values for the ID entry in the trailer\n * Any strings in an Encrypt dictionary\n * Any strings that are inside streams such as content streams and compressed object streams, which themselves are encrypted\n\n如果Stream对象引用了一个外部文件，那么它的内容就不应被加密，因为它不是当前 PDF 文件的一部分。然而，如果内容是内嵌在 PDF 文件内时("Embedded File Streams")，是应该像其他流对象一样被加密的。 从 PDF 1.5 开始，嵌入的文件可以在未加密的文档中加密(可以参考 "Crypt Filters")\n\n那么怎么判断文档是否加密以及加密方式、如果解密呢？\n\nPDF 文档的加密信息存储在 Trailer 段的 trailer 字典的 Encrypt 条目。如果没有找到这个条目，那么可以认为当前文档没有被加密。这个条目有以下内容：\n\n * Filter\n   * 指定文档的首选security handler的名称，它应该是用于加密文档的安全处理程序的名称。这个安全处理程序(handler)是一个软件模块，它实现了加密过程的各个方面并控制对加密文档内容的访问。\n   * PDF 指定了一个标准的基于密码的安全处理程序，所有符合要求的阅读器都应支持，但符合要求的阅读器可以选择提供他们自己的附加安全处理程序。\n   * 如果SubFilter不存在，则在打开文档时仅应使用此安全处理程序。如果存在，则符合标准的读取器可以使用任何实现SubFilter指定格式的安全处理程序。\n * SubFilter\n   * 指定encryption dictionary的语法。它允许处理程序之间的互操作性；也就是说，文档可以由首选处理程序(Filter)以外的处理程序解密, 如果它们都支持SubFilter指定的格式的话。\n * V\n   * Optional，指定加密算法。可以不存在，不存在时当做默认值 0；如果存在，则值应当大于 0。\n   * 对于 V 值 2 和 3，长度条目指定加密密钥的确切长度。在 PDF 1.5 中，V 的值 4 允许安全处理程序使用自己的加密和解密算法，并指定要在特定stream上使用的 Crypt Filters。\n * Length 加密秘钥的长度(bits)\n\n详细解密流程，可以参考官方文档...\n\n目前来说，PDF加密方式目前已经增加为三种：口令加密、证书加密、Adobe LiveCycle Rights Management，下面进行简单的介绍：\n\n 1. 口令加密：\n\n作为第一代PDF安全加密方式，到现在也一直广泛应用。口令加密分为：文档打开密码（open password）、权限密码（permission password）。\n\n * 文档打开密码：要求用户在打开文件时，需要输入密码\n * 权限密码：打开PDF文件并进行阅读，并不需要权限密码，只有更改权限设置或进行受限制操作时（打印，编辑和复制PDF中的内容），才需要输入权限密码。\n\n如果使用两种类型的密码保护PDF，则可以使用任一密码打开它。但是，只有权限密码才允许用户更改受限制的功能。\n\n 2. 证书加密：\n\n使用证书保护PDF时，可以指定收件人并为每个收件人或用户组定义文件访问级别。类似与口令加密的权限密码，可以进行权限限制，例如，允许一个组签名并填写表单，另一个组可以编辑文本或删除页面。\n\n用户可以从可信任身份列表，磁盘上的文件，LDAP服务器或Windows证书存储区（仅限Windows）中选择证书。始终将您的证书包含在收件人列表中，以便以后可以打开该文档。\n\n 3. Adobe LiveCycle Rights Management\n\nTODO\n\n# 2.4.2 Object Streams\n\n从 PDF 1.5 开始，indirect objects (except other streams) 可能会存在于 object streams(标记为 /Type /ObjStm) 中。这项技术使 non-stream 对象能够应用标准流过滤器，减小具有大量小型间接对象的文件的大小，并且对于标记 PDF 尤其有用。 对象流不支持指定对象的代号（0 除外）。\n\n# 2.4.3 Linearized PDF 线性化\n\nPDF 文件有两种布局：non-linearized (not "optimized") 和 linearized ("optimized")。 非线性 PDF 文件可能比线性 PDF 文件小，但访问速度较慢，因为组装文档页面所需的部分数据分散在整个 PDF 文件中。 线性化 PDF 文件（也称为 "optimized" 或 "web optimized" PDF 文件）的构造方式使它们能够在 Web 浏览器插件中读取，而无需等待整个文件下载完成，因为第一页所需的所有对象以最佳方式组织显示在文件的开头。 PDF 文件可以使用 Adobe Acrobat 软件或 QPDF 进行优化。\n\nLinearized PDF 文件的主要目标是：打开文档时，尽快显示第一页。 要查看的第一页可以是文档的任意页面，不一定是页面0（尽管在第0页打开是最常见的）。\n\n注意, 已经线性化的PDF，可以进行增量更新，但是，修改后的文档就不再是线性化文件，需要重新整理文件才能再次生成线性化文件。另外，基于 Linearized PDF 文件的以上特性，可以认识到只有在页面数量很多的情况下，才能突出表现出它快速网络浏览的优势。\n\n# 2.4.4 Extensions\n\nExtensions字典保存在```catalog``字典中，该字典应包含一个或多个键，用于标识开发人员定义的ISO 32000-1标准扩展。\n\nAdobe公司后面进行功能扩展和改善，又为了与之前PDF1.7标准做区别，通常用Extensions来标识。\n\nPDF–1.7\n<</Type /Catalog\n  /Extensions\n  <</GLGR\n    <</BaseVersion /1.7\n    /ExtensionLevel 1002\n    >>\n  >>\n>>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nExtensions字典的内容，不用来显示，通常包含的是用于开发用的内容。扩展字典中的所有开发人员扩展字典条目，以及它们的条目，都应是直接对象。\n\n例如：\n\n * BaseVersion ：PDF版本的名称。 该名称应与catalog的Version使用的语法一致\n * ExtensionLevel ：由开发人员定义的整数，表示正在使用的扩展名。 如果开发人员为给定的BaseVersion引入了多个扩展，则该开发人员分配的扩展级别编号将随着时间的推移而增加。\n\n\n# 2.5 Increamental update\n\nincreamental update 增量更新提供了一种更新PDF文件而无需完全重写的方法，根据PDF规范（1.7），增量更新的工作方式如下：可以逐步更新PDF文件的内容，而无需重写整个文件。更改将附加到文件末尾，保留原始内容。\n\n当PDF阅读器呈现PDF文档时，它从文件末尾开始。它读取最后一个预告片并跟随到根对象和交叉引用表的链接，以构建它将要呈现的文档的逻辑结构。当阅读器遇到更新的对象时，它会忽略相同对象的原始版本。\n\n一个PDF文件允许增量更新的次数不受限制。简单的判断PDF是否增量更新的方法是：文档中存在多个%%EOF。\n\n\n# 4. Fix Pdf Structure\n\nPDF文件破损，通常是一些非法操作造成的。PDF文件中有部分内容缺失，如xref，重要的object对象等。\n\n 1. xref破损\n\n解决这个问题，并不复杂，只需要从文件头开始读取对象，记录下对象号和对象起始偏移位置，重新建立xref（交叉引用表），将无效的简介引用置空值，就可以了，如果同一个间接对象出现多次，取最晚出现的那个为准。如果PDF文件是加密的，要先将加密对象进行解析，然后计算出密钥，用于其他对象的解密。\n\n 2. 间接对象破损\n\n间接对象通常是对象没有正常的结束符号，reader在进行该对象解析时，发生错误。这种情况，如果没有损害到xref，可以根据xref计算出每个间接对象其实偏移位置，在读取间接对象时发现当前位置超出该对象在PDF文件中保存的区域时，将该对象设置为无效对象，且所有引用到该对象的间接引用对象修改为null。\n\n 3. xref和间接对象都破损\n\n这种情况比较麻烦，核心方法，还是要重建xref。\n\n在读取到异常对象时，要及时的判断对象是否异常终止，比如：读取到一个破损的文件，发现对象长度异常的长，且连续出现多个“obj”和“endobject”，那就可以判断该对象错误了，并将该对象设置为无效，然后重新定位新的间接对象的开始位置，继续往后解析。\n\n\n# 5 Document structure\n\n\n\n\n# 5.1 Catalog\n\n文档对象层次结构的根是 Catalog 字典，通过PDF文件 trailer 中的 Root 条目进行定位。 一个简单的示例如下：\n\n1 0 obj \n  << /Type /Catalog  \n     /Pages 2 0 R  \n     /PageMode /UseOutlines\n     /Outlines 3 0 R\n  >>\nendobj\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n该目录包含对定义文档内容，大纲（outline），文章线程（article threads），命名目标（named destinations）和其他属性的其他对象的引用。 此外，它还包含有关如何在屏幕上显示文档的信息，例如是否应自动显示其大纲（outline）和缩略图页面图像（thumbnail），以及打开文档时是否显示除第一页以外的某些位置。\n\nPDF Reader 应当从此节点开始，构建 Page Tree, 并逐步展开页面细节并进行渲染。\n\n\n# 5.2 Common Data Structures\n\nPDF格式中，一些通用用途的数据结构被定义，它们是由基本对象类型组合而来，在整个PDF中的许多地方都有使用。这里简单介绍文本字符串，日期，矩形，名称树和数字树相关的数据结构。更加复杂的数据结构可以参考 PDF 文档。\n\n# 5.2.1 String & Text\n\nPDF 1.7 标准中定义的 PDF data types 中常见的 string 有：\n\nTYPE                   DESCRIPTION                                           NOTE\nASCII string           ASCII 字符组成的字节流                                        \nbyte string            表示字符或其他二进制数据的一系列字节                                    如果这种类型表示字符，则编码应由上下文确定\nstring                 非 text string 的字符串                                    从 PDF 1.7 开始，此类型进一步限定为以下类型：PDFDocEncoded string、ASCII\n                                                                             string和 byte string。\ndate                   Date (ASCII string)                                   严格遵循ISO / IEC 8824的定义, 日期格式为：(D:YYYYMMDDHHmmSSOHH\'mm )\nPDFDocEncoded string   使用 PDFDocEncoding 加密字符串形成的字节流                         PDF格式只使用 UTF-16BE 编码 Unicode(带字节序标记)\ntext string            使用 PDFDocEncoding 或 UTF-16BE 编码字符串形成的字节流，并带有前导字节序标记   主要用在人工可读的字符串信息，例如文本注释，书签名称，文档信息等\ntext stream            Text stream                                           本质上是一个流，不过其未编码字节应满足与 text string 在编码、字节顺序和前导字节方面有相同要求\n\n关于 date 格式的说明:\n\n 1. 前缀D必需存在，年份字段（YYYY）必需存在，后面字段可以不存在\n 2. 其它字段说明:\n    \n    NAME   DESCRIPTION\n    YYYY   年份\n    MM     月份（01-12）, 默认值为01\n    DD     当天（01-31）, 默认值为01\n    HH     小时（00-23）, 默认值为0\n    mm     分钟（00-59）, 默认值为0\n    SS     秒（00-59）, 默认值为0\n    O      时差，由加号（+ , 本地时间晚于UT），减号（ - , 本地时间早于UT）或 大写Z（本地时间等于UT）表示\n    HH     时差中的小时数（00-23），后面跟着符号（’）, 默认值为0\n    mm     时差中的分钟数（00-59）, 默认值为0\n\n# 5.2.2 Others\n\nPDF 1.7 标准中定义的其它 PDF data types 如下：\n\nTYPE                 DESCRIPTION                                 NOTE\narray                Array object                                \nboolean              Boolean value                               \ndictionary           Dictionary object                           \nfile specification   File specification (string or dictionary)   用于引用外部文件内容\nfunction             Function (dictionary or stream)             \ninteger              Integer number                              \nname                 Name object                                 \nname tree            Name tree (dictionary)                      树形结构，每个节点都应是字典对象。键是字符串，并且键是排序的，可以用于高效查找\nnull                 Null object                                 \nnumber               Number (integer or real)                    \nnumber tree          Number tree (dictionary)                    树形结构，每个节点都应是字典对象。键是整数，并且键按数字升序排序，可以用于高效查找\nrectangle            Rectangle (array)                           矩形用于描述页面上的位置和各种对象的边界框。矩形是由一个四个数字的数组(一对对角线的坐标)表示。通常表示为：[llx\n                                                                 lly urx ury]，按顺序指定矩形的左下x，左下y，右上y和右上y坐标。\nstream               Stream object                               \n\n\n# 5.3 PageLabel\n\nPDF PageLabel 页面标签可用于描述页面的页码。允许非连续页面编号，可以看为页面添加任意标签（例如在文档的开头包含罗马数字）。PageLabel对象可用于指定要使用的编号样式（例如，大写或小写罗马，十进制等），第一页的起始编号以及要预先附加到的任意前缀每个数字（例如，“A-”生成“A-1”，“A-2”，“A-3”等。）\n\nPDF文档中的每个页面都由整数页索引标识，该索引表示页面在文档中的相对位置。另外，文档可以有选择地定义页面标签以在屏幕上或在打印中可视地识别每个页面。\n\n页面标签和页面索引不需要重合：索引是固定的，从第一页的1开始连续通过文档运行，但标签可以以适合特定文档的任何方式指定。例如，如果文档以12页用罗马数字编号的前端内容开头，而文档的其余部分用阿拉伯语编号，则第一页的页面索引为1，页面标签为i，第12页将具有索引12和标签xii，第十三页将具有索引13和标签1。\n\n\n# 5.4 Outlines\n\noutlines，书签。PDF文档支持文件大纲（书签），用户可以通过点击书签完成跳转功能，类似与office word中的大纲功能。\n\n常用的跳转功能有：跳转到文档内部页面、跳转到其他PDF文档的某一页、跳转到web页面、跳转到外部文件（非PDF）等等。\n\n书签是一个树状结构，根据遍历First、Next，得到完整的书签节点。下面是一个书签的例子，可以通过这个例子深入了解其结构：\n\n48 0 obj\n<</MarkInfo <</Marked true>>\n/Metadata 3 0 R\n/Outlines 73 0 R\n/PageLayout /OneColumn\n/PageMode /UseOutlines            % 书签根节点\n/Pages 2 0 R\n/StructTreeRoot 5 0 R\n/Type/Catalog\n/ViewerPreferences<</HideMenubar true/HideToolbar true>>>>\nendobj\n\n73 0 obj\n<</Count 4                     % 子节点数量\n/First 74 0 R                  % 第一个子节点对应的间接引用对象\n/Last 75 0 R                   % 最后一个子节点对应的间接引用对象\n/Type/Outlines>>\nendobj\n\n74 0 obj\n<</A 77 0 R                  % 跳转功能的间接引用对象\n/Count 2                     % 子节点数量\n/First 78 0 R                % 第一个子节点对应的间接引用对象\n/Last 79 0 R                 % 最后一个子节点对应的间接引用对象\n/Next 75 0 R                 % 兄弟节点对应的间接引用对象\n/Parent 73 0 R               % 父节点对应的间接引用对象\n/Title(book1)>>              % 书签显示内容\nendobj\n\n75 0 obj\n<</A 78 0 R\n/C[1.0 0.333328 0.0]         % 书签字体颜色\n/F 2                         % 书签字体标记（粗体/斜体/粗斜体）\n/Next 76 0 R\n/Parent 71 0 R\n/Title(mark1)>>\nendobj\n\n76 0 obj\n<<\n/D[\n49 0 R                       % 跳转到文档对应的页面对象\n/Fit                         % 跳转到对应页面展示的内容\n]              \n/S/GoTo                      % 跳转类型，该类型告诉浏览器跳转到文档内页面\n>>\nendobj\n\n77 0 obj\n<</D[49 0 R/Fit]/S/GoTo>>\nendobj\n\n78 0 obj\n<</A 81 0 R/Next 79 0 R/Parent 74 0 R/Title(mark1)>>\nendobj\n\n79 0 obj\n<</A 80 0 R/Parent 74 0 R/Prev 78 0 R/Title(mark2)>>\nendobj\n\n80 0 obj\n<</D[49 0 R/Fit]/S/GoTo>>\nendobj\n\n81 0 obj\n<</D[49 0 R/Fit]/S/GoTo>>\nendobj\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n\n\n\n# 5.5 Action\n\nAction 字典的内容大致如下：\n\n3 0 obj\n<< /Type /Action\n/S /GoToE\n/D (Chapter 1)\n/T << /R /P\n/T << /R /C\n/N (Another embedded document) >>\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n/Type /Action说明当前字典为Action的描述，/S指明动作类型，/N(可选)指定当前动作完成后需要执行的动作或动作序列。\n\nAction 动作，除了用于跳转到文档中的某个页面之外，annotation或outline也可以指定要执行的动作，例如：启动应用程序，播放声音，改变注释的外观状态。 annotation或outline字典中的A(optional)条目可以指定一个在annotation或outline被激活时执行的动作。在 PDF 1.2 中，各种其他情况(Trigger Events)也可能触发Action。此外，文档的Catalog也可以通过OpenAction(optional)条目指定在打开文档时应执行的操作。\n\n下面列出PDF支持的标准的Action类型：\n\nACTION        DESCRIPTION                         NOTE\nGoTo          转到当前文档中的目标位置                        \nGoToR         转到另一个文档中的目标位置                       Go-to remote\nGoToE         转到某个嵌入文件                            Go-to embedded\nLaunch        启动应用程序，通常是打开文件                      \nThread        开始阅读文章线索                            \nURI           解析到URI(统一资源标识符，代表Internet上资源的字符串)   通常是作为超文本链接的目标的文件\nSound         播放音频                                \nMovie         播放视频                                \nHide          设置 annotation 的隐藏标志                 通过设置或清除一个或多个注释的隐藏标志，来隐藏或显示这些注释\nNamed         执行符合PDF标准的阅读器预定义的操作                 \nSubmitForm    将数据发送到服务器（类似于网页的form）               此操作会将所选交互式表单字段的名称和值传送到指定的URL\nResetForm     将字段设置为其默认值                          \nImportData    从文件导入字段值                            此操作应将表单数据格式（FDF）数据从指定文件导入到文档的交互式表单中\nJavaScript    执行 JS 脚本                            \nSetOCGState   设置可选内容组的状态                          \nRendition     控制多媒体内容的播放                          \nTrans         使用transition字典更新文档的显示               PDF 1.5 中 transition 可用于控制一系列 action 期间的绘图\nGoTo3DView    设置3D注释的当前视图                         PDF 1.6 中标识3D注释并指定要使用的注释的视图\n\n\n# 5.6 Destinations\n\nDestinations本质上是一个命名的页面视图。它将一个独一无二的名称与单个 PDF 文档中的特定页面位置相关联。书签和链接可以在 Go to a page view, Go to a page view in another document和Go to a page in attachment actions 中使用命名目标而不是直接页面引用。\n\n那为什么要使用它呢？\n\nDestinations允许设置跨 PDF 文档集合的导航路径。链接多个 PDF 文档时建议使用命名目标，因为与链接到页面不同，链接到Destinations不受单个文档中页面添加或删除的影响。例如，如果 A.pdf 中的链接指向 B.pdf 中的命名目的地“Chapter1”，那么如果 B.pdf 中的某些页面已被删除、移动或插入新页面，则此链接将继续正常工作。如果 A.pdf 直接引用 B.pdf 中的特定页面，则情况并非如此。对 B.pdf 中页面的任何更改都会破坏直接页面链接。\n\n\n# 5.7 Article thread\n\n某些类型的文档可能会包含逻辑连接，而这个逻辑顺序并不是物理顺序。比如：新闻报道可以从新闻通讯的第一页开始，然后转到一个或多个非连续的内页。\n\n为了表示物理上不连续但逻辑相关的项目的序列，PDF文档定义了一个或多个Article（PDF 1.1）。 Article的顺序由article thread定义; 组成文章的各个内容项在线程上称为珠子（bead）。 用户可以通过点击从一个珠子到下一个珠子进行跳转。\n\n文档Catalog中可以定义的可选Threads条目，该条目中定义了一个Thread词典组成的数组，用来表示文档Articles。Thread内的每个单独的bead应由bead字典表示。Thread字典的“F”条目应指定Threads中的第一个bead; bead通过“N”（下一个）和“V”（前一个）条目，构成一个在一个双向链表，将所有bead顺序链接在一起。 此外，对于出现 article beads 的每个页面，页面对象（Page）应包含一个B条目，其值是页面上的bead间接引用的数组，顺序是按照绘图顺序进行排列。\n\n\n# 5.8 Interactive Forms\n\nInteractive Forms 交互式表单，有时也称为 AcroForm，是通过交互方式，从用户端收集信息字段的集合。\n\nPDF文档中，任何页面都可以存在任意数量的字段，而所有这些字段可以构成跨越整个文档的单个全局交互式表单。这些字段的任意子集可以从文档导入或导出。\n\n文档交互表单中的每个字段都应由 field 字段字典定义。文档交互表单的内容和属性应由交互式表单字典定义，该字典应从文档目录中的AcroForm条目引用。\n\n出于定义和命名的目的，可以按层次结构（树形结构）来组织字段，并且可以从字段层次结构中的祖先那里继承祖先的属性。 层次结构中的字段子节点，还可以包括用于定义其在页面上的 widget 窗口小部件注释（当只定义了一个widget时，field字典和widget字典可以合并为一个字典）。 具有子字段的字段称为非终端字段（即中间节点），没有子字段的字段称为终端字段（即叶节点）。\n\n下表显示了交互式表单字典的内容：\n\nKEY               TYPE              DESCRIPTION\nFields            array             根 field 字段数组（字段层次结构中没有祖先的字段）\nNeedAppearances   boolean           optional，指定是否为文档中的所有 widget 注释构造外观流和外观字典。 默认值：false\nSigFlags          integer           optional，PDF 1.3 开始，用于指定与签名字段相关的各种文档级别特征。 默认值：0\nCO                array             （如果文档中的任何字段具有包含C条目的附加操作字典，则为必需; PDF\n                                    1.3）具有计算操作的字段字典的间接引用数组，由于某个字段的变化，导致需要根据计算顺序重新计算其值\nDR                dictionary        optional，表单字段外观将使用到的默认资源（如字体，图案或颜色空间）的资源字典。\n                                    该字典至少应包含一个Font条目，用于指定显示文本的默认字体的资源名称和字体字典\nDA                string            optional，可变文本字段的DA属性的文档范围默认值\nQ                 integer           optional，可变文本字段的Q属性的文档范围默认值\nXFA               stream or array   optional，PDF 1.5 开始，用于包含XFA资源的流或数组，其格式应由数据包（XDP）规范描述。\n                                    此条目的值应该是表示XML数据包的全部内容的流，或者是表示包含XML数据包的各个数据包的文本字符串和流对象的数组\n\n\n# 5.9 Forms Data Format\n\nForms Data Format 表单数据格式。FDF是一种文件格式，用于表示PDF格式中包含的表单数据和注释。此格式由 Adobe Systems Incorporated 发明，它基于PDF格式。您可以在Adobe的PDF参考中找到FDF格式的详细规范。\n\nFDF格式可用于各种工作流程。以下是几个示例：\n\n * 将表单数据发送到服务器并从服务器接收修改后的表单数据。此工作流程看起来像这样：\n   \n     a. 表单数据以FDF格式提交给服务器。（通常，当客户端计算机上的用户单击表单上的“提交”按钮时，会发生这种情况。）\n     b. 在服务器上，FDF数据被修改。\n     c. 服务器将修改后的FDF数据发送回客户端。\n     d. 在客户端计算机上，表单中的字段将填充修改后的数据。\n   \n   \n   1\n   2\n   3\n   4\n   \n * 存档表单数据。此工作流程看起来像这样：\n   \n     a. 用户使用Adobe Acrobat或其他PDF编辑/查看应用程序以FDF格式导出表单数据。（要在Adobe Acrobat 6.x for Windows中执行此操作，请单击高级>表单>导出表单数据，然后选择Acrobat FDF文件（* .fdf）作为“另存为类型”。如果您使用的是另一个版本，则该过程可能会有所不同）\n     b. FDF文件保存在公司的档案中。\n     c. 要查看表单数据，用户将使用Adobe Acrobat或其他一些PDF查看/编辑应用程序，来打开FDF文件; 这将导致PDF查看/编辑应用程序产生三个操作：1）找到需要导出表单数据的PDF表单，2）将表单数据加载到表单中，3）在屏幕上显示带有加载数据的表单。\n   \n   \n   1\n   2\n   3\n   \n\n您可能想知道为什么要存档包含PDF表单数据的FDF文件，而不是简单地使用包含表单数据的PDF。有两个原因：\n\n 1. 包含PDF表单的表单数据的FDF文件，比包含表单PDF本身的文件小得多，因此归档FDF文件比归档表单PDF需要更少的存储空间。\n 2. 人们用来查看表单PDF并与之交互的某些软件不允许用户保存填写的表单PDF。例如，免费的“Adobe Reader”软件不允许这样做。\n\n重要说明：FDF文件包含表单PDF的文件名和位置（FDF文件是从该表单PDF中导出的）。Adobe Acrobat（以及任何支持PDF表单的PDF查看/编辑应用程序）依赖于该文件名和位置，以便在打开FDF文件时检索和打开相应的PDF表单。换句话说：打开FDF文件时，PDF查看/编辑应用程序会根据指定的位置，显示PDF表单。\n\n因此，如果您是考虑实施归档FDF数据的系统的开发人员，则需要确保您的系统具有将所需表单PDF存储在已知位置的可靠方法。否则，PDF查看/编辑应用程序无法始终在需要时检索和打开表单PDF。\n\n某些PDF查看/编辑应用程序不支持与表单PDF相关的所有功能。\n\n总之，FDF可在将表单数据提交给服务器，接收响应，并将响应结果合并到交互式表单中。 它还可用于将表单数据导出为独立的文件，这些文件可以存储，以电子方式传输，也可以导回到相应的PDF交互式表单中。 此外，从PDF 1.3开始，FDF可用于定义注释的容器，使得这些注释与它们所在PDF文档分离。\n\n另外，虽然 FDF 基于 PDF; 它使用PDF一样的语法，并且具有基本相同的文件结构。但是，它在以下方面与PDF不同：\n\n * 交叉引用表是可选的。\n * 不应增量更新FDF文件。 对象只能是0代，FDF文件中没有两个对象具有相同的对象编号。\n * 文档结构比PDF简单得多，因为FDF文档的主体只包含一个必需对象。\n * 流的长度不应由间接对象指定。\n * FDF使用MIME内容类型application/vnd.fdf。 在Windows和UNIX平台上，FDF文件的扩展名为.fdf; 在Mac OS上，他们的文件类型是FDF。\n\n\n# 5.10 XFA\n\nXFA(XML Forms Architecture)这是由JetForm建议和开发的一系列专有 XML规范，用于增强Web表单的处理。PDF 1.5 引入了基于XFA 的交互式表单的支持。XFA规范被引用作为ISO 32000-1规范（PDF 1.7）应用必不可少的外部规范。XML Forms Architecture未标准化为ISO标准。\n\nXFA表单保存在PDF文件内部，可以作为XDP（XML数据包）文件进行保存，可以在Adobe的LiveCycle Designer软件中打开。\n\n虽然XFA可以使用PDF，但XFA并不依赖于特定的页面描述语言。\n\nXFA 有静态和动态表格之分。在静态形式中，无论字段内容如何， 表单的外观和布局都是固定的。动态表单（自XFA 2.1或2.2定义）可以通过多种方式更改外观以响应数据的更改。动态表单需要在文件打开时呈现其内容。动态表单还可以被设计为改变结构以适应提供给表单的数据结构的变化。例如，如果没有数据，则可以省略表单的页面。另一个例子是可能占用页面上可变空间量的字段，调整其自身以有效地保持其内容。动态表单不能依赖于其样板的PDF表示，因为样板的定位和布局随着字段的增长和收缩或子表单被省略和包含而改变。\n\n\n# 6 Graphics\n\n\n\n\n# 6.1 Graphics Objects\n\nGraphics Objects， 图形对象。内容流中存在两种类型的元素：一、图形对象（字体，shading，图片，通常用name对象表示），二、修饰图形对象的操作符（定位，缩放，颜色，大小，剪切，透明等），由这两类元素描绘出了页面的外观。\n\nPDF提供五种类型的图形对象：\n\n * 路径对象，可以是直线，矩形和贝塞尔曲线，或它们组合而成的任意形状。 路径可以自身相交。\n * 文本对象，由一个或多个字符串组成。\n * 外部对象（XObject），是在内容流外部定义的对象，并作为命名资源引用（“资源字典”）。\n * 内联图像对象，使用特殊语法直接在内容流中表示小图像的数据。\n * shading对象，描述几何形状，其颜色是形状内位置的任意函数。 （在绘制其他图形对象时，shading也可以被视为颜色;在这种情况下，它不被视为单独的图形对象。）\n\nPDF 1.3及更早版本不支持透明，由于每个图形对象按顺序绘制，后面绘制的内容，会把前面绘制的内容覆盖掉。PDF 1.4开始支持透明成像模型，对象可以根据设置透明程度。\n\n\n# 6.2 Coordinate Systems\n\nPDF中，所有绘制都在画布（也就是我们看到的页面page）上进行的。坐标系决定了显示在页面上的文本、图形和图像的位置、方向和大小。这里介绍 PDF 中使用的坐标系，包括它们之间的关系以及如何转换。\n\n# 6.2.1 Coordinate Spaces\n\n路径和位置是通过一对坐标进行定义的， x 和 y 表示二维坐标空间中的水平位置和垂直位置。坐标空间由以下与当前页面相关的属性决定：\n\n * 坐标原点\n * X和Y轴的方向\n * 沿X和Y轴的长度\n\nPDF定义了几种坐标空间，用于解析图形对象的坐标。坐标空间之间可以相互变换，这些变换由变换矩阵定义，变换矩阵可以指定二维坐标的任何线性映射，包括平移、缩放、旋转、反射和倾斜。\n\n# 1. 设备空间\n\n每一种用来显示PDF的设备（显示器、打印机），都可能有自己的独特的一套设备坐标系，也被称作设备空间，或是坐标原点不同，X和Y轴的方向不同，也可能是分辨率不同，这些不同就会导致显示出来的对象不一样，如： 同一个图形对象在72像素/英寸显示器设备坐标系中显示效果，后者是在600点/英寸打印机的设备坐标系中打印效果，显著不同。\n\n# 2. 用户空间\n\n为了避免不同设备的设备坐标系对显示对象的影响，PDF定义了一种与设备无关的坐标系，该坐标系始终与当前页面具有相同的关系，而不管打印或显示在哪个输出设备上。这种与设备无关的坐标系称为用户空间。\n\n文档的每个页面都会被用户空间的默认状态初始化。页面字典中的CropBox条目指定了输出介质（即显示窗口或打印页面）的可见矩形区域。通常情况下，正 x 轴水平向右延伸，正 y 轴垂直向上延伸（可能因页面字典中的Rotate条目而改变）。沿 x 和 y 轴的长度单位由页面字典中的UserUnit条目（PDF 1.6）设置。如果该条目不存在或不被支持，则使用1/72英寸的默认值。这个坐标系称为默认用户坐标系。\n\nNote1：在PostScript中，默认用户空间的原点始终对应于输出介质的左下角。PDF文档中默认也是这样的，但并不一定如此；页面字典的CropBox条目，可以指定在输出介质上，可见的默认用户空间中的任何位置和大小的矩形区域。\n\nNote2：默认用户空间中单位大小的默认值（1/72英寸）与印刷行业中广泛使用的基础单位点大致相同。然而，它并不完全相同。一个点没有通用的定义。\n\n从理论上讲，用户空间是一个无限大的平面。这个平面中只有一小部分对应于输出设备的可成像区域：由页面字典中的CropBox条目定义的矩形区域(每一页的可成像区域大小可以不同)。用户空间中的坐标可以是任意实数或正整数，用户空间坐标的分辨率与设备空间的像素分辨率无关。\n\n从用户空间到设备空间的转换，由转换矩阵current transformation matrix (CTM)定义，该矩阵是PDF graphics state的一个元素。符合要求的阅读器可以针对特定输出设备的原始分辨率调整 CTM，从而保持 PDF 页面描述的设备无关性。\n\nNote3：无论使用何种输出设备，默认用户空间都为 PDF 页面描述提供了一致、可靠的起始位置。如有必要，PDF 内容流可以通过应用坐标变换运算符 cm 来修改用户空间以使其更适合其需要。因此，内容流中可能出现的绝对坐标相对于当前页面并不是绝对的，因为它们是在一个可以滑动和收缩或扩展的坐标系中表达的。坐标系转换不仅增强了设备独立性，而且本身就是一个有用的工具。\n\n下图显示了这如何允许用户空间中指定的对象显示相同的对象，而不管它是在哪个设备上呈现的。\n\n# 3. 其他坐标空间\n\n除了设备空间和用户空间外，PDF还使用了各种其他坐标空间用于特殊目的：\n\n * Text space\n   * 文本定位操作符，来用指定文本的位置。\n * Glyph space\n   * 从字形空间到文本空间的转换由字体矩阵定义。\n * Form space\n   * 从form空间到用户空间的转换由包含在form XObject中的矩阵来指定。\n * Image space\n   * 所有图像都在图像空间中定义。要进行绘制时，通过CTM将图像映射到页面的某个区域。\n * Pattern space\n   * 从pattern 空间到用户空间的转换由pattern 中包含的pattern 矩阵指定。\n\n# 4. 坐标空间之间的关系\n\n下图显示了上述坐标空间之间的关系。图中的每个箭头表示从一个坐标空间到另一个坐标空间的转换。PDF 允许对这些转换中的许多进行修改。\n\n由于 PDF 坐标空间是相对于彼此定义的，对一种变换所做的更改会影响在多个坐标空间中定义的对象的外观。例如，CTM中的一个变化定义了从用户空间到设备空间的转换，它会影响表单、文本、图像和模式，因为它们都来自用户空间的上游。\n\n# 6.2.2 Common Transformations\n\n转换矩阵描述了两个坐标空间之间的关系。通过修改变换矩阵，可以缩放、旋转、平移对象。\n\nPDF中的转换矩阵由六个数字指定，通常以数组的形式出现。通常，这个数组表示为[a b c d e f]；它可以表示从一个坐标系到另一个坐标系的任何线性变换。下面列出的转换的类型：\n\n * 平移：指定为[1 0 0 1 tx ty]，其中tx和ty分别是在水平和垂直尺寸中转换坐标系原点的距离。\n * 缩放：指定为[SX 0 0 Sy 0 0]。SX为水平方式缩放倍数，Sy为垂直方向缩放倍数。\n * 旋转：指定为[cosθ sinθ −sinθ cosθ 0 0]，它具有将坐标系轴逆时针旋转角度θ的效果。\n * 倾斜：指定为[1 tanα tanβ 1 0 0]，它使X轴倾斜一个角度α，Y轴倾斜一个角度β。\n\n如果将多个转换组合在一起，则它们的应用顺序非常重要。例如，先缩放后平移X轴，与先平移然后缩放X轴不同。一般来说，为了获得预期的结果，应按以下顺序进行转换：1.平移，2.旋转，3.缩放或倾斜\n\n请注意，scale-rotate-translate顺序会导致坐标系变形，使X和Y轴不再垂直；建议的translate-rotate-scale顺序不会导致变形\n\n\n# Reference\n\n * ISO 32000-1:2008 Document management — Portable document format — Part 1: PDF 1.7\n * Introduction_to_PDF from gnupdf\n * wiki - PDF',normalizedContent:'# pdf 格式简析\n\n\n# 1. introduce\n\nportable document format (pdf), 由adobe system incorporated 公司在1992年发明的一种编程形式的文档格式，它所有显示的内容，都是通过相应的操作符进行绘制的。\n\n基于 pdf 的组织结构和展示形式，可以知道 pdf 有以下优点:\n\n * 一致性：\n   * 在不同的设备上打开 pdf 文档，展示效果是完全一致的，不会出现段落错乱、文字乱码这些排版问题。尤其是文档中可以嵌入字体文件，避免了客户端没有对应字体，而导致文字显示不一致的问题。所以，在印刷行业，绝大多数用的都是pdf格式。\n * 不易修改：\n   * pdf 格式复杂，对已经保存的pdf文件，想要进行重新排版比较复杂，这就保证了 pdf 文件不容易被篡改。\n * 安全性：\n   * pdf文档可以进行加密，包括以下几种加密形式：文档打开密码，文档权限(如，复制操作等)密码，文档证书密码，加密的方法包括：rc4，aes，通过加密这种形式，可以达到资料防扩散等目的。\n * 不失真：\n   * pdf文件中使用了矢量图，无论放大多少倍，都不会导致使用矢量图绘制的文字、图案失真。\n * 支持多种压缩方式：\n   * 为了减少pdf文件的size，pdf格式支持各种压缩方式：asciihex，ascii85，lzw，runlength，ccitt，jbig2，jpeg(dct)，jpeg2000(jpx)\n * 支持多种印刷标准：\n   * 支持 pdf-a，pdf-x 等\n\n为了了解 pdf 这些特性的实现原理，我们需要对其结构有一定了解。一般来说，pdf 结构分为物理结构(file structure)和逻辑结构(document structure)。物理结构用于根据 pdf 文件格式的约定从文件中读取各个对象；逻辑结构用于根据读取的文件结构、对象构建对象树，以按照对象的空间结构显示出 pdf 文件。\n\n\n# 2. file structure\n\n标准的pdf文档一般包括四个部分：\n\n结构                作用                                                    备注\nheader            存储pdf版本                                               一般是在首行 %pdf-xxx\nbody              存储间接对象                                                这是构成pdf比重最大的内容\ncross-reference   保存各个间接对象在文件中的起始地址                                     \ntrailer           存储交叉索引表的起始位置, 根对象（root），加密对象（encrypt），文档信息对象（info）等   包含 startxref 和 %%eof\n\n解析 pdf 文件一般以下步骤进行：\n\n 1. 检查 header 确认是否 pdf 格式 以及 版本\n 2. 从文件尾部读取 %%eof，再查找 startxref 位置，并读取 cross-reference 的偏移\n 3. 读取 trailer 段(在 startxref 前，一般来说二者临近 )，从中读取文档的元信息\n 4. 从 cross-reference 中解析 indirect-object 的 objid、genid、offset 等信息\n 5. 从 indirect-object 中解析 pdf 内容、布局相关的详细信息\n\n当然，以上步骤只是简单的描述流程，其中还有很多细节需要处理，比如：linearized pdf、incremental updates、object streams(标记为 /type /objstm) 等等...\n\n一个 pdf 文件，可以在结构上形成一棵对象树，这些对象可以分为 8 种类型：\n\n * boolean values\n   * representing true or false\n * integers and real numbers\n * strings\n   * enclosed within parentheses ((...)). strings may contain 8-bit characters.\n * names, starting with a forward slash (/)\n   * name 被定义为字节流，但是现实中经常被用作可以阅读的text，这时规定以 utf-8 编码方式表示\n * arrays\n   * ordered collections of objects enclosed within square brackets ([...])\n * dictionaries\n   * collections of objects indexed by names enclosed within double angle brackets (<<...>>)\n * streams\n   * usually containing large amounts of optionally compressed binary data, preceded by a dictionary and enclosed between the stream and endstream keywords.\n * the null object\n\n另外，pdf 中可以存在注释，它是以 % 符号开始。pdf 中的 object 可以分为 direct (embedded in another object) 和 indirect。indirect objects 使用 objid 和 genid 进行编号，并且如果驻留在文档根中，则会在 obj 和 endobj 关键字之间定义。\n\n\n# 2.1 header\n\n一般情况下，文件头，即，pdf文件的第一行，它用来定义pdf的版本，从而确定该pdf遵循的哪个版本的pdf规范。pdf版本是向下兼容的，即高版本的规范，兼容低版本的规范。\n\n正常情况下，%pdf 标记会出现在文件首行、首部。但是现实中，为了兼容异常做得更健壮，会在文件首部的 n 个字节内搜索这个标记，并完成 头部、版本号 的判断。如果文件头部，没有找到此标记，可以认为不是 pdf 文件。\n\n如果 %pdf 标记不是出现在文件的首行首部，那么 pdf 文件中的 startxref、cross-reference table 等中偏移地址是相对于文件第一个字节还是 %pdf 标记首部的呢？\n\n答案是相对于 %pdf 标记首部的偏移。根据 pdf 的 iso 文档，%pdf应当出现在文件的首行首部，在保证文档完整性的同时，在文件首部或尾部增加内容，并不会改变 pdf 文件内部的内容(包含相对偏移)。所以，解析 pdf 文件时，首个 %pdf 和 最后一个 %%eof 标记的位置很重要。\n\n一般的，%pdf 标记后跟随的 1.x 就是 pdf 文件的版本号。\n\n从 pdf 1.4 开始，支持将版本号放置于 trailer 中 root 对象的 category 字典的 version 属性中。这里的版本号是可选的，如果存在时(通常是在pdf增量更新时用到)，应当以此版本号为准。\n\n\n# 2.2 trailer\n\ntrailer 部分包含了 trailer 段、startxref 段、%%eof 标记 三部分。结构如下:\n\ntrailer\n    << /size 642\n       /root 1 0 r /info 2 0 r\n       /encrypt << ... >>\n       /id [ <7919a5d3c67dca9aa6777b99d4a0214d>\n          <b8e48d9b43300bb87f6ff6c528d13fc2> ]\n       /prev 2027\n    >>\nstartxref\nbyte_offset_of_the_last_cross-reference_section\n%%eof\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\ntrailer 段用于存储交叉索引表的起始位置，根对象（root），加密对象（encrypt），文档信息对象（info）等。例如，info 中包含以下属性信息：\n\nobject name    description\ntitle          文档标题\nauthor         创建文件的作者\nsubject        文档主题\nkeywords       文档关键字\ncreator        如果pdf是由其他格式转换而来的，creator是创建原始文档的应用程序名\nproducer       如果pdf是由其他格式转换而来的，producer是创建pdf文件的应用程序名\ncreationdate   文档创建的时间\nmoddate        文档上一次修改的时间\n\nstartxref 所在行应该在 trailer 结构之后，并且 startxref、byte_offset_of_the_last_cross-reference_section、%%eof 按顺序每个各占一行。\n\n由于 pdf 的 increment update 模式的存在，文件中的 trailer 结构可能并不唯一。\n\n注意，在某些情况下会缺失 %%eof 标记，并且大多 pdf 阅读器能够宽容的处理这种情况。\n\n\n# 2.3 cross-reference table\n\n交叉索引表是pdf文件的重要部分，主要用途是保存各个间接对象在文件中的起始地址。\n\n那么交叉引用表的位置在什么地方呢？其实很简单，trailer 段的 startxref 指示了交叉索引表的具体偏移位置。根据这个偏移，可以很容易读取到 xref 标记以及其后的内容。\n\nxref 段的结构如下：\n\nxref \n0 3\n0000000004 65535 f \n0022826162 00000 n \n0022826184 00000 n \n6 2\n0022826260 00000 n \n0000000006 00007 f\n0022829428 00000 n \n0000000088 00001 f \n0000000000 00001 f  \n...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n首先，以包含关键字 xref 的一行为起点。紧接着这一行，就是一个或者多个 cross-reference subsections(交叉索引表子段，没有顺序)。每个交叉索引表子段包含一行或多行内容，每行包含一个 indirect object 的入口信息：偏移地址(10-digit)、修订号、n/f标记(in use/free)。\n\n交叉索引表的第一个条目，应该都是 object number 0、free、generation number = 65535，这标识着 free 对象链表的头。链表的尾部重新指向 object number 0 的对象。需要注意的是，一个 free 的 entry 的偏移地址表示下一个 free 对象在交叉索引表中的索引，它可以不在交叉索引表中的索引中，这表示下一个对象不存；它也可以是 0，这表示这个对象已经被删除。\n\n此外，交叉索引表在文件中可以存在单个，也可以存在多个。多个交叉引用表通常出现在两个情况：一、增量保存，二、线性化。\n\n当存在多个交叉索引表时，需要注意以下问题：\n\n 1. 交叉索引表的查找\n\n * 通常在交叉引用表之后的 trailer 字典中会保存 /prev 对象，该 key 对应的值就是上一个交叉引用表的位置。\n\n 2. 同一个间接对象存在不同的引用表中\n\n * 一个文件中出现多个交叉引用表时，可能出现同一个间接对象存在不同的引用表中，这时，要以出现在文件最后位置的那个为准，前面的忽略，这种情况，通常是由于修改了pdf文件，导致其中的一个或多个对象发生了变化，pdf生成器根据输出要求，进行增加输出，只输出修改的对象，然后在文件末尾加上更新的交叉引用表。\n\n在 pdf 1.5 版本之前，交叉引用表总是采用 ascii 格式，用 xref 关键字标记，并跟随由间接对象组成的主体。 1.5 版引入了 cross-reference streams ，它们具有标准流对象的形式，可能应用了过滤器。 这样的流可以用来代替 ascii 格式的交叉引用表，并包含二进制格式的偏移量和其他信息。 该格式很灵活，因为它允许指定整数宽度（使用 /w 数组），因此例如，大小不超过 64 kib 的文档可能仅将 2 个字节用于对象偏移。\n\n当使用 cross-reference streams 方式来表达交叉引用表时，关键字 xref 和 trailer 应该不会再出现。此时 startxref 指示的偏移地址上就是 cross-reference streams 流对象。结构如下（通过对象 /type /xref 标记）：\n\n关于 cross-reference streams 的解析流程可以参考官方文档。\n\n\n# 2.4 body\n\n由 indirect objects 组成的文件内容主体。单个对象的格式如下：\n\nobjid genid obj\n...\nendobj\n\n\n1\n2\n3\n\n\n# 2.4.1 encryption\n\npdf 中的加密，主要是针对内容的处理，这也就说明了为什么 pdf 的加密主要应用在 strings 和 streams 对象。总有例外，如：\n\n * the values for the id entry in the trailer\n * any strings in an encrypt dictionary\n * any strings that are inside streams such as content streams and compressed object streams, which themselves are encrypted\n\n如果stream对象引用了一个外部文件，那么它的内容就不应被加密，因为它不是当前 pdf 文件的一部分。然而，如果内容是内嵌在 pdf 文件内时("embedded file streams")，是应该像其他流对象一样被加密的。 从 pdf 1.5 开始，嵌入的文件可以在未加密的文档中加密(可以参考 "crypt filters")\n\n那么怎么判断文档是否加密以及加密方式、如果解密呢？\n\npdf 文档的加密信息存储在 trailer 段的 trailer 字典的 encrypt 条目。如果没有找到这个条目，那么可以认为当前文档没有被加密。这个条目有以下内容：\n\n * filter\n   * 指定文档的首选security handler的名称，它应该是用于加密文档的安全处理程序的名称。这个安全处理程序(handler)是一个软件模块，它实现了加密过程的各个方面并控制对加密文档内容的访问。\n   * pdf 指定了一个标准的基于密码的安全处理程序，所有符合要求的阅读器都应支持，但符合要求的阅读器可以选择提供他们自己的附加安全处理程序。\n   * 如果subfilter不存在，则在打开文档时仅应使用此安全处理程序。如果存在，则符合标准的读取器可以使用任何实现subfilter指定格式的安全处理程序。\n * subfilter\n   * 指定encryption dictionary的语法。它允许处理程序之间的互操作性；也就是说，文档可以由首选处理程序(filter)以外的处理程序解密, 如果它们都支持subfilter指定的格式的话。\n * v\n   * optional，指定加密算法。可以不存在，不存在时当做默认值 0；如果存在，则值应当大于 0。\n   * 对于 v 值 2 和 3，长度条目指定加密密钥的确切长度。在 pdf 1.5 中，v 的值 4 允许安全处理程序使用自己的加密和解密算法，并指定要在特定stream上使用的 crypt filters。\n * length 加密秘钥的长度(bits)\n\n详细解密流程，可以参考官方文档...\n\n目前来说，pdf加密方式目前已经增加为三种：口令加密、证书加密、adobe livecycle rights management，下面进行简单的介绍：\n\n 1. 口令加密：\n\n作为第一代pdf安全加密方式，到现在也一直广泛应用。口令加密分为：文档打开密码（open password）、权限密码（permission password）。\n\n * 文档打开密码：要求用户在打开文件时，需要输入密码\n * 权限密码：打开pdf文件并进行阅读，并不需要权限密码，只有更改权限设置或进行受限制操作时（打印，编辑和复制pdf中的内容），才需要输入权限密码。\n\n如果使用两种类型的密码保护pdf，则可以使用任一密码打开它。但是，只有权限密码才允许用户更改受限制的功能。\n\n 2. 证书加密：\n\n使用证书保护pdf时，可以指定收件人并为每个收件人或用户组定义文件访问级别。类似与口令加密的权限密码，可以进行权限限制，例如，允许一个组签名并填写表单，另一个组可以编辑文本或删除页面。\n\n用户可以从可信任身份列表，磁盘上的文件，ldap服务器或windows证书存储区（仅限windows）中选择证书。始终将您的证书包含在收件人列表中，以便以后可以打开该文档。\n\n 3. adobe livecycle rights management\n\ntodo\n\n# 2.4.2 object streams\n\n从 pdf 1.5 开始，indirect objects (except other streams) 可能会存在于 object streams(标记为 /type /objstm) 中。这项技术使 non-stream 对象能够应用标准流过滤器，减小具有大量小型间接对象的文件的大小，并且对于标记 pdf 尤其有用。 对象流不支持指定对象的代号（0 除外）。\n\n# 2.4.3 linearized pdf 线性化\n\npdf 文件有两种布局：non-linearized (not "optimized") 和 linearized ("optimized")。 非线性 pdf 文件可能比线性 pdf 文件小，但访问速度较慢，因为组装文档页面所需的部分数据分散在整个 pdf 文件中。 线性化 pdf 文件（也称为 "optimized" 或 "web optimized" pdf 文件）的构造方式使它们能够在 web 浏览器插件中读取，而无需等待整个文件下载完成，因为第一页所需的所有对象以最佳方式组织显示在文件的开头。 pdf 文件可以使用 adobe acrobat 软件或 qpdf 进行优化。\n\nlinearized pdf 文件的主要目标是：打开文档时，尽快显示第一页。 要查看的第一页可以是文档的任意页面，不一定是页面0（尽管在第0页打开是最常见的）。\n\n注意, 已经线性化的pdf，可以进行增量更新，但是，修改后的文档就不再是线性化文件，需要重新整理文件才能再次生成线性化文件。另外，基于 linearized pdf 文件的以上特性，可以认识到只有在页面数量很多的情况下，才能突出表现出它快速网络浏览的优势。\n\n# 2.4.4 extensions\n\nextensions字典保存在```catalog``字典中，该字典应包含一个或多个键，用于标识开发人员定义的iso 32000-1标准扩展。\n\nadobe公司后面进行功能扩展和改善，又为了与之前pdf1.7标准做区别，通常用extensions来标识。\n\npdf–1.7\n<</type /catalog\n  /extensions\n  <</glgr\n    <</baseversion /1.7\n    /extensionlevel 1002\n    >>\n  >>\n>>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nextensions字典的内容，不用来显示，通常包含的是用于开发用的内容。扩展字典中的所有开发人员扩展字典条目，以及它们的条目，都应是直接对象。\n\n例如：\n\n * baseversion ：pdf版本的名称。 该名称应与catalog的version使用的语法一致\n * extensionlevel ：由开发人员定义的整数，表示正在使用的扩展名。 如果开发人员为给定的baseversion引入了多个扩展，则该开发人员分配的扩展级别编号将随着时间的推移而增加。\n\n\n# 2.5 increamental update\n\nincreamental update 增量更新提供了一种更新pdf文件而无需完全重写的方法，根据pdf规范（1.7），增量更新的工作方式如下：可以逐步更新pdf文件的内容，而无需重写整个文件。更改将附加到文件末尾，保留原始内容。\n\n当pdf阅读器呈现pdf文档时，它从文件末尾开始。它读取最后一个预告片并跟随到根对象和交叉引用表的链接，以构建它将要呈现的文档的逻辑结构。当阅读器遇到更新的对象时，它会忽略相同对象的原始版本。\n\n一个pdf文件允许增量更新的次数不受限制。简单的判断pdf是否增量更新的方法是：文档中存在多个%%eof。\n\n\n# 4. fix pdf structure\n\npdf文件破损，通常是一些非法操作造成的。pdf文件中有部分内容缺失，如xref，重要的object对象等。\n\n 1. xref破损\n\n解决这个问题，并不复杂，只需要从文件头开始读取对象，记录下对象号和对象起始偏移位置，重新建立xref（交叉引用表），将无效的简介引用置空值，就可以了，如果同一个间接对象出现多次，取最晚出现的那个为准。如果pdf文件是加密的，要先将加密对象进行解析，然后计算出密钥，用于其他对象的解密。\n\n 2. 间接对象破损\n\n间接对象通常是对象没有正常的结束符号，reader在进行该对象解析时，发生错误。这种情况，如果没有损害到xref，可以根据xref计算出每个间接对象其实偏移位置，在读取间接对象时发现当前位置超出该对象在pdf文件中保存的区域时，将该对象设置为无效对象，且所有引用到该对象的间接引用对象修改为null。\n\n 3. xref和间接对象都破损\n\n这种情况比较麻烦，核心方法，还是要重建xref。\n\n在读取到异常对象时，要及时的判断对象是否异常终止，比如：读取到一个破损的文件，发现对象长度异常的长，且连续出现多个“obj”和“endobject”，那就可以判断该对象错误了，并将该对象设置为无效，然后重新定位新的间接对象的开始位置，继续往后解析。\n\n\n# 5 document structure\n\n\n\n\n# 5.1 catalog\n\n文档对象层次结构的根是 catalog 字典，通过pdf文件 trailer 中的 root 条目进行定位。 一个简单的示例如下：\n\n1 0 obj \n  << /type /catalog  \n     /pages 2 0 r  \n     /pagemode /useoutlines\n     /outlines 3 0 r\n  >>\nendobj\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n该目录包含对定义文档内容，大纲（outline），文章线程（article threads），命名目标（named destinations）和其他属性的其他对象的引用。 此外，它还包含有关如何在屏幕上显示文档的信息，例如是否应自动显示其大纲（outline）和缩略图页面图像（thumbnail），以及打开文档时是否显示除第一页以外的某些位置。\n\npdf reader 应当从此节点开始，构建 page tree, 并逐步展开页面细节并进行渲染。\n\n\n# 5.2 common data structures\n\npdf格式中，一些通用用途的数据结构被定义，它们是由基本对象类型组合而来，在整个pdf中的许多地方都有使用。这里简单介绍文本字符串，日期，矩形，名称树和数字树相关的数据结构。更加复杂的数据结构可以参考 pdf 文档。\n\n# 5.2.1 string & text\n\npdf 1.7 标准中定义的 pdf data types 中常见的 string 有：\n\ntype                   description                                           note\nascii string           ascii 字符组成的字节流                                        \nbyte string            表示字符或其他二进制数据的一系列字节                                    如果这种类型表示字符，则编码应由上下文确定\nstring                 非 text string 的字符串                                    从 pdf 1.7 开始，此类型进一步限定为以下类型：pdfdocencoded string、ascii\n                                                                             string和 byte string。\ndate                   date (ascii string)                                   严格遵循iso / iec 8824的定义, 日期格式为：(d:yyyymmddhhmmssohh\'mm )\npdfdocencoded string   使用 pdfdocencoding 加密字符串形成的字节流                         pdf格式只使用 utf-16be 编码 unicode(带字节序标记)\ntext string            使用 pdfdocencoding 或 utf-16be 编码字符串形成的字节流，并带有前导字节序标记   主要用在人工可读的字符串信息，例如文本注释，书签名称，文档信息等\ntext stream            text stream                                           本质上是一个流，不过其未编码字节应满足与 text string 在编码、字节顺序和前导字节方面有相同要求\n\n关于 date 格式的说明:\n\n 1. 前缀d必需存在，年份字段（yyyy）必需存在，后面字段可以不存在\n 2. 其它字段说明:\n    \n    name   description\n    yyyy   年份\n    mm     月份（01-12）, 默认值为01\n    dd     当天（01-31）, 默认值为01\n    hh     小时（00-23）, 默认值为0\n    mm     分钟（00-59）, 默认值为0\n    ss     秒（00-59）, 默认值为0\n    o      时差，由加号（+ , 本地时间晚于ut），减号（ - , 本地时间早于ut）或 大写z（本地时间等于ut）表示\n    hh     时差中的小时数（00-23），后面跟着符号（’）, 默认值为0\n    mm     时差中的分钟数（00-59）, 默认值为0\n\n# 5.2.2 others\n\npdf 1.7 标准中定义的其它 pdf data types 如下：\n\ntype                 description                                 note\narray                array object                                \nboolean              boolean value                               \ndictionary           dictionary object                           \nfile specification   file specification (string or dictionary)   用于引用外部文件内容\nfunction             function (dictionary or stream)             \ninteger              integer number                              \nname                 name object                                 \nname tree            name tree (dictionary)                      树形结构，每个节点都应是字典对象。键是字符串，并且键是排序的，可以用于高效查找\nnull                 null object                                 \nnumber               number (integer or real)                    \nnumber tree          number tree (dictionary)                    树形结构，每个节点都应是字典对象。键是整数，并且键按数字升序排序，可以用于高效查找\nrectangle            rectangle (array)                           矩形用于描述页面上的位置和各种对象的边界框。矩形是由一个四个数字的数组(一对对角线的坐标)表示。通常表示为：[llx\n                                                                 lly urx ury]，按顺序指定矩形的左下x，左下y，右上y和右上y坐标。\nstream               stream object                               \n\n\n# 5.3 pagelabel\n\npdf pagelabel 页面标签可用于描述页面的页码。允许非连续页面编号，可以看为页面添加任意标签（例如在文档的开头包含罗马数字）。pagelabel对象可用于指定要使用的编号样式（例如，大写或小写罗马，十进制等），第一页的起始编号以及要预先附加到的任意前缀每个数字（例如，“a-”生成“a-1”，“a-2”，“a-3”等。）\n\npdf文档中的每个页面都由整数页索引标识，该索引表示页面在文档中的相对位置。另外，文档可以有选择地定义页面标签以在屏幕上或在打印中可视地识别每个页面。\n\n页面标签和页面索引不需要重合：索引是固定的，从第一页的1开始连续通过文档运行，但标签可以以适合特定文档的任何方式指定。例如，如果文档以12页用罗马数字编号的前端内容开头，而文档的其余部分用阿拉伯语编号，则第一页的页面索引为1，页面标签为i，第12页将具有索引12和标签xii，第十三页将具有索引13和标签1。\n\n\n# 5.4 outlines\n\noutlines，书签。pdf文档支持文件大纲（书签），用户可以通过点击书签完成跳转功能，类似与office word中的大纲功能。\n\n常用的跳转功能有：跳转到文档内部页面、跳转到其他pdf文档的某一页、跳转到web页面、跳转到外部文件（非pdf）等等。\n\n书签是一个树状结构，根据遍历first、next，得到完整的书签节点。下面是一个书签的例子，可以通过这个例子深入了解其结构：\n\n48 0 obj\n<</markinfo <</marked true>>\n/metadata 3 0 r\n/outlines 73 0 r\n/pagelayout /onecolumn\n/pagemode /useoutlines            % 书签根节点\n/pages 2 0 r\n/structtreeroot 5 0 r\n/type/catalog\n/viewerpreferences<</hidemenubar true/hidetoolbar true>>>>\nendobj\n\n73 0 obj\n<</count 4                     % 子节点数量\n/first 74 0 r                  % 第一个子节点对应的间接引用对象\n/last 75 0 r                   % 最后一个子节点对应的间接引用对象\n/type/outlines>>\nendobj\n\n74 0 obj\n<</a 77 0 r                  % 跳转功能的间接引用对象\n/count 2                     % 子节点数量\n/first 78 0 r                % 第一个子节点对应的间接引用对象\n/last 79 0 r                 % 最后一个子节点对应的间接引用对象\n/next 75 0 r                 % 兄弟节点对应的间接引用对象\n/parent 73 0 r               % 父节点对应的间接引用对象\n/title(book1)>>              % 书签显示内容\nendobj\n\n75 0 obj\n<</a 78 0 r\n/c[1.0 0.333328 0.0]         % 书签字体颜色\n/f 2                         % 书签字体标记（粗体/斜体/粗斜体）\n/next 76 0 r\n/parent 71 0 r\n/title(mark1)>>\nendobj\n\n76 0 obj\n<<\n/d[\n49 0 r                       % 跳转到文档对应的页面对象\n/fit                         % 跳转到对应页面展示的内容\n]              \n/s/goto                      % 跳转类型，该类型告诉浏览器跳转到文档内页面\n>>\nendobj\n\n77 0 obj\n<</d[49 0 r/fit]/s/goto>>\nendobj\n\n78 0 obj\n<</a 81 0 r/next 79 0 r/parent 74 0 r/title(mark1)>>\nendobj\n\n79 0 obj\n<</a 80 0 r/parent 74 0 r/prev 78 0 r/title(mark2)>>\nendobj\n\n80 0 obj\n<</d[49 0 r/fit]/s/goto>>\nendobj\n\n81 0 obj\n<</d[49 0 r/fit]/s/goto>>\nendobj\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n\n\n\n# 5.5 action\n\naction 字典的内容大致如下：\n\n3 0 obj\n<< /type /action\n/s /gotoe\n/d (chapter 1)\n/t << /r /p\n/t << /r /c\n/n (another embedded document) >>\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n/type /action说明当前字典为action的描述，/s指明动作类型，/n(可选)指定当前动作完成后需要执行的动作或动作序列。\n\naction 动作，除了用于跳转到文档中的某个页面之外，annotation或outline也可以指定要执行的动作，例如：启动应用程序，播放声音，改变注释的外观状态。 annotation或outline字典中的a(optional)条目可以指定一个在annotation或outline被激活时执行的动作。在 pdf 1.2 中，各种其他情况(trigger events)也可能触发action。此外，文档的catalog也可以通过openaction(optional)条目指定在打开文档时应执行的操作。\n\n下面列出pdf支持的标准的action类型：\n\naction        description                         note\ngoto          转到当前文档中的目标位置                        \ngotor         转到另一个文档中的目标位置                       go-to remote\ngotoe         转到某个嵌入文件                            go-to embedded\nlaunch        启动应用程序，通常是打开文件                      \nthread        开始阅读文章线索                            \nuri           解析到uri(统一资源标识符，代表internet上资源的字符串)   通常是作为超文本链接的目标的文件\nsound         播放音频                                \nmovie         播放视频                                \nhide          设置 annotation 的隐藏标志                 通过设置或清除一个或多个注释的隐藏标志，来隐藏或显示这些注释\nnamed         执行符合pdf标准的阅读器预定义的操作                 \nsubmitform    将数据发送到服务器（类似于网页的form）               此操作会将所选交互式表单字段的名称和值传送到指定的url\nresetform     将字段设置为其默认值                          \nimportdata    从文件导入字段值                            此操作应将表单数据格式（fdf）数据从指定文件导入到文档的交互式表单中\njavascript    执行 js 脚本                            \nsetocgstate   设置可选内容组的状态                          \nrendition     控制多媒体内容的播放                          \ntrans         使用transition字典更新文档的显示               pdf 1.5 中 transition 可用于控制一系列 action 期间的绘图\ngoto3dview    设置3d注释的当前视图                         pdf 1.6 中标识3d注释并指定要使用的注释的视图\n\n\n# 5.6 destinations\n\ndestinations本质上是一个命名的页面视图。它将一个独一无二的名称与单个 pdf 文档中的特定页面位置相关联。书签和链接可以在 go to a page view, go to a page view in another document和go to a page in attachment actions 中使用命名目标而不是直接页面引用。\n\n那为什么要使用它呢？\n\ndestinations允许设置跨 pdf 文档集合的导航路径。链接多个 pdf 文档时建议使用命名目标，因为与链接到页面不同，链接到destinations不受单个文档中页面添加或删除的影响。例如，如果 a.pdf 中的链接指向 b.pdf 中的命名目的地“chapter1”，那么如果 b.pdf 中的某些页面已被删除、移动或插入新页面，则此链接将继续正常工作。如果 a.pdf 直接引用 b.pdf 中的特定页面，则情况并非如此。对 b.pdf 中页面的任何更改都会破坏直接页面链接。\n\n\n# 5.7 article thread\n\n某些类型的文档可能会包含逻辑连接，而这个逻辑顺序并不是物理顺序。比如：新闻报道可以从新闻通讯的第一页开始，然后转到一个或多个非连续的内页。\n\n为了表示物理上不连续但逻辑相关的项目的序列，pdf文档定义了一个或多个article（pdf 1.1）。 article的顺序由article thread定义; 组成文章的各个内容项在线程上称为珠子（bead）。 用户可以通过点击从一个珠子到下一个珠子进行跳转。\n\n文档catalog中可以定义的可选threads条目，该条目中定义了一个thread词典组成的数组，用来表示文档articles。thread内的每个单独的bead应由bead字典表示。thread字典的“f”条目应指定threads中的第一个bead; bead通过“n”（下一个）和“v”（前一个）条目，构成一个在一个双向链表，将所有bead顺序链接在一起。 此外，对于出现 article beads 的每个页面，页面对象（page）应包含一个b条目，其值是页面上的bead间接引用的数组，顺序是按照绘图顺序进行排列。\n\n\n# 5.8 interactive forms\n\ninteractive forms 交互式表单，有时也称为 acroform，是通过交互方式，从用户端收集信息字段的集合。\n\npdf文档中，任何页面都可以存在任意数量的字段，而所有这些字段可以构成跨越整个文档的单个全局交互式表单。这些字段的任意子集可以从文档导入或导出。\n\n文档交互表单中的每个字段都应由 field 字段字典定义。文档交互表单的内容和属性应由交互式表单字典定义，该字典应从文档目录中的acroform条目引用。\n\n出于定义和命名的目的，可以按层次结构（树形结构）来组织字段，并且可以从字段层次结构中的祖先那里继承祖先的属性。 层次结构中的字段子节点，还可以包括用于定义其在页面上的 widget 窗口小部件注释（当只定义了一个widget时，field字典和widget字典可以合并为一个字典）。 具有子字段的字段称为非终端字段（即中间节点），没有子字段的字段称为终端字段（即叶节点）。\n\n下表显示了交互式表单字典的内容：\n\nkey               type              description\nfields            array             根 field 字段数组（字段层次结构中没有祖先的字段）\nneedappearances   boolean           optional，指定是否为文档中的所有 widget 注释构造外观流和外观字典。 默认值：false\nsigflags          integer           optional，pdf 1.3 开始，用于指定与签名字段相关的各种文档级别特征。 默认值：0\nco                array             （如果文档中的任何字段具有包含c条目的附加操作字典，则为必需; pdf\n                                    1.3）具有计算操作的字段字典的间接引用数组，由于某个字段的变化，导致需要根据计算顺序重新计算其值\ndr                dictionary        optional，表单字段外观将使用到的默认资源（如字体，图案或颜色空间）的资源字典。\n                                    该字典至少应包含一个font条目，用于指定显示文本的默认字体的资源名称和字体字典\nda                string            optional，可变文本字段的da属性的文档范围默认值\nq                 integer           optional，可变文本字段的q属性的文档范围默认值\nxfa               stream or array   optional，pdf 1.5 开始，用于包含xfa资源的流或数组，其格式应由数据包（xdp）规范描述。\n                                    此条目的值应该是表示xml数据包的全部内容的流，或者是表示包含xml数据包的各个数据包的文本字符串和流对象的数组\n\n\n# 5.9 forms data format\n\nforms data format 表单数据格式。fdf是一种文件格式，用于表示pdf格式中包含的表单数据和注释。此格式由 adobe systems incorporated 发明，它基于pdf格式。您可以在adobe的pdf参考中找到fdf格式的详细规范。\n\nfdf格式可用于各种工作流程。以下是几个示例：\n\n * 将表单数据发送到服务器并从服务器接收修改后的表单数据。此工作流程看起来像这样：\n   \n     a. 表单数据以fdf格式提交给服务器。（通常，当客户端计算机上的用户单击表单上的“提交”按钮时，会发生这种情况。）\n     b. 在服务器上，fdf数据被修改。\n     c. 服务器将修改后的fdf数据发送回客户端。\n     d. 在客户端计算机上，表单中的字段将填充修改后的数据。\n   \n   \n   1\n   2\n   3\n   4\n   \n * 存档表单数据。此工作流程看起来像这样：\n   \n     a. 用户使用adobe acrobat或其他pdf编辑/查看应用程序以fdf格式导出表单数据。（要在adobe acrobat 6.x for windows中执行此操作，请单击高级>表单>导出表单数据，然后选择acrobat fdf文件（* .fdf）作为“另存为类型”。如果您使用的是另一个版本，则该过程可能会有所不同）\n     b. fdf文件保存在公司的档案中。\n     c. 要查看表单数据，用户将使用adobe acrobat或其他一些pdf查看/编辑应用程序，来打开fdf文件; 这将导致pdf查看/编辑应用程序产生三个操作：1）找到需要导出表单数据的pdf表单，2）将表单数据加载到表单中，3）在屏幕上显示带有加载数据的表单。\n   \n   \n   1\n   2\n   3\n   \n\n您可能想知道为什么要存档包含pdf表单数据的fdf文件，而不是简单地使用包含表单数据的pdf。有两个原因：\n\n 1. 包含pdf表单的表单数据的fdf文件，比包含表单pdf本身的文件小得多，因此归档fdf文件比归档表单pdf需要更少的存储空间。\n 2. 人们用来查看表单pdf并与之交互的某些软件不允许用户保存填写的表单pdf。例如，免费的“adobe reader”软件不允许这样做。\n\n重要说明：fdf文件包含表单pdf的文件名和位置（fdf文件是从该表单pdf中导出的）。adobe acrobat（以及任何支持pdf表单的pdf查看/编辑应用程序）依赖于该文件名和位置，以便在打开fdf文件时检索和打开相应的pdf表单。换句话说：打开fdf文件时，pdf查看/编辑应用程序会根据指定的位置，显示pdf表单。\n\n因此，如果您是考虑实施归档fdf数据的系统的开发人员，则需要确保您的系统具有将所需表单pdf存储在已知位置的可靠方法。否则，pdf查看/编辑应用程序无法始终在需要时检索和打开表单pdf。\n\n某些pdf查看/编辑应用程序不支持与表单pdf相关的所有功能。\n\n总之，fdf可在将表单数据提交给服务器，接收响应，并将响应结果合并到交互式表单中。 它还可用于将表单数据导出为独立的文件，这些文件可以存储，以电子方式传输，也可以导回到相应的pdf交互式表单中。 此外，从pdf 1.3开始，fdf可用于定义注释的容器，使得这些注释与它们所在pdf文档分离。\n\n另外，虽然 fdf 基于 pdf; 它使用pdf一样的语法，并且具有基本相同的文件结构。但是，它在以下方面与pdf不同：\n\n * 交叉引用表是可选的。\n * 不应增量更新fdf文件。 对象只能是0代，fdf文件中没有两个对象具有相同的对象编号。\n * 文档结构比pdf简单得多，因为fdf文档的主体只包含一个必需对象。\n * 流的长度不应由间接对象指定。\n * fdf使用mime内容类型application/vnd.fdf。 在windows和unix平台上，fdf文件的扩展名为.fdf; 在mac os上，他们的文件类型是fdf。\n\n\n# 5.10 xfa\n\nxfa(xml forms architecture)这是由jetform建议和开发的一系列专有 xml规范，用于增强web表单的处理。pdf 1.5 引入了基于xfa 的交互式表单的支持。xfa规范被引用作为iso 32000-1规范（pdf 1.7）应用必不可少的外部规范。xml forms architecture未标准化为iso标准。\n\nxfa表单保存在pdf文件内部，可以作为xdp（xml数据包）文件进行保存，可以在adobe的livecycle designer软件中打开。\n\n虽然xfa可以使用pdf，但xfa并不依赖于特定的页面描述语言。\n\nxfa 有静态和动态表格之分。在静态形式中，无论字段内容如何， 表单的外观和布局都是固定的。动态表单（自xfa 2.1或2.2定义）可以通过多种方式更改外观以响应数据的更改。动态表单需要在文件打开时呈现其内容。动态表单还可以被设计为改变结构以适应提供给表单的数据结构的变化。例如，如果没有数据，则可以省略表单的页面。另一个例子是可能占用页面上可变空间量的字段，调整其自身以有效地保持其内容。动态表单不能依赖于其样板的pdf表示，因为样板的定位和布局随着字段的增长和收缩或子表单被省略和包含而改变。\n\n\n# 6 graphics\n\n\n\n\n# 6.1 graphics objects\n\ngraphics objects， 图形对象。内容流中存在两种类型的元素：一、图形对象（字体，shading，图片，通常用name对象表示），二、修饰图形对象的操作符（定位，缩放，颜色，大小，剪切，透明等），由这两类元素描绘出了页面的外观。\n\npdf提供五种类型的图形对象：\n\n * 路径对象，可以是直线，矩形和贝塞尔曲线，或它们组合而成的任意形状。 路径可以自身相交。\n * 文本对象，由一个或多个字符串组成。\n * 外部对象（xobject），是在内容流外部定义的对象，并作为命名资源引用（“资源字典”）。\n * 内联图像对象，使用特殊语法直接在内容流中表示小图像的数据。\n * shading对象，描述几何形状，其颜色是形状内位置的任意函数。 （在绘制其他图形对象时，shading也可以被视为颜色;在这种情况下，它不被视为单独的图形对象。）\n\npdf 1.3及更早版本不支持透明，由于每个图形对象按顺序绘制，后面绘制的内容，会把前面绘制的内容覆盖掉。pdf 1.4开始支持透明成像模型，对象可以根据设置透明程度。\n\n\n# 6.2 coordinate systems\n\npdf中，所有绘制都在画布（也就是我们看到的页面page）上进行的。坐标系决定了显示在页面上的文本、图形和图像的位置、方向和大小。这里介绍 pdf 中使用的坐标系，包括它们之间的关系以及如何转换。\n\n# 6.2.1 coordinate spaces\n\n路径和位置是通过一对坐标进行定义的， x 和 y 表示二维坐标空间中的水平位置和垂直位置。坐标空间由以下与当前页面相关的属性决定：\n\n * 坐标原点\n * x和y轴的方向\n * 沿x和y轴的长度\n\npdf定义了几种坐标空间，用于解析图形对象的坐标。坐标空间之间可以相互变换，这些变换由变换矩阵定义，变换矩阵可以指定二维坐标的任何线性映射，包括平移、缩放、旋转、反射和倾斜。\n\n# 1. 设备空间\n\n每一种用来显示pdf的设备（显示器、打印机），都可能有自己的独特的一套设备坐标系，也被称作设备空间，或是坐标原点不同，x和y轴的方向不同，也可能是分辨率不同，这些不同就会导致显示出来的对象不一样，如： 同一个图形对象在72像素/英寸显示器设备坐标系中显示效果，后者是在600点/英寸打印机的设备坐标系中打印效果，显著不同。\n\n# 2. 用户空间\n\n为了避免不同设备的设备坐标系对显示对象的影响，pdf定义了一种与设备无关的坐标系，该坐标系始终与当前页面具有相同的关系，而不管打印或显示在哪个输出设备上。这种与设备无关的坐标系称为用户空间。\n\n文档的每个页面都会被用户空间的默认状态初始化。页面字典中的cropbox条目指定了输出介质（即显示窗口或打印页面）的可见矩形区域。通常情况下，正 x 轴水平向右延伸，正 y 轴垂直向上延伸（可能因页面字典中的rotate条目而改变）。沿 x 和 y 轴的长度单位由页面字典中的userunit条目（pdf 1.6）设置。如果该条目不存在或不被支持，则使用1/72英寸的默认值。这个坐标系称为默认用户坐标系。\n\nnote1：在postscript中，默认用户空间的原点始终对应于输出介质的左下角。pdf文档中默认也是这样的，但并不一定如此；页面字典的cropbox条目，可以指定在输出介质上，可见的默认用户空间中的任何位置和大小的矩形区域。\n\nnote2：默认用户空间中单位大小的默认值（1/72英寸）与印刷行业中广泛使用的基础单位点大致相同。然而，它并不完全相同。一个点没有通用的定义。\n\n从理论上讲，用户空间是一个无限大的平面。这个平面中只有一小部分对应于输出设备的可成像区域：由页面字典中的cropbox条目定义的矩形区域(每一页的可成像区域大小可以不同)。用户空间中的坐标可以是任意实数或正整数，用户空间坐标的分辨率与设备空间的像素分辨率无关。\n\n从用户空间到设备空间的转换，由转换矩阵current transformation matrix (ctm)定义，该矩阵是pdf graphics state的一个元素。符合要求的阅读器可以针对特定输出设备的原始分辨率调整 ctm，从而保持 pdf 页面描述的设备无关性。\n\nnote3：无论使用何种输出设备，默认用户空间都为 pdf 页面描述提供了一致、可靠的起始位置。如有必要，pdf 内容流可以通过应用坐标变换运算符 cm 来修改用户空间以使其更适合其需要。因此，内容流中可能出现的绝对坐标相对于当前页面并不是绝对的，因为它们是在一个可以滑动和收缩或扩展的坐标系中表达的。坐标系转换不仅增强了设备独立性，而且本身就是一个有用的工具。\n\n下图显示了这如何允许用户空间中指定的对象显示相同的对象，而不管它是在哪个设备上呈现的。\n\n# 3. 其他坐标空间\n\n除了设备空间和用户空间外，pdf还使用了各种其他坐标空间用于特殊目的：\n\n * text space\n   * 文本定位操作符，来用指定文本的位置。\n * glyph space\n   * 从字形空间到文本空间的转换由字体矩阵定义。\n * form space\n   * 从form空间到用户空间的转换由包含在form xobject中的矩阵来指定。\n * image space\n   * 所有图像都在图像空间中定义。要进行绘制时，通过ctm将图像映射到页面的某个区域。\n * pattern space\n   * 从pattern 空间到用户空间的转换由pattern 中包含的pattern 矩阵指定。\n\n# 4. 坐标空间之间的关系\n\n下图显示了上述坐标空间之间的关系。图中的每个箭头表示从一个坐标空间到另一个坐标空间的转换。pdf 允许对这些转换中的许多进行修改。\n\n由于 pdf 坐标空间是相对于彼此定义的，对一种变换所做的更改会影响在多个坐标空间中定义的对象的外观。例如，ctm中的一个变化定义了从用户空间到设备空间的转换，它会影响表单、文本、图像和模式，因为它们都来自用户空间的上游。\n\n# 6.2.2 common transformations\n\n转换矩阵描述了两个坐标空间之间的关系。通过修改变换矩阵，可以缩放、旋转、平移对象。\n\npdf中的转换矩阵由六个数字指定，通常以数组的形式出现。通常，这个数组表示为[a b c d e f]；它可以表示从一个坐标系到另一个坐标系的任何线性变换。下面列出的转换的类型：\n\n * 平移：指定为[1 0 0 1 tx ty]，其中tx和ty分别是在水平和垂直尺寸中转换坐标系原点的距离。\n * 缩放：指定为[sx 0 0 sy 0 0]。sx为水平方式缩放倍数，sy为垂直方向缩放倍数。\n * 旋转：指定为[cosθ sinθ −sinθ cosθ 0 0]，它具有将坐标系轴逆时针旋转角度θ的效果。\n * 倾斜：指定为[1 tanα tanβ 1 0 0]，它使x轴倾斜一个角度α，y轴倾斜一个角度β。\n\n如果将多个转换组合在一起，则它们的应用顺序非常重要。例如，先缩放后平移x轴，与先平移然后缩放x轴不同。一般来说，为了获得预期的结果，应按以下顺序进行转换：1.平移，2.旋转，3.缩放或倾斜\n\n请注意，scale-rotate-translate顺序会导致坐标系变形，使x和y轴不再垂直；建议的translate-rotate-scale顺序不会导致变形\n\n\n# reference\n\n * iso 32000-1:2008 document management — portable document format — part 1: pdf 1.7\n * introduction_to_pdf from gnupdf\n * wiki - pdf',charsets:{cjk:!0}},{title:"InkScape",frontmatter:{title:"InkScape",date:"2022-03-22T22:07:00.000Z",lastmod:null,publish:!0,categories:"ui",keywords:"ui",description:null,tags:null,permalink:null},regularPath:"/blog/skills/ui/inkscape_tutorial.html",relativePath:"blog/skills/ui/inkscape_tutorial.md",key:"v-03728847",path:"/blog/skills/ui/inkscape_tutorial.html",headers:[{level:2,title:"Base",slug:"base",normalizedTitle:"base",charIndex:24},{level:2,title:"Text:",slug:"text",normalizedTitle:"text:",charIndex:129},{level:2,title:"Path & Object",slug:"path-object",normalizedTitle:"path &amp; object",charIndex:null}],headersStr:"Base Text: Path & Object",content:'# InkScape Tutorial\n\n\n# Base\n\n * square : 双击对象，会发现定点位置有白色的方形和圆形的点，可以进行调节\n * stroke\n   * shift 按键，调节颜色；右键 stroke width，可以调节宽度\n\n\n# Text:\n\n * 单行的字符间距：\n   * shift + alt(option)\n * 选中字符的位置：\n   * alt(option) + "上下左右方向键"\n * 文字的排列曲线：\n   * 使用 shift 同时选中图像和Text，再使用: "Text -> Put on Path"，可以将文字沿图形边缘排列\n * Extenstions -> Text, 有一些常用功能\n\n\n# Path & Object\n\n * Path 手工绘制\n   * bezier\n     * 编辑 node 模式，选中一个 node 同时按住 shift，可以制作曲线; 双击 path 上的任意一点，即可新增一个 node; 选中一个 node 后可以通过 delete 键删除它\n   * freehand\n     * "Path -> Simplify" 可以减少路径上的 node (也就是更smoothly)\n * Object 预定义的对象\n   * 选中对象, 如 square、circle、text 等\n   * "Path -> Object to Path" 可以将 object 转换为 path\n\n\n# Reference\n\n * https://www.bilibili.com/video/BV1Qf4y117Hg?p=8&spm_id_from=pageDriver\n\n * https://pixabay.com/zh/images/search/persion/',normalizedContent:'# inkscape tutorial\n\n\n# base\n\n * square : 双击对象，会发现定点位置有白色的方形和圆形的点，可以进行调节\n * stroke\n   * shift 按键，调节颜色；右键 stroke width，可以调节宽度\n\n\n# text:\n\n * 单行的字符间距：\n   * shift + alt(option)\n * 选中字符的位置：\n   * alt(option) + "上下左右方向键"\n * 文字的排列曲线：\n   * 使用 shift 同时选中图像和text，再使用: "text -> put on path"，可以将文字沿图形边缘排列\n * extenstions -> text, 有一些常用功能\n\n\n# path & object\n\n * path 手工绘制\n   * bezier\n     * 编辑 node 模式，选中一个 node 同时按住 shift，可以制作曲线; 双击 path 上的任意一点，即可新增一个 node; 选中一个 node 后可以通过 delete 键删除它\n   * freehand\n     * "path -> simplify" 可以减少路径上的 node (也就是更smoothly)\n * object 预定义的对象\n   * 选中对象, 如 square、circle、text 等\n   * "path -> object to path" 可以将 object 转换为 path\n\n\n# reference\n\n * https://www.bilibili.com/video/bv1qf4y117hg?p=8&spm_id_from=pagedriver\n\n * https://pixabay.com/zh/images/search/persion/',charsets:{cjk:!0}},{title:"UI 杂项",frontmatter:{title:"UI 杂项",date:"2022-02-22T22:07:00.000Z",lastmod:null,publish:!0,categories:"ui",keywords:"ui",description:null,tags:null,permalink:null},regularPath:"/blog/skills/ui/utils.html",relativePath:"blog/skills/ui/utils.md",key:"v-cf80e5c2",path:"/blog/skills/ui/utils.html",headers:[{level:2,title:"Collection",slug:"collection",normalizedTitle:"collection",charIndex:12},{level:2,title:"Android",slug:"android",normalizedTitle:"android",charIndex:27},{level:3,title:"屏幕",slug:"屏幕",normalizedTitle:"屏幕",charIndex:39},{level:3,title:"颜色",slug:"颜色",normalizedTitle:"颜色",charIndex:245},{level:3,title:"Material Design",slug:"material-design",normalizedTitle:"material design",charIndex:351},{level:3,title:"空间",slug:"空间",normalizedTitle:"空间",charIndex:501},{level:3,title:"动画",slug:"动画",normalizedTitle:"动画",charIndex:837},{level:3,title:"颜色",slug:"颜色-2",normalizedTitle:"颜色",charIndex:245},{level:3,title:"文字",slug:"文字",normalizedTitle:"文字",charIndex:1460},{level:3,title:"布局",slug:"布局",normalizedTitle:"布局",charIndex:1763},{level:3,title:"组件（Components）",slug:"组件-components",normalizedTitle:"组件（components）",charIndex:2243},{level:2,title:"Reference",slug:"reference",normalizedTitle:"reference",charIndex:5937}],headersStr:"Collection Android 屏幕 颜色 Material Design 空间 动画 颜色 文字 布局 组件（Components） Reference",content:'# UI 杂项\n\n\n# Collection\n\n\n# Android\n\n\n# 屏幕\n\n标识       尺寸            DPI   启动图标(DPI)   菜单图标(DPI)\nmdpi     360 * 540     160   48 * 48     24 * 24\nxhdpi    720 * 1280    320   96 * 96     48 * 48\nxxhdpi   1080 * 1920   480   144 * 144   72 * 72\n\n\n# 颜色\n\n在 Android 中 0x00 表示完全透明，0xFF 表示完全不透明，比较适中的透明度是 0x1E le="background: #303F9F"> aaaaaaaaaaaaaaaaaaa\n\n\n# Material Design\n\nMaterial Design，质感设计，由 Google 推出的设计语言，旨在为手机、平板、电脑等平台提供一致、更广泛的『外观和感觉』。\n\nMaterial Design 的核心思想，就是把物理世界的体验带进屏幕。去掉现实中的杂质和随机性，保留其最原始纯净的形态、空间关系、变化与过渡，配合虚拟世界的灵活特性，还原最贴近真实的体验，达到简洁与直观的效果。\n\nMaterial Design 是最重视跨平台体验的一套设计语言。由于规范严格细致，保证它在各个平台使用体验高度一致。\n\n\n\n\n# 空间\n\nMaterial Design引入了z轴的概念，z轴垂直于屏幕，用来表现元素的层叠关系。z值（海拔高度）越高，元素离界面底层（水平面）越远，投影越重。这里有一个前提，所有的元素的厚度都是1dp。\n\n所有元素都有默认的海拔高度，对它进行操作会抬升它的海拔高度，操作结束后，它应该落回默认海拔高度。同一种元素，同样的操作，抬升的高度是一致的。\n\n注意：这不止是设计中的概念，开发人员确实可以通过一个值来控制元素的海拔高度和投影。\n\n\n\n\n# 动画\n\nMaterial Design 重视动画效果，它反复强调一点：动画不只是装饰，它有含义，能表达元素、界面之间的关系，具备功能上的作用。\n\n# easing\n\n\n\n动画要贴近真实世界，就要重视 easing。物理世界中的运动和变化都是有加速和减速过程的，忽然开始、忽然停止的匀速动画显得机械而不真实。考虑动画的easing，要先考虑它在现实世界中的运动规律。\n\n# 水波纹\n\n\n\n# 转场效果\n\n\n\n所有可点击的元素，都应该有这样的反馈效果。通过这个动画，将点击的位置与所操作的元素关联起来，体现了 Material Design 动画的功能性。\n\n\n\n通过过渡动画，表达界面之间的空间与层级关系，并且跨界面传递信息。从父界面进入子界面，需要抬升子元素的海拔高度，并展开至整个屏幕，反之亦然。\n\n\n\n多个相似元素，动画的设计要有先后次序，起到引导视线的作用。\n\n\n\n相似元素的运动，要符合统一的规律。\n\n# 细节动画\n\n通过图标的变化和一些细节来达到令人愉悦的效果:\n\n\n\n\n# 颜色\n\n颜色不宜过多。选取一种主色、一种辅助色（非必需），在此基础上进行明度、饱和度变化，构成配色方案。\n\nAppbar 背景使用主色，状态栏背景使用深一级的主色或20%透明度的纯黑。\n\n小面积需要高亮显示的地方使用辅助色。\n\n其余颜色通过纯黑#000000与纯白#ffffff的透明度变化来展现（包括图标和分隔线），而且透明度限定了几个值。\n\n颜色   普通文字   减淡文字   禁用状态/提示文字   分隔线\n黑色   87%    54%    26%         12%\n白色   100%   70%    30%         12%\n\n\n# 文字\n\n用途   小字提示   正文/按钮           小标题             APPBAR文字   大标题    超大号文字\n字号   12sp   14sp(桌面端13sp)   16sp(桌面端15sp)   20sp       24sp   34sp/45sp/56sp/112sp\n\n长篇幅正文，每行建议60字符（英文）左右。短文本，建议每行30字符（英文）左右。\n\n\n# 布局\n\n所有可操作元素最小点击区域尺寸：48dp X 48dp。\n\n栅格系统的最小单位是8dp，一切距离、尺寸都应该是8dp的整数倍。以下是一些常见的尺寸与距离：\n\n用途             距离\n顶部状态栏高度        24dp\nAppbar最小高度     56dp\n底部导航栏高度        48dp\n悬浮按钮           56x56dp/40x40dp\n用户头像           64x64dp/40x40dp\n小图标点击区域        48x48dp\n侧边抽屉到屏幕右边的距离   56dp\n卡片间距           8dp\n分隔线上下留白        8dp\n大多元素的留白距离      16dp\n屏幕左右对齐基线       16dp\n文字左侧对齐基线       72dp\n\n\n\n另外注意56dp这个数字，许多尺寸可变的控件，比如对话框、菜单等，宽度都可以按56的整数倍来设计。\n\n还有非常多规范，不详细列举，遵循8dp栅格很容易找到适合的尺寸与距离。平板与PC上留白更多，距离与尺寸要相应增大。\n\n\n# 组件（Components）\n\n# 底部导航（Bottom navigation）\n\n\n\n# 底部动作条（Bottom Sheets）\n\n\n\n底部动作条是一个从屏幕底部边缘向上滑出的一个面板，使用这种方式向用户呈现一组功能。底部动作条呈现了简单、清晰、无需额外解释的一组操作。\n\n通常以列表形式出现，支持上下滚动。也可以是网格式的。\n\n# 卡片（Cards）\n\n\n\n卡片是包含一组特定数据集的纸片，数据集含有各种相关信息，例如，关于单一主题的照片，文本，和链接。卡片通常是通往更详细复杂信息的入口。卡片有固定的宽度和可变的高度。最大高度限制于可适应平台上单一视图的内容，但如果需要它可以临时扩展（例如，显示评论栏）。卡片不会翻转以展示其背后的信息。\n\n在以下情况考虑使用卡片：\n\n * 同时展现多种不同内容\n * 卡片内容之间不需要进行比较\n * 包含了长度不确定的内容，比如评论\n * 包含丰富的内容与操作项，比如赞、滚动条、评论\n * 本该是列表，但文字超过3行\n * 本该是网格，但需要展现更多文字\n\n卡片最多有两块操作区域。辅助操作区至多包含两个操作项，更多操作需要使用下拉菜单。其余部分都是主操作区。\n\n圆角    正文字体      标题          扁平按钮                            内容留白   卡片间留白   屏幕边界与卡片间留白\n2dp   14/16sp   24/24+ sp   Roboto Medium, 14sp, 10sp 字间距   16dp   8dp     8dp\n\n# 纸片（Chips）\n\n纸片是一种小块的用来呈现复杂实体的块，比如说日历的事件或联系人。它可以包含一张图片，一个短字符串(必要时可能被截取的字符串)，或者是其它的一些与实体对象有关的简洁的信息。\n\nChips 可以非常方便的通过托拽来操作。通过按压动作可以触发悬浮卡片(或者是全屏视图)中的 Chip 对应实体的视图，或者是弹出与 Chip 实体相关的操作菜单。\n\n狭小空间内表现复杂信息的一个组件，比如日期、联系人选择器。\n\n\n\n# 提示框（Dialogs）\n\n\n\nDialogs 用于提示用户作一些决定，或者是完成某个任务时需要的一些其它额外的信息。 Dialog 可以是用一种 取消/确定 的简单应答模式，也可以是自定义布局的复杂模式，比如说一些文本设置或者是文本输入 。\n\n一些复杂的操作，尤其是每个决策都需要相关解释说明的情况下是不适合使用 Dialog 形式的。\n\nDialog 包含了一个标题(可选)，内容 ，事件。\n\n * 标题：主要是用于简单描述下选择类型。它是可选的，要需要的时候赋值即可。\n * 内容：主要是描述要作出一个什么样的决定 。\n * 事件：主要是允许用户通过确认一个具体操作来继续下一步活动。\n\n\n\n# 分隔线（Dividers）\n\nDividers 主要用于管理和分隔列表和页面布局内的内容，以便让内容生成更好的视觉效果及空间感。示例中呈现的分隔线是一种弱规则，弱到不会去打扰到用户对内容的关注。\n\n 1. 列表中有头像、图片等元素时，使用内嵌分隔线，左端与文字对齐; 没有头像、图标等元素时，需要用通栏分隔线:\n\n 2. 图片本身就起到划定区域的作用，所以相册列表不需要分隔线:\n\n\n\n 3. 谨慎使用分隔线，留白和小标题也能起到分隔作用。能用留白的地方，优先使用留白。分隔线的层级高于留白。\n\n\n\n 4. 通栏分隔线的层级高于内嵌分隔线\n\n\n\n# 网格（Grids）\n\n网格列表是一种标准列表视图的可选组件。网格列表与应用于布局和其他可视视图中的网格有着明显的区别。\n\n一般来说，网格只能垂直滚动。单个瓦片不支持滑动手势，也不鼓励使用拖放操作。网格中的单元格间距是2dp或8dp。\n\n\n\n网格由单元格构成，单元格中的瓦片用来承载内容。瓦片可以横跨多个单元格:\n\n\n\n瓦片内容包括主要内容（primary content）和次要内容(secondary content)。主要内容是有着重要区别的内容，典型的如图片。次要内容可以是一个动作按钮或者文本。\n\n\n\n# 列表（Lists）\n\n列表作为一个单一的连续元素来以垂直排列的方式显示多行条目。\n\n列表由单一连续的列构成，该列又等分成相同宽度称为行（rows）的子部分。行是瓦片（tiles）的容器。瓦片中存放内容，并且在列表中可以改变高度。\n\n如果列表项内容文字超过3行，请改用卡片。如果列表项的主要区别在于图片，请改用网格。\n\n列表包含主操作区与副操作区。副操作区位于列表右侧，其余都是主操作区。在同一个列表中，主、副操作区的内容与位置要保持一致。\n\n\n\n主操作区与副操作区的图标或图形元素是列表控制项，列表的控制项可以是勾选框、开关、拖动排序、展开/收起等操作，也可以包含快捷键提示、二级菜单等提示信息。\n\n\n\n在同一个列表中，滑动手势操作保持一致。\n\n# 菜单（Menus）\n\n\n\n注意：菜单到上下留出8dp距离。\n\n# 进度和动态（Progress & activity）\n\n线形进度条只出现在纸片的边缘:\n\n\n\n环形进度条也分时间已知和时间未知两种:\n\n加载详细信息时，也可以使用进度条:\n\n\n\n# Snackbars & toasts\n\n\n\nSnackbars至多包含一个操作项，不能包含图标。不能出现一个以上的Snackbars。\n\nSnackbars在移动设备上，出现在底部。在PC上，应该悬浮在屏幕左下角。\n\n不一定要用户响应的提示，可以使用Snackbars。非常重要的提示，必须用户来决定的，应该用对话框。\n\n\n\nSnackbars不能遮挡住悬浮按钮，悬浮按钮要上移让出位置。\n\n\n\nSnackbars的留白比较大，24dp。\n\n\n\ntoasts和Snackbars类似，样式和位置可以自定义，建议遵循Snackbars的规则设计。\n\n\n\n# 副标题（Subheaders）\n\n\n\n小标题是列表或网格中的特殊瓦片，描述列表内容的分类、排序等信息。\n\n\n\n滚动时，如果列表较长，小标题会固定在顶部，直到下一个小标题将它顶上去。\n\n\n\n存在浮动按钮时，小标题要让出位置，与文字对齐。\n\n\n\n# Tabs\n\n\n\n在一个 app 中，tabs 使在不同的视图和功能间探索和切换以及浏览不同类别的数据集合起来变得简单。\n\n\n\ntab文字要显示完整，字号保持一致，不能折行，文字与图标不能混用。\n\n\n\n# 文本字段（Text fields）\n\n文本框可以让用户输入文本。它们可以是单行的，带或不带滚动条，也可以是多行的，并且带有一个图标。点击文本框后显示光标，并自动显示键盘。除了输入，文本框可以进行其他任务操作，如文本选择（剪切，复制，粘贴）以及数据的自动查找功能。\n\n简单一根横线就能代表输入框，可以带图标:\n\n\n\n激活状态和错误状态，横线的宽度变为2dp，颜色改变:\n\n\n\n输入框点击区域高度至少48dp，但横线并不在点击区域的底部，还有8dp距离。\n\n\n\n输入框提示文字，可以在输入内容后，缩小停留在输入框左上角; 整个点击区域增高，提示文字也是点击区域的一部分:\n\n通栏输入框是没有横线的，这种情况下通常有分隔线将输入框隔开:\n\n\n\n右下角可以加入字数统计。字数统计不要默认显示，字数接近上限时再显示出来。\n\n通栏输入框也可以有字数统计，单行的字数统计显示在同一行右侧:\n\n\n\n错误提示显示在输入框的左下方。默认提示文本可以转换为错误提示:\n\n字数限制与错误提示都会使点击区域增高:\n\n\n\n同时有多个输入框错误时，顶部要有一个全局的错误提示:\n\n\n\n输入框尽量带有自动补全功能:\n\n\n\n# 工具提示（Tooltips）\n\n提示只用在小图标上，文字不需要提示。鼠标悬停、获得焦点、手指长按都可以触发提示。\n\n\n\n触摸提示（左）和鼠标提示（右）的尺寸是不同的，背景都带有90%的透明度:\n\n# Steppers\n\n# 导航（Navigation）\n\nTabs:\n\n\n\nBottom navigation bar 1:\n\n\n\nBottom navigation bar 2:\n\n\n\nNavigation drawer:\n\n\n\n# 导航抽屉（Navigation drawer）\n\n侧边抽屉从左侧滑出，占据整个屏幕高度，遵循普通列表的布局规则。手机端的侧边抽屉距离屏幕右侧56dp。\n\n\n\n侧边抽屉支持滚动。如果内容过长，设置和帮助反馈可以固定在底部；列表较短不需要滚动时，设置和帮助反馈跟随在列表后面；抽屉收起时，会保留之前的滚动位置:\n\n# 通知（Notifications）\n\n\n\n# 权限（Permissions）\n\n\n\n# 设置界面（Settings）\n\n\n\n设置和帮助反馈通常放在侧边抽屉中。如果没有侧边抽屉，则放在Appbar的下拉菜单底部。设置界面只能包含设置项，诸如关于、反馈之类的界面，入口应该放在其他地方。\n\n\n# Reference\n\n 1. https://www.cnblogs.com/weekbo/p/9018121.html\n\n使用 style 属性修改文字的背景色: 红色 绿色 蓝色 颜色值 颜色值',normalizedContent:'# ui 杂项\n\n\n# collection\n\n\n# android\n\n\n# 屏幕\n\n标识       尺寸            dpi   启动图标(dpi)   菜单图标(dpi)\nmdpi     360 * 540     160   48 * 48     24 * 24\nxhdpi    720 * 1280    320   96 * 96     48 * 48\nxxhdpi   1080 * 1920   480   144 * 144   72 * 72\n\n\n# 颜色\n\n在 android 中 0x00 表示完全透明，0xff 表示完全不透明，比较适中的透明度是 0x1e le="background: #303f9f"> aaaaaaaaaaaaaaaaaaa\n\n\n# material design\n\nmaterial design，质感设计，由 google 推出的设计语言，旨在为手机、平板、电脑等平台提供一致、更广泛的『外观和感觉』。\n\nmaterial design 的核心思想，就是把物理世界的体验带进屏幕。去掉现实中的杂质和随机性，保留其最原始纯净的形态、空间关系、变化与过渡，配合虚拟世界的灵活特性，还原最贴近真实的体验，达到简洁与直观的效果。\n\nmaterial design 是最重视跨平台体验的一套设计语言。由于规范严格细致，保证它在各个平台使用体验高度一致。\n\n\n\n\n# 空间\n\nmaterial design引入了z轴的概念，z轴垂直于屏幕，用来表现元素的层叠关系。z值（海拔高度）越高，元素离界面底层（水平面）越远，投影越重。这里有一个前提，所有的元素的厚度都是1dp。\n\n所有元素都有默认的海拔高度，对它进行操作会抬升它的海拔高度，操作结束后，它应该落回默认海拔高度。同一种元素，同样的操作，抬升的高度是一致的。\n\n注意：这不止是设计中的概念，开发人员确实可以通过一个值来控制元素的海拔高度和投影。\n\n\n\n\n# 动画\n\nmaterial design 重视动画效果，它反复强调一点：动画不只是装饰，它有含义，能表达元素、界面之间的关系，具备功能上的作用。\n\n# easing\n\n\n\n动画要贴近真实世界，就要重视 easing。物理世界中的运动和变化都是有加速和减速过程的，忽然开始、忽然停止的匀速动画显得机械而不真实。考虑动画的easing，要先考虑它在现实世界中的运动规律。\n\n# 水波纹\n\n\n\n# 转场效果\n\n\n\n所有可点击的元素，都应该有这样的反馈效果。通过这个动画，将点击的位置与所操作的元素关联起来，体现了 material design 动画的功能性。\n\n\n\n通过过渡动画，表达界面之间的空间与层级关系，并且跨界面传递信息。从父界面进入子界面，需要抬升子元素的海拔高度，并展开至整个屏幕，反之亦然。\n\n\n\n多个相似元素，动画的设计要有先后次序，起到引导视线的作用。\n\n\n\n相似元素的运动，要符合统一的规律。\n\n# 细节动画\n\n通过图标的变化和一些细节来达到令人愉悦的效果:\n\n\n\n\n# 颜色\n\n颜色不宜过多。选取一种主色、一种辅助色（非必需），在此基础上进行明度、饱和度变化，构成配色方案。\n\nappbar 背景使用主色，状态栏背景使用深一级的主色或20%透明度的纯黑。\n\n小面积需要高亮显示的地方使用辅助色。\n\n其余颜色通过纯黑#000000与纯白#ffffff的透明度变化来展现（包括图标和分隔线），而且透明度限定了几个值。\n\n颜色   普通文字   减淡文字   禁用状态/提示文字   分隔线\n黑色   87%    54%    26%         12%\n白色   100%   70%    30%         12%\n\n\n# 文字\n\n用途   小字提示   正文/按钮           小标题             appbar文字   大标题    超大号文字\n字号   12sp   14sp(桌面端13sp)   16sp(桌面端15sp)   20sp       24sp   34sp/45sp/56sp/112sp\n\n长篇幅正文，每行建议60字符（英文）左右。短文本，建议每行30字符（英文）左右。\n\n\n# 布局\n\n所有可操作元素最小点击区域尺寸：48dp x 48dp。\n\n栅格系统的最小单位是8dp，一切距离、尺寸都应该是8dp的整数倍。以下是一些常见的尺寸与距离：\n\n用途             距离\n顶部状态栏高度        24dp\nappbar最小高度     56dp\n底部导航栏高度        48dp\n悬浮按钮           56x56dp/40x40dp\n用户头像           64x64dp/40x40dp\n小图标点击区域        48x48dp\n侧边抽屉到屏幕右边的距离   56dp\n卡片间距           8dp\n分隔线上下留白        8dp\n大多元素的留白距离      16dp\n屏幕左右对齐基线       16dp\n文字左侧对齐基线       72dp\n\n\n\n另外注意56dp这个数字，许多尺寸可变的控件，比如对话框、菜单等，宽度都可以按56的整数倍来设计。\n\n还有非常多规范，不详细列举，遵循8dp栅格很容易找到适合的尺寸与距离。平板与pc上留白更多，距离与尺寸要相应增大。\n\n\n# 组件（components）\n\n# 底部导航（bottom navigation）\n\n\n\n# 底部动作条（bottom sheets）\n\n\n\n底部动作条是一个从屏幕底部边缘向上滑出的一个面板，使用这种方式向用户呈现一组功能。底部动作条呈现了简单、清晰、无需额外解释的一组操作。\n\n通常以列表形式出现，支持上下滚动。也可以是网格式的。\n\n# 卡片（cards）\n\n\n\n卡片是包含一组特定数据集的纸片，数据集含有各种相关信息，例如，关于单一主题的照片，文本，和链接。卡片通常是通往更详细复杂信息的入口。卡片有固定的宽度和可变的高度。最大高度限制于可适应平台上单一视图的内容，但如果需要它可以临时扩展（例如，显示评论栏）。卡片不会翻转以展示其背后的信息。\n\n在以下情况考虑使用卡片：\n\n * 同时展现多种不同内容\n * 卡片内容之间不需要进行比较\n * 包含了长度不确定的内容，比如评论\n * 包含丰富的内容与操作项，比如赞、滚动条、评论\n * 本该是列表，但文字超过3行\n * 本该是网格，但需要展现更多文字\n\n卡片最多有两块操作区域。辅助操作区至多包含两个操作项，更多操作需要使用下拉菜单。其余部分都是主操作区。\n\n圆角    正文字体      标题          扁平按钮                            内容留白   卡片间留白   屏幕边界与卡片间留白\n2dp   14/16sp   24/24+ sp   roboto medium, 14sp, 10sp 字间距   16dp   8dp     8dp\n\n# 纸片（chips）\n\n纸片是一种小块的用来呈现复杂实体的块，比如说日历的事件或联系人。它可以包含一张图片，一个短字符串(必要时可能被截取的字符串)，或者是其它的一些与实体对象有关的简洁的信息。\n\nchips 可以非常方便的通过托拽来操作。通过按压动作可以触发悬浮卡片(或者是全屏视图)中的 chip 对应实体的视图，或者是弹出与 chip 实体相关的操作菜单。\n\n狭小空间内表现复杂信息的一个组件，比如日期、联系人选择器。\n\n\n\n# 提示框（dialogs）\n\n\n\ndialogs 用于提示用户作一些决定，或者是完成某个任务时需要的一些其它额外的信息。 dialog 可以是用一种 取消/确定 的简单应答模式，也可以是自定义布局的复杂模式，比如说一些文本设置或者是文本输入 。\n\n一些复杂的操作，尤其是每个决策都需要相关解释说明的情况下是不适合使用 dialog 形式的。\n\ndialog 包含了一个标题(可选)，内容 ，事件。\n\n * 标题：主要是用于简单描述下选择类型。它是可选的，要需要的时候赋值即可。\n * 内容：主要是描述要作出一个什么样的决定 。\n * 事件：主要是允许用户通过确认一个具体操作来继续下一步活动。\n\n\n\n# 分隔线（dividers）\n\ndividers 主要用于管理和分隔列表和页面布局内的内容，以便让内容生成更好的视觉效果及空间感。示例中呈现的分隔线是一种弱规则，弱到不会去打扰到用户对内容的关注。\n\n 1. 列表中有头像、图片等元素时，使用内嵌分隔线，左端与文字对齐; 没有头像、图标等元素时，需要用通栏分隔线:\n\n 2. 图片本身就起到划定区域的作用，所以相册列表不需要分隔线:\n\n\n\n 3. 谨慎使用分隔线，留白和小标题也能起到分隔作用。能用留白的地方，优先使用留白。分隔线的层级高于留白。\n\n\n\n 4. 通栏分隔线的层级高于内嵌分隔线\n\n\n\n# 网格（grids）\n\n网格列表是一种标准列表视图的可选组件。网格列表与应用于布局和其他可视视图中的网格有着明显的区别。\n\n一般来说，网格只能垂直滚动。单个瓦片不支持滑动手势，也不鼓励使用拖放操作。网格中的单元格间距是2dp或8dp。\n\n\n\n网格由单元格构成，单元格中的瓦片用来承载内容。瓦片可以横跨多个单元格:\n\n\n\n瓦片内容包括主要内容（primary content）和次要内容(secondary content)。主要内容是有着重要区别的内容，典型的如图片。次要内容可以是一个动作按钮或者文本。\n\n\n\n# 列表（lists）\n\n列表作为一个单一的连续元素来以垂直排列的方式显示多行条目。\n\n列表由单一连续的列构成，该列又等分成相同宽度称为行（rows）的子部分。行是瓦片（tiles）的容器。瓦片中存放内容，并且在列表中可以改变高度。\n\n如果列表项内容文字超过3行，请改用卡片。如果列表项的主要区别在于图片，请改用网格。\n\n列表包含主操作区与副操作区。副操作区位于列表右侧，其余都是主操作区。在同一个列表中，主、副操作区的内容与位置要保持一致。\n\n\n\n主操作区与副操作区的图标或图形元素是列表控制项，列表的控制项可以是勾选框、开关、拖动排序、展开/收起等操作，也可以包含快捷键提示、二级菜单等提示信息。\n\n\n\n在同一个列表中，滑动手势操作保持一致。\n\n# 菜单（menus）\n\n\n\n注意：菜单到上下留出8dp距离。\n\n# 进度和动态（progress & activity）\n\n线形进度条只出现在纸片的边缘:\n\n\n\n环形进度条也分时间已知和时间未知两种:\n\n加载详细信息时，也可以使用进度条:\n\n\n\n# snackbars & toasts\n\n\n\nsnackbars至多包含一个操作项，不能包含图标。不能出现一个以上的snackbars。\n\nsnackbars在移动设备上，出现在底部。在pc上，应该悬浮在屏幕左下角。\n\n不一定要用户响应的提示，可以使用snackbars。非常重要的提示，必须用户来决定的，应该用对话框。\n\n\n\nsnackbars不能遮挡住悬浮按钮，悬浮按钮要上移让出位置。\n\n\n\nsnackbars的留白比较大，24dp。\n\n\n\ntoasts和snackbars类似，样式和位置可以自定义，建议遵循snackbars的规则设计。\n\n\n\n# 副标题（subheaders）\n\n\n\n小标题是列表或网格中的特殊瓦片，描述列表内容的分类、排序等信息。\n\n\n\n滚动时，如果列表较长，小标题会固定在顶部，直到下一个小标题将它顶上去。\n\n\n\n存在浮动按钮时，小标题要让出位置，与文字对齐。\n\n\n\n# tabs\n\n\n\n在一个 app 中，tabs 使在不同的视图和功能间探索和切换以及浏览不同类别的数据集合起来变得简单。\n\n\n\ntab文字要显示完整，字号保持一致，不能折行，文字与图标不能混用。\n\n\n\n# 文本字段（text fields）\n\n文本框可以让用户输入文本。它们可以是单行的，带或不带滚动条，也可以是多行的，并且带有一个图标。点击文本框后显示光标，并自动显示键盘。除了输入，文本框可以进行其他任务操作，如文本选择（剪切，复制，粘贴）以及数据的自动查找功能。\n\n简单一根横线就能代表输入框，可以带图标:\n\n\n\n激活状态和错误状态，横线的宽度变为2dp，颜色改变:\n\n\n\n输入框点击区域高度至少48dp，但横线并不在点击区域的底部，还有8dp距离。\n\n\n\n输入框提示文字，可以在输入内容后，缩小停留在输入框左上角; 整个点击区域增高，提示文字也是点击区域的一部分:\n\n通栏输入框是没有横线的，这种情况下通常有分隔线将输入框隔开:\n\n\n\n右下角可以加入字数统计。字数统计不要默认显示，字数接近上限时再显示出来。\n\n通栏输入框也可以有字数统计，单行的字数统计显示在同一行右侧:\n\n\n\n错误提示显示在输入框的左下方。默认提示文本可以转换为错误提示:\n\n字数限制与错误提示都会使点击区域增高:\n\n\n\n同时有多个输入框错误时，顶部要有一个全局的错误提示:\n\n\n\n输入框尽量带有自动补全功能:\n\n\n\n# 工具提示（tooltips）\n\n提示只用在小图标上，文字不需要提示。鼠标悬停、获得焦点、手指长按都可以触发提示。\n\n\n\n触摸提示（左）和鼠标提示（右）的尺寸是不同的，背景都带有90%的透明度:\n\n# steppers\n\n# 导航（navigation）\n\ntabs:\n\n\n\nbottom navigation bar 1:\n\n\n\nbottom navigation bar 2:\n\n\n\nnavigation drawer:\n\n\n\n# 导航抽屉（navigation drawer）\n\n侧边抽屉从左侧滑出，占据整个屏幕高度，遵循普通列表的布局规则。手机端的侧边抽屉距离屏幕右侧56dp。\n\n\n\n侧边抽屉支持滚动。如果内容过长，设置和帮助反馈可以固定在底部；列表较短不需要滚动时，设置和帮助反馈跟随在列表后面；抽屉收起时，会保留之前的滚动位置:\n\n# 通知（notifications）\n\n\n\n# 权限（permissions）\n\n\n\n# 设置界面（settings）\n\n\n\n设置和帮助反馈通常放在侧边抽屉中。如果没有侧边抽屉，则放在appbar的下拉菜单底部。设置界面只能包含设置项，诸如关于、反馈之类的界面，入口应该放在其他地方。\n\n\n# reference\n\n 1. https://www.cnblogs.com/weekbo/p/9018121.html\n\n使用 style 属性修改文字的背景色: 红色 绿色 蓝色 颜色值 颜色值',charsets:{cjk:!0}},{title:"字符集 & 编码",frontmatter:{title:"字符集 & 编码",date:"2021-11-18T00:00:00.000Z",lastmod:null,publish:!0,categories:null,keywords:null,description:null,tags:null,permalink:null},regularPath:"/blog/skills/utils/charscter_and_coding.html",relativePath:"blog/skills/utils/charscter_and_coding.md",key:"v-7d6afdba",path:"/blog/skills/utils/charscter_and_coding.html",headers:[{level:2,title:"ASCII",slug:"ascii",normalizedTitle:"ascii",charIndex:19},{level:2,title:"ANSI",slug:"ansi",normalizedTitle:"ansi",charIndex:34},{level:3,title:"中文",slug:"中文",normalizedTitle:"中文",charIndex:350},{level:2,title:"Unicode",slug:"unicode",normalizedTitle:"unicode",charIndex:1235},{level:2,title:"Coding-Model",slug:"coding-model",normalizedTitle:"coding-model",charIndex:1479}],headersStr:"ASCII ANSI 中文 Unicode Coding-Model",content:'# 字符集 & 编码\n\n\n\n\n\n\n# ASCII\n\nASCII 是 ANSI 的一部分，仅使用 0x00 ~ 0x7F，是目前最普及的一种字符编码，它扎根于我们的互联网，操作系统，键盘，打印机，文件字体和打印机等。\n\n\n# ANSI\n\nANSI是一种字符编码方式，为使计算机支持更多语言，通常使用 0x00~0x7f 范围的1 个字节来表示 1 个英文字符。超出此范围的使用0x80~0xFFFF来编码，即扩展的ASCII编码。\n\n注意 code page 的使用。code page 主要用于解决 字节与字符的快速对照，也就是直接将 字节与某种字符集的字符编码 之间相互映射。\n\n其中常见的字符集，如GB2312、GBK、GB18030、Big5、Shift_JIS 等都属于此编码方式。\n\n\n# 中文\n\n# GB2312\n\nGB2312 或 GB2312-80 是中国国家标准简体中文字符集, 由中国国家标准总局发布, 1981 年 5 月 1 日实施。\n\nGB2312 对任意一个图形字符都采用两个字节表示，并对所收汉字进行了"分区"处理，每区含有 94 个汉字/符号，分别对应第一字节和第二字节。这种表示方式也称为区位码:\n\n * 01-09 区为特殊符号\n * 16-55 区为一级汉字，按拼音排序\n * 56-87 区为二级汉字，按部首/笔画排序\n * 10-15 区及 88-94 区则未有编码\n\nGB 2312 的编码范围为(分别为首字节、尾字节): 0x21H ~ 0x77, 0x21 ~ 0x7EH。这与 ASCII 有重叠，通行方法是将 GB 码两个字节的最高位置 1 以示区别，所以最终的编码范围为: 0xA1 ~ 0xF7, 0xA1 ~ 0xFE。\n\n# GBK\n\nGBK 即汉字内码扩展规范，K 为汉语拼音 Kuo Zhan（扩展）中"扩"字的声母。英文全称 Chinese Internal Code Specification。\n\nGBK 向下与 GB 2312 完全兼容，向上支持 ISO 10646 国际标准，在前者向后者过渡过程中起到的承上启下的作用。\n\nGBK 采用双字节表示，总体编码范围为(分别为首字节、尾字节): 0x81 ~ 0xFE, 0x40 ~ 0xFE，剔除 XX7F 一条线。\n\n# GB18030\n\nGB18030 与 GB2312 和 GBK 兼容，共收录汉字70244个。GB18030 编码是一二四字节变长编码:\n\n * 单字节，其值从 0 到 0x7F，与 ASCII 编码兼容\n * 双字节，第一个字节的值从 0x81 ~ 0xFE，第二个字节的值从 0x40 ~ 0xFE(不包括0x7F)，与 GBK 标准兼容\n * 四字节，第一个字节的值从 0x81 ~ 0xFE，第二个字节的值从 0x30 ~ 0x39，第三个字节从0x81 ~ 0xFE，第四个字节从 0x30 ~ 0x39\n\n\n# Unicode\n\n其中 utf8 和 utf16 都是变长编码，只不过 utf16 可以完整的表达 BMP (基础平面) 中的所有字符，所以一般都认为其固定为 2bytes(这个美丽的错误源自 windows 的 unicode 定义, 它其实是 ucs-2)。\n\nutf16 和 utf32 则因为 byte-order 问题，必定需要在文档开头通过 BOM 头指明字节序。utf8 按照设计原理来看，是没有 byte-order 问题的，不过微软还是给其定义了 BOM 头。\n\n\n# Coding-Model\n\n统一码(Unicode)和通用字符集(UCS)所描述的编码系统，提出了全新的编码思路，它将字符集与字符编码的概念更为细致地分解为了以下几个方面：\n\n 1. 有哪些字符；\n 2. 这些字符的编号是什么；\n 3. 这些编号如何编码成一系列逻辑层面有限大小的数字，即码元序列；\n 4. 这些逻辑层面的码元序列如何转换为(即映射为)物理层面的字节序列(即字节流)；\n 5. 在某些特殊的传输环境中(比如Email中)，再进一步将字节序列进行适应性编码处理。\n\n这几个方面作为一个整体，构成了现代字符编码模型。现代字符编码模型之所以要分解为这么几个方面，其核心思想是创建一个能够用不同方式来编码的通用字符集。注意这里的关键词：“不同方式”与“通用”。',normalizedContent:'# 字符集 & 编码\n\n\n\n\n\n\n# ascii\n\nascii 是 ansi 的一部分，仅使用 0x00 ~ 0x7f，是目前最普及的一种字符编码，它扎根于我们的互联网，操作系统，键盘，打印机，文件字体和打印机等。\n\n\n# ansi\n\nansi是一种字符编码方式，为使计算机支持更多语言，通常使用 0x00~0x7f 范围的1 个字节来表示 1 个英文字符。超出此范围的使用0x80~0xffff来编码，即扩展的ascii编码。\n\n注意 code page 的使用。code page 主要用于解决 字节与字符的快速对照，也就是直接将 字节与某种字符集的字符编码 之间相互映射。\n\n其中常见的字符集，如gb2312、gbk、gb18030、big5、shift_jis 等都属于此编码方式。\n\n\n# 中文\n\n# gb2312\n\ngb2312 或 gb2312-80 是中国国家标准简体中文字符集, 由中国国家标准总局发布, 1981 年 5 月 1 日实施。\n\ngb2312 对任意一个图形字符都采用两个字节表示，并对所收汉字进行了"分区"处理，每区含有 94 个汉字/符号，分别对应第一字节和第二字节。这种表示方式也称为区位码:\n\n * 01-09 区为特殊符号\n * 16-55 区为一级汉字，按拼音排序\n * 56-87 区为二级汉字，按部首/笔画排序\n * 10-15 区及 88-94 区则未有编码\n\ngb 2312 的编码范围为(分别为首字节、尾字节): 0x21h ~ 0x77, 0x21 ~ 0x7eh。这与 ascii 有重叠，通行方法是将 gb 码两个字节的最高位置 1 以示区别，所以最终的编码范围为: 0xa1 ~ 0xf7, 0xa1 ~ 0xfe。\n\n# gbk\n\ngbk 即汉字内码扩展规范，k 为汉语拼音 kuo zhan（扩展）中"扩"字的声母。英文全称 chinese internal code specification。\n\ngbk 向下与 gb 2312 完全兼容，向上支持 iso 10646 国际标准，在前者向后者过渡过程中起到的承上启下的作用。\n\ngbk 采用双字节表示，总体编码范围为(分别为首字节、尾字节): 0x81 ~ 0xfe, 0x40 ~ 0xfe，剔除 xx7f 一条线。\n\n# gb18030\n\ngb18030 与 gb2312 和 gbk 兼容，共收录汉字70244个。gb18030 编码是一二四字节变长编码:\n\n * 单字节，其值从 0 到 0x7f，与 ascii 编码兼容\n * 双字节，第一个字节的值从 0x81 ~ 0xfe，第二个字节的值从 0x40 ~ 0xfe(不包括0x7f)，与 gbk 标准兼容\n * 四字节，第一个字节的值从 0x81 ~ 0xfe，第二个字节的值从 0x30 ~ 0x39，第三个字节从0x81 ~ 0xfe，第四个字节从 0x30 ~ 0x39\n\n\n# unicode\n\n其中 utf8 和 utf16 都是变长编码，只不过 utf16 可以完整的表达 bmp (基础平面) 中的所有字符，所以一般都认为其固定为 2bytes(这个美丽的错误源自 windows 的 unicode 定义, 它其实是 ucs-2)。\n\nutf16 和 utf32 则因为 byte-order 问题，必定需要在文档开头通过 bom 头指明字节序。utf8 按照设计原理来看，是没有 byte-order 问题的，不过微软还是给其定义了 bom 头。\n\n\n# coding-model\n\n统一码(unicode)和通用字符集(ucs)所描述的编码系统，提出了全新的编码思路，它将字符集与字符编码的概念更为细致地分解为了以下几个方面：\n\n 1. 有哪些字符；\n 2. 这些字符的编号是什么；\n 3. 这些编号如何编码成一系列逻辑层面有限大小的数字，即码元序列；\n 4. 这些逻辑层面的码元序列如何转换为(即映射为)物理层面的字节序列(即字节流)；\n 5. 在某些特殊的传输环境中(比如email中)，再进一步将字节序列进行适应性编码处理。\n\n这几个方面作为一个整体，构成了现代字符编码模型。现代字符编码模型之所以要分解为这么几个方面，其核心思想是创建一个能够用不同方式来编码的通用字符集。注意这里的关键词：“不同方式”与“通用”。',charsets:{cjk:!0}},{title:"Programing for Children",frontmatter:{title:"Programing for Children",date:"2022-03-05T14:11:00.000Z",lastmod:null,publish:!0,categories:null,keywords:null,description:null,tags:null,permalink:null},regularPath:"/blog/skills/utils/child_program.html",relativePath:"blog/skills/utils/child_program.md",key:"v-dde8b282",path:"/blog/skills/utils/child_program.html",headers:[{level:2,title:"Content",slug:"content",normalizedTitle:"content",charIndex:24},{level:3,title:"Learn the fundamentals with the self-paced courses",slug:"learn-the-fundamentals-with-the-self-paced-courses",normalizedTitle:"learn the fundamentals with the self-paced courses",charIndex:36},{level:3,title:"Teacher View",slug:"teacher-view",normalizedTitle:"teacher view",charIndex:117},{level:3,title:"Computer Science Discoveries ('21-'22)",slug:"computer-science-discoveries-21-22",normalizedTitle:"computer science discoveries ('21-'22)",charIndex:166},{level:2,title:"Pre-reader Express (2021)",slug:"pre-reader-express-2021",normalizedTitle:"pre-reader express (2021)",charIndex:334},{level:2,title:"Computer Science Fundamentals",slug:"computer-science-fundamentals",normalizedTitle:"computer science fundamentals",charIndex:1517},{level:3,title:"Course A (2021)",slug:"course-a-2021",normalizedTitle:"course a (2021)",charIndex:1551},{level:3,title:"Course B (2021)",slug:"course-b-2021",normalizedTitle:"course b (2021)",charIndex:1620},{level:3,title:"Course C (2021)",slug:"course-c-2021",normalizedTitle:"course c (2021)",charIndex:1680},{level:3,title:"Course D (2021)",slug:"course-d-2021",normalizedTitle:"course d (2021)",charIndex:1740},{level:3,title:"Course E (2021)",slug:"course-e-2021",normalizedTitle:"course e (2021)",charIndex:1800},{level:3,title:"Course F (2021)",slug:"course-f-2021",normalizedTitle:"course f (2021)",charIndex:1860}],headersStr:"Content Learn the fundamentals with the self-paced courses Teacher View Computer Science Discoveries ('21-'22) Pre-reader Express (2021) Computer Science Fundamentals Course A (2021) Course B (2021) Course C (2021) Course D (2021) Course E (2021) Course F (2021)",content:"# 少儿编程\n\n\n# code.org\n\n\n# Content\n\n\n# Learn the fundamentals with the self-paced courses\n\nComputer Science at Home\n\n\n# Teacher View\n\nYou can teach computer science\n\n\n# Computer Science Discoveries ('21-'22)\n\nhttps://studio.code.org/s/csd1-2021 https://docs.google.com/document/d/1myJwrDyRlAjwVNDS3gs-3JaJNhogsGMt9Swo-bpySgE/preview\n\n\n# Pre-reader Express (2021)\n\nINDEX   CATEGORY     LESSON NAME                     PROGRESS   KEY POINT                NOTE\n1       Sequencing   Learn to Drag and Drop          1 - 12                              \n2       Sequencing   Sequencing with Scrat           1 - 7                               \n3       Sequencing   Programming with Angry Birds    1 - 9      循环(Repeat) && 单步(Step)   尝试所有能想到的方法\n4       Sequencing   Programming with Rey and BB-8   1 - 12     序列(Sequence)             最优方法(block 最少)\n5       Sequencing   Programming with Harvester      1 - 15     Pick && Debug            \n6       Loops        Loops with Scrat                1 - 12                              Instructions 中的条件\n7       Loops        Loops with Laurel               1 - 13     Get && Goal              按条件得分高\n8       Loops        Ocean Scene with Loops          1 - 14     Draw && Jump             Artist，想象\n9       Loops        Drawing Gardens with Loops      1 - 9      Pattern && Color         \n10      Events       On the Move with Events         1- 8       When && Set && Show      Actions\n11      Events       A Royal Battle with Events      1 - 7      When                     复杂的游戏\n\n\n# Computer Science Fundamentals\n\n\n# Course A (2021)\n\nGrade level: Kindergarten Number of lessons: 13\n\n\n# Course B (2021)\n\nGrade level: 1st Number of lessons: 13\n\n\n# Course C (2021)\n\nGrade level: 2nd Number of lessons: 16\n\n\n# Course D (2021)\n\nGrade level: 3rd Number of lessons: 17\n\n\n# Course E (2021)\n\nGrade level: 4th Number of lessons: 18\n\n\n# Course F (2021)\n\nGrade level: 5th Number of lessons: 20",normalizedContent:"# 少儿编程\n\n\n# code.org\n\n\n# content\n\n\n# learn the fundamentals with the self-paced courses\n\ncomputer science at home\n\n\n# teacher view\n\nyou can teach computer science\n\n\n# computer science discoveries ('21-'22)\n\nhttps://studio.code.org/s/csd1-2021 https://docs.google.com/document/d/1myjwrdyrlajwvnds3gs-3jajnhogsgmt9swo-bpysge/preview\n\n\n# pre-reader express (2021)\n\nindex   category     lesson name                     progress   key point                note\n1       sequencing   learn to drag and drop          1 - 12                              \n2       sequencing   sequencing with scrat           1 - 7                               \n3       sequencing   programming with angry birds    1 - 9      循环(repeat) && 单步(step)   尝试所有能想到的方法\n4       sequencing   programming with rey and bb-8   1 - 12     序列(sequence)             最优方法(block 最少)\n5       sequencing   programming with harvester      1 - 15     pick && debug            \n6       loops        loops with scrat                1 - 12                              instructions 中的条件\n7       loops        loops with laurel               1 - 13     get && goal              按条件得分高\n8       loops        ocean scene with loops          1 - 14     draw && jump             artist，想象\n9       loops        drawing gardens with loops      1 - 9      pattern && color         \n10      events       on the move with events         1- 8       when && set && show      actions\n11      events       a royal battle with events      1 - 7      when                     复杂的游戏\n\n\n# computer science fundamentals\n\n\n# course a (2021)\n\ngrade level: kindergarten number of lessons: 13\n\n\n# course b (2021)\n\ngrade level: 1st number of lessons: 13\n\n\n# course c (2021)\n\ngrade level: 2nd number of lessons: 16\n\n\n# course d (2021)\n\ngrade level: 3rd number of lessons: 17\n\n\n# course e (2021)\n\ngrade level: 4th number of lessons: 18\n\n\n# course f (2021)\n\ngrade level: 5th number of lessons: 20",charsets:{cjk:!0}},{title:"Windows Wallpapers",frontmatter:{title:"Windows Wallpapers",date:"2022-03-10T00:00:00.000Z",lastmod:null,publish:!0,categories:null,keywords:null,description:null,tags:null,permalink:null},regularPath:"/blog/skills/utils/windows_wallpapers.html",relativePath:"blog/skills/utils/windows_wallpapers.md",key:"v-6cc2a996",path:"/blog/skills/utils/windows_wallpapers.html",headers:[{level:2,title:"Windows 聚焦",slug:"windows-聚焦",normalizedTitle:"windows 聚焦",charIndex:25},{level:2,title:"锁屏壁纸",slug:"锁屏壁纸",normalizedTitle:"锁屏壁纸",charIndex:125}],headersStr:"Windows 聚焦 锁屏壁纸",content:'# Windows Wallpapers\n\n\n# Windows 聚焦\n\nWindows 聚焦是一个锁屏界面背景选项，可在锁屏界面上显示不同的背景图像并且有时提供建议。 Windows 聚焦在所有桌面版本的 Windows 10 中都可用。\n\n\n# 锁屏壁纸\n\n在使用 Windows 10 的时候，我们发现 Windows 10 的锁屏壁纸是会不断自动更换的，而且质量都非常高，网罗了全球各地的风景。\n\n之所以如此，是因为 Windows 10 锁屏被设置为了 "Windows 10聚焦"。聚焦会自动从网络上下载富有美感的锁屏壁纸，每日都会更换。\n\n然而，当你看到某张壁纸特别喜欢，想要收藏以后常用时，发现微软默认并未提供这一功能，也就是说这些壁纸默认并不能下载到本地，你只能在这张壁纸轮值的当天看到它。\n\n不过，Windows 10聚焦的锁屏图片虽然不能被用户直接下载，但其实系统会将它下载缓存在本地目录中(需要手动增加 JPG 或 JPEG 后缀)： C:\\Users\\用户名\\AppData\\Local\\Packages\\Microsoft.Windows.ContentDeliveryManager_cw5n1h2txyewy\\LocalState\\Assets',normalizedContent:'# windows wallpapers\n\n\n# windows 聚焦\n\nwindows 聚焦是一个锁屏界面背景选项，可在锁屏界面上显示不同的背景图像并且有时提供建议。 windows 聚焦在所有桌面版本的 windows 10 中都可用。\n\n\n# 锁屏壁纸\n\n在使用 windows 10 的时候，我们发现 windows 10 的锁屏壁纸是会不断自动更换的，而且质量都非常高，网罗了全球各地的风景。\n\n之所以如此，是因为 windows 10 锁屏被设置为了 "windows 10聚焦"。聚焦会自动从网络上下载富有美感的锁屏壁纸，每日都会更换。\n\n然而，当你看到某张壁纸特别喜欢，想要收藏以后常用时，发现微软默认并未提供这一功能，也就是说这些壁纸默认并不能下载到本地，你只能在这张壁纸轮值的当天看到它。\n\n不过，windows 10聚焦的锁屏图片虽然不能被用户直接下载，但其实系统会将它下载缓存在本地目录中(需要手动增加 jpg 或 jpeg 后缀)： c:\\users\\用户名\\appdata\\local\\packages\\microsoft.windows.contentdeliverymanager_cw5n1h2txyewy\\localstate\\assets',charsets:{cjk:!0}},{title:"utilization",frontmatter:{published:!0,title:"utilization",description:"jiao's blog",keywords:[null],categories:["utilization","devops"],permalink:"/blog/utilization/",date:"2020-04-13T00:00:00.000Z",tags:[null]},regularPath:"/blog/utilization/",relativePath:"blog/utilization/README.md",key:"v-5f9b1d8c",path:"/blog/utilization/",headersStr:null,content:"# UTILIZATION\n\n * 实践：K8S 之 Downward Api\n * 实践：创建Redis Cluster\n * 反编译Apk\n * 实践：Dind\n * 实践：Consul 部署\n * 实践：批量拉取Git项目脚本\n * 汉字字符编码及转换",normalizedContent:"# utilization\n\n * 实践：k8s 之 downward api\n * 实践：创建redis cluster\n * 反编译apk\n * 实践：dind\n * 实践：consul 部署\n * 实践：批量拉取git项目脚本\n * 汉字字符编码及转换",charsets:{cjk:!0}},{title:"汉字字符编码及转换",frontmatter:{title:"汉字字符编码及转换",date:"2020-04-13T00:00:00.000Z",description:"中文字符编码实现方案",permalink:null,categories:["blog","utilization"],tags:[null]},regularPath:"/blog/utilization/ch_pinyin_tran.html",relativePath:"blog/utilization/ch_pinyin_tran.md",key:"v-0dc92f7f",path:"/blog/utilization/ch_pinyin_tran.html",headers:[{level:2,title:"汉字转拼音",slug:"汉字转拼音",normalizedTitle:"汉字转拼音",charIndex:42},{level:3,title:"Unicode 字符平面",slug:"unicode-字符平面",normalizedTitle:"unicode 字符平面",charIndex:192},{level:3,title:"GB2312、GBK、GB18030",slug:"gb2312、gbk、gb18030",normalizedTitle:"gb2312、gbk、gb18030",charIndex:575},{level:3,title:"Reference",slug:"reference",normalizedTitle:"reference",charIndex:1582}],headersStr:"汉字转拼音 Unicode 字符平面 GB2312、GBK、GB18030 Reference",content:"# 汉字字符编码及转换\n\n> Date: 2020-04-16 16:16\n\n\n# 汉字转拼音\n\n基本思路就是从 unicode.org 获取到字符码以及对应的拼音Unihan.zip，然后再通过脚本解析成需要的格式，并输出为 dictionary。 (其中，Unihan.zip 内容说明见：reports/tr38)\n\n在使用时，将输入字符串解析成单个的汉字，去查字典。\n\n\n# Unicode 字符平面\n\n当前的 Unicode 字符分为17组编排，每组称为平面（Plane），而每平面拥有65536（即216）个代码点。然而当前只用了少数平面\n\nunicode 编码采用了 2bytes 进行表达。表达方式为：[0 - 0x10][0 ~ 0xFFFF], 第一部分为平面id，第二部分就是字符值。\n\n其中，常见的有：\n\n * 0号平面，基本多文种平面，Basic Multilingual Plane，简称 BMP\n * 1号平面，多文种补充平面，Supplementary Multilingual Plane，简称 SMP\n * 15号平面，保留作为私人使用区（A区），Private Use Area-A，简称 PUA-A\n * 16号平面，保留作为私人使用区（B区），Private Use Area-B，简称 PUA-B\n\n\n# GB2312、GBK、GB18030\n\n借着这个机会，又重新学习了下 GB2312、GBK、GB18030 这几种汉字编码的历史。\n\n 1. GB2312 或 (GB2312-80) 是中国国家标准简体中文字符集，全称《信息交换用汉字编码字符集·基本集》，又称 GB 0，由中国国家标准总局发布，1981 年 5 月 1 日实施.\n\n它采用两个字节表示一个字符，同时兼容了 ASCII。为了兼容 ASCII，它规定，一个小于127的字符的意义与原来相同，但当两个大于127的字符连在一起时，就表示一个汉字。就是说，对于每个字节只使用大于 127 的值用于编码。\n\nGB2312 共收录 6763 个汉字，另外还收录了包括拉丁字母、希腊字母、日文平假名及片假名字母、俄语西里尔字母等在内的 682 个字符。\n\nGB2312 基本满足了汉字的计算机处理需要，它覆盖了中国 99.75% 的使用频率。但是却对于人名、古汉语等方面出现的罕用字无能为力，这导致了后来 GBK 及 GB 18030 汉字字符集的出现。\n\n 2. GBK GBK 即汉字内码扩展规范，K 为汉语拼音 Kuo Zhan（扩展）中“扩”字的声母。英文全称 Chinese Internal Code Specification。\n\nGBK 共收入 21886 个汉字和图形符号，GBK 向下与 GB 2312 完全兼容。\n\nGBK 采用双字节表示，总体编码范围为 8140-FEFE 之间，首字节在 81-FE 之间，尾字节在 40-FE 之间，剔除 XX7F 一条线。\n\n 3. GB18030 全称是：国家标准 GB18030-2005，是目前中国最新的字符集，是 GB18030-2000 的修订版。GB18030 完全兼容 GBK，共收录汉字70244个。\n\n与 UTF-8 相同，GB18030 采用多字节编码，采用 1、2、4 字节变长编码。\n\n * 单字节，其值从 0 到 0x7F，与 ASCII 编码兼容。\n * 双字节，第一个字节的值从 0x81 到 0xFE，第二个字节的值从 0x40 到 0xFE(不含0x7F)，以与 GBK 标准兼容。\n * 四字节，第一个字节的值从 0x81 到 0xFE，第二个字节的值从 0x30 到 0x39，第三个字节从0x81 到 0xFE，第四个字节从 0x30 到 0x39。\n\n\n# Reference\n\n * go 语言的 汉字转拼音 实现：go-pinyin\n   * 依赖库：pinyin-data",normalizedContent:"# 汉字字符编码及转换\n\n> date: 2020-04-16 16:16\n\n\n# 汉字转拼音\n\n基本思路就是从 unicode.org 获取到字符码以及对应的拼音unihan.zip，然后再通过脚本解析成需要的格式，并输出为 dictionary。 (其中，unihan.zip 内容说明见：reports/tr38)\n\n在使用时，将输入字符串解析成单个的汉字，去查字典。\n\n\n# unicode 字符平面\n\n当前的 unicode 字符分为17组编排，每组称为平面（plane），而每平面拥有65536（即216）个代码点。然而当前只用了少数平面\n\nunicode 编码采用了 2bytes 进行表达。表达方式为：[0 - 0x10][0 ~ 0xffff], 第一部分为平面id，第二部分就是字符值。\n\n其中，常见的有：\n\n * 0号平面，基本多文种平面，basic multilingual plane，简称 bmp\n * 1号平面，多文种补充平面，supplementary multilingual plane，简称 smp\n * 15号平面，保留作为私人使用区（a区），private use area-a，简称 pua-a\n * 16号平面，保留作为私人使用区（b区），private use area-b，简称 pua-b\n\n\n# gb2312、gbk、gb18030\n\n借着这个机会，又重新学习了下 gb2312、gbk、gb18030 这几种汉字编码的历史。\n\n 1. gb2312 或 (gb2312-80) 是中国国家标准简体中文字符集，全称《信息交换用汉字编码字符集·基本集》，又称 gb 0，由中国国家标准总局发布，1981 年 5 月 1 日实施.\n\n它采用两个字节表示一个字符，同时兼容了 ascii。为了兼容 ascii，它规定，一个小于127的字符的意义与原来相同，但当两个大于127的字符连在一起时，就表示一个汉字。就是说，对于每个字节只使用大于 127 的值用于编码。\n\ngb2312 共收录 6763 个汉字，另外还收录了包括拉丁字母、希腊字母、日文平假名及片假名字母、俄语西里尔字母等在内的 682 个字符。\n\ngb2312 基本满足了汉字的计算机处理需要，它覆盖了中国 99.75% 的使用频率。但是却对于人名、古汉语等方面出现的罕用字无能为力，这导致了后来 gbk 及 gb 18030 汉字字符集的出现。\n\n 2. gbk gbk 即汉字内码扩展规范，k 为汉语拼音 kuo zhan（扩展）中“扩”字的声母。英文全称 chinese internal code specification。\n\ngbk 共收入 21886 个汉字和图形符号，gbk 向下与 gb 2312 完全兼容。\n\ngbk 采用双字节表示，总体编码范围为 8140-fefe 之间，首字节在 81-fe 之间，尾字节在 40-fe 之间，剔除 xx7f 一条线。\n\n 3. gb18030 全称是：国家标准 gb18030-2005，是目前中国最新的字符集，是 gb18030-2000 的修订版。gb18030 完全兼容 gbk，共收录汉字70244个。\n\n与 utf-8 相同，gb18030 采用多字节编码，采用 1、2、4 字节变长编码。\n\n * 单字节，其值从 0 到 0x7f，与 ascii 编码兼容。\n * 双字节，第一个字节的值从 0x81 到 0xfe，第二个字节的值从 0x40 到 0xfe(不含0x7f)，以与 gbk 标准兼容。\n * 四字节，第一个字节的值从 0x81 到 0xfe，第二个字节的值从 0x30 到 0x39，第三个字节从0x81 到 0xfe，第四个字节从 0x30 到 0x39。\n\n\n# reference\n\n * go 语言的 汉字转拼音 实现：go-pinyin\n   * 依赖库：pinyin-data",charsets:{cjk:!0}},{title:"反编译apk",frontmatter:{title:"反编译apk",date:"2020-06-23T00:00:00.000Z",description:"反编译apk",categories:["blog"],tags:[null],permalink:null},regularPath:"/blog/utilization/foo_apk_reverse.html",relativePath:"blog/utilization/foo_apk_reverse.md",key:"v-25c8ca33",path:"/blog/utilization/foo_apk_reverse.html",headers:[{level:2,title:"反编译包",slug:"反编译包",normalizedTitle:"反编译包",charIndex:13},{level:2,title:"反编译dex",slug:"反编译dex",normalizedTitle:"反编译dex",charIndex:174},{level:2,title:"自由世界",slug:"自由世界",normalizedTitle:"自由世界",charIndex:259},{level:2,title:"重新打包",slug:"重新打包",normalizedTitle:"重新打包",charIndex:296},{level:2,title:"重新签名",slug:"重新签名",normalizedTitle:"重新签名",charIndex:336}],headersStr:"反编译包 反编译dex 自由世界 重新打包 重新签名",content:"# 反编译apk\n\n\n# 反编译包\n\n    apktool d -f [待反编译的apk] -o [反编译之后存放文件夹] \n    说明：\n        -s 参数可以指明跳过 dex 转成 smali 的步骤; \n           不带此参数时，生成的是 smali 文件集合, 带上时生成 dex 文件\n\n\n1\n2\n3\n4\n\n\n\n# 反编译dex\n\n    dex2jar-2.0 [dex文件] \n    说明：\n        生成jar文件，可以使用 jd-gui 打开\n\n\n1\n2\n3\n\n\n\n# 自由世界\n\n    jd-gui 打开 jar 文件 \n\n\n1\n\n\n\n# 重新打包\n\n    apktool.bat b [文件夹] \n\n\n1\n\n\n\n# 重新签名\n\n    java -jar signapk.jar testkey.x509.pem testkey.pk8 test.zip test_signed.zip \n\n\n1\n",normalizedContent:"# 反编译apk\n\n\n# 反编译包\n\n    apktool d -f [待反编译的apk] -o [反编译之后存放文件夹] \n    说明：\n        -s 参数可以指明跳过 dex 转成 smali 的步骤; \n           不带此参数时，生成的是 smali 文件集合, 带上时生成 dex 文件\n\n\n1\n2\n3\n4\n\n\n\n# 反编译dex\n\n    dex2jar-2.0 [dex文件] \n    说明：\n        生成jar文件，可以使用 jd-gui 打开\n\n\n1\n2\n3\n\n\n\n# 自由世界\n\n    jd-gui 打开 jar 文件 \n\n\n1\n\n\n\n# 重新打包\n\n    apktool.bat b [文件夹] \n\n\n1\n\n\n\n# 重新签名\n\n    java -jar signapk.jar testkey.x509.pem testkey.pk8 test.zip test_signed.zip \n\n\n1\n",charsets:{cjk:!0}},{title:"实践：批量拉取git项目脚本",frontmatter:{title:"实践：批量拉取git项目脚本",date:"2021-01-21T00:00:00.000Z",description:"实践：批量拉取git项目脚本",permalink:null,categories:["blog","utilization"],tags:[null]},regularPath:"/blog/utilization/foo_batch_pulls.html",relativePath:"blog/utilization/foo_batch_pulls.md",key:"v-0b34dfc2",path:"/blog/utilization/foo_batch_pulls.html",headersStr:null,content:'# 实践：批量拉取git项目脚本\n\n> repo.sh\n\n#! /bin/bash\n#\n# repo.sh\n#\n# Distributed under terms of the MIT license.\n#\n\n# 结构\n#   project \n#   dirname project project project\n\n#!/bin/bash\nset -xu \n\npwd= `cd $(dir $0);pwd`\nstamp=`date +"%Y%m%d%H%M%S"`\n\ncat > dirs.dat <<EOF\n    common\n    vendor\n    samples\n    tools\n    config\n    docs\n    monitor svcwatcher svcmonitor\nEOF\n\ncase $1 in\n"clone")\n# git clone http 时账号里的 @ 需要替换成 %40, 不然就会把后续识别为url\ncat dirs.dat | awk \'{clone="git clone http://{user}:{pass}@gitlab.xxxxxx.com/repository/";if(NF>1){cmd="mkdir -p "$1"";system(cmd);for(i=2;i<=NF;i++){cmd=clone$1"/"$i".git ./"$1"/"$i;print(cmd);system(cmd);}}else{cmd=clone$1".git";print(cmd);system(cmd);}}\';\n;;\n"update")\necho "=> cmd $1 is valid"\ncat dirs.dat | awk \'{update="; git pull;";if(NF>1){for(i=2;i<=NF;i++){cmd="cd "$1"/"$i update"cd ..";print(cmd);system(cmd);}}else{cmd="cd "$1 update" cd ..";print(cmd);system(cmd);}}\';\n;;\n*)\necho "=> cmd $1 is invalid"\n;;\nesac\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n',normalizedContent:'# 实践：批量拉取git项目脚本\n\n> repo.sh\n\n#! /bin/bash\n#\n# repo.sh\n#\n# distributed under terms of the mit license.\n#\n\n# 结构\n#   project \n#   dirname project project project\n\n#!/bin/bash\nset -xu \n\npwd= `cd $(dir $0);pwd`\nstamp=`date +"%y%m%d%h%m%s"`\n\ncat > dirs.dat <<eof\n    common\n    vendor\n    samples\n    tools\n    config\n    docs\n    monitor svcwatcher svcmonitor\neof\n\ncase $1 in\n"clone")\n# git clone http 时账号里的 @ 需要替换成 %40, 不然就会把后续识别为url\ncat dirs.dat | awk \'{clone="git clone http://{user}:{pass}@gitlab.xxxxxx.com/repository/";if(nf>1){cmd="mkdir -p "$1"";system(cmd);for(i=2;i<=nf;i++){cmd=clone$1"/"$i".git ./"$1"/"$i;print(cmd);system(cmd);}}else{cmd=clone$1".git";print(cmd);system(cmd);}}\';\n;;\n"update")\necho "=> cmd $1 is valid"\ncat dirs.dat | awk \'{update="; git pull;";if(nf>1){for(i=2;i<=nf;i++){cmd="cd "$1"/"$i update"cd ..";print(cmd);system(cmd);}}else{cmd="cd "$1 update" cd ..";print(cmd);system(cmd);}}\';\n;;\n*)\necho "=> cmd $1 is invalid"\n;;\nesac\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n',charsets:{cjk:!0}},{title:"实践：consul 部署",frontmatter:{title:"实践：consul 部署",date:"2020-04-13T00:00:00.000Z",description:"实践：consul 部署",permalink:null,categories:["blog","utilization"],tags:[null]},regularPath:"/blog/utilization/foo_consul.html",relativePath:"blog/utilization/foo_consul.md",key:"v-9af6bf82",path:"/blog/utilization/foo_consul.html",headers:[{level:2,title:"部署",slug:"部署",normalizedTitle:"部署",charIndex:12},{level:2,title:"consul 功能",slug:"consul-功能",normalizedTitle:"consul 功能",charIndex:1329},{level:3,title:"功能概述",slug:"功能概述",normalizedTitle:"功能概述",charIndex:1343},{level:3,title:"理解",slug:"理解",normalizedTitle:"理解",charIndex:2571},{level:2,title:"agent: client & server",slug:"agent-client-server",normalizedTitle:"agent: client &amp; server",charIndex:null},{level:3,title:"agent (client)",slug:"agent-client",normalizedTitle:"agent (client)",charIndex:3156},{level:3,title:"agent -server",slug:"agent-server",normalizedTitle:"agent -server",charIndex:3219},{level:3,title:"Appendix",slug:"appendix",normalizedTitle:"appendix",charIndex:5042}],headersStr:"部署 consul 功能 功能概述 理解 agent: client & server agent (client) agent -server Appendix",content:'# 实践：consul 部署\n\n\n# 部署\n\n * dockerfile\n   * \'docker-compose.yml\'\n * 命令\n   \n   运行集群：docker-compose up -d \n   启动集群：docker-compose start\n   停止集群：docker-compose stop\n   清理集群：docker-compose down \n   查看集群：docker-compose ps\n   查看容器ip：\n       sudo docker ps | grep consul | awk \'{print($NF)}\' | xargs -t -I {} sudo docker inspect --format \'{{with index .NetworkSettings.Networks "consul_consul-demo" }}{{.IPAddress}}{{end}}\' {}\n   \n       sudo docker ps | grep consul | awk \'{print($NF)}\' | xargs -t -I {} sudo docker inspect --format \'{{ $network := index .NetworkSettings.Networks "consul_consul-demo" }}{{ $network.IPAddress}}\' {}\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   \n * consul 常用配置\n   \n       -server ： 定义agent运行在server模式\n       -bootstrap-expect ：在一个datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定sever数目的候才会引导整个集群，该标记不能和bootstrap共用\n       -bind：该地址用来在集群内部的通讯，集群内的所有节点到地址都必须是可达的，默认是0.0.0.0\n       -node：节点在集群中的名称，在一个集群中必须是唯一的，默认是该节点的主机名\n       -ui-dir： 提供存放web ui资源的路径，该目录必须是可读的\n       -rejoin：使consul忽略先前的离开，在再次启动后仍旧尝试加入集群中。\n       -config-dir：：配置文件目录，里面所有以.json结尾的文件都会被加载\n       -client：consul服务侦听地址，这个地址提供HTTP、DNS、RPC等服务，默认是127.0.0.1所以不对外提供服务，如果你要对外提供服务改成0.0.0.0\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   \n * web页面\n   * localhost:8500\n * 注意\n   * k8s部署时，应当部署 server 为 stateful，client 为 daemonset\n\n\n# consul 功能\n\n\n# 功能概述\n\n * 查询\n   * 一般情况下所有 agent 收到的查询以及修改请求，都会转发到 leader。但可以通过配置一致性策略，使得 server 即可响应查询，不必到转达 leader。\n   * 相关描述：\n     * reference: internals/consensus\n     \n         When an RPC request arrives at a non-leader server, the request is forwarded to the leader. If the RPC is a query type, meaning it is read-only, the leader generates the result based on the current state of the FSM. If the RPC is a transaction type, meaning it modifies state, the leader generates a new log entry and applies it using Raft.\n     \n     \n     1\n     \n   * 缓存\n     * agent 默认是支持缓存的，但需要请求时指定是否使用以及相应的策略\n     * 相关描述：\n       * reference: connect/index\n       \n           To enable microsecond-speed responses on agent Connect API endpoints, the Consul agent locally caches most Connect-related data and sets up background blocking queries against the server to update the cache in the background. \n       \n       \n       1\n       \n   * blocking query\n   * k8s/run\n * 注册(服务)\n   * 由用户向 agent (包含server、client) 发起注册请求，同时在这个 agent 上持久化这个注册信息，同时启动一个 goroutine 进行健康检查。并将，注册信息同步给所有 server 并由 server 进行持久化(这个过程涉及 server 之间信息一致性的处理)。同时，将健康检查的结果同步给 server 节点。 ？？？？ server 和 client 之间健康检查信息的同步过程 ？？？\n * 健康检查\n   * 由接收到用户发起的注册 agent 进行。间隔由注册时的健康检查相关参数指定，一般为 10s\n\n\n# 理解\n\n * 同为 agent，client 和 server 大部分功能都是一样的，除了由于 client 不参与_选举_ 以及 由之带来的一些不支持的行为：数据持久化\n * 为什么 agent 会有 server 和 client 之分：\n   * 当 server 数过多时，一致性的处理会占用大量资源，并且较慢的达到一致性。所以，server 一般为 3~5 个。\n   * 但是当用户的服务数量较大时，少量的 server 又会带来处理用户请求的性能问题，如：单个 server 能保持的连接数、server 的机器负载，.etc\n   * 所以需要具有 server 的大部分功能，但又不参与选举以及一致性维持的 agent，也就是：agent client\n     * agent client 也要把所有请求转发到 server 进行处理的，server 不是依然压力很大吗？\n       * 这里就要提到：agent 之间的通信是走 8300 端口，通过维持长连接(也有连接池)进行的，而用户请求 agent 一般是通过 http 请求。\n       * 最后就是 agent client 可以分散健康检查的压力，特别是在使用缓存的情况下，可以很大程度上减轻 server 压力。\n\n\n# agent: client & server\n\n\n# agent (client)\n\n客户端使用 "hashicorp/consul/api" 中提供的方式访问 agent or agent -server, 默认情况下是访问：http://127.0.0.1:8500\n\n在发起请求时，通过 QueryOptions.UseCache 参数来指定是否使用缓存，通过 consul/agent/cache:RegisterOptions.Refresh 指定刷新策略。 缓存特性详见:api/features/caching\n\n\n# agent -server\n\n使用 "github.com/mitchellh/cli"，使得 consul 的 agent 启动时可以处理的命令行集中在 "consul/command/commands_oss.go"。\n\n以 agent 为例，它的主要处理逻辑在："consul/command/agent", 此后关于 agent 的具体处理会转到 "consul/agent/agent.go" 进行处理。\n\nhttps://www.consul.io/docs/internals/anti-entropy.html#catalog catalog 是 consul 服务发现功能的基石 The catalog maintains the high-level view of the cluster, including which services are available, which nodes run those services, health information, and more.\n\nServices and checks within the context of the catalog have a much more limited set of fields when compared with the agent. This is because the catalog is only responsible for recording and returning information about services, nodes, and health.\n\nThe catalog is maintained only by server nodes. This is because the catalog is replicated via the Raft log to provide a consolidated and consistent view of the cluster.\n\nhttps://www.consul.io/docs/internals/anti-entropy.html#agent\n\nEach Consul agent maintains its own set of service and check registrations as well as health information. The agents are responsible for executing their own health checks and updating their local state.\n\nServices and checks within the context of an agent have a rich set of configuration options available. This is because the agent is responsible for generating information about its services and their health through the use of health checks.\n\nConsul has a clear separation between the global service catalog and the agent\'s local state as discussed above. The anti-entropy mechanism reconciles these two views of the world: anti-entropy is a synchronization of the local agent state and the catalog.\n\n\n# Appendix\n\n> docker-compose.yml\n\n# source: https://github.com/hashicorp/consul/blob/master/demo/docker-compose-cluster/docker-compose.yml\n\nversion: \'3\'\n\nservices:\n\n  consul-agent-1: &consul-agent\n    image: consul:latest\n    networks:\n      - consul-demo\n    command: "agent -retry-join consul-server-bootstrap -client 0.0.0.0"\n\n  consul-agent-2:\n    <<: *consul-agent\n\n  consul-agent-3:\n    <<: *consul-agent\n\n  consul-server-1: &consul-server\n    <<: *consul-agent\n    command: "agent -server -retry-join consul-server-bootstrap -client 0.0.0.0"\n\n  consul-server-2:\n    <<: *consul-server\n\n  consul-server-bootstrap:\n    <<: *consul-agent\n    ports:\n      - "8400:8400"\n      - "8500:8500"\n      - "8600:8600"\n      - "8600:8600/udp"\n    command: "agent -server -bootstrap-expect 3 -ui -client 0.0.0.0"\n\nnetworks:\n  consul-demo:\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n',normalizedContent:'# 实践：consul 部署\n\n\n# 部署\n\n * dockerfile\n   * \'docker-compose.yml\'\n * 命令\n   \n   运行集群：docker-compose up -d \n   启动集群：docker-compose start\n   停止集群：docker-compose stop\n   清理集群：docker-compose down \n   查看集群：docker-compose ps\n   查看容器ip：\n       sudo docker ps | grep consul | awk \'{print($nf)}\' | xargs -t -i {} sudo docker inspect --format \'{{with index .networksettings.networks "consul_consul-demo" }}{{.ipaddress}}{{end}}\' {}\n   \n       sudo docker ps | grep consul | awk \'{print($nf)}\' | xargs -t -i {} sudo docker inspect --format \'{{ $network := index .networksettings.networks "consul_consul-demo" }}{{ $network.ipaddress}}\' {}\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   \n * consul 常用配置\n   \n       -server ： 定义agent运行在server模式\n       -bootstrap-expect ：在一个datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定sever数目的候才会引导整个集群，该标记不能和bootstrap共用\n       -bind：该地址用来在集群内部的通讯，集群内的所有节点到地址都必须是可达的，默认是0.0.0.0\n       -node：节点在集群中的名称，在一个集群中必须是唯一的，默认是该节点的主机名\n       -ui-dir： 提供存放web ui资源的路径，该目录必须是可读的\n       -rejoin：使consul忽略先前的离开，在再次启动后仍旧尝试加入集群中。\n       -config-dir：：配置文件目录，里面所有以.json结尾的文件都会被加载\n       -client：consul服务侦听地址，这个地址提供http、dns、rpc等服务，默认是127.0.0.1所以不对外提供服务，如果你要对外提供服务改成0.0.0.0\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   \n * web页面\n   * localhost:8500\n * 注意\n   * k8s部署时，应当部署 server 为 stateful，client 为 daemonset\n\n\n# consul 功能\n\n\n# 功能概述\n\n * 查询\n   * 一般情况下所有 agent 收到的查询以及修改请求，都会转发到 leader。但可以通过配置一致性策略，使得 server 即可响应查询，不必到转达 leader。\n   * 相关描述：\n     * reference: internals/consensus\n     \n         when an rpc request arrives at a non-leader server, the request is forwarded to the leader. if the rpc is a query type, meaning it is read-only, the leader generates the result based on the current state of the fsm. if the rpc is a transaction type, meaning it modifies state, the leader generates a new log entry and applies it using raft.\n     \n     \n     1\n     \n   * 缓存\n     * agent 默认是支持缓存的，但需要请求时指定是否使用以及相应的策略\n     * 相关描述：\n       * reference: connect/index\n       \n           to enable microsecond-speed responses on agent connect api endpoints, the consul agent locally caches most connect-related data and sets up background blocking queries against the server to update the cache in the background. \n       \n       \n       1\n       \n   * blocking query\n   * k8s/run\n * 注册(服务)\n   * 由用户向 agent (包含server、client) 发起注册请求，同时在这个 agent 上持久化这个注册信息，同时启动一个 goroutine 进行健康检查。并将，注册信息同步给所有 server 并由 server 进行持久化(这个过程涉及 server 之间信息一致性的处理)。同时，将健康检查的结果同步给 server 节点。 ？？？？ server 和 client 之间健康检查信息的同步过程 ？？？\n * 健康检查\n   * 由接收到用户发起的注册 agent 进行。间隔由注册时的健康检查相关参数指定，一般为 10s\n\n\n# 理解\n\n * 同为 agent，client 和 server 大部分功能都是一样的，除了由于 client 不参与_选举_ 以及 由之带来的一些不支持的行为：数据持久化\n * 为什么 agent 会有 server 和 client 之分：\n   * 当 server 数过多时，一致性的处理会占用大量资源，并且较慢的达到一致性。所以，server 一般为 3~5 个。\n   * 但是当用户的服务数量较大时，少量的 server 又会带来处理用户请求的性能问题，如：单个 server 能保持的连接数、server 的机器负载，.etc\n   * 所以需要具有 server 的大部分功能，但又不参与选举以及一致性维持的 agent，也就是：agent client\n     * agent client 也要把所有请求转发到 server 进行处理的，server 不是依然压力很大吗？\n       * 这里就要提到：agent 之间的通信是走 8300 端口，通过维持长连接(也有连接池)进行的，而用户请求 agent 一般是通过 http 请求。\n       * 最后就是 agent client 可以分散健康检查的压力，特别是在使用缓存的情况下，可以很大程度上减轻 server 压力。\n\n\n# agent: client & server\n\n\n# agent (client)\n\n客户端使用 "hashicorp/consul/api" 中提供的方式访问 agent or agent -server, 默认情况下是访问：http://127.0.0.1:8500\n\n在发起请求时，通过 queryoptions.usecache 参数来指定是否使用缓存，通过 consul/agent/cache:registeroptions.refresh 指定刷新策略。 缓存特性详见:api/features/caching\n\n\n# agent -server\n\n使用 "github.com/mitchellh/cli"，使得 consul 的 agent 启动时可以处理的命令行集中在 "consul/command/commands_oss.go"。\n\n以 agent 为例，它的主要处理逻辑在："consul/command/agent", 此后关于 agent 的具体处理会转到 "consul/agent/agent.go" 进行处理。\n\nhttps://www.consul.io/docs/internals/anti-entropy.html#catalog catalog 是 consul 服务发现功能的基石 the catalog maintains the high-level view of the cluster, including which services are available, which nodes run those services, health information, and more.\n\nservices and checks within the context of the catalog have a much more limited set of fields when compared with the agent. this is because the catalog is only responsible for recording and returning information about services, nodes, and health.\n\nthe catalog is maintained only by server nodes. this is because the catalog is replicated via the raft log to provide a consolidated and consistent view of the cluster.\n\nhttps://www.consul.io/docs/internals/anti-entropy.html#agent\n\neach consul agent maintains its own set of service and check registrations as well as health information. the agents are responsible for executing their own health checks and updating their local state.\n\nservices and checks within the context of an agent have a rich set of configuration options available. this is because the agent is responsible for generating information about its services and their health through the use of health checks.\n\nconsul has a clear separation between the global service catalog and the agent\'s local state as discussed above. the anti-entropy mechanism reconciles these two views of the world: anti-entropy is a synchronization of the local agent state and the catalog.\n\n\n# appendix\n\n> docker-compose.yml\n\n# source: https://github.com/hashicorp/consul/blob/master/demo/docker-compose-cluster/docker-compose.yml\n\nversion: \'3\'\n\nservices:\n\n  consul-agent-1: &consul-agent\n    image: consul:latest\n    networks:\n      - consul-demo\n    command: "agent -retry-join consul-server-bootstrap -client 0.0.0.0"\n\n  consul-agent-2:\n    <<: *consul-agent\n\n  consul-agent-3:\n    <<: *consul-agent\n\n  consul-server-1: &consul-server\n    <<: *consul-agent\n    command: "agent -server -retry-join consul-server-bootstrap -client 0.0.0.0"\n\n  consul-server-2:\n    <<: *consul-server\n\n  consul-server-bootstrap:\n    <<: *consul-agent\n    ports:\n      - "8400:8400"\n      - "8500:8500"\n      - "8600:8600"\n      - "8600:8600/udp"\n    command: "agent -server -bootstrap-expect 3 -ui -client 0.0.0.0"\n\nnetworks:\n  consul-demo:\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n',charsets:{cjk:!0}},{title:"实践：DIND",frontmatter:{title:"实践：DIND",date:"2021-01-13T00:00:00.000Z",description:"实践：DIND",keywords:["dind","jenkins"],permalink:null,categories:["blog","utilization"],tags:[null]},regularPath:"/blog/utilization/foo_docker_jenkins_dind.html",relativePath:"blog/utilization/foo_docker_jenkins_dind.md",key:"v-ccf5212a",path:"/blog/utilization/foo_docker_jenkins_dind.html",headers:[{level:2,title:"registry",slug:"registry",normalizedTitle:"registry",charIndex:14},{level:2,title:"jenkins",slug:"jenkins",normalizedTitle:"jenkins",charIndex:291},{level:2,title:"Appendix: 相关文件",slug:"appendix-相关文件",normalizedTitle:"appendix: 相关文件",charIndex:1069}],headersStr:"registry jenkins Appendix: 相关文件",content:'# 实践：DIND\n\n\n# registry\n\n * run\n   * docker run -d -p 5000:5000 -v /tmp/registry:/registry --name registry registry\n * watch\n   * http://127.0.0.1:5000/v2/_catalog\n * test\n   * docker build -t localhost:5000/containersol/nodejs_app\n   * docker push localhost:5000/containersol/nodejs_app\n\n\n# jenkins\n\n * build\n   * docker build -t containersol/jenkins_with_docker -f dockerfile_jenkins .\n * run\n   * docker run -d -p 8081:8080 -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v $(pwd):/var/jenkins_data -v jenkins-stuff:/var/jenkins_home --name jenkins containersol/jenkins_with_docker\n   \n       -v /usr/lib64/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7\n       --user jenkins\n   \n   \n   1\n   2\n   \n * test\n   * docker exec -it --user jenkins [container_id] /bin/bash\n   * docker build -t localhost:5000/containersol/nodejs_app:v2 -f /var/jenkins_data/dockerfile_nodejs /var/jenkins_data\n * note\n   * 一定要保证：在 dockerfile_jenkins 中, RUN groupadd -g 980 docker, 时的 gid(980) 和 宿主机的docker组gid一致\n * watch\n   * http://127.0.0.1:8081\n\n\n# Appendix: 相关文件\n\n> app.js\n\n// Load the http module to create an http server.\nvar http = require(\'http\');\n\n// Configure our HTTP server to respond with Hello World to all requests.\nvar server = http.createServer(function (request, response) {\nresponse.writeHead(200, {"Content-Type": "text/plain"});\nresponse.end("Hello World\\n");\n});\n\n// Listen on port 8000, IP defaults to "0.0.0.0"\nserver.listen(8000);\n\n// Put a friendly message on the terminal\nconsole.log("Server running at http://127.0.0.1:8000/");\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n> build.sh\n\n#!/bin/bash\n\nif [ -z "${1}" ]; then\nversion="latest"\nelse\nversion="${1}"\nfi\n\ncd nodejs_app\ndocker build -t localhost:5000/containersol/nodejs_app:${version} .\ncd ..\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n> push.sh\n\n#!/bin/bash\n\nif [ -z "${1}" ]; then\nversion="latest"\nelse\nversion="${1}"\nfi\n\ndocker push localhost:5000/containersol/nodejs_app:"${version}"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n> start.sh\n\n#!/bin/bash\n\n# http://127.0.0.1:8000/\n\ndocker build -t my_nodejs_image .\ndocker run -p 8000:8000 my_nodejs_image\n\n\n1\n2\n3\n4\n5\n6\n\n\n> dockerfile_jenkins\n\nFROM jenkins\n\nMAINTAINER ContainerSolutions\n\nUSER root\n#TODO the group ID for docker group on my Ubuntu is 125, therefore I can only run docker commands if I have same group id inside. \n# Otherwise the socket file is not accessible.\nRUN groupadd -g 980 docker && usermod -a -G docker jenkins \nUSER jenkins\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n> dockerfile_nodejs\n\nFROM google/nodejs\n\nWORKDIR /app\nADD package.json /app/\nRUN npm install\nADD . /app\n\nEXPOSE 8000\nCMD []\nENTRYPOINT ["/nodejs/bin/npm", "start"]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n> package.json\n\n{\n    "name": "hello-world",\n    "description": "hello world",\n    "version": "0.0.1",\n    "private": true,\n    "dependencies": {\n        "express": "3.x"\n    },\n    "scripts": {"start": "node app.js"}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n',normalizedContent:'# 实践：dind\n\n\n# registry\n\n * run\n   * docker run -d -p 5000:5000 -v /tmp/registry:/registry --name registry registry\n * watch\n   * http://127.0.0.1:5000/v2/_catalog\n * test\n   * docker build -t localhost:5000/containersol/nodejs_app\n   * docker push localhost:5000/containersol/nodejs_app\n\n\n# jenkins\n\n * build\n   * docker build -t containersol/jenkins_with_docker -f dockerfile_jenkins .\n * run\n   * docker run -d -p 8081:8080 -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v $(pwd):/var/jenkins_data -v jenkins-stuff:/var/jenkins_home --name jenkins containersol/jenkins_with_docker\n   \n       -v /usr/lib64/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7\n       --user jenkins\n   \n   \n   1\n   2\n   \n * test\n   * docker exec -it --user jenkins [container_id] /bin/bash\n   * docker build -t localhost:5000/containersol/nodejs_app:v2 -f /var/jenkins_data/dockerfile_nodejs /var/jenkins_data\n * note\n   * 一定要保证：在 dockerfile_jenkins 中, run groupadd -g 980 docker, 时的 gid(980) 和 宿主机的docker组gid一致\n * watch\n   * http://127.0.0.1:8081\n\n\n# appendix: 相关文件\n\n> app.js\n\n// load the http module to create an http server.\nvar http = require(\'http\');\n\n// configure our http server to respond with hello world to all requests.\nvar server = http.createserver(function (request, response) {\nresponse.writehead(200, {"content-type": "text/plain"});\nresponse.end("hello world\\n");\n});\n\n// listen on port 8000, ip defaults to "0.0.0.0"\nserver.listen(8000);\n\n// put a friendly message on the terminal\nconsole.log("server running at http://127.0.0.1:8000/");\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n> build.sh\n\n#!/bin/bash\n\nif [ -z "${1}" ]; then\nversion="latest"\nelse\nversion="${1}"\nfi\n\ncd nodejs_app\ndocker build -t localhost:5000/containersol/nodejs_app:${version} .\ncd ..\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n> push.sh\n\n#!/bin/bash\n\nif [ -z "${1}" ]; then\nversion="latest"\nelse\nversion="${1}"\nfi\n\ndocker push localhost:5000/containersol/nodejs_app:"${version}"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n> start.sh\n\n#!/bin/bash\n\n# http://127.0.0.1:8000/\n\ndocker build -t my_nodejs_image .\ndocker run -p 8000:8000 my_nodejs_image\n\n\n1\n2\n3\n4\n5\n6\n\n\n> dockerfile_jenkins\n\nfrom jenkins\n\nmaintainer containersolutions\n\nuser root\n#todo the group id for docker group on my ubuntu is 125, therefore i can only run docker commands if i have same group id inside. \n# otherwise the socket file is not accessible.\nrun groupadd -g 980 docker && usermod -a -g docker jenkins \nuser jenkins\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n> dockerfile_nodejs\n\nfrom google/nodejs\n\nworkdir /app\nadd package.json /app/\nrun npm install\nadd . /app\n\nexpose 8000\ncmd []\nentrypoint ["/nodejs/bin/npm", "start"]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n> package.json\n\n{\n    "name": "hello-world",\n    "description": "hello world",\n    "version": "0.0.1",\n    "private": true,\n    "dependencies": {\n        "express": "3.x"\n    },\n    "scripts": {"start": "node app.js"}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n',charsets:{cjk:!0}},{title:"实践：k8s 之 downward api",frontmatter:{title:"实践：k8s 之 downward api",date:"2020-04-13T00:00:00.000Z",description:"k8s 之 downward api",permalink:null,categories:["blog","utilization"],tags:[null]},regularPath:"/blog/utilization/foo_k8s_downward_api.html",relativePath:"blog/utilization/foo_k8s_downward_api.md",key:"v-c6b25e82",path:"/blog/utilization/foo_k8s_downward_api.html",headersStr:null,content:'#\n\n * expose Pod and Container fields to a running Container\n   * docs: https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/#the-downward-api\n   * example:\n   \n     apiVersion: v1\n     kind: Pod\n     metadata:\n       name: test-host-ip\n     spec:\n       containers:\n         - name: test-host-ip\n           image: k8s.gcr.io/busybox\n           command: [ "sh", "-c"]\n           args:\n           - while true; do\n               echo -en \'\\n\';\n               printenv MY_NODE_NAME MY_POD_NAME MY_POD_NAMESPACE;\n               printenv MY_POD_IP MY_POD_SERVICE_ACCOUNT;\n               sleep 10;\n             done;\n           env:\n             - name: MY_NODE_IP\n               valueFrom:\n                 fieldRef:\n                   fieldPath: status.hostIP\n             - name: MY_NODE_NAME\n               valueFrom:\n                 fieldRef:\n                   fieldPath: spec.nodeName\n             - name: MY_POD_NAME\n               valueFrom:\n                 fieldRef:\n                   fieldPath: metadata.name\n             - name: MY_POD_NAMESPACE\n               valueFrom:\n                 fieldRef:\n                   fieldPath: metadata.namespace\n       restartPolicy: Never\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   19\n   20\n   21\n   22\n   23\n   24\n   25\n   26\n   27\n   28\n   29\n   30\n   31\n   32\n   33\n   34\n   ',normalizedContent:'#\n\n * expose pod and container fields to a running container\n   * docs: https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/#the-downward-api\n   * example:\n   \n     apiversion: v1\n     kind: pod\n     metadata:\n       name: test-host-ip\n     spec:\n       containers:\n         - name: test-host-ip\n           image: k8s.gcr.io/busybox\n           command: [ "sh", "-c"]\n           args:\n           - while true; do\n               echo -en \'\\n\';\n               printenv my_node_name my_pod_name my_pod_namespace;\n               printenv my_pod_ip my_pod_service_account;\n               sleep 10;\n             done;\n           env:\n             - name: my_node_ip\n               valuefrom:\n                 fieldref:\n                   fieldpath: status.hostip\n             - name: my_node_name\n               valuefrom:\n                 fieldref:\n                   fieldpath: spec.nodename\n             - name: my_pod_name\n               valuefrom:\n                 fieldref:\n                   fieldpath: metadata.name\n             - name: my_pod_namespace\n               valuefrom:\n                 fieldref:\n                   fieldpath: metadata.namespace\n       restartpolicy: never\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   19\n   20\n   21\n   22\n   23\n   24\n   25\n   26\n   27\n   28\n   29\n   30\n   31\n   32\n   33\n   34\n   ',charsets:{}},{title:"实践：创建redis cluster",frontmatter:{title:"实践：创建redis cluster",date:"2020-04-13T00:00:00.000Z",description:"实践：创建redis cluster",permalink:null,categories:["blog","utilization"],tags:[null]},regularPath:"/blog/utilization/foo_redis_cluster.html",relativePath:"blog/utilization/foo_redis_cluster.md",key:"v-019d6745",path:"/blog/utilization/foo_redis_cluster.html",headers:[{level:2,title:"创建redis cluster",slug:"创建redis-cluster",normalizedTitle:"创建redis cluster",charIndex:2},{level:3,title:"1、创建docker实例",slug:"_1、创建docker实例",normalizedTitle:"1、创建docker实例",charIndex:22},{level:3,title:"2、创建cluster",slug:"_2、创建cluster",normalizedTitle:"2、创建cluster",charIndex:363},{level:2,title:"测试",slug:"测试",normalizedTitle:"测试",charIndex:1448},{level:2,title:"数据迁移流程",slug:"数据迁移流程",normalizedTitle:"数据迁移流程",charIndex:1892},{level:2,title:"redis cluster",slug:"redis-cluster",normalizedTitle:"redis cluster",charIndex:4}],headersStr:"创建redis cluster 1、创建docker实例 2、创建cluster 测试 数据迁移流程 redis cluster",content:'# 创建redis cluster\n\n\n# 1、创建docker实例\n\n    docker run -d --net host --name myredis_a redis:5.0 redis-server --cluster-enabled yes --port 7000\n    docker run -d --net host --name myredis_b redis:5.0 redis-server --cluster-enabled yes --port 7001\n\n\n1\n2\n\n * 说明\n   * 需要使用 --net host\n     * 见 https://redis.io/topics/cluster-tutorial 中 "Redis Cluster and Docker" 的表述\n\n\n# 2、创建cluster\n\n * 结构\n   * myredis_a -- master\n   * myredis_b -- master\n   * myredis_c -- master\n   * myredis_d -- slave of myredis_c\n\n# A - 使用 redis-trib.rb 工具\n\n    redis-trib.rb create --replicas 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005\n\n\n1\n\n\n# B - 纯手工配置\n\n * 使用 cluster addslots 命令均匀切分 16384 个slot为3段\n   \n       shell:\n           for i in {0..5461}; do redis-cli -h 10.0.2.15 -p 7001 cluster addslots $i; done\n           for i in {5462..10923}; do redis-cli -h 10.0.2.15 -p 7002 cluster addslots $i; done\n           for i in {10924..16384}; do redis-cli -h 10.0.2.15 -p 7003 cluster addslots $i; done\n   \n   \n   1\n   2\n   3\n   4\n   \n * 建立各个实例之间的通信\n   * 只需要在一台机器上进行操作就可以，其他机器会自动添加通信的配置\n   \n       进入redis-cli命令：\n           127.0.0.1:6379> cluster meet 10.0.2.15 63791\n           ...\n   \n   \n   1\n   2\n   3\n   \n * 建立主从节点关系\n   * 登录从节点，使用 cluster replicate 指定当前节点是哪个节点的 replica\n   \n       root@jiao:~# redis-cli -h 10.0.2.15 -p 7004\n       10.0.2.15:7004> cluster replicate 20c7dc8245c14b87fb0efb70769f02402e5b9c2a\n   \n   \n   1\n   2\n   \n\n\n# 测试\n\n * ./redis-cli -c -h 10.0.2.15 -p 7000\n   * 注意加参数-c，表示进入cluster模式\n * failover\n   * 停掉 myredis_c (DEBUG SEGFAULT), 观察 myredis_d 的选主流程\n   * 启动 myredis_c, 观察 myredis_c 和 myredis_d 的主从关系转换\n * scale out\n   * 新增节点\n     * docker run -d --net host --name myredis_e redis:5.0 redis-server --cluster-enabled yes --port 7005\n   * 重新划分slot\n     * 工具 redis-trib.rb\n       * ./redis-trib.rb reshard [cluster_node_ip:cluster_node_port]\n     * 手工\n       * 数据迁移流程\n * scale in\n   * 只有slave节点和空的master节点可以删除\n     * 如果master非空，先用reshard把上面的slot移动到其它node后再删除\n     * 如果有一组master-slave节点，将master上所有slot移到其它节点，然后将master删除，剩下的slave会另寻他主，变成其它master的slave\n\n\n\n\n\n# 数据迁移流程\n\n * 流程\n   * 设定迁移中的节点状态\n     * 比如要把slot x的数据从节点A迁移到节点B的话，需要把A设置成MIGRATING状态，B设置成IMPORTING状态。\n       \n           CLUSTER SETSLOT <slot> IMPORTING <node_id_A>\n           CLUSTER SETSLOT <slot> MIGRATING <node_id_B>\n       \n       \n       1\n       2\n       \n   * 迁移数据\n     * 这一步首先使用CLUSTER GETKEYSINSLOT 命令获取该slot中所有的key, 然后每个key依次用MIGRATE命令转移数据。\n     * 注意\n       * 因为MIGRATE命令是原子性的，在单个key的迁移过程中，对这个key的访问会被阻塞。如果key的值比较多时, 影响相对明显。\n   * 对两个节点使用cluster setslot node来消除importing和migrating标记, 并且设置槽位\n     * 注意：这里可能会遇到 Epoch Collision 问题\n       * 根源: 主从和slot的一致性是由epoch来管理的\n       * 原因：迁移最后一步消除importing使用的cluster setslot node, 如果另外一个节点也同时bump epoch, 就可能出现epoch collision\n         * 如果对一个节点使用cluster setslot node的时候节点有importing flag, 节点会bump epoch。如果节点没有importing flag, 它会直接设置槽位, 但不会增加自己的node epoch。\n         * reference: [https://blog.csdn.net/u011535541/article/details/78834565]\n * 影响\n   * redis cluster的数据迁移基本不会影响集群使用\n     * 但是，在数据从节点A迁移到B的过程中，数据可能在A上，也可能在B上，redis是怎么知道要到哪个节点上去找的呢？\n       * ASK和MOVED转向: MOVED是永久转向信号，ASK则表示只这一次操作做转向\n         * reference: [http://redisdoc.com/topic/cluster-spec.html#moved]\n         * 在节点A向节点B的数据迁移过程中，当客户端在A中没找到某个key时,就会得到一个ASK，然后再去B中查找，实际上就是多查一次\n         * 需要注意的是，客户端查询B时，需要先发一条ASKING命令，否则这个针对带有IMPORTING状态的槽的命令请求将被节点B拒绝\n * reference\n   * [https://zhuanlan.zhihu.com/p/25060071]\n   * [https://blog.csdn.net/u011535541/article/details/78834565]\n\n\n# redis cluster\n\n    CLUSTER SETSLOT <slot> NODE <node_id> 将槽 slot 指派给 node_id 指定的节点，如果槽已经指派给另一个节点，那么先让另一个节点删除该槽，然后再进行指派\n    CLUSTER SETSLOT <slot> MIGRATING <node_id> 将本节点的槽 slot 迁移到 node_id 指定的节点中\n    CLUSTER SETSLOT <slot> IMPORTING <node_id> 从 node_id 指定的节点中导入槽 slot 到本节点\n    CLUSTER SETSLOT <slot> STABLE 取消对槽 slot 的导入(import)或者迁移(migrate)\n\n\n1\n2\n3\n4\n',normalizedContent:'# 创建redis cluster\n\n\n# 1、创建docker实例\n\n    docker run -d --net host --name myredis_a redis:5.0 redis-server --cluster-enabled yes --port 7000\n    docker run -d --net host --name myredis_b redis:5.0 redis-server --cluster-enabled yes --port 7001\n\n\n1\n2\n\n * 说明\n   * 需要使用 --net host\n     * 见 https://redis.io/topics/cluster-tutorial 中 "redis cluster and docker" 的表述\n\n\n# 2、创建cluster\n\n * 结构\n   * myredis_a -- master\n   * myredis_b -- master\n   * myredis_c -- master\n   * myredis_d -- slave of myredis_c\n\n# a - 使用 redis-trib.rb 工具\n\n    redis-trib.rb create --replicas 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005\n\n\n1\n\n\n# b - 纯手工配置\n\n * 使用 cluster addslots 命令均匀切分 16384 个slot为3段\n   \n       shell:\n           for i in {0..5461}; do redis-cli -h 10.0.2.15 -p 7001 cluster addslots $i; done\n           for i in {5462..10923}; do redis-cli -h 10.0.2.15 -p 7002 cluster addslots $i; done\n           for i in {10924..16384}; do redis-cli -h 10.0.2.15 -p 7003 cluster addslots $i; done\n   \n   \n   1\n   2\n   3\n   4\n   \n * 建立各个实例之间的通信\n   * 只需要在一台机器上进行操作就可以，其他机器会自动添加通信的配置\n   \n       进入redis-cli命令：\n           127.0.0.1:6379> cluster meet 10.0.2.15 63791\n           ...\n   \n   \n   1\n   2\n   3\n   \n * 建立主从节点关系\n   * 登录从节点，使用 cluster replicate 指定当前节点是哪个节点的 replica\n   \n       root@jiao:~# redis-cli -h 10.0.2.15 -p 7004\n       10.0.2.15:7004> cluster replicate 20c7dc8245c14b87fb0efb70769f02402e5b9c2a\n   \n   \n   1\n   2\n   \n\n\n# 测试\n\n * ./redis-cli -c -h 10.0.2.15 -p 7000\n   * 注意加参数-c，表示进入cluster模式\n * failover\n   * 停掉 myredis_c (debug segfault), 观察 myredis_d 的选主流程\n   * 启动 myredis_c, 观察 myredis_c 和 myredis_d 的主从关系转换\n * scale out\n   * 新增节点\n     * docker run -d --net host --name myredis_e redis:5.0 redis-server --cluster-enabled yes --port 7005\n   * 重新划分slot\n     * 工具 redis-trib.rb\n       * ./redis-trib.rb reshard [cluster_node_ip:cluster_node_port]\n     * 手工\n       * 数据迁移流程\n * scale in\n   * 只有slave节点和空的master节点可以删除\n     * 如果master非空，先用reshard把上面的slot移动到其它node后再删除\n     * 如果有一组master-slave节点，将master上所有slot移到其它节点，然后将master删除，剩下的slave会另寻他主，变成其它master的slave\n\n\n\n\n\n# 数据迁移流程\n\n * 流程\n   * 设定迁移中的节点状态\n     * 比如要把slot x的数据从节点a迁移到节点b的话，需要把a设置成migrating状态，b设置成importing状态。\n       \n           cluster setslot <slot> importing <node_id_a>\n           cluster setslot <slot> migrating <node_id_b>\n       \n       \n       1\n       2\n       \n   * 迁移数据\n     * 这一步首先使用cluster getkeysinslot 命令获取该slot中所有的key, 然后每个key依次用migrate命令转移数据。\n     * 注意\n       * 因为migrate命令是原子性的，在单个key的迁移过程中，对这个key的访问会被阻塞。如果key的值比较多时, 影响相对明显。\n   * 对两个节点使用cluster setslot node来消除importing和migrating标记, 并且设置槽位\n     * 注意：这里可能会遇到 epoch collision 问题\n       * 根源: 主从和slot的一致性是由epoch来管理的\n       * 原因：迁移最后一步消除importing使用的cluster setslot node, 如果另外一个节点也同时bump epoch, 就可能出现epoch collision\n         * 如果对一个节点使用cluster setslot node的时候节点有importing flag, 节点会bump epoch。如果节点没有importing flag, 它会直接设置槽位, 但不会增加自己的node epoch。\n         * reference: [https://blog.csdn.net/u011535541/article/details/78834565]\n * 影响\n   * redis cluster的数据迁移基本不会影响集群使用\n     * 但是，在数据从节点a迁移到b的过程中，数据可能在a上，也可能在b上，redis是怎么知道要到哪个节点上去找的呢？\n       * ask和moved转向: moved是永久转向信号，ask则表示只这一次操作做转向\n         * reference: [http://redisdoc.com/topic/cluster-spec.html#moved]\n         * 在节点a向节点b的数据迁移过程中，当客户端在a中没找到某个key时,就会得到一个ask，然后再去b中查找，实际上就是多查一次\n         * 需要注意的是，客户端查询b时，需要先发一条asking命令，否则这个针对带有importing状态的槽的命令请求将被节点b拒绝\n * reference\n   * [https://zhuanlan.zhihu.com/p/25060071]\n   * [https://blog.csdn.net/u011535541/article/details/78834565]\n\n\n# redis cluster\n\n    cluster setslot <slot> node <node_id> 将槽 slot 指派给 node_id 指定的节点，如果槽已经指派给另一个节点，那么先让另一个节点删除该槽，然后再进行指派\n    cluster setslot <slot> migrating <node_id> 将本节点的槽 slot 迁移到 node_id 指定的节点中\n    cluster setslot <slot> importing <node_id> 从 node_id 指定的节点中导入槽 slot 到本节点\n    cluster setslot <slot> stable 取消对槽 slot 的导入(import)或者迁移(migrate)\n\n\n1\n2\n3\n4\n',charsets:{cjk:!0}},{title:"utility",frontmatter:{published:!0,title:"utility",description:"jiao's blog",keywords:[null],categories:["tools","rnote"],permalink:"/blog/utility/",date:"2020-04-13T00:00:00.000Z",tags:[null]},regularPath:"/blog/xnote/",relativePath:"blog/xnote/README.md",key:"v-2fe5090c",path:"/blog/utility/",headersStr:null,content:"# UTILITY\n\n * 持续交付(极客时间)摘要\n * Deep Mind\n * 关于Pm\n * Interesting Xxx\n * 关于总结\n * Google 技能评分卡\n * 关于股市\n * Skill And Communication\n * Architecture(极客时间)摘要\n * Refactor\n * 关于心学",normalizedContent:"# utility\n\n * 持续交付(极客时间)摘要\n * deep mind\n * 关于pm\n * interesting xxx\n * 关于总结\n * google 技能评分卡\n * 关于股市\n * skill and communication\n * architecture(极客时间)摘要\n * refactor\n * 关于心学",charsets:{cjk:!0}},{title:"关于总结",frontmatter:{title:"关于总结",date:"2022-01-19T00:00:00.000Z",description:"关于总结",permalink:null,categories:["blog","xnote"],tags:[null]},regularPath:"/blog/xnote/about_acknowledge.html",relativePath:"blog/xnote/about_acknowledge.md",key:"v-a6752c4a",path:"/blog/xnote/about_acknowledge.html",headers:[{level:2,title:"I 知行合一",slug:"i-知行合一",normalizedTitle:"i 知行合一",charIndex:11},{level:3,title:"客观事实",slug:"客观事实",normalizedTitle:"客观事实",charIndex:213},{level:3,title:"知",slug:"知",normalizedTitle:"知",charIndex:13},{level:3,title:"行",slug:"行",normalizedTitle:"行",charIndex:14},{level:2,title:"II 关于选择",slug:"ii-关于选择",normalizedTitle:"ii 关于选择",charIndex:763},{level:3,title:"发现自己什么都不懂，什么都想学",slug:"发现自己什么都不懂-什么都想学",normalizedTitle:"发现自己什么都不懂，什么都想学",charIndex:775},{level:3,title:"取舍",slug:"取舍",normalizedTitle:"取舍",charIndex:710},{level:2,title:"III 关于思维",slug:"iii-关于思维",normalizedTitle:"iii 关于思维",charIndex:2020},{level:3,title:"深度思维",slug:"深度思维",normalizedTitle:"深度思维",charIndex:2032},{level:3,title:"高维思维",slug:"高维思维",normalizedTitle:"高维思维",charIndex:2184},{level:2,title:"IV 关于沟通",slug:"iv-关于沟通",normalizedTitle:"iv 关于沟通",charIndex:2291},{level:3,title:"学会讲好一个故事",slug:"学会讲好一个故事",normalizedTitle:"学会讲好一个故事",charIndex:2551},{level:3,title:"SCQA法则",slug:"scqa法则",normalizedTitle:"scqa法则",charIndex:2792},{level:3,title:"STAR法则",slug:"star法则",normalizedTitle:"star法则",charIndex:2982},{level:2,title:"V 关于影响力",slug:"v-关于影响力",normalizedTitle:"v 关于影响力",charIndex:3113},{level:3,title:"个人品牌",slug:"个人品牌",normalizedTitle:"个人品牌",charIndex:3456},{level:2,title:"VI 关于领导力",slug:"vi-关于领导力",normalizedTitle:"vi 关于领导力",charIndex:4104},{level:3,title:"知",slug:"知-2",normalizedTitle:"知",charIndex:13},{level:3,title:"行",slug:"行-2",normalizedTitle:"行",charIndex:14},{level:2,title:"VII 关于价值与价格",slug:"vii-关于价值与价格",normalizedTitle:"vii 关于价值与价格",charIndex:4912},{level:3,title:"不对称",slug:"不对称",normalizedTitle:"不对称",charIndex:4928},{level:3,title:"薪资",slug:"薪资",normalizedTitle:"薪资",charIndex:5285},{level:3,title:"成本",slug:"成本",normalizedTitle:"成本",charIndex:5676},{level:3,title:"发展与变化",slug:"发展与变化",normalizedTitle:"发展与变化",charIndex:5889},{level:2,title:"VIII 关于兴趣",slug:"viii-关于兴趣",normalizedTitle:"viii 关于兴趣",charIndex:5924},{level:2,title:"IX 关于行",slug:"ix-关于行",normalizedTitle:"ix 关于行",charIndex:5966},{level:3,title:"1. 学习",slug:"_1-学习",normalizedTitle:"1. 学习",charIndex:6016},{level:3,title:"2. 做事",slug:"_2-做事",normalizedTitle:"2. 做事",charIndex:6273},{level:3,title:"3. 势",slug:"_3-势",normalizedTitle:"3. 势",charIndex:6483},{level:3,title:"4. 定位",slug:"_4-定位",normalizedTitle:"4. 定位",charIndex:6517},{level:3,title:"5. 工作量预估",slug:"_5-工作量预估",normalizedTitle:"5. 工作量预估",charIndex:6672},{level:2,title:"X 自省、归纳",slug:"x-自省、归纳",normalizedTitle:"x 自省、归纳",charIndex:6819},{level:3,title:"1. 自省",slug:"_1-自省",normalizedTitle:"1. 自省",charIndex:6831},{level:3,title:"2. 经验",slug:"_2-经验",normalizedTitle:"2. 经验",charIndex:7001},{level:3,title:"3. 著名的知识",slug:"_3-著名的知识",normalizedTitle:"3. 著名的知识",charIndex:7217},{level:3,title:"4. 著名的问题",slug:"_4-著名的问题",normalizedTitle:"4. 著名的问题",charIndex:7694},{level:2,title:"XI 推荐阅读",slug:"xi-推荐阅读",normalizedTitle:"xi 推荐阅读",charIndex:7769}],headersStr:"I 知行合一 客观事实 知 行 II 关于选择 发现自己什么都不懂，什么都想学 取舍 III 关于思维 深度思维 高维思维 IV 关于沟通 学会讲好一个故事 SCQA法则 STAR法则 V 关于影响力 个人品牌 VI 关于领导力 知 行 VII 关于价值与价格 不对称 薪资 成本 发展与变化 VIII 关于兴趣 IX 关于行 1. 学习 2. 做事 3. 势 4. 定位 5. 工作量预估 X 自省、归纳 1. 自省 2. 经验 3. 著名的知识 4. 著名的问题 XI 推荐阅读",content:'# 关于总结\n\n\n# I 知行合一\n\n> 知：指导行，行：反馈知\n\n# 知与行、道和术\n\n知行存在于各个方向、层面、维度，并相互影响；不同的(或大或小的)知和行都有各自的道和术(道本质, 术方法)。\n\n小到晚饭吃什么，大到人生目标；以及怎么提升沟通技巧、怎么提升领导力、怎么提高收入...等等\n\n如，我们所谓的世界观和方法论也是知和行的不同表述：世界观主要解决世界"是什么"的问题，而方法论主要解决"怎么办"的问题。\n\n\n# 客观事实\n\n一件件或大或小的客观事实汇聚成了繁杂的世界\n\n对客观事实由简单到复杂的逐步梳理形成认知、智慧：\n\n\n# 知\n\n> 学习(认识) -> 本质 -> 发散、联想 -> 抽象 -> 创造\n\n我们需要通过学习来认识这些客观事实, 洞悉其本质; 还需要在探究(众多)客观事实(表象)的本质过程中，抽象出自己的智慧(道); 在掌握了足够的认知时，可以进行创作以验证认知同时产生价值。\n\n思维是增强认知的重要手段。如，5Why 思维方式帮助我们挖掘更深层次的知，流程思维方式帮助我们高效的行\n\n随着知的深入，复杂度发生变化，思考维度也从点、线、面发展到多维、高维：个体(客观存在) --\x3e 环境 --\x3e 生态 --\x3e 系统 --\x3e 势(时来天地皆同力)\n\n创造力是人最重要的素质。神最大的能力就是创造力！\n\n\n# 行\n\n * 践行自己的认知\n   * Just Do It\n   * 君子性非异也，善假于物也\n * 选择\n   * 我们无法控制自身之外的其它任何事物，所以我们经常会面对各种选择\n   * 持经达变: 拥抱变化，变化是常态，唯一不变的就是变化自身\n   * 生活从来没有平衡，只有取舍(最需要的和最感兴趣的)。换句话说，最重要的事，永远只有一件。\n\n人定胜天 和 顺势而为 ？\n\n\n# II 关于选择\n\n\n# 发现自己什么都不懂，什么都想学\n\n发现自己什么都不懂，什么都想学，又什么都学不精，是不是一种病态？这是一个知乎上很多人参与的一个问题。\n\n首先，当你发现什么都不懂，什么都想学的时候，最先做的应该不是迷惘，而是庆幸。因为你的目光不再偏居一隅，开始探索广阔的世界。之所以迷惘是因为『世界』是如此广阔，如果任何方向都想探索的话，很容易迷路。。。\n\n因此面对海量的知识，首先应当意识到学是学不完的，学了不用也会非常容易忘记。所以，要有取舍之心，不能什么都学会，也就没必要什么都想学。这是一种心态，可以让你面对无穷选择的时候不会有犹豫、迷惘、恐惧这些负面情绪。\n\n面对复杂多变、看不清远处的路口，如何选择依然是个头疼的问题，这时付诸行动比选择更重要。学习尤为如此，作为新的开端，学习的状态比学什么更重要。很多知识要学一段时间才能发现兴趣，才知道是否有用。\n\n总之，什么都不懂，很正常，因为这是新的开始；什么都想学，是缺少取舍的心态，先开始学一个再说；什么都不精，学过几年才见分晓，一万小时才算精通。\n\n最忌讳，什么都想学的时候，就什么都学，但每一点都是浅尝辄止；看似忙忙碌碌，不停的学习，实际上却收获甚微。。。而焦虑也会反复出现，终其原因就是：没有成就感。\n\n面对众多路口，不知道如何选择时，需要迅速行动起来，去探索，尝试找出合适的道路，然后坚持下去；当览过当前道路的美景后，可以在探索过的路口中再选择一个，然后坚持下去。。。\n\n\n# 取舍\n\n谨记，生活从来没有平衡，只有取舍(最需要的和最感兴趣的)。换句话说，最重要的事，永远只有一件。\n\n想要得到更多的钱，那就牺牲更多的享乐时间；想要顾及家庭，那必定要在职场里做出妥协；想要说走就走的旅行，那就让自己能够在当下所在的环境中脱离出来——无论是职场位置的放手，亦或者是家庭事务的放手。\n\n最害怕的，则是不愿意冒险，也不愿意舍得的那一部分人——到头来自己哪一面都没有尽情得到，并且还要责怪这过分的生活本身。\n\n我们可以尝试以一种上帝视角，来观望自己所做出的种种选择。到最后大概率会发现，这一路走来，全都是自己最深处的欲望在驱使，全是自我无法舍弃的部分在支撑。\n\n总之，对大多数人来说，选择是在借用过去的经验、试图指导现在的生活、以期待在未来获益。在面对选择时，我给出的建议如下：可以分为专和广两个方面来考虑。\n\n * 专：就是要找到自己目前最需要的和自己最感兴趣的领域，记住，一定要宁缺毋滥，保持一个少而精的原则。\n * 广：就是去广泛涉猎别的领域，这些领域需要对待的原则就是，好读书，不求甚解，切忌在这些领域钻牛角尖。这样既不会磨灭学习的兴趣，也可以使你小有成就感。\n\n一样东西学不精就说明这个东西在你现实生活中并没有得到马上的应用。就像我们看书一样，假如我们能够带着问题去看书，那我们就可以很快的解决这个问题，那我们就会对这个答案很印象深刻。那假如我们学习一个东西，只是单纯为了学而学，现实生活中根本没有用到的话，那就是没有必要的学习了。\n\n\n# III 关于思维\n\n> 深度思维是数据(表象)转化为认知的有效工具\n\n好的思维方式为知提供更好的分析；对的思维方式为行指导高效的路径\n\n\n# 深度思维\n\n洞察细微，让你高效的解决日常的具体事物\n\n常见的方法有：\n\n 1. 思维逻辑链\n    * 5Why、5So\n 2. 换位思维\n 3. 可视化思维\n 4. 流程思维\n\n\n# 高维思维\n\n打开思维的格局，让你站在更高、更广的视角看待问题，以更深刻更巧妙的方式解决问题\n\n常见的方法有：\n\n 1. 生态思维\n 2. 系统思维\n 3. 大势思维\n    * 马太效应\n 4. 兵法思维\n\n\n# IV 关于沟通\n\n好胜人，耻闻过，骋辩给，眩聪明，厉威严，恣强愎，此六者，君上之弊也.\n                                   - 《资治通鉴· 唐纪四十五·德宗建中四年》\n\n\n1\n2\n\n\n沟通交流是必需技能，它有助于自我进化：口头沟通 <--- (二者的权衡) ---\x3e 文字沟通\n\n沟通的要点：\n\n * 空杯心态(谦逊, 虚怀若谷)\n   * 有助于我们控制控制情绪\n * 换位思考\n   * 共情(同理心)\n   * 利益分享(F.A.B)：关注对方的需求, 达成自己的目标\n\n\n# 学会讲好一个故事\n\n> 摘自<你如何听懂我说的话>(黄执中)\n\n讲好一个故事的三大原则：简单、具体、意外(有两种实操手法: 造冲突、设悬念)\n\n对于具体，这里有个例子：在2000年世纪之交的时候，基本上所有的国家领导人发表讲话的时候，都是说一些假大空的愿景和展望，但是新加坡领导人的一个讲话，让人印象深刻，他说在未来3年，我们希望每个厕所都有厕纸。哎哟，好具体啊，这么多年过去了，我已经不记得中国领导人、美国领导人在那个时候讲了什么，但唯独记得住，新加坡领导人说的那番话。\n\n\n# SCQA法则\n\nSCQA法则，一个讲故事屡试不爽的逻辑。比如下面的故事：\n\n    Situation: 520快到了，我想买个戒指，向女朋友求婚\n    Conflict: 不过买戒指的钱不够\n    Question: 我该怎么凑足不够的那笔钱\n    Auswer: 找高中的一个铁哥们借\n\n\n1\n2\n3\n4\n\n\n所谓的SCQA法则，就是场景-冲突-问题-解决方案\n\n\n# STAR法则\n\nSTAR法则，一个表达自己的好方法\n\n    Situation(情境)\n    Task(任务)\n    Action(行动, 指方案和做法)\n    Result(结果, 指效果和意义)\n\n\n1\n2\n3\n4\n\n\ntips: 结果先行\n\n\n# V 关于影响力\n\n> 想让别人接受的一切都是商品，包括我们自己\n\n影响力包括对外、对内两部分：\n\n * 大部分人提到影响力，会提到一个技术人员在外部被多少技术会议邀请，有多少技术文章被其他人引用和认可。其实对外影响力的目标是作用在对内影响力上。\n * 通过对业界的影响力以及方案判断和决策不断的验证，建立管理层对于技术团队整体的信任。这样在决策和预判过程当中，技术管理者的技术基因才可能有话语权，可以让公司以合适的技术节奏和技术路线来发展，避免过少或者过多的技术投入影响业务。\n * 对于员工的影响力，是员工发自心底的一呼百应，通过准确的技术判断、正确的管理决策、合适的领导方法让员工信服决策者而不是因为职位的高低而去执行。这样才可以打造一个积极向上、海纳百川的产品技术团队。\n\n\n# 个人品牌\n\n什么是"个人品牌"？简单来说，就是一个人带给别人的印象，以及所影响的人的范围。我们说一个人个人品牌很好，通常是说他在某一方面有专长，有权威，同时他还影响和帮助了很多人。\n\n从这个角度出发，技术人可以从下面几个维度思考，打造自己的个人品牌或者影响力：\n\n * 通过社交媒体多发表观点，尤其是针对热点事件，让自己在关键时刻不缺位。但是这个方式也有自己的副作用，如果在社交媒体上过于活跃，比如在每个群里都能看到他在说话，好像随时都在响应大家，可能会给人留下没有专注于本职工作的印象。学会“隐藏自己的实力”，多发表有见地和有理有据的内容，可以作为自己使用社交媒体的礼仪之一。\n * 多参与有品质的会议，并发表演讲，或者写“博客 / 公众号”也是不错的办法。因为不论是一个 45 分钟的分享，还是一个 2000 字的文章，都代表着你对一个问题的深入思考，这在现在已经泛滥的浅层信息流中是比较稀有的东西，自然会受到更多人的关注。需要注意的是，不要一个内容到处讲，要克制，就好像武侠小说里面的剑客，不是随意拔剑的，剑一出手，必定置敌人于死地。如果是公司需要自己多露面，那么至少每次讲的内容要有 30% 的更新。\n * 出书，可能是当前最有效的建立个人品牌的方法，尤其是和一些有品牌的出版社合作。通常情况下，越是难度高的产出，越容易受人肯定。如果说公众号代表一个人当下的深入思考，出书则代表一个人对过去一段时间的深入总结，而且还要花费数月把它形成文字写出来，是代表着一种严肃的，真实的付出。\n\n\n# VI 关于领导力\n\n> 领导力，就是"成事"的能力\n\n领导力，也就是"成事"的能力，对最终结果负责是级领导力的最高体现。领导力就是用各种各样的方法、人员、影响力、号召力、决策力将一个事情从 0 到 1 的能力，如果把事情做成 0.99，都不是领导力的体现。\n\n\n# 知\n\n培养领导力需要着眼于从以下几种能力和素质：\n\n * 能成事的能力\n * 决策力\n   * 迅速拍板并为结果负责的能力\n     * 大家所理解的决策，经常是给老板三个方案，老板从中拍板一个最好的，然后让大家去执行。其实实际情况并不是这样的，作为一个高级管理者，经常能看到下属遇到一些困难的球(问题)，大家想尽一切办法去接着这个球，好接的球基层、中层管理者都搞定了，出现在你面前的一定都是"仙人球"。所以，技术管理者看到的情况，经常不是"两好选其优"，而是"两害取其轻"。通俗的讲，面前两坨翔，一坨大的一坨小的，让你必须选一坨吃，如果你不迅速确定，这两坨马上各自增长一倍。\n * 沟通力\n   * 倾听与准确反馈的能力\n     * 简单地说，沟通力，就是在合适的时间对合适的人用合适方法说合适的事情。体现在，对外交流、对上沟通(像CEO一样思考问题、数据说话)、对下沟通等。\n * 影响力\n   * 号召管理层和员工一致行动的能力。"职位不是别人给的，而是自己挣出来的"，这句话就是影响力的真实表现。\n * 商业思维\n * 技术前瞻(战略层次)\n\n\n# 行\n\n谨记：宰相必起于州府，猛将必发于卒伍\n\n徐直军说过，站在管理者的角度来讲，绩效管理就是要让你的下属都愿意跟着你一起干。\n\n领悟团队开发文化：\n\n * 多讨论、用白板，勤跟踪，要闭环\n\nSMART\n\n小公司如同轻骑兵（敏捷、速度、攻击），大公司如同重骑兵（稳扎稳打，防御，安全，集团军）\n\n流程的思想精髓是什么呢？\n\n * 先僵化、再优化、再固化。 像华为一样，用流程解放管理\n\n\n# VII 关于价值与价格\n\n世界是不对称的。正是因为不对称，才有了各种需求，由此产生了价值与价格。\n\n\n# 不对称\n\n很多人都有个认知误区，觉得自己"这也不行，那也不会，没有什么擅长的"，所以没有赚钱的机会。其实，任何的不对称都可能赚钱，要善于发掘"不对称"。\n\n常见的不对称可以分类为:\n\n 1. 资源不对称: 你有的，别人没有\n 2. 信息不对称: 你知道的，别人不知道\n\n * 几年前，有个人制作了一本电子书，教大家在美国亚马逊网站上传电子书来赚钱。这本电子书也就是40多页，其实就是将在亚马逊网站上传电子书的流程截图说明而已，很多内容都是官网中就有了。他将这本书的售价定位49元，轻松销售几千乃至上万套。\n\n 3. 认知不对称: 你会的，别人不会\n\n * 内容付费靠什么来赚钱？其实就是将知识或是技能通过有偿分享的模式来进行赚钱。\n\n\n# 薪资\n\n我们常常认为工资的高低似乎和你的技能、经验呈正比关系。而这仅仅是一个表象，那么它的实质是什么呢？\n\n薪资不是支付给技能的，而是支付给责任的。责任越大，工资越高\n\n对于管理岗位，因为经理人不属于个人贡献者，所以其工资的一部分通常和团队绩效绑定，称为绩效奖金。这个奖金一般在管理岗的全部薪酬中的百分比会随着薪酬的增加而增加，比如：高层可能占到 50%，而中层占到 20%-30%。\n\n前 Intel CEO 安迪·格鲁夫说过：每一份工作所包含的最大价值都是有限的，不管一个人在这个职位上待了多久，最后总会达到薪资的上限。 这个上限就是岗位工资范围的天花板。而外部市场会提供一些工资立即涨 50% 甚至翻倍的机会。此时，先不要自大的以为你的价值被低估了，很可能是外部公司出现了岗位空缺，空缺的岗位职责实际可能比你在当前公司的职责更大，也就是说你还要考虑自己能否承担得起。\n\n\n# 成本\n\n市场上的商品有两种销售方式：\n\n * 卖的更多：大型卖场，薄利多销\n * 卖的更贵：奢侈品，相对成本一百倍的毛利\n\n对于程序员，主要的成本有两个：\n\n * 技能成本：专注于提供技术和服务本身所占用的时间和注意力\n * 传递成本：让你潜在的"客户"知道你所能提供的技术和服务的价值占用的时间和注意力\n\n程序员提供的技术服务因为无法卖的更多，所以只有一种选择，像奢侈品一样卖的更贵，前提是学会像奢侈品牌一样思考。\n\n\n# 发展与变化\n\n真正认识你价值的人，最终会成为你价值的一部分。\n\n\n# VIII 关于兴趣\n\n目标：有能力促使兴趣和擅长的发展，并使他们逐渐重合。\n\n\n# IX 关于行\n\n> 归纳演绎: WHY(为什么)、HOW(怎么做)、WHAT(做成了什么)\n\n\n# 1. 学习\n\n * 方法：忆、思、说、写、用\n   * 影响因素：有关自身的好奇心、逻辑性、操控力，和有关环境的挑战、榜样和反馈\n * 目标：化繁(发散)为简(抽象), 由简入繁; 举一反三, 融会贯通\n   * 系统化: 点 -> 面 -> 体\n   * 结构化: 建立专家体系, 方法论\n\n>> 概况：解决什么问题，每个点做到什么程度\n>> 实践 - 先主干后枝叶, 由基础到上层建筑\n>> 思考 - 由本质到细节, 由框架到全面\n>> 拓展 - 规模由小到大时, 量变引发质变\n\n\n1\n2\n3\n4\n\n\n\n# 2. 做事\n\n极致(ONE MORE STEP) 、 Plan B\n\n * 靠谱：自己表达的每一个观点，都要有支撑(数据、详情等)\n   * 量化 => 实践 => 反馈 => 迭代\n     * "If you can\'t measure it, you can’t manage it"(你如果无法度量它，就无法管理它) - 管理学大师-彼得德鲁克\n * 维度：高维度思考、看待问题\n * 思路：分治、迭代\n\n\n# 3. 势\n\n如果说内功是成功的基石，那么外势就是成功的杠杆\n\n\n# 4. 定位\n\n * 想清楚定位：独特价值、壁垒\n * 技术 & 业务\n   * 技术支持业务：别把技术太当回事，别不把技术当回事\n   * 像CEO一样思考(高维思考)\n * 科技发展方向\n   * 自动化 + 智能化\n   * 需求 ---\x3e 设计 ---((声明式)数据 + 算法)---\x3e 产品\n\n\n# 5. 工作量预估\n\n影响工作量预估的主要因素是人：内因(愿景) + 外因\n\n常用的方法：\n\n * 二的幂次方为单位(小时)\n * 乐观 + 悲观 系数结合进行预估\n   * 提需求的人会相对乐观，实现需求的人会相对悲观，所以需要融合\n   * 80%的工作量，预留20%的临时插入工作\n\n\n# X 自省、归纳\n\n\n# 1. 自省\n\n * 内功体现在：解决问题的能力，依赖以下能力：\n   * 学习能力、精益能力、协作能力、领导能力\n * 成长的体现:\n   * 技术、视野(包括人脉、认知)\n * tips: 自我反思 --- 有始有终，不要虎头蛇尾\n   * 始(为什么要做); 终(成果如何，复盘、形成方法论，扩大成果，这一步只占5%但很重要)\n\n\n# 2. 经验\n\n * 责任感：主动挖掘, 主动承担\n   * 角色转变：规则制定者\n * 先说(答案)先死：答案==承担责任（？）\n * 危机感：日子一天天好一年年变坏：反之亦如此\n * 目标感：当你忙的像牲口一样时，你需要停下来想想看为什么了\n * 人更习惯选择题，而不是思考题\n * 具体的批评有助成长, 抽象的批评有打压意味\n * 选人更重要一点，选择后选择相信\n * 考验情商：问最喜欢的人，次之，问最讨厌的人（？）\n\n\n# 3. 著名的知识\n\n * 三种推理方式\n   * 归纳推理、演绎推理、类比推理\n * 黄金圈法则：what(表象) how(方法) why(为什么,本质)\n   * What - How - Why : 实现深入细节「1->0.1」\n   * Why - How - What : 实现构思创造「0->1」\n * 第一性原理\n   * 又称“第一原理”, 古希腊哲学家亚里士多德提出的一个哲学术语："每个系统中存在一个最基本的命题,它不能被违背或删除"\n   * 埃隆·马斯克(特斯拉汽车CEO)的应用：回溯事物的本质, 颠覆固化认知, 重新思考怎么做\n * mece原则\n   * 可以用于构建知识树\n * PDCA 循环\n   * 其含义是将质量管理分为四个阶段，即计划（plan）、执行（do）、检查（check）、行动（Action）\n * 东西方意识差异\n   * 西方：上帝 创造 人\n   * 东方：人 升级成 神 ：自我中心意识强、要面子\n * 如何从一个工程师思维，转变成一个产品经理的思考\n   * 项目目标 => 商业目标\n\n\n# 4. 著名的问题\n\n * 零知识证明: 认证理论的一个重要协议\n * 拜占庭将军问题\n * 两富翁在不互相透露具体财产的情况下，比较谁更富有\n\n\n# XI 推荐阅读\n\n * 《金字塔原理》\n * 《高效能人士的七个习惯》\n * 《好好说话》\n * 《原则》\n * 《我是这样拿到风投的》\n * 《人人都是产品经理》\n\n** TO BE CONTINUE XI XIII XIV XV **',normalizedContent:'# 关于总结\n\n\n# i 知行合一\n\n> 知：指导行，行：反馈知\n\n# 知与行、道和术\n\n知行存在于各个方向、层面、维度，并相互影响；不同的(或大或小的)知和行都有各自的道和术(道本质, 术方法)。\n\n小到晚饭吃什么，大到人生目标；以及怎么提升沟通技巧、怎么提升领导力、怎么提高收入...等等\n\n如，我们所谓的世界观和方法论也是知和行的不同表述：世界观主要解决世界"是什么"的问题，而方法论主要解决"怎么办"的问题。\n\n\n# 客观事实\n\n一件件或大或小的客观事实汇聚成了繁杂的世界\n\n对客观事实由简单到复杂的逐步梳理形成认知、智慧：\n\n\n# 知\n\n> 学习(认识) -> 本质 -> 发散、联想 -> 抽象 -> 创造\n\n我们需要通过学习来认识这些客观事实, 洞悉其本质; 还需要在探究(众多)客观事实(表象)的本质过程中，抽象出自己的智慧(道); 在掌握了足够的认知时，可以进行创作以验证认知同时产生价值。\n\n思维是增强认知的重要手段。如，5why 思维方式帮助我们挖掘更深层次的知，流程思维方式帮助我们高效的行\n\n随着知的深入，复杂度发生变化，思考维度也从点、线、面发展到多维、高维：个体(客观存在) --\x3e 环境 --\x3e 生态 --\x3e 系统 --\x3e 势(时来天地皆同力)\n\n创造力是人最重要的素质。神最大的能力就是创造力！\n\n\n# 行\n\n * 践行自己的认知\n   * just do it\n   * 君子性非异也，善假于物也\n * 选择\n   * 我们无法控制自身之外的其它任何事物，所以我们经常会面对各种选择\n   * 持经达变: 拥抱变化，变化是常态，唯一不变的就是变化自身\n   * 生活从来没有平衡，只有取舍(最需要的和最感兴趣的)。换句话说，最重要的事，永远只有一件。\n\n人定胜天 和 顺势而为 ？\n\n\n# ii 关于选择\n\n\n# 发现自己什么都不懂，什么都想学\n\n发现自己什么都不懂，什么都想学，又什么都学不精，是不是一种病态？这是一个知乎上很多人参与的一个问题。\n\n首先，当你发现什么都不懂，什么都想学的时候，最先做的应该不是迷惘，而是庆幸。因为你的目光不再偏居一隅，开始探索广阔的世界。之所以迷惘是因为『世界』是如此广阔，如果任何方向都想探索的话，很容易迷路。。。\n\n因此面对海量的知识，首先应当意识到学是学不完的，学了不用也会非常容易忘记。所以，要有取舍之心，不能什么都学会，也就没必要什么都想学。这是一种心态，可以让你面对无穷选择的时候不会有犹豫、迷惘、恐惧这些负面情绪。\n\n面对复杂多变、看不清远处的路口，如何选择依然是个头疼的问题，这时付诸行动比选择更重要。学习尤为如此，作为新的开端，学习的状态比学什么更重要。很多知识要学一段时间才能发现兴趣，才知道是否有用。\n\n总之，什么都不懂，很正常，因为这是新的开始；什么都想学，是缺少取舍的心态，先开始学一个再说；什么都不精，学过几年才见分晓，一万小时才算精通。\n\n最忌讳，什么都想学的时候，就什么都学，但每一点都是浅尝辄止；看似忙忙碌碌，不停的学习，实际上却收获甚微。。。而焦虑也会反复出现，终其原因就是：没有成就感。\n\n面对众多路口，不知道如何选择时，需要迅速行动起来，去探索，尝试找出合适的道路，然后坚持下去；当览过当前道路的美景后，可以在探索过的路口中再选择一个，然后坚持下去。。。\n\n\n# 取舍\n\n谨记，生活从来没有平衡，只有取舍(最需要的和最感兴趣的)。换句话说，最重要的事，永远只有一件。\n\n想要得到更多的钱，那就牺牲更多的享乐时间；想要顾及家庭，那必定要在职场里做出妥协；想要说走就走的旅行，那就让自己能够在当下所在的环境中脱离出来——无论是职场位置的放手，亦或者是家庭事务的放手。\n\n最害怕的，则是不愿意冒险，也不愿意舍得的那一部分人——到头来自己哪一面都没有尽情得到，并且还要责怪这过分的生活本身。\n\n我们可以尝试以一种上帝视角，来观望自己所做出的种种选择。到最后大概率会发现，这一路走来，全都是自己最深处的欲望在驱使，全是自我无法舍弃的部分在支撑。\n\n总之，对大多数人来说，选择是在借用过去的经验、试图指导现在的生活、以期待在未来获益。在面对选择时，我给出的建议如下：可以分为专和广两个方面来考虑。\n\n * 专：就是要找到自己目前最需要的和自己最感兴趣的领域，记住，一定要宁缺毋滥，保持一个少而精的原则。\n * 广：就是去广泛涉猎别的领域，这些领域需要对待的原则就是，好读书，不求甚解，切忌在这些领域钻牛角尖。这样既不会磨灭学习的兴趣，也可以使你小有成就感。\n\n一样东西学不精就说明这个东西在你现实生活中并没有得到马上的应用。就像我们看书一样，假如我们能够带着问题去看书，那我们就可以很快的解决这个问题，那我们就会对这个答案很印象深刻。那假如我们学习一个东西，只是单纯为了学而学，现实生活中根本没有用到的话，那就是没有必要的学习了。\n\n\n# iii 关于思维\n\n> 深度思维是数据(表象)转化为认知的有效工具\n\n好的思维方式为知提供更好的分析；对的思维方式为行指导高效的路径\n\n\n# 深度思维\n\n洞察细微，让你高效的解决日常的具体事物\n\n常见的方法有：\n\n 1. 思维逻辑链\n    * 5why、5so\n 2. 换位思维\n 3. 可视化思维\n 4. 流程思维\n\n\n# 高维思维\n\n打开思维的格局，让你站在更高、更广的视角看待问题，以更深刻更巧妙的方式解决问题\n\n常见的方法有：\n\n 1. 生态思维\n 2. 系统思维\n 3. 大势思维\n    * 马太效应\n 4. 兵法思维\n\n\n# iv 关于沟通\n\n好胜人，耻闻过，骋辩给，眩聪明，厉威严，恣强愎，此六者，君上之弊也.\n                                   - 《资治通鉴· 唐纪四十五·德宗建中四年》\n\n\n1\n2\n\n\n沟通交流是必需技能，它有助于自我进化：口头沟通 <--- (二者的权衡) ---\x3e 文字沟通\n\n沟通的要点：\n\n * 空杯心态(谦逊, 虚怀若谷)\n   * 有助于我们控制控制情绪\n * 换位思考\n   * 共情(同理心)\n   * 利益分享(f.a.b)：关注对方的需求, 达成自己的目标\n\n\n# 学会讲好一个故事\n\n> 摘自<你如何听懂我说的话>(黄执中)\n\n讲好一个故事的三大原则：简单、具体、意外(有两种实操手法: 造冲突、设悬念)\n\n对于具体，这里有个例子：在2000年世纪之交的时候，基本上所有的国家领导人发表讲话的时候，都是说一些假大空的愿景和展望，但是新加坡领导人的一个讲话，让人印象深刻，他说在未来3年，我们希望每个厕所都有厕纸。哎哟，好具体啊，这么多年过去了，我已经不记得中国领导人、美国领导人在那个时候讲了什么，但唯独记得住，新加坡领导人说的那番话。\n\n\n# scqa法则\n\nscqa法则，一个讲故事屡试不爽的逻辑。比如下面的故事：\n\n    situation: 520快到了，我想买个戒指，向女朋友求婚\n    conflict: 不过买戒指的钱不够\n    question: 我该怎么凑足不够的那笔钱\n    auswer: 找高中的一个铁哥们借\n\n\n1\n2\n3\n4\n\n\n所谓的scqa法则，就是场景-冲突-问题-解决方案\n\n\n# star法则\n\nstar法则，一个表达自己的好方法\n\n    situation(情境)\n    task(任务)\n    action(行动, 指方案和做法)\n    result(结果, 指效果和意义)\n\n\n1\n2\n3\n4\n\n\ntips: 结果先行\n\n\n# v 关于影响力\n\n> 想让别人接受的一切都是商品，包括我们自己\n\n影响力包括对外、对内两部分：\n\n * 大部分人提到影响力，会提到一个技术人员在外部被多少技术会议邀请，有多少技术文章被其他人引用和认可。其实对外影响力的目标是作用在对内影响力上。\n * 通过对业界的影响力以及方案判断和决策不断的验证，建立管理层对于技术团队整体的信任。这样在决策和预判过程当中，技术管理者的技术基因才可能有话语权，可以让公司以合适的技术节奏和技术路线来发展，避免过少或者过多的技术投入影响业务。\n * 对于员工的影响力，是员工发自心底的一呼百应，通过准确的技术判断、正确的管理决策、合适的领导方法让员工信服决策者而不是因为职位的高低而去执行。这样才可以打造一个积极向上、海纳百川的产品技术团队。\n\n\n# 个人品牌\n\n什么是"个人品牌"？简单来说，就是一个人带给别人的印象，以及所影响的人的范围。我们说一个人个人品牌很好，通常是说他在某一方面有专长，有权威，同时他还影响和帮助了很多人。\n\n从这个角度出发，技术人可以从下面几个维度思考，打造自己的个人品牌或者影响力：\n\n * 通过社交媒体多发表观点，尤其是针对热点事件，让自己在关键时刻不缺位。但是这个方式也有自己的副作用，如果在社交媒体上过于活跃，比如在每个群里都能看到他在说话，好像随时都在响应大家，可能会给人留下没有专注于本职工作的印象。学会“隐藏自己的实力”，多发表有见地和有理有据的内容，可以作为自己使用社交媒体的礼仪之一。\n * 多参与有品质的会议，并发表演讲，或者写“博客 / 公众号”也是不错的办法。因为不论是一个 45 分钟的分享，还是一个 2000 字的文章，都代表着你对一个问题的深入思考，这在现在已经泛滥的浅层信息流中是比较稀有的东西，自然会受到更多人的关注。需要注意的是，不要一个内容到处讲，要克制，就好像武侠小说里面的剑客，不是随意拔剑的，剑一出手，必定置敌人于死地。如果是公司需要自己多露面，那么至少每次讲的内容要有 30% 的更新。\n * 出书，可能是当前最有效的建立个人品牌的方法，尤其是和一些有品牌的出版社合作。通常情况下，越是难度高的产出，越容易受人肯定。如果说公众号代表一个人当下的深入思考，出书则代表一个人对过去一段时间的深入总结，而且还要花费数月把它形成文字写出来，是代表着一种严肃的，真实的付出。\n\n\n# vi 关于领导力\n\n> 领导力，就是"成事"的能力\n\n领导力，也就是"成事"的能力，对最终结果负责是级领导力的最高体现。领导力就是用各种各样的方法、人员、影响力、号召力、决策力将一个事情从 0 到 1 的能力，如果把事情做成 0.99，都不是领导力的体现。\n\n\n# 知\n\n培养领导力需要着眼于从以下几种能力和素质：\n\n * 能成事的能力\n * 决策力\n   * 迅速拍板并为结果负责的能力\n     * 大家所理解的决策，经常是给老板三个方案，老板从中拍板一个最好的，然后让大家去执行。其实实际情况并不是这样的，作为一个高级管理者，经常能看到下属遇到一些困难的球(问题)，大家想尽一切办法去接着这个球，好接的球基层、中层管理者都搞定了，出现在你面前的一定都是"仙人球"。所以，技术管理者看到的情况，经常不是"两好选其优"，而是"两害取其轻"。通俗的讲，面前两坨翔，一坨大的一坨小的，让你必须选一坨吃，如果你不迅速确定，这两坨马上各自增长一倍。\n * 沟通力\n   * 倾听与准确反馈的能力\n     * 简单地说，沟通力，就是在合适的时间对合适的人用合适方法说合适的事情。体现在，对外交流、对上沟通(像ceo一样思考问题、数据说话)、对下沟通等。\n * 影响力\n   * 号召管理层和员工一致行动的能力。"职位不是别人给的，而是自己挣出来的"，这句话就是影响力的真实表现。\n * 商业思维\n * 技术前瞻(战略层次)\n\n\n# 行\n\n谨记：宰相必起于州府，猛将必发于卒伍\n\n徐直军说过，站在管理者的角度来讲，绩效管理就是要让你的下属都愿意跟着你一起干。\n\n领悟团队开发文化：\n\n * 多讨论、用白板，勤跟踪，要闭环\n\nsmart\n\n小公司如同轻骑兵（敏捷、速度、攻击），大公司如同重骑兵（稳扎稳打，防御，安全，集团军）\n\n流程的思想精髓是什么呢？\n\n * 先僵化、再优化、再固化。 像华为一样，用流程解放管理\n\n\n# vii 关于价值与价格\n\n世界是不对称的。正是因为不对称，才有了各种需求，由此产生了价值与价格。\n\n\n# 不对称\n\n很多人都有个认知误区，觉得自己"这也不行，那也不会，没有什么擅长的"，所以没有赚钱的机会。其实，任何的不对称都可能赚钱，要善于发掘"不对称"。\n\n常见的不对称可以分类为:\n\n 1. 资源不对称: 你有的，别人没有\n 2. 信息不对称: 你知道的，别人不知道\n\n * 几年前，有个人制作了一本电子书，教大家在美国亚马逊网站上传电子书来赚钱。这本电子书也就是40多页，其实就是将在亚马逊网站上传电子书的流程截图说明而已，很多内容都是官网中就有了。他将这本书的售价定位49元，轻松销售几千乃至上万套。\n\n 3. 认知不对称: 你会的，别人不会\n\n * 内容付费靠什么来赚钱？其实就是将知识或是技能通过有偿分享的模式来进行赚钱。\n\n\n# 薪资\n\n我们常常认为工资的高低似乎和你的技能、经验呈正比关系。而这仅仅是一个表象，那么它的实质是什么呢？\n\n薪资不是支付给技能的，而是支付给责任的。责任越大，工资越高\n\n对于管理岗位，因为经理人不属于个人贡献者，所以其工资的一部分通常和团队绩效绑定，称为绩效奖金。这个奖金一般在管理岗的全部薪酬中的百分比会随着薪酬的增加而增加，比如：高层可能占到 50%，而中层占到 20%-30%。\n\n前 intel ceo 安迪·格鲁夫说过：每一份工作所包含的最大价值都是有限的，不管一个人在这个职位上待了多久，最后总会达到薪资的上限。 这个上限就是岗位工资范围的天花板。而外部市场会提供一些工资立即涨 50% 甚至翻倍的机会。此时，先不要自大的以为你的价值被低估了，很可能是外部公司出现了岗位空缺，空缺的岗位职责实际可能比你在当前公司的职责更大，也就是说你还要考虑自己能否承担得起。\n\n\n# 成本\n\n市场上的商品有两种销售方式：\n\n * 卖的更多：大型卖场，薄利多销\n * 卖的更贵：奢侈品，相对成本一百倍的毛利\n\n对于程序员，主要的成本有两个：\n\n * 技能成本：专注于提供技术和服务本身所占用的时间和注意力\n * 传递成本：让你潜在的"客户"知道你所能提供的技术和服务的价值占用的时间和注意力\n\n程序员提供的技术服务因为无法卖的更多，所以只有一种选择，像奢侈品一样卖的更贵，前提是学会像奢侈品牌一样思考。\n\n\n# 发展与变化\n\n真正认识你价值的人，最终会成为你价值的一部分。\n\n\n# viii 关于兴趣\n\n目标：有能力促使兴趣和擅长的发展，并使他们逐渐重合。\n\n\n# ix 关于行\n\n> 归纳演绎: why(为什么)、how(怎么做)、what(做成了什么)\n\n\n# 1. 学习\n\n * 方法：忆、思、说、写、用\n   * 影响因素：有关自身的好奇心、逻辑性、操控力，和有关环境的挑战、榜样和反馈\n * 目标：化繁(发散)为简(抽象), 由简入繁; 举一反三, 融会贯通\n   * 系统化: 点 -> 面 -> 体\n   * 结构化: 建立专家体系, 方法论\n\n>> 概况：解决什么问题，每个点做到什么程度\n>> 实践 - 先主干后枝叶, 由基础到上层建筑\n>> 思考 - 由本质到细节, 由框架到全面\n>> 拓展 - 规模由小到大时, 量变引发质变\n\n\n1\n2\n3\n4\n\n\n\n# 2. 做事\n\n极致(one more step) 、 plan b\n\n * 靠谱：自己表达的每一个观点，都要有支撑(数据、详情等)\n   * 量化 => 实践 => 反馈 => 迭代\n     * "if you can\'t measure it, you can’t manage it"(你如果无法度量它，就无法管理它) - 管理学大师-彼得德鲁克\n * 维度：高维度思考、看待问题\n * 思路：分治、迭代\n\n\n# 3. 势\n\n如果说内功是成功的基石，那么外势就是成功的杠杆\n\n\n# 4. 定位\n\n * 想清楚定位：独特价值、壁垒\n * 技术 & 业务\n   * 技术支持业务：别把技术太当回事，别不把技术当回事\n   * 像ceo一样思考(高维思考)\n * 科技发展方向\n   * 自动化 + 智能化\n   * 需求 ---\x3e 设计 ---((声明式)数据 + 算法)---\x3e 产品\n\n\n# 5. 工作量预估\n\n影响工作量预估的主要因素是人：内因(愿景) + 外因\n\n常用的方法：\n\n * 二的幂次方为单位(小时)\n * 乐观 + 悲观 系数结合进行预估\n   * 提需求的人会相对乐观，实现需求的人会相对悲观，所以需要融合\n   * 80%的工作量，预留20%的临时插入工作\n\n\n# x 自省、归纳\n\n\n# 1. 自省\n\n * 内功体现在：解决问题的能力，依赖以下能力：\n   * 学习能力、精益能力、协作能力、领导能力\n * 成长的体现:\n   * 技术、视野(包括人脉、认知)\n * tips: 自我反思 --- 有始有终，不要虎头蛇尾\n   * 始(为什么要做); 终(成果如何，复盘、形成方法论，扩大成果，这一步只占5%但很重要)\n\n\n# 2. 经验\n\n * 责任感：主动挖掘, 主动承担\n   * 角色转变：规则制定者\n * 先说(答案)先死：答案==承担责任（？）\n * 危机感：日子一天天好一年年变坏：反之亦如此\n * 目标感：当你忙的像牲口一样时，你需要停下来想想看为什么了\n * 人更习惯选择题，而不是思考题\n * 具体的批评有助成长, 抽象的批评有打压意味\n * 选人更重要一点，选择后选择相信\n * 考验情商：问最喜欢的人，次之，问最讨厌的人（？）\n\n\n# 3. 著名的知识\n\n * 三种推理方式\n   * 归纳推理、演绎推理、类比推理\n * 黄金圈法则：what(表象) how(方法) why(为什么,本质)\n   * what - how - why : 实现深入细节「1->0.1」\n   * why - how - what : 实现构思创造「0->1」\n * 第一性原理\n   * 又称“第一原理”, 古希腊哲学家亚里士多德提出的一个哲学术语："每个系统中存在一个最基本的命题,它不能被违背或删除"\n   * 埃隆·马斯克(特斯拉汽车ceo)的应用：回溯事物的本质, 颠覆固化认知, 重新思考怎么做\n * mece原则\n   * 可以用于构建知识树\n * pdca 循环\n   * 其含义是将质量管理分为四个阶段，即计划（plan）、执行（do）、检查（check）、行动（action）\n * 东西方意识差异\n   * 西方：上帝 创造 人\n   * 东方：人 升级成 神 ：自我中心意识强、要面子\n * 如何从一个工程师思维，转变成一个产品经理的思考\n   * 项目目标 => 商业目标\n\n\n# 4. 著名的问题\n\n * 零知识证明: 认证理论的一个重要协议\n * 拜占庭将军问题\n * 两富翁在不互相透露具体财产的情况下，比较谁更富有\n\n\n# xi 推荐阅读\n\n * 《金字塔原理》\n * 《高效能人士的七个习惯》\n * 《好好说话》\n * 《原则》\n * 《我是这样拿到风投的》\n * 《人人都是产品经理》\n\n** to be continue xi xiii xiv xv **',charsets:{cjk:!0}},{title:"关于心学",frontmatter:{title:"关于心学",date:"2022-03-28T00:00:00.000Z",description:"关于心学的学习认知",permalink:null,categories:["blog","xnote"],tags:[null]},regularPath:"/blog/xnote/about_heart_and_mind.html",relativePath:"blog/xnote/about_heart_and_mind.md",key:"v-0dd9b182",path:"/blog/xnote/about_heart_and_mind.html",headers:[{level:2,title:"三贼",slug:"三贼",normalizedTitle:"三贼",charIndex:228},{level:3,title:"焦虑：静中求",slug:"焦虑-静中求",normalizedTitle:"焦虑：静中求",charIndex:303},{level:3,title:"欲望：舍中得",slug:"欲望-舍中得",normalizedTitle:"欲望：舍中得",charIndex:513},{level:3,title:"犹豫：事上练",slug:"犹豫-事上练",normalizedTitle:"犹豫：事上练",charIndex:592}],headersStr:"三贼 焦虑：静中求 欲望：舍中得 犹豫：事上练",content:'# 关于心学\n\n心学是儒学的一个学派，可以按照其主张译为：Learning of the Heart-and-Mind，心学也称为“陆王学派”，所以也可译为：Lu-Wang school。\n\n王阳明，明代著名的思想家、文学家、哲学家和军事家，陆王心学之集大成者，精通儒家、道家、佛家。与孔子、孟子、朱熹并称为孔、孟、朱、王。解放前曾任浙大中文系教授的胡哲敷曾说：五百年来，能把学问在事业上表现出来的，只有两人：一为明朝的王守仁，一则清朝的曾国藩。\n\n\n# 三贼\n\n被誉为“千古第一完人”的明朝哲学家王阳明提出：“坐中静，破焦虑之贼；舍中得，破欲望之贼；事上练，破犹豫之贼，三贼皆破，则万事可成。”\n\n\n# 焦虑：静中求\n\n人之所以会焦虑是基于过去的经验对未来产生的恐惧，可以用冥想打坐等方法让自己回到当下，能够活在当下的人不会焦虑。\n\n庄子有言:”圣人之静也，非曰静也善，故静也。" 心斋坐忘，不是为了追求静的好处才去静坐，如果内心一直执着于静的好处，便不可真正入静。只有自然进入忘我状态，与万物融为一体，无拘无束，自由自在，才能破除焦虑之贼。\n\n但，又有言，"人无远虑必有近忧"？静坐时可以破除焦虑，那静坐之后呢？\n\n\n# 欲望：舍中得\n\n人的痛苦多来自于欲望，即为贪婪和占有，也是一种匮乏的表现，如果能够学会舍，则内心越来越丰盛。\n\n但，欲望也有好坏之分，舍什么怎么舍？\n\n\n# 犹豫：事上练\n\n知行合一',normalizedContent:'# 关于心学\n\n心学是儒学的一个学派，可以按照其主张译为：learning of the heart-and-mind，心学也称为“陆王学派”，所以也可译为：lu-wang school。\n\n王阳明，明代著名的思想家、文学家、哲学家和军事家，陆王心学之集大成者，精通儒家、道家、佛家。与孔子、孟子、朱熹并称为孔、孟、朱、王。解放前曾任浙大中文系教授的胡哲敷曾说：五百年来，能把学问在事业上表现出来的，只有两人：一为明朝的王守仁，一则清朝的曾国藩。\n\n\n# 三贼\n\n被誉为“千古第一完人”的明朝哲学家王阳明提出：“坐中静，破焦虑之贼；舍中得，破欲望之贼；事上练，破犹豫之贼，三贼皆破，则万事可成。”\n\n\n# 焦虑：静中求\n\n人之所以会焦虑是基于过去的经验对未来产生的恐惧，可以用冥想打坐等方法让自己回到当下，能够活在当下的人不会焦虑。\n\n庄子有言:”圣人之静也，非曰静也善，故静也。" 心斋坐忘，不是为了追求静的好处才去静坐，如果内心一直执着于静的好处，便不可真正入静。只有自然进入忘我状态，与万物融为一体，无拘无束，自由自在，才能破除焦虑之贼。\n\n但，又有言，"人无远虑必有近忧"？静坐时可以破除焦虑，那静坐之后呢？\n\n\n# 欲望：舍中得\n\n人的痛苦多来自于欲望，即为贪婪和占有，也是一种匮乏的表现，如果能够学会舍，则内心越来越丰盛。\n\n但，欲望也有好坏之分，舍什么怎么舍？\n\n\n# 犹豫：事上练\n\n知行合一',charsets:{cjk:!0}},{title:"关于PM",frontmatter:{title:"关于PM",date:"2021-01-03T00:00:00.000Z",description:"关于PM",permalink:null,categories:["blog","xnote"],tags:[null]},regularPath:"/blog/xnote/about_pm.html",relativePath:"blog/xnote/about_pm.md",key:"v-5d28d3ff",path:"/blog/xnote/about_pm.html",headers:[{level:2,title:"关于PM",slug:"关于pm",normalizedTitle:"关于pm",charIndex:2}],headersStr:"关于PM",content:"# 关于PM\n\n\n\n> 本文转载自...(来源找不到了，如有任何问题，请联系我)",normalizedContent:"# 关于pm\n\n\n\n> 本文转载自...(来源找不到了，如有任何问题，请联系我)",charsets:{cjk:!0}},{title:"Refactor",frontmatter:{title:"Refactor",date:"2020-04-13T00:00:00.000Z",description:"架构之重构的12条军规",permalink:null,categories:["blog","xnote"],tags:[null]},regularPath:"/blog/xnote/about_refactor.html",relativePath:"blog/xnote/about_refactor.md",key:"v-d5db50c2",path:"/blog/xnote/about_refactor.html",headers:[{level:2,title:"代码重构思考",slug:"代码重构思考",normalizedTitle:"代码重构思考",charIndex:21},{level:3,title:"烂代码",slug:"烂代码",normalizedTitle:"烂代码",charIndex:32},{level:3,title:"Clean Code",slug:"clean-code",normalizedTitle:"clean code",charIndex:162},{level:3,title:"重构的重要原则",slug:"重构的重要原则",normalizedTitle:"重构的重要原则",charIndex:266},{level:2,title:"架构之重构的12条军规",slug:"架构之重构的12条军规",normalizedTitle:"架构之重构的12条军规",charIndex:836},{level:3,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:852},{level:3,title:"1、确定重构的目的和必要性",slug:"_1、确定重构的目的和必要性",normalizedTitle:"1、确定重构的目的和必要性",charIndex:1121},{level:3,title:"2、定义“重构完成”的界限",slug:"_2、定义-重构完成-的界限",normalizedTitle:"2、定义“重构完成”的界限",charIndex:1346},{level:3,title:"3、渐进式重构",slug:"_3、渐进式重构",normalizedTitle:"3、渐进式重构",charIndex:1563},{level:3,title:"4、确定当前的架构状态",slug:"_4、确定当前的架构状态",normalizedTitle:"4、确定当前的架构状态",charIndex:1851},{level:3,title:"5、不要忽略数据",slug:"_5、不要忽略数据",normalizedTitle:"5、不要忽略数据",charIndex:2144},{level:3,title:"6、管理好技术债务",slug:"_6、管理好技术债务",normalizedTitle:"6、管理好技术债务",charIndex:2374},{level:3,title:"7、远离那些虚荣的东西",slug:"_7、远离那些虚荣的东西",normalizedTitle:"7、远离那些虚荣的东西",charIndex:2603},{level:3,title:"8、做好准备面对压力",slug:"_8、做好准备面对压力",normalizedTitle:"8、做好准备面对压力",charIndex:2986},{level:3,title:"9、了解业务",slug:"_9、了解业务",normalizedTitle:"9、了解业务",charIndex:3379},{level:3,title:"10、做好面对非技术因素的准备",slug:"_10、做好面对非技术因素的准备",normalizedTitle:"10、做好面对非技术因素的准备",charIndex:3721},{level:3,title:"11、对于代码质量有所掌握",slug:"_11、对于代码质量有所掌握",normalizedTitle:"11、对于代码质量有所掌握",charIndex:4107},{level:3,title:"12、让团队做好准备",slug:"_12、让团队做好准备",normalizedTitle:"12、让团队做好准备",charIndex:4432},{level:3,title:"结尾",slug:"结尾",normalizedTitle:"结尾",charIndex:4488},{level:2,title:"Reference",slug:"reference",normalizedTitle:"reference",charIndex:4582}],headersStr:"代码重构思考 烂代码 Clean Code 重构的重要原则 架构之重构的12条军规 前言 1、确定重构的目的和必要性 2、定义“重构完成”的界限 3、渐进式重构 4、确定当前的架构状态 5、不要忽略数据 6、管理好技术债务 7、远离那些虚荣的东西 8、做好准备面对压力 9、了解业务 10、做好面对非技术因素的准备 11、对于代码质量有所掌握 12、让团队做好准备 结尾 Reference",content:"# 代码重构(Refactor)\n\n\n# 代码重构思考\n\n\n# 烂代码\n\n生成烂代码的原因，一般人都会认为有以下几种甚至更过：\n\n 1. 需求变更\n 2. 旧的逻辑难以维护\n 3. 交付压力\n 4. 自己的代码设计(这个是关键)\n\n烂代码产生的一个重要原因是：破窗效应 ---\x3e 惯性 ---\x3e 好的更好，坏的更坏\n\n\n# Clean Code\n\n * 持续集成\n   * 保证日常流程中所有开发人员的code clean\n * Unit Test\n   * 死循环：无单元测试 ---\x3e 不敢动以前代码 ---\x3e 烂代码\n\n\n# 重构的重要原则\n\n * do no harm\n   * 重构过程，首先要做到不伤害\n   * 隔离原有代码，尽量不动原有逻辑，保证原有功能的同时再增加新功能\n * baby step\n   * 一系列小步骤的改进，并逐步验证(测试)\n   * 重构是在不改变原有代码行为的前提下，对其进行的一系列小的改进，逐步完成预期目标\n * 解耦\n   * 重构时一个重要的动作就是要解耦(函数内、函数间等)，否则很难重构\n     * 把数据处理封装，避免需要修改时，到处找数据的使用点进行修改，而造成 漏掉 或者 修改点过多造成工作量过大的问题\n   * 优先重构痛点：经常改动的复杂代码\n   * public函数是流程函数，只应由各种独立功能的函数组成\n * 新旧隔离\n   * 如果没做到新旧代码隔离，会逐步变成各种补丁交叉，造成可读性、可维护性急剧下降\n   * 代码隔离的方法，如：\n     * 新生方法 sprout method\n     * 新生类 sprout class：如，接口、观察者、直接加功能类\n     * 外覆方法 wrapper method\n\n总之：\n\n * 重构不等于重写：重构是小步迭代、逐步验证；重写是，完全推翻重来\n * 对于眼中的烂项目，如果用同样的思路去重构，只不过是一个新的烂项目的开始\n\n\n# 架构之重构的12条军规\n\n\n# 前言\n\n对于开发者来说，架构设计是软件研发过程中最重要的一环，所谓没有图纸，就建不了房子。在遍地App的互联网时代，架构设计有了一些比较成熟的模式，开发者和架构师也可以经常借鉴。\n\n但是，随着应用的不断发展，最初的架构往往面临着各种问题，比如无法满足客户的需求、无法实现应用的扩展、无法实现新的特性等等。在这种情况下，我们如何避免一些坑，尽量比较成功地实现架构的重构，是很多开发者和架构师亟需解决的问题。\n\n在这里，跟大家分享一下Uber的工程主管Raffi Krikorian的12条规则，并附上一些解读，希望对大家有所启发。\n\n\n# 1、确定重构的目的和必要性\n\n看起来这个规矩有些多余，但是请不要忽略。每一次架构的重构都是“伤筋动骨”，就像做手术一样，即使再成功，也会伤元气，所以决策者们首先要分析架构重构的理由和其他备选方案，明确重构的目的是为了满足业务需求，并且是不得不做的最佳方案，然后再考虑其他问题。\n\n检查清单：\n\n * 架构重构的原因是什么，是为了满足业务的需要还是只是觉得架构不好看？\n * 除了架构重构之外，还有其他备选方案吗？是否都分析过这些方案的利弊？\n\n\n# 2、定义“重构完成”的界限\n\n如果确定要重构，那么要把目标明确下来，也就是重构的边界条件，怎么才算是“完成”了重构，目标要有数据量化，或者有能够测试的办法。这也是一个需求分析的过程，如果需求不明确，那么规格说明书没法写清楚，负责重构的团队也没有明确的目标，不能以重构的时间或者主观的判断为结束的依据。\n\n检查清单：\n\n * 重构的目标可以量化，或者说可以测试吗？\n * 重构完成的标准是什么？得到业务部门或者领导的认可了吗？\n\n\n# 3、渐进式重构\n\n现在软件研发最流行的就是快速迭代、持续交付、尽早反馈。这同样可以用在架构的重构上，重构过程的难度不亚于构建一个新产品，所以在设计重构的时候，要引入持续交付的流程，每一个重构步骤或者模块都要快速部署并得到反馈，以便评估重构的效果，及时作出策略调整。\n\n有的人会说，我们的架构重构是釜底抽薪型的，没法渐进，只能一蹴而就。如果是这种情况，可以考虑在另外一套拷贝的系统中做重构，经过谨慎测试之后，将数据和业务迁移过去。\n\n检查清单：\n\n * 能否把重构过程分成小的迭代，每一次改进都能尽快得到反馈？\n * 重构过程中的效果能够定期展示给业务部门或者领导吗？\n\n\n# 4、确定当前的架构状态\n\n在启动重构之前，团队要对当前的架构状态有清晰的了解，也就是设定好基准，以便评估重构的效果。\n\n有些负责重构的架构师或者开发者，往往还没有搞清楚现有的架构设计，就开始重构了，结果经常出现这样的情况：重构到某个阶段，发现行不通，然后一拍脑袋说，哦，原来这块的架构是这个样的，是为了达到某某业务需求啊，这块不能动，得想别的办法。\n\n类似的例子在研发团队中时有发生，也提醒我们要慎重小心。记得有位哲人说过，了解别人很容易，了解自己很难。\n\n检查清单：\n\n * 你了解当前的架构设计吗？它的设计初衷和之前的选型方案知道吗？\n * 你能给架构设定一个基准状态吗？\n\n\n# 5、不要忽略数据\n\n数据的重要性不言而喻，业务都是以数据流为载体的，所以架构重构的本质就是对于数据流的重构。\n\n数据对重构的重要性主要体现在两个方面：\n\n 1. 在重构设计时，需要考虑业务数据的需求，重构之后的系统对于数据的存储、处理、分析等功能是否有影响；\n 2. 在重构过程中，考虑依靠数据甚至是实际的数据来验证重构的效果，提供评估的支持。\n\n检查清单：\n\n * 业务数据的需求在重构设计中有体现吗？\n * 重构过程中能否通过实际数据来验证效果？\n\n\n# 6、管理好技术债务\n\n技术债务就像信用卡一样，会有很高的利息率，就如同给团队留下了大量的帐务开销。\n\n组织应该培养一种保证设计质量的文化。应当鼓励重构、同时也应当鼓励持续设计以及其它有关代码质量的实践。在开发时间中应当专门抽出一部分以解决技术债务。如果没有合适的照料，那么真实世界中的代码会变得越来越复杂难懂。\n\n检查清单：\n\n * 团队对技术债务有跟踪和备忘录机制吗？还是开发人员可以随意的产生债务？\n * 针对技术债务有定期的培训、回顾机制吗？\n\n\n# 7、远离那些虚荣的东西\n\n架构的重构过程应该是以目标为导向，换句话说“注重实效”。\n\n对于技术人来说，一个经常被轻视的问题在于，喜欢追逐新鲜的热门技术，这其实是个好事情，说明技术人勇于创新，不断接受新技术。但是对于架构的重构这样的关键性任务来说，是不是新技术并不重要，重要的是能不能实现重构的目标。\n\n对于新技术来说，虽然热度大，但是人才储备还不足，大家踩过的坑还不多，积累的失败教训和成功经验还不够，在这种情况下，建议大家不要头脑一热就上马新技术，应该客观冷静地评估新技术和成熟技术对架构重构的影响和效果，以数据和经验来说话，而不要追赶时髦。\n\n检查清单：\n\n * 重构的技术选型是否有详实的数据和专家评估？\n * 选用的技术是否有良好的人才积累和足够的经验支持？你是不是实验小白鼠？\n * 在技术选型时，是否至少有两个方案待评估？有没有成熟的技术方案？\n\n\n# 8、做好准备面对压力\n\n这条军规更像是对架构师们的心理建议，软件开发过程中，压力无处不在。\n\n对于架构重构来说，压力来源于多个方面：管理层、团队成员、同级部门等等。说白了，架构重构对个人来说往往是一件出力不讨好的事情。和做一个新产品能够取得很高的赞赏相比，重构的成绩往往并不受领导重视，而且出了问题还要承担很大的责任。从软件开发角度看，做新产品是从0到1，而架构重构是从-1到1，复杂性和难度通常更大。\n\n因此，重构的负责人要提前做好心理准备，舒缓压力的一个技巧是，设置好里程碑，将重构的成果量化，并且和业务的变化关联起来，定期向利益相关各方同步状态，得到大家的理解和支持。\n\n检查清单：\n\n * 架构的重构是否得到了管理层（特别是最高管理层）的支持？他们是否对重构的时间、任务量有直接的认识？\n * 你的重构计划中是否包含了一些可以量化的成果？是否定期向管理层展示这些成果？\n\n\n# 9、了解业务\n\n虽然看起来像是一句废话，但是我想Raffi Krikorian特意把这条提出来一定是有理由的。\n\n架构重构的最终目的是改进业务，所以对于业务的了解将有助于架构师和技术人确定重构目标的优先级和关键路径。比如，我们需要知道哪些关键业务的架构是不能碰的，哪些业务之间是互相关联的，哪些业务的架构是需要优先重构的...等等。\n\n除了了解业务本身，我们还需要了解“人”，表面上管理层是重构目标的裁决者，但实际上业务部门的人才是。技术人需要了解他们的业务需求，并将其转化为重构目标。通过这种方式，架构重构的意义才能得到具体的体现。\n\n检查清单：\n\n * 是否与业务部门就架构重构所能实现的业务目标进行过充分的讨论和确认？\n * 是否对关键业务和优先重构的业务进行了确认？\n\n\n# 10、做好面对非技术因素的准备\n\n恩......这又是一个不那么让人舒服的建议。\n\n不管你是否愿意相信，技术在架构重构（以及其他很关键的公司决策中）的影响因素中并不是最高的，我们还会涉及到商业利益、管理层偏好、大客户影响、办公室zhengzhi等等，对于架构师和技术人来说，这些因素往往不是他们所能掌控的。我们能做的就是，根据不同的影响因素，调整目标。\n\n请记住，不要死扛这个目标，当有人提出不同的意见时，要坦诚地和他们交流，并告知他们如何采纳意见，那么重构目标会有变化，然后让其他利益相关者也知道这些变化。\n\n非技术因素的影响是客观存在的，而且从商业层面来说也是合理的，所以对于技术人来说要学会适应。\n\n检查清单：\n\n * 当非技术因素影响架构的重构时，你是否对目标做了调整并告知了利益相关各方？\n * 你是否准备以开放而不是抵制的心态来对待非技术因素的影响？\n\n\n# 11、对于代码质量有所掌握\n\n这和上文中所提到的“管理好技术债务”有异曲同工之处。\n\n架构的重构对代码质量要求很高，一方面是重构过程对bug的容忍性比新产品的研发更低，另一方面也决定了下一次重构的难易程度。\n\n关于代码质量的书籍和文章已经有很多，在这里只想提醒大家一点：代码审查是一个非常好的办法。代码审查是软件开发过程中的必要步骤，既可以帮助被审查者提到代码质量，又可以让审查者加深对产品的理解。不论团队多忙，一定要保证代码提交之前，是经过其他成员审核过的，短期来看会占用团队的时间，长期来看是事半功倍的好事。\n\n检查清单：\n\n * 团队成员是否对代码质量有足够的重视？是否有奖惩措施？\n * 团队内部是否有代码质量的标准文档和审查流程？\n\n\n# 12、让团队做好准备\n\n这是Raffi Krikorian列举的最后一条军规，是对之前所有建议的总结。\n\n\n# 结尾\n\n关于架构的重构，Raffi Krikorian给了很好的建议，不过到底有没有效果，还是要实践中检验。尽信书不如无书，来源于实践中的经验是最有价值的，为技术人所用才有意义。\n\n\n# Reference\n\n 1. 《重构-改善既有代码的设计》\n 2. 《程序员的职业素养》\n 3. 《修改代码的艺术》\n 4. architect-12-rules-complete",normalizedContent:"# 代码重构(refactor)\n\n\n# 代码重构思考\n\n\n# 烂代码\n\n生成烂代码的原因，一般人都会认为有以下几种甚至更过：\n\n 1. 需求变更\n 2. 旧的逻辑难以维护\n 3. 交付压力\n 4. 自己的代码设计(这个是关键)\n\n烂代码产生的一个重要原因是：破窗效应 ---\x3e 惯性 ---\x3e 好的更好，坏的更坏\n\n\n# clean code\n\n * 持续集成\n   * 保证日常流程中所有开发人员的code clean\n * unit test\n   * 死循环：无单元测试 ---\x3e 不敢动以前代码 ---\x3e 烂代码\n\n\n# 重构的重要原则\n\n * do no harm\n   * 重构过程，首先要做到不伤害\n   * 隔离原有代码，尽量不动原有逻辑，保证原有功能的同时再增加新功能\n * baby step\n   * 一系列小步骤的改进，并逐步验证(测试)\n   * 重构是在不改变原有代码行为的前提下，对其进行的一系列小的改进，逐步完成预期目标\n * 解耦\n   * 重构时一个重要的动作就是要解耦(函数内、函数间等)，否则很难重构\n     * 把数据处理封装，避免需要修改时，到处找数据的使用点进行修改，而造成 漏掉 或者 修改点过多造成工作量过大的问题\n   * 优先重构痛点：经常改动的复杂代码\n   * public函数是流程函数，只应由各种独立功能的函数组成\n * 新旧隔离\n   * 如果没做到新旧代码隔离，会逐步变成各种补丁交叉，造成可读性、可维护性急剧下降\n   * 代码隔离的方法，如：\n     * 新生方法 sprout method\n     * 新生类 sprout class：如，接口、观察者、直接加功能类\n     * 外覆方法 wrapper method\n\n总之：\n\n * 重构不等于重写：重构是小步迭代、逐步验证；重写是，完全推翻重来\n * 对于眼中的烂项目，如果用同样的思路去重构，只不过是一个新的烂项目的开始\n\n\n# 架构之重构的12条军规\n\n\n# 前言\n\n对于开发者来说，架构设计是软件研发过程中最重要的一环，所谓没有图纸，就建不了房子。在遍地app的互联网时代，架构设计有了一些比较成熟的模式，开发者和架构师也可以经常借鉴。\n\n但是，随着应用的不断发展，最初的架构往往面临着各种问题，比如无法满足客户的需求、无法实现应用的扩展、无法实现新的特性等等。在这种情况下，我们如何避免一些坑，尽量比较成功地实现架构的重构，是很多开发者和架构师亟需解决的问题。\n\n在这里，跟大家分享一下uber的工程主管raffi krikorian的12条规则，并附上一些解读，希望对大家有所启发。\n\n\n# 1、确定重构的目的和必要性\n\n看起来这个规矩有些多余，但是请不要忽略。每一次架构的重构都是“伤筋动骨”，就像做手术一样，即使再成功，也会伤元气，所以决策者们首先要分析架构重构的理由和其他备选方案，明确重构的目的是为了满足业务需求，并且是不得不做的最佳方案，然后再考虑其他问题。\n\n检查清单：\n\n * 架构重构的原因是什么，是为了满足业务的需要还是只是觉得架构不好看？\n * 除了架构重构之外，还有其他备选方案吗？是否都分析过这些方案的利弊？\n\n\n# 2、定义“重构完成”的界限\n\n如果确定要重构，那么要把目标明确下来，也就是重构的边界条件，怎么才算是“完成”了重构，目标要有数据量化，或者有能够测试的办法。这也是一个需求分析的过程，如果需求不明确，那么规格说明书没法写清楚，负责重构的团队也没有明确的目标，不能以重构的时间或者主观的判断为结束的依据。\n\n检查清单：\n\n * 重构的目标可以量化，或者说可以测试吗？\n * 重构完成的标准是什么？得到业务部门或者领导的认可了吗？\n\n\n# 3、渐进式重构\n\n现在软件研发最流行的就是快速迭代、持续交付、尽早反馈。这同样可以用在架构的重构上，重构过程的难度不亚于构建一个新产品，所以在设计重构的时候，要引入持续交付的流程，每一个重构步骤或者模块都要快速部署并得到反馈，以便评估重构的效果，及时作出策略调整。\n\n有的人会说，我们的架构重构是釜底抽薪型的，没法渐进，只能一蹴而就。如果是这种情况，可以考虑在另外一套拷贝的系统中做重构，经过谨慎测试之后，将数据和业务迁移过去。\n\n检查清单：\n\n * 能否把重构过程分成小的迭代，每一次改进都能尽快得到反馈？\n * 重构过程中的效果能够定期展示给业务部门或者领导吗？\n\n\n# 4、确定当前的架构状态\n\n在启动重构之前，团队要对当前的架构状态有清晰的了解，也就是设定好基准，以便评估重构的效果。\n\n有些负责重构的架构师或者开发者，往往还没有搞清楚现有的架构设计，就开始重构了，结果经常出现这样的情况：重构到某个阶段，发现行不通，然后一拍脑袋说，哦，原来这块的架构是这个样的，是为了达到某某业务需求啊，这块不能动，得想别的办法。\n\n类似的例子在研发团队中时有发生，也提醒我们要慎重小心。记得有位哲人说过，了解别人很容易，了解自己很难。\n\n检查清单：\n\n * 你了解当前的架构设计吗？它的设计初衷和之前的选型方案知道吗？\n * 你能给架构设定一个基准状态吗？\n\n\n# 5、不要忽略数据\n\n数据的重要性不言而喻，业务都是以数据流为载体的，所以架构重构的本质就是对于数据流的重构。\n\n数据对重构的重要性主要体现在两个方面：\n\n 1. 在重构设计时，需要考虑业务数据的需求，重构之后的系统对于数据的存储、处理、分析等功能是否有影响；\n 2. 在重构过程中，考虑依靠数据甚至是实际的数据来验证重构的效果，提供评估的支持。\n\n检查清单：\n\n * 业务数据的需求在重构设计中有体现吗？\n * 重构过程中能否通过实际数据来验证效果？\n\n\n# 6、管理好技术债务\n\n技术债务就像信用卡一样，会有很高的利息率，就如同给团队留下了大量的帐务开销。\n\n组织应该培养一种保证设计质量的文化。应当鼓励重构、同时也应当鼓励持续设计以及其它有关代码质量的实践。在开发时间中应当专门抽出一部分以解决技术债务。如果没有合适的照料，那么真实世界中的代码会变得越来越复杂难懂。\n\n检查清单：\n\n * 团队对技术债务有跟踪和备忘录机制吗？还是开发人员可以随意的产生债务？\n * 针对技术债务有定期的培训、回顾机制吗？\n\n\n# 7、远离那些虚荣的东西\n\n架构的重构过程应该是以目标为导向，换句话说“注重实效”。\n\n对于技术人来说，一个经常被轻视的问题在于，喜欢追逐新鲜的热门技术，这其实是个好事情，说明技术人勇于创新，不断接受新技术。但是对于架构的重构这样的关键性任务来说，是不是新技术并不重要，重要的是能不能实现重构的目标。\n\n对于新技术来说，虽然热度大，但是人才储备还不足，大家踩过的坑还不多，积累的失败教训和成功经验还不够，在这种情况下，建议大家不要头脑一热就上马新技术，应该客观冷静地评估新技术和成熟技术对架构重构的影响和效果，以数据和经验来说话，而不要追赶时髦。\n\n检查清单：\n\n * 重构的技术选型是否有详实的数据和专家评估？\n * 选用的技术是否有良好的人才积累和足够的经验支持？你是不是实验小白鼠？\n * 在技术选型时，是否至少有两个方案待评估？有没有成熟的技术方案？\n\n\n# 8、做好准备面对压力\n\n这条军规更像是对架构师们的心理建议，软件开发过程中，压力无处不在。\n\n对于架构重构来说，压力来源于多个方面：管理层、团队成员、同级部门等等。说白了，架构重构对个人来说往往是一件出力不讨好的事情。和做一个新产品能够取得很高的赞赏相比，重构的成绩往往并不受领导重视，而且出了问题还要承担很大的责任。从软件开发角度看，做新产品是从0到1，而架构重构是从-1到1，复杂性和难度通常更大。\n\n因此，重构的负责人要提前做好心理准备，舒缓压力的一个技巧是，设置好里程碑，将重构的成果量化，并且和业务的变化关联起来，定期向利益相关各方同步状态，得到大家的理解和支持。\n\n检查清单：\n\n * 架构的重构是否得到了管理层（特别是最高管理层）的支持？他们是否对重构的时间、任务量有直接的认识？\n * 你的重构计划中是否包含了一些可以量化的成果？是否定期向管理层展示这些成果？\n\n\n# 9、了解业务\n\n虽然看起来像是一句废话，但是我想raffi krikorian特意把这条提出来一定是有理由的。\n\n架构重构的最终目的是改进业务，所以对于业务的了解将有助于架构师和技术人确定重构目标的优先级和关键路径。比如，我们需要知道哪些关键业务的架构是不能碰的，哪些业务之间是互相关联的，哪些业务的架构是需要优先重构的...等等。\n\n除了了解业务本身，我们还需要了解“人”，表面上管理层是重构目标的裁决者，但实际上业务部门的人才是。技术人需要了解他们的业务需求，并将其转化为重构目标。通过这种方式，架构重构的意义才能得到具体的体现。\n\n检查清单：\n\n * 是否与业务部门就架构重构所能实现的业务目标进行过充分的讨论和确认？\n * 是否对关键业务和优先重构的业务进行了确认？\n\n\n# 10、做好面对非技术因素的准备\n\n恩......这又是一个不那么让人舒服的建议。\n\n不管你是否愿意相信，技术在架构重构（以及其他很关键的公司决策中）的影响因素中并不是最高的，我们还会涉及到商业利益、管理层偏好、大客户影响、办公室zhengzhi等等，对于架构师和技术人来说，这些因素往往不是他们所能掌控的。我们能做的就是，根据不同的影响因素，调整目标。\n\n请记住，不要死扛这个目标，当有人提出不同的意见时，要坦诚地和他们交流，并告知他们如何采纳意见，那么重构目标会有变化，然后让其他利益相关者也知道这些变化。\n\n非技术因素的影响是客观存在的，而且从商业层面来说也是合理的，所以对于技术人来说要学会适应。\n\n检查清单：\n\n * 当非技术因素影响架构的重构时，你是否对目标做了调整并告知了利益相关各方？\n * 你是否准备以开放而不是抵制的心态来对待非技术因素的影响？\n\n\n# 11、对于代码质量有所掌握\n\n这和上文中所提到的“管理好技术债务”有异曲同工之处。\n\n架构的重构对代码质量要求很高，一方面是重构过程对bug的容忍性比新产品的研发更低，另一方面也决定了下一次重构的难易程度。\n\n关于代码质量的书籍和文章已经有很多，在这里只想提醒大家一点：代码审查是一个非常好的办法。代码审查是软件开发过程中的必要步骤，既可以帮助被审查者提到代码质量，又可以让审查者加深对产品的理解。不论团队多忙，一定要保证代码提交之前，是经过其他成员审核过的，短期来看会占用团队的时间，长期来看是事半功倍的好事。\n\n检查清单：\n\n * 团队成员是否对代码质量有足够的重视？是否有奖惩措施？\n * 团队内部是否有代码质量的标准文档和审查流程？\n\n\n# 12、让团队做好准备\n\n这是raffi krikorian列举的最后一条军规，是对之前所有建议的总结。\n\n\n# 结尾\n\n关于架构的重构，raffi krikorian给了很好的建议，不过到底有没有效果，还是要实践中检验。尽信书不如无书，来源于实践中的经验是最有价值的，为技术人所用才有意义。\n\n\n# reference\n\n 1. 《重构-改善既有代码的设计》\n 2. 《程序员的职业素养》\n 3. 《修改代码的艺术》\n 4. architect-12-rules-complete",charsets:{cjk:!0}},{title:"Skill and Communication",frontmatter:{title:"Skill and Communication",date:"2020-04-13T00:00:00.000Z",description:"技术与交流",permalink:null,categories:["blog","xnote"],tags:[null]},regularPath:"/blog/xnote/about_skill_communication.html",relativePath:"blog/xnote/about_skill_communication.md",key:"v-f76e517a",path:"/blog/xnote/about_skill_communication.html",headers:[{level:2,title:"不完美的故事",slug:"不完美的故事",normalizedTitle:"不完美的故事",charIndex:30},{level:2,title:"思考与总结",slug:"思考与总结",normalizedTitle:"思考与总结",charIndex:45}],headersStr:"不完美的故事 思考与总结",content:"# Skill and Communication\n\n\n# 不完美的故事\n\n\n\n\n\n\n# 思考与总结\n\n专长 ---\x3e (逐渐变化的环境下的)解决问题能力 ---\x3e 善于创造多赢局面\n\n如果“会来事儿”的意思是说“善于创造多赢局面”的话，那这事儿还真的值得好好研究，好好实践。\n\n如果不是, 就别死磕了, 这属于非得用自己的劣势去跟别人的优势竞争, 这样就永远在追赶, 赶不上的。不如换条道,发展垂直领域的能力这个混社会的硬通货, 让自己加入到社会大系统里, 如果你能给别人提供价值, 又不依附于某个特定的系统, 你就不需要会来事儿也可以过得很好了。\n\n\n# Reference\n\n * https://www.zhihu.com/question/20940082",normalizedContent:"# skill and communication\n\n\n# 不完美的故事\n\n\n\n\n\n\n# 思考与总结\n\n专长 ---\x3e (逐渐变化的环境下的)解决问题能力 ---\x3e 善于创造多赢局面\n\n如果“会来事儿”的意思是说“善于创造多赢局面”的话，那这事儿还真的值得好好研究，好好实践。\n\n如果不是, 就别死磕了, 这属于非得用自己的劣势去跟别人的优势竞争, 这样就永远在追赶, 赶不上的。不如换条道,发展垂直领域的能力这个混社会的硬通货, 让自己加入到社会大系统里, 如果你能给别人提供价值, 又不依附于某个特定的系统, 你就不需要会来事儿也可以过得很好了。\n\n\n# reference\n\n * https://www.zhihu.com/question/20940082",charsets:{cjk:!0}},{title:"关于股市",frontmatter:{title:"关于股市",date:"2021-01-03T00:00:00.000Z",description:"about stock",permalink:null,categories:["blog","xnote"],tags:[null]},regularPath:"/blog/xnote/about_stock.html",relativePath:"blog/xnote/about_stock.md",key:"v-15f1fc67",path:"/blog/xnote/about_stock.html",headers:[{level:2,title:"指标",slug:"指标",normalizedTitle:"指标",charIndex:11}],headersStr:"指标",content:"# 关于股市\n\n\n# 指标\n\n# 市净率(PB, price to book value)\n\nPB = 每股股价 / 每股净资产\n\n用市净率估值只适合银行，钢铁水泥，房地产等周期性行业。为什么只适合这几个行业呢？因为这些行业太成熟了，没有高增长，股民就赚不到钱，那就只能在你估值很低的时候买才有钱赚。\n\n# 市盈率(PE, price earnings ratio)\n\nPE = 每股股价 / 每股收益(EPS)\n\n用PE估值的逻辑是基于公司增长的，你出的价格是买它的盈利能力。比如股价是30元，每股盈利是2元，静态市盈率就是15倍，意思就是在公司赚钱能力不增长的情况下，15年收回成本，但如果有增长，就看增长速度的快慢了。\n\n一般我们用静态市盈率，15倍左右就是正常的。但是这个倍数和经验数据只能用在那些稳定增长，有稳定预期的成熟行业，比如消费品，零售，医药酒类等。\n\n# 净资产收益率(ROE, return on equity)\n\nROE = 税后净利润 / 净资产\n\nROE 的标准是15%，和市盈率15倍对应\n\n这个指标反映了公司的赚钱能力到底怎么样，这是核心的指标。什么意思呢？公司投资100块钱，如果赚15块，ROE就是15%，赚20块，ROE就是20%。这个数字越高，说明生意越好，回报率越高，在解读财报的时候这是衡量一个企业资金利用效率的核心指标。\n\n# 市盈率增长率(PEG)\n\nPEG = 市盈率/净利润增长率\n\n如果得出的数值是小于等于1，说明可以买入。数字越大证明泡沫越大，数字越小越安全。\n\n它的核心原理就是你赚钱的速度必须值得你出的价格，因为上市公司的净利润增长速度决定了投资人的赚钱速度，所以至少是1:1的水平，作为投资人才划得来。比如一个公司的市盈率是25倍，但是它的净利润增长率是30%，25/30=0.83，小于1，那么就可以买。而如果这个公司净利润增长率是20%，那么结果就是大于1，就证明这个公司不值这个价格，因为赚钱的速度跟不上。\n\n得出来的数字最小，就证明这个公司越被低估了，越值得买入，超过1就不值得了。\n\n这个公式的神奇之处在于无论你多高的市盈率，我都不怕，只要你的净利润增长速度跟的上，我就不怕，其实挺公平的，你干多少活，我就给你出什么价，你创造的价值要配的上你的工资水平，流水线的工人也好，一个公司的总经理也好，都是根据他赚钱的能力来定价的，\n\n净资产收益率ROE÷市净率PB 净资产收益率是衡量一个公司的赚钱能力，而市净率是衡量一个公司的出价高低，那么拿前者除以后者会怎么样呢？ 因为分母是市净率，市净率越高，证明价格越高，净资产收益率越高，证明赚钱能力越强，所以得出的数值是越高就越好。 这个公式的核心意义在于对比，而不是单看，尤其挑选个股的时候，用着行业的对比上，简直就是一绝。 比如想在白酒行业选一支股票，不知道怎么选: 第一步：把净资产收益率排名前5找出来，由高往低排，越高越有投资价值 第二步：把市净率排名前5找出来，由低往高排，越低越有投资价值 我晕，那二个指标选哪一个？不急，拿净资产收益率除以市净率，得出的数值越高，就证明越有投资价值，这样一来就同时兼顾了赚钱能力和估值了。\n\n预测未来收益法 直接通过市盈率计算 假设一个股票正常的估值是20倍，就可以先算出他应该的每股收益是多少。公式：价格/20估值=应该有的每股收益.这个公式的意思是说，既然你的价格是这么多，那么你的每股收益应该值多少，如果现在真实的每股收益低于这个数，就是不值这个价格。\n\n格雷厄姆的估值法\n\n现金流折现法\n\n彼得林奇的一个著名的论断：任何一家公司的股票如果定价合理的话，市盈率就会与收益增长率相等，这就是【PEG估值法】的来源。计算公式：PEG=PE/公司盈利增长率。PEG=1的时候是合理估值，小于1是低估，大于1是高估。",normalizedContent:"# 关于股市\n\n\n# 指标\n\n# 市净率(pb, price to book value)\n\npb = 每股股价 / 每股净资产\n\n用市净率估值只适合银行，钢铁水泥，房地产等周期性行业。为什么只适合这几个行业呢？因为这些行业太成熟了，没有高增长，股民就赚不到钱，那就只能在你估值很低的时候买才有钱赚。\n\n# 市盈率(pe, price earnings ratio)\n\npe = 每股股价 / 每股收益(eps)\n\n用pe估值的逻辑是基于公司增长的，你出的价格是买它的盈利能力。比如股价是30元，每股盈利是2元，静态市盈率就是15倍，意思就是在公司赚钱能力不增长的情况下，15年收回成本，但如果有增长，就看增长速度的快慢了。\n\n一般我们用静态市盈率，15倍左右就是正常的。但是这个倍数和经验数据只能用在那些稳定增长，有稳定预期的成熟行业，比如消费品，零售，医药酒类等。\n\n# 净资产收益率(roe, return on equity)\n\nroe = 税后净利润 / 净资产\n\nroe 的标准是15%，和市盈率15倍对应\n\n这个指标反映了公司的赚钱能力到底怎么样，这是核心的指标。什么意思呢？公司投资100块钱，如果赚15块，roe就是15%，赚20块，roe就是20%。这个数字越高，说明生意越好，回报率越高，在解读财报的时候这是衡量一个企业资金利用效率的核心指标。\n\n# 市盈率增长率(peg)\n\npeg = 市盈率/净利润增长率\n\n如果得出的数值是小于等于1，说明可以买入。数字越大证明泡沫越大，数字越小越安全。\n\n它的核心原理就是你赚钱的速度必须值得你出的价格，因为上市公司的净利润增长速度决定了投资人的赚钱速度，所以至少是1:1的水平，作为投资人才划得来。比如一个公司的市盈率是25倍，但是它的净利润增长率是30%，25/30=0.83，小于1，那么就可以买。而如果这个公司净利润增长率是20%，那么结果就是大于1，就证明这个公司不值这个价格，因为赚钱的速度跟不上。\n\n得出来的数字最小，就证明这个公司越被低估了，越值得买入，超过1就不值得了。\n\n这个公式的神奇之处在于无论你多高的市盈率，我都不怕，只要你的净利润增长速度跟的上，我就不怕，其实挺公平的，你干多少活，我就给你出什么价，你创造的价值要配的上你的工资水平，流水线的工人也好，一个公司的总经理也好，都是根据他赚钱的能力来定价的，\n\n净资产收益率roe÷市净率pb 净资产收益率是衡量一个公司的赚钱能力，而市净率是衡量一个公司的出价高低，那么拿前者除以后者会怎么样呢？ 因为分母是市净率，市净率越高，证明价格越高，净资产收益率越高，证明赚钱能力越强，所以得出的数值是越高就越好。 这个公式的核心意义在于对比，而不是单看，尤其挑选个股的时候，用着行业的对比上，简直就是一绝。 比如想在白酒行业选一支股票，不知道怎么选: 第一步：把净资产收益率排名前5找出来，由高往低排，越高越有投资价值 第二步：把市净率排名前5找出来，由低往高排，越低越有投资价值 我晕，那二个指标选哪一个？不急，拿净资产收益率除以市净率，得出的数值越高，就证明越有投资价值，这样一来就同时兼顾了赚钱能力和估值了。\n\n预测未来收益法 直接通过市盈率计算 假设一个股票正常的估值是20倍，就可以先算出他应该的每股收益是多少。公式：价格/20估值=应该有的每股收益.这个公式的意思是说，既然你的价格是这么多，那么你的每股收益应该值多少，如果现在真实的每股收益低于这个数，就是不值这个价格。\n\n格雷厄姆的估值法\n\n现金流折现法\n\n彼得林奇的一个著名的论断：任何一家公司的股票如果定价合理的话，市盈率就会与收益增长率相等，这就是【peg估值法】的来源。计算公式：peg=pe/公司盈利增长率。peg=1的时候是合理估值，小于1是低估，大于1是高估。",charsets:{cjk:!0}},{title:"Interesting Xxx",frontmatter:{title:"Interesting Xxx",date:"2021-06-03T00:00:00.000Z",description:"有趣的内容",permalink:null,categories:["blog","xnote"],tags:[null]},regularPath:"/blog/xnote/interesting_xxx.html",relativePath:"blog/xnote/interesting_xxx.md",key:"v-8cf30266",path:"/blog/xnote/interesting_xxx.html",headers:[{level:2,title:"Interesting Repositories",slug:"interesting-repositories",normalizedTitle:"interesting repositories",charIndex:56}],headersStr:"Interesting Repositories",content:"# Interesting Xxx\n\n> JustDoIt\n\n * 凤凰架构：构建可靠的大型分布式系统\n\n\n# Interesting Repositories\n\n * https://github.com/moyada/stealer\n   \n   * 抖音、快手、火山、皮皮虾，视频去水印程序\n\n * VirtualXposed & taichi\n   \n   * https://github.com/taichi-framework/TaiChi\n   * https://github.com/android-hacker/VirtualXposed\n\n * Deploy\n   \n   * snapmod: 带外框的截屏的app\n\n * 幼儿英语启蒙卡片\n\n * 本地密码管理软件 KeePassX\n\n * OBS Studio https://obsproject.com/\n\n * Shotcut https://shotcut.org/\n\n * Apache Superset https://github.com/apache/superset\n   \n   * Apache Superset是一个现代的、轻量级可视化BI分析工具。Apache Superset在可视化、易用性和交互性上非常有特色，用户可以轻松对数据进行可视化分析。而且Apache Superset 已经达到企业级商业软件的水平。\n * ",normalizedContent:"# interesting xxx\n\n> justdoit\n\n * 凤凰架构：构建可靠的大型分布式系统\n\n\n# interesting repositories\n\n * https://github.com/moyada/stealer\n   \n   * 抖音、快手、火山、皮皮虾，视频去水印程序\n\n * virtualxposed & taichi\n   \n   * https://github.com/taichi-framework/taichi\n   * https://github.com/android-hacker/virtualxposed\n\n * deploy\n   \n   * snapmod: 带外框的截屏的app\n\n * 幼儿英语启蒙卡片\n\n * 本地密码管理软件 keepassx\n\n * obs studio https://obsproject.com/\n\n * shotcut https://shotcut.org/\n\n * apache superset https://github.com/apache/superset\n   \n   * apache superset是一个现代的、轻量级可视化bi分析工具。apache superset在可视化、易用性和交互性上非常有特色，用户可以轻松对数据进行可视化分析。而且apache superset 已经达到企业级商业软件的水平。\n * ",charsets:{cjk:!0}},{title:"deep mind",frontmatter:{title:"deep mind",date:"2022-01-17T00:00:00.000Z",description:"深度思维",permalink:null,categories:["blog","xnote"],tags:[null]},regularPath:"/blog/xnote/rnote_deep_mind.html",relativePath:"blog/xnote/rnote_deep_mind.md",key:"v-455450db",path:"/blog/xnote/rnote_deep_mind.html",headers:[{level:2,title:"第一章 思维逻辑链",slug:"第一章-思维逻辑链",normalizedTitle:"第一章 思维逻辑链",charIndex:389},{level:2,title:"第二章 换位思维",slug:"第二章-换位思维",normalizedTitle:"第二章 换位思维",charIndex:460},{level:2,title:"第三章 可视化思维",slug:"第三章-可视化思维",normalizedTitle:"第三章 可视化思维",charIndex:650},{level:2,title:"第四章 流程化思维",slug:"第四章-流程化思维",normalizedTitle:"第四章 流程化思维",charIndex:820},{level:3,title:"秘籍思维的谬误",slug:"秘籍思维的谬误",normalizedTitle:"秘籍思维的谬误",charIndex:834},{level:3,title:"全流程优化",slug:"全流程优化",normalizedTitle:"全流程优化",charIndex:890},{level:2,title:"第五章 生态思维",slug:"第五章-生态思维",normalizedTitle:"第五章 生态思维",charIndex:1731},{level:3,title:"衍生模型I：淘金模型",slug:"衍生模型i-淘金模型",normalizedTitle:"衍生模型i：淘金模型",charIndex:1987},{level:3,title:"衍生模型Ⅱ：森林模型",slug:"衍生模型ii-森林模型",normalizedTitle:"衍生模型ⅱ：森林模型",charIndex:2131},{level:3,title:"衍生模型Ⅲ：池塘模型",slug:"衍生模型iii-池塘模型",normalizedTitle:"衍生模型ⅲ：池塘模型",charIndex:2312},{level:2,title:"第六章 系统思维",slug:"第六章-系统思维",normalizedTitle:"第六章 系统思维",charIndex:2696},{level:2,title:"第七章 大势思维",slug:"第七章-大势思维",normalizedTitle:"第七章 大势思维",charIndex:2946},{level:2,title:"第八章 兵法思维",slug:"第八章-兵法思维",normalizedTitle:"第八章 兵法思维",charIndex:4514},{level:2,title:"第九章 慢即是快",slug:"第九章-慢即是快",normalizedTitle:"第九章 慢即是快",charIndex:4955},{level:3,title:"为什么需要专注",slug:"为什么需要专注",normalizedTitle:"为什么需要专注",charIndex:5038},{level:3,title:"为什么专注很难做到",slug:"为什么专注很难做到",normalizedTitle:"为什么专注很难做到",charIndex:5487},{level:3,title:"精神图腾",slug:"精神图腾",normalizedTitle:"精神图腾",charIndex:5613}],headersStr:"第一章 思维逻辑链 第二章 换位思维 第三章 可视化思维 第四章 流程化思维 秘籍思维的谬误 全流程优化 第五章 生态思维 衍生模型I：淘金模型 衍生模型Ⅱ：森林模型 衍生模型Ⅲ：池塘模型 第六章 系统思维 第七章 大势思维 第八章 兵法思维 第九章 慢即是快 为什么需要专注 为什么专注很难做到 精神图腾",content:'# 深度思维\n\n特点：\n\n 1. 较长的思维逻辑链\n 2. 突破自我为中心的局限性，灵活切换看问题的视角\n 3. 在繁杂的信息流中保持思维能力\n 4. 以宏观视角分析问题，认知事物所处的生态特性、事物长期趋势等\n\n训练：\n\n 1. 深度思维的学习要像知识点一样有明确的、可操作的内容，不能仅仅停留在某种理念的基础上。\n\n技术大师：(主要用于处理日常工作的具体事物，就像一个个小工具，能让你高效的解决问题)\n\n 1. 思维逻辑链\n 2. 换位思维\n 3. 可视化思维\n 4. 流程思维\n\n思维的格局：(能让你站在更高、更广的视角看待问题，以更深刻更巧妙的方式解决问题) 5. 生态思维 6. 系统思维 7. 大势思维 8. 兵法思维 9. 慢即是快\n\n《深度思维》一书无法概括深度思维的全部(实际上任何人都无法穷尽所有的思维方法)，有很多思维方法并没有被纳入到本书中来。\n\n\n# 第一章 思维逻辑链\n\n\n\n * 5Why\n   * 诞生自丰田汽车\n * 5So\n   * 《深度思维》作者开发\n\n逻辑链条概率传导\n\n\n# 第二章 换位思维\n\n如果不懂别人是怎么想的，你的努力或许会白费。你需要建立共同认知、 克服自我中心，才能自如切换视角进行换位思维，将深度思维的功效发挥到极 致。\n\n换位思维，简单的说就是，如果我是他，会怎么想。但，这有个关键条件，得和别人有共同的认知系统。\n\n * 六顶思考帽 (爱德华·德·波诺)\n   * 全局分析、客观事实、感性直觉、乐观思考、保守行事、创新思维。\n\n\n# 第三章 可视化思维\n\n矩阵分析法\n\n * 艾森豪威尔矩阵\n * 安索夫矩阵\n * 创造自己的矩阵类思维工具\n\n工作仪表盘\n\n * 为了让这些重要事项能够经常出现在我们的 工作记忆里，我们需要一个外部的提醒——这就是仪表盘的运作方式。\n\n总的来说，可视化思维的核心在于其原理而不是形态，只要懂得原 理就能自行开发工具，并且千变万化。\n\n\n# 第四章 流程化思维\n\n\n# 秘籍思维的谬误\n\n伟大的成就不是因为有某种秘籍，而是来源于对流程的掌控和优化。你需要识别流程的结构、类型，并学会全流程优化的方法，这才是在真实世界里成长为高手的方法。\n\n秘籍型思维的谬误，似乎从未远离人群。秘籍型思维的本质，是把复杂的东西过于简单化，企图用一个相对简单的秘籍去代替复杂的成功规律。\n\n秘籍型思维的可怕之处在于，他有一部分是正确的。有些时候，一些特定的方法真的是太管用了，一定时间内确实可以"一招鲜吃遍天"，让人短时间内感到无比的兴奋---但从长期来看，这些对单一方法的依赖会让人不再成长。\n\n回拉关系有用吗？有用，真的有用，情商高、会说话也一样，确实有用。所以当家长、前辈、导师们宣称这些秘籍万能的时候，很多人真的容易相信，因为能举出太多的例子来证明这些东西多么有用。一个原本只是有一定作用的东西，被放大成了万能的、唯一的，于是你把全部的希望都押在了一个东西上，继而放弃了对其他事物的观察和学习，最终无可避免的走向失败，这就是秘籍的危险之处。\n\n简单的说，秘籍思维会人为放大某些方法的用处，如果一个东西只有一分用处，而你却误认为它有三分。\n\n秘籍型思维代表了简单情境下个别方法和要点对全局的决定性影响，它往往与复杂的现实生活不符，尤其与经过互联网改造的现代复杂商业社会不符。\n\n\n# 全流程优化\n\n全流程优化，在平凡中创造奇迹的方法。\n\n一件复杂的事情往往由多个流程、步骤组成，把每一个流程、步骤都进行优化，做到(接近)最好，就叫"全流程优化"。\n\n全流程优化具有复利属性。 在计算成本时适用的是加法，而计算成果时适用的是乘法。也就是说，做的好就是全流程优化，对应复利；做不好就成了全流程损耗，对应"复亏"。\n\n * 思考：\n   1. 以电商店铺为例，尝试分析全流程优化\n   2. 因为全流程优化的复利属性，互联网相对传统行业流程更长，兴衰发展更加迅速\n\n现在我们都知道全流程优化非常重要，但有时我们没有那么多资源做全流程优化，只能暂时优化一部分流程，那该怎么办？这时候要借助艾森豪威尔矩阵，而某个流程的重要程度可以从：损益程度、影响广度、扩散度这三个方面来衡量。\n\n\n# 第五章 生态思维\n\n嵌在生态中的个体，将被生态所推动。当你研究一个事物时，不仅要分析个体，更要观察整个生态、洞察期中复杂的规律。\n\n个体 ---\x3e 环境 ---\x3e 生态 ---\x3e 系统\n\n生态思维的核心原理：\n\n * 由于生态中的事物是广泛关联的，所以个体事物的发展趋势、状态变化和各种选择并不是随机的，也不是完全独立自主决定的，而是受到整个生态的影响。因此，思考某个事物的时候，不应当仅仅思考这个个体，还应思考他所处的整个生态--他周围的环境以及他与环境的关系。\n\n思考：游戏主播带货场景，带什么货？\n\n\n# 衍生模型I：淘金模型\n\n淘金模型，竞争再激烈也能赢的思维方式。\n\n十九世纪中前期的美国西部淘金梦中，你应该去，但不是去淘金，而是去卖牛仔裤。\n\n淘金模型的本质是一个共生模型。你会看到其他人，不是只看到竞争者，而是要看到生态中的共生可能性。\n\n思考：老龄化社会的到来，有什么机会？\n\n\n# 衍生模型Ⅱ：森林模型\n\n不是天才的人，如何应对强大的对手\n\n森林模型的本质： 森林模型的本质上是一个生态位模型。生态位是指物种在生态中所处的位置，包括空间、时间、食物种类等因素。生态位思维的核心原理是：当你遭遇强者竞争时，除了与其死拼以外，还可以选择避开他的(时间、空间、食物等)位置。\n\n思考：互联网创业，如果BAT也来做你这个类似的产品，该怎么办？\n\n\n# 衍生模型Ⅲ：池塘模型\n\n如何突破发展的瓶颈\n\n在一个池塘生态中，水草要和藻类争夺养料，蜉蝣生物要避免被小鱼吃掉，小鱼又要躲避大鱼，大鱼之间这要相互竞争食物和繁殖空间。它们的竞争最终造就了池塘的生机。这就是池塘模型，它的本质是平台模型。\n\n你很容易理解平台公司的好处：开淘宝店的未必赚钱，但淘宝平台本身一定赚钱。但，一般人习惯于在别人的平台上活动，但却未思考过或许可以制造一个自己的平台。为什么？一个很重要的原因是：平台看起来太大了。\n\n但我们要意识到，平台不仅是一个结果，也是一种思维：太平洋固然是一个生态，家门口的小池塘也是一个生态。\n\n生态思维告诉你，不要把目光仅聚焦在一个事物上，而要观察思考它的生态，既包括周围的环境，也包括它与周围事物的关系。这一思路的改变，常常能让人豁然开朗、大梦初醒。\n\n思考：游戏主播带货场景，当越来越多的主播带货时，怎么办？\n\n\n# 第六章 系统思维\n\n在更高的层面上解决问题\n\n在复杂的情境中，传统的因果关系被颠覆，微观层面的静态分失效了。你需要站在更高的层面上，以更宏观的、系统的高度去看待和解决问题。\n\n系统思维则要求我们时常留意各个部分之间的关系，认为系统并不等于部分之和。\n\n静态的事物理解起来更容易一些，但动态的系统才是世界频繁展现出的样貌。\n\n从更宏观的角度解决问题：利用系统思维做出大胆的反常的决定。\n\n良性循环是怎么样构建出来的：设计系统结构，做一只无形的大手。\n\n颠覆线性因果，系统结构带来反常规的智慧。\n\n\n# 第七章 大势思维\n\n与宏大的趋势相比，个人的力量是渺小的，只有借助趋势的力量才能在人生中乘风破浪。如何识别趋势并站在趋势之中，是每个想要成就自己的人所要学习的重要课题。\n\n时来天地皆同力。真正伟大的力量是时代的趋势。\n\n趋势，是因为某种内在规律而导致的未来的大概率或者必然走向。\n\n抓住趋势的本质：发现趋势不是瞎猜，是掌握规律。大势思维是对各类宏观规律的具体认知。\n\n越是强大、深刻的规律，就越能造就宏大的、确定性的趋势。\n\n 1. 马太效应\n    * 马太效应的厉害之处在于，它往往比其他规律更加强大。当它和其它规律起冲突的时候，往往能够覆盖、推翻其他规律。\n 2. 人口变化\n    * 人是一切文明与社会经济活动的根基。如果说什么规律能够造就大级别的趋势，那么与人口有关的规律必然是期中之一。\n    * 与人口有关的规律也是非常强大的---比如人口数量与人口结构---当它与其他规律冲突的时候，往往也能够推翻其他规律而保证自己的留存。\n    * 思考，可以思考日本和印度的发展趋势。\n\n大的趋势，大家都能很容易察觉到，既然大家都知道这件事情, 那我知道了又能怎么样呢？能有什么机会呢？\n\n比如二胎政策会让婴幼儿用品产业复苏，老龄化趋势则造就了医疗和养老行业的机会，这些简单的结论很多人都知道了。那么你能够根据这个趋势得出些什么新的东西吗？要大多数人想不到的才有机会。\n\n这个问题也是造成很多人不愿意去关注人口趋势(以及其他趋势)变化的重要原因，以为只能得到一些大家都知道的、显而易见的知识，没太多应用价值。这个问题，是大势思维在现实生活中得到应用的真正瓶颈。\n\n人们很容易看懂一些简单的规律，但不太容易经过精细的思维加工推导出相对复杂的衍生结论。那些被人民广泛知道的简单规律和知识无法带给你特殊的优势，只有少数人通晓的道理才能让你夺得先机。\n\n如果你想思考出一般人不知道的结论，你就需要用到复杂的思维方法了。\n\n以中国的人口规律为例。看完中国的人口年龄结构，只能想到婴儿用品和养老医疗这些路人皆知的事情？没关系，我们试一试把多种思维方法和人口趋势结合起来使用，看看能不能得到什么重要的，真正能指导现实生活的结论。\n\n * 马太效应与人口规律\n   * 小城镇会越发缺少活力，甚至会产生"老人城"、"老人村"，由此带来小城镇的房产会快速贬值...\n * 生态思维与人口规律\n   * 中国的老年人越来越多，但养老和医疗产业的准入门槛太高，我们还有其他机会吗？\n   * 受益于一辈子的储蓄、保险以及房产增值等，这些老年人不缺钱，那他们的休闲娱乐是否会多元化？麻将、广场舞、旅游？以旅游为例，60岁的老人还能有精力去旅游，而70岁的老人可能才需要养老护理。也就是说，老年旅游甚至比养老护理来的更早。\n * 淘金模型\n   * 养老和医疗产业的准入门槛太高，但我们可以从周边入手：养老护理包括场地建设、设备购买、护理人员招聘培训等多个部分。普通人物理拿出几千万上亿的资金入场，但可以从中挑选一些资金投入较低的环节入手，如：护理人员招聘，可以通过劳务中介、代理招聘、中低端猎头等形式。如果你去做一个护理行业的专业性招聘网站或劳务公司，你就成了养老产业大公司的好帮手，与他们共生。\n * 逻辑思维链与人口规律\n   * 二胎政策放开后，迎来了一批新生儿。我们试着通过5Why、5So法综合使用，看看能发现婴幼儿用品市场的哪些新特性。\n   * 会发现：目前的新生儿有很多是有生育想法的妇女的存量消化，这些人的财富比以前会更多，教育观念也会更强...\n   * 就是说：婴幼儿的增速是否稳定尚不确定，需要持续关注；中高端产品更受欢迎；科学教养相关行业会有很好的发展机会。\n\n思考：当下AI的大势扑面而来时，你能发现什么机会呢？\n\n\n# 第八章 兵法思维\n\n人生如打仗，打仗要懂兵法。兵法思维讲述的是这样一些思维模式：如何规避风险，捕捉机会，掌握主动权，以确保在漫长的人生中获得总体上最优的发展。\n\n一次次大大小小的战斗汇聚成了这一场生命的战争。兵法思维，首推《孙子兵法》。\n\n绝大多数兵书都是讲战争的具体技术，而《孙子兵法》则是讲战争之"道"。我们命运的战争不是枪林剑雨，而是学业、人脉、求职、创业等。这些战争需要的是道，而非术。即我们不用持刀枪进退杀伐，而要将深刻的智慧应用于生活，设计自己的人生胜负手。\n\n * 胜兵先胜而后求战，败兵先站而后求胜\n   * 但在某些领域，如投资、创业等，要确定必胜是不可能的。这时候，我们可以考虑借助 凯里公式\n * 善战者，致人而不致于人\n   * 致人而不致于人，简单的说就是要主动不要被动\n * 胜可知，而不可为也\n   * 机会未到时，积极准备先保证自己的不败，但不可妄动；时机到来时，要准确识别并抓住它\n     * 投资界有句名义：最难的不是交易，而是不交易\n\n\n# 第九章 慢即是快\n\n在这个鼓吹少年得志的时代里，对于出身平凡、缺乏资源、没有背景的人来说，专注做好一件事才是大概率的生存知道。慢即是快，这是技术，也是心法。\n\n\n# 为什么需要专注\n\n投入和产出，从来都不是成正比的。我们要意识到，大部分的投入都是不能产生直接价值的。\n\n\n\n可以看到，当你最初投入一些资源的时候，你的能力水平并没有得到飞速提升，更无法因此获得收入。即便再投入一点资源进入快速提升区间，获得了一定的能力成长后，其收入水平也非常一般。只有当投入了大量资源进入高原期以后，收入水平才能迎来真正的大幅增长。\n\n对于那些智力、知识积累、技术水平、人脉、资金等资源本就不出众的人来说，如果他们把有限的资源分散到不同的领域，那么每一个领域都会停留在低速启动区间，他将永远面临较低收入，以及随之而来的各种烦恼。所以，普通人最好的策略就是专注，把所有的力量集中到一点，在一个领域冲进能力的高原区域，并得到金钱上的自由。这是一条对于普通人来说风险最低、成功率最高的道路。\n\n总之，对于资质、背景都很普通的人来说，专注努力是最佳策略。相应地，当你的资源越丰厚、天赋越高时，你进行资源整合、跨界发展、多元化经营的空间也就越大，成功率也就越高---但依然不可高估。\n\n\n# 为什么专注很难做到\n\n其中有两个问题最有共性：\n\n 1. 如果自己倾尽全力投入的大方向就是错的怎么办？\n    * 需要借助深度思维格局篇来帮助确定正确方向\n 2. 加速成长末期的技术难度\n    * 需要借助深度思维技术篇来帮助突破技术难度\n\n\n# 精神图腾\n\n在这个鼓吹少年得志的时代，我更偏爱大器晚成。\n\n精神图腾 --- 大气晚成司马懿。\n\n平均来讲，人的一生每三年就会有一次机会。3年这个数据是经过社会检验的，如工作2-3年后，初级管理职位是一次机会；工作3-4年后，中级管理职位是一次机会...\n\n\n\n根据概率公式，我们可以知道，越到后面，成功的概率越大。没有资源，不是天才，你的命运最大的胜算其实就是概率和时间。\n\n如果说努力和方法开启了成就的可能，专注让这个可能有了一定的提高，那么漫长的生命和时间则将这个概率提高到了可以接受的程度，让你第一次有了对抗命运的主动权。',normalizedContent:'# 深度思维\n\n特点：\n\n 1. 较长的思维逻辑链\n 2. 突破自我为中心的局限性，灵活切换看问题的视角\n 3. 在繁杂的信息流中保持思维能力\n 4. 以宏观视角分析问题，认知事物所处的生态特性、事物长期趋势等\n\n训练：\n\n 1. 深度思维的学习要像知识点一样有明确的、可操作的内容，不能仅仅停留在某种理念的基础上。\n\n技术大师：(主要用于处理日常工作的具体事物，就像一个个小工具，能让你高效的解决问题)\n\n 1. 思维逻辑链\n 2. 换位思维\n 3. 可视化思维\n 4. 流程思维\n\n思维的格局：(能让你站在更高、更广的视角看待问题，以更深刻更巧妙的方式解决问题) 5. 生态思维 6. 系统思维 7. 大势思维 8. 兵法思维 9. 慢即是快\n\n《深度思维》一书无法概括深度思维的全部(实际上任何人都无法穷尽所有的思维方法)，有很多思维方法并没有被纳入到本书中来。\n\n\n# 第一章 思维逻辑链\n\n\n\n * 5why\n   * 诞生自丰田汽车\n * 5so\n   * 《深度思维》作者开发\n\n逻辑链条概率传导\n\n\n# 第二章 换位思维\n\n如果不懂别人是怎么想的，你的努力或许会白费。你需要建立共同认知、 克服自我中心，才能自如切换视角进行换位思维，将深度思维的功效发挥到极 致。\n\n换位思维，简单的说就是，如果我是他，会怎么想。但，这有个关键条件，得和别人有共同的认知系统。\n\n * 六顶思考帽 (爱德华·德·波诺)\n   * 全局分析、客观事实、感性直觉、乐观思考、保守行事、创新思维。\n\n\n# 第三章 可视化思维\n\n矩阵分析法\n\n * 艾森豪威尔矩阵\n * 安索夫矩阵\n * 创造自己的矩阵类思维工具\n\n工作仪表盘\n\n * 为了让这些重要事项能够经常出现在我们的 工作记忆里，我们需要一个外部的提醒——这就是仪表盘的运作方式。\n\n总的来说，可视化思维的核心在于其原理而不是形态，只要懂得原 理就能自行开发工具，并且千变万化。\n\n\n# 第四章 流程化思维\n\n\n# 秘籍思维的谬误\n\n伟大的成就不是因为有某种秘籍，而是来源于对流程的掌控和优化。你需要识别流程的结构、类型，并学会全流程优化的方法，这才是在真实世界里成长为高手的方法。\n\n秘籍型思维的谬误，似乎从未远离人群。秘籍型思维的本质，是把复杂的东西过于简单化，企图用一个相对简单的秘籍去代替复杂的成功规律。\n\n秘籍型思维的可怕之处在于，他有一部分是正确的。有些时候，一些特定的方法真的是太管用了，一定时间内确实可以"一招鲜吃遍天"，让人短时间内感到无比的兴奋---但从长期来看，这些对单一方法的依赖会让人不再成长。\n\n回拉关系有用吗？有用，真的有用，情商高、会说话也一样，确实有用。所以当家长、前辈、导师们宣称这些秘籍万能的时候，很多人真的容易相信，因为能举出太多的例子来证明这些东西多么有用。一个原本只是有一定作用的东西，被放大成了万能的、唯一的，于是你把全部的希望都押在了一个东西上，继而放弃了对其他事物的观察和学习，最终无可避免的走向失败，这就是秘籍的危险之处。\n\n简单的说，秘籍思维会人为放大某些方法的用处，如果一个东西只有一分用处，而你却误认为它有三分。\n\n秘籍型思维代表了简单情境下个别方法和要点对全局的决定性影响，它往往与复杂的现实生活不符，尤其与经过互联网改造的现代复杂商业社会不符。\n\n\n# 全流程优化\n\n全流程优化，在平凡中创造奇迹的方法。\n\n一件复杂的事情往往由多个流程、步骤组成，把每一个流程、步骤都进行优化，做到(接近)最好，就叫"全流程优化"。\n\n全流程优化具有复利属性。 在计算成本时适用的是加法，而计算成果时适用的是乘法。也就是说，做的好就是全流程优化，对应复利；做不好就成了全流程损耗，对应"复亏"。\n\n * 思考：\n   1. 以电商店铺为例，尝试分析全流程优化\n   2. 因为全流程优化的复利属性，互联网相对传统行业流程更长，兴衰发展更加迅速\n\n现在我们都知道全流程优化非常重要，但有时我们没有那么多资源做全流程优化，只能暂时优化一部分流程，那该怎么办？这时候要借助艾森豪威尔矩阵，而某个流程的重要程度可以从：损益程度、影响广度、扩散度这三个方面来衡量。\n\n\n# 第五章 生态思维\n\n嵌在生态中的个体，将被生态所推动。当你研究一个事物时，不仅要分析个体，更要观察整个生态、洞察期中复杂的规律。\n\n个体 ---\x3e 环境 ---\x3e 生态 ---\x3e 系统\n\n生态思维的核心原理：\n\n * 由于生态中的事物是广泛关联的，所以个体事物的发展趋势、状态变化和各种选择并不是随机的，也不是完全独立自主决定的，而是受到整个生态的影响。因此，思考某个事物的时候，不应当仅仅思考这个个体，还应思考他所处的整个生态--他周围的环境以及他与环境的关系。\n\n思考：游戏主播带货场景，带什么货？\n\n\n# 衍生模型i：淘金模型\n\n淘金模型，竞争再激烈也能赢的思维方式。\n\n十九世纪中前期的美国西部淘金梦中，你应该去，但不是去淘金，而是去卖牛仔裤。\n\n淘金模型的本质是一个共生模型。你会看到其他人，不是只看到竞争者，而是要看到生态中的共生可能性。\n\n思考：老龄化社会的到来，有什么机会？\n\n\n# 衍生模型ⅱ：森林模型\n\n不是天才的人，如何应对强大的对手\n\n森林模型的本质： 森林模型的本质上是一个生态位模型。生态位是指物种在生态中所处的位置，包括空间、时间、食物种类等因素。生态位思维的核心原理是：当你遭遇强者竞争时，除了与其死拼以外，还可以选择避开他的(时间、空间、食物等)位置。\n\n思考：互联网创业，如果bat也来做你这个类似的产品，该怎么办？\n\n\n# 衍生模型ⅲ：池塘模型\n\n如何突破发展的瓶颈\n\n在一个池塘生态中，水草要和藻类争夺养料，蜉蝣生物要避免被小鱼吃掉，小鱼又要躲避大鱼，大鱼之间这要相互竞争食物和繁殖空间。它们的竞争最终造就了池塘的生机。这就是池塘模型，它的本质是平台模型。\n\n你很容易理解平台公司的好处：开淘宝店的未必赚钱，但淘宝平台本身一定赚钱。但，一般人习惯于在别人的平台上活动，但却未思考过或许可以制造一个自己的平台。为什么？一个很重要的原因是：平台看起来太大了。\n\n但我们要意识到，平台不仅是一个结果，也是一种思维：太平洋固然是一个生态，家门口的小池塘也是一个生态。\n\n生态思维告诉你，不要把目光仅聚焦在一个事物上，而要观察思考它的生态，既包括周围的环境，也包括它与周围事物的关系。这一思路的改变，常常能让人豁然开朗、大梦初醒。\n\n思考：游戏主播带货场景，当越来越多的主播带货时，怎么办？\n\n\n# 第六章 系统思维\n\n在更高的层面上解决问题\n\n在复杂的情境中，传统的因果关系被颠覆，微观层面的静态分失效了。你需要站在更高的层面上，以更宏观的、系统的高度去看待和解决问题。\n\n系统思维则要求我们时常留意各个部分之间的关系，认为系统并不等于部分之和。\n\n静态的事物理解起来更容易一些，但动态的系统才是世界频繁展现出的样貌。\n\n从更宏观的角度解决问题：利用系统思维做出大胆的反常的决定。\n\n良性循环是怎么样构建出来的：设计系统结构，做一只无形的大手。\n\n颠覆线性因果，系统结构带来反常规的智慧。\n\n\n# 第七章 大势思维\n\n与宏大的趋势相比，个人的力量是渺小的，只有借助趋势的力量才能在人生中乘风破浪。如何识别趋势并站在趋势之中，是每个想要成就自己的人所要学习的重要课题。\n\n时来天地皆同力。真正伟大的力量是时代的趋势。\n\n趋势，是因为某种内在规律而导致的未来的大概率或者必然走向。\n\n抓住趋势的本质：发现趋势不是瞎猜，是掌握规律。大势思维是对各类宏观规律的具体认知。\n\n越是强大、深刻的规律，就越能造就宏大的、确定性的趋势。\n\n 1. 马太效应\n    * 马太效应的厉害之处在于，它往往比其他规律更加强大。当它和其它规律起冲突的时候，往往能够覆盖、推翻其他规律。\n 2. 人口变化\n    * 人是一切文明与社会经济活动的根基。如果说什么规律能够造就大级别的趋势，那么与人口有关的规律必然是期中之一。\n    * 与人口有关的规律也是非常强大的---比如人口数量与人口结构---当它与其他规律冲突的时候，往往也能够推翻其他规律而保证自己的留存。\n    * 思考，可以思考日本和印度的发展趋势。\n\n大的趋势，大家都能很容易察觉到，既然大家都知道这件事情, 那我知道了又能怎么样呢？能有什么机会呢？\n\n比如二胎政策会让婴幼儿用品产业复苏，老龄化趋势则造就了医疗和养老行业的机会，这些简单的结论很多人都知道了。那么你能够根据这个趋势得出些什么新的东西吗？要大多数人想不到的才有机会。\n\n这个问题也是造成很多人不愿意去关注人口趋势(以及其他趋势)变化的重要原因，以为只能得到一些大家都知道的、显而易见的知识，没太多应用价值。这个问题，是大势思维在现实生活中得到应用的真正瓶颈。\n\n人们很容易看懂一些简单的规律，但不太容易经过精细的思维加工推导出相对复杂的衍生结论。那些被人民广泛知道的简单规律和知识无法带给你特殊的优势，只有少数人通晓的道理才能让你夺得先机。\n\n如果你想思考出一般人不知道的结论，你就需要用到复杂的思维方法了。\n\n以中国的人口规律为例。看完中国的人口年龄结构，只能想到婴儿用品和养老医疗这些路人皆知的事情？没关系，我们试一试把多种思维方法和人口趋势结合起来使用，看看能不能得到什么重要的，真正能指导现实生活的结论。\n\n * 马太效应与人口规律\n   * 小城镇会越发缺少活力，甚至会产生"老人城"、"老人村"，由此带来小城镇的房产会快速贬值...\n * 生态思维与人口规律\n   * 中国的老年人越来越多，但养老和医疗产业的准入门槛太高，我们还有其他机会吗？\n   * 受益于一辈子的储蓄、保险以及房产增值等，这些老年人不缺钱，那他们的休闲娱乐是否会多元化？麻将、广场舞、旅游？以旅游为例，60岁的老人还能有精力去旅游，而70岁的老人可能才需要养老护理。也就是说，老年旅游甚至比养老护理来的更早。\n * 淘金模型\n   * 养老和医疗产业的准入门槛太高，但我们可以从周边入手：养老护理包括场地建设、设备购买、护理人员招聘培训等多个部分。普通人物理拿出几千万上亿的资金入场，但可以从中挑选一些资金投入较低的环节入手，如：护理人员招聘，可以通过劳务中介、代理招聘、中低端猎头等形式。如果你去做一个护理行业的专业性招聘网站或劳务公司，你就成了养老产业大公司的好帮手，与他们共生。\n * 逻辑思维链与人口规律\n   * 二胎政策放开后，迎来了一批新生儿。我们试着通过5why、5so法综合使用，看看能发现婴幼儿用品市场的哪些新特性。\n   * 会发现：目前的新生儿有很多是有生育想法的妇女的存量消化，这些人的财富比以前会更多，教育观念也会更强...\n   * 就是说：婴幼儿的增速是否稳定尚不确定，需要持续关注；中高端产品更受欢迎；科学教养相关行业会有很好的发展机会。\n\n思考：当下ai的大势扑面而来时，你能发现什么机会呢？\n\n\n# 第八章 兵法思维\n\n人生如打仗，打仗要懂兵法。兵法思维讲述的是这样一些思维模式：如何规避风险，捕捉机会，掌握主动权，以确保在漫长的人生中获得总体上最优的发展。\n\n一次次大大小小的战斗汇聚成了这一场生命的战争。兵法思维，首推《孙子兵法》。\n\n绝大多数兵书都是讲战争的具体技术，而《孙子兵法》则是讲战争之"道"。我们命运的战争不是枪林剑雨，而是学业、人脉、求职、创业等。这些战争需要的是道，而非术。即我们不用持刀枪进退杀伐，而要将深刻的智慧应用于生活，设计自己的人生胜负手。\n\n * 胜兵先胜而后求战，败兵先站而后求胜\n   * 但在某些领域，如投资、创业等，要确定必胜是不可能的。这时候，我们可以考虑借助 凯里公式\n * 善战者，致人而不致于人\n   * 致人而不致于人，简单的说就是要主动不要被动\n * 胜可知，而不可为也\n   * 机会未到时，积极准备先保证自己的不败，但不可妄动；时机到来时，要准确识别并抓住它\n     * 投资界有句名义：最难的不是交易，而是不交易\n\n\n# 第九章 慢即是快\n\n在这个鼓吹少年得志的时代里，对于出身平凡、缺乏资源、没有背景的人来说，专注做好一件事才是大概率的生存知道。慢即是快，这是技术，也是心法。\n\n\n# 为什么需要专注\n\n投入和产出，从来都不是成正比的。我们要意识到，大部分的投入都是不能产生直接价值的。\n\n\n\n可以看到，当你最初投入一些资源的时候，你的能力水平并没有得到飞速提升，更无法因此获得收入。即便再投入一点资源进入快速提升区间，获得了一定的能力成长后，其收入水平也非常一般。只有当投入了大量资源进入高原期以后，收入水平才能迎来真正的大幅增长。\n\n对于那些智力、知识积累、技术水平、人脉、资金等资源本就不出众的人来说，如果他们把有限的资源分散到不同的领域，那么每一个领域都会停留在低速启动区间，他将永远面临较低收入，以及随之而来的各种烦恼。所以，普通人最好的策略就是专注，把所有的力量集中到一点，在一个领域冲进能力的高原区域，并得到金钱上的自由。这是一条对于普通人来说风险最低、成功率最高的道路。\n\n总之，对于资质、背景都很普通的人来说，专注努力是最佳策略。相应地，当你的资源越丰厚、天赋越高时，你进行资源整合、跨界发展、多元化经营的空间也就越大，成功率也就越高---但依然不可高估。\n\n\n# 为什么专注很难做到\n\n其中有两个问题最有共性：\n\n 1. 如果自己倾尽全力投入的大方向就是错的怎么办？\n    * 需要借助深度思维格局篇来帮助确定正确方向\n 2. 加速成长末期的技术难度\n    * 需要借助深度思维技术篇来帮助突破技术难度\n\n\n# 精神图腾\n\n在这个鼓吹少年得志的时代，我更偏爱大器晚成。\n\n精神图腾 --- 大气晚成司马懿。\n\n平均来讲，人的一生每三年就会有一次机会。3年这个数据是经过社会检验的，如工作2-3年后，初级管理职位是一次机会；工作3-4年后，中级管理职位是一次机会...\n\n\n\n根据概率公式，我们可以知道，越到后面，成功的概率越大。没有资源，不是天才，你的命运最大的胜算其实就是概率和时间。\n\n如果说努力和方法开启了成就的可能，专注让这个可能有了一定的提高，那么漫长的生命和时间则将这个概率提高到了可以接受的程度，让你第一次有了对抗命运的主动权。',charsets:{cjk:!0}},{title:"ARCHITECTURE(极客时间)摘要",frontmatter:{title:"ARCHITECTURE(极客时间)摘要",date:"2020-04-13T00:00:00.000Z",description:"ARCHITECTURE(极客时间)摘要",permalink:null,categories:["blog","xnote"],tags:[null]},regularPath:"/blog/xnote/rnote_geekbang_architecture.html",relativePath:"blog/xnote/rnote_geekbang_architecture.md",key:"v-162635f9",path:"/blog/xnote/rnote_geekbang_architecture.html",headers:[{level:2,title:"ARCHITECTURE",slug:"architecture",normalizedTitle:"architecture",charIndex:2},{level:3,title:"概况",slug:"概况",normalizedTitle:"概况",charIndex:128},{level:2,title:"目录",slug:"目录",normalizedTitle:"目录",charIndex:760},{level:2,title:"开篇",slug:"开篇",normalizedTitle:"开篇",charIndex:797},{level:2,title:"01 | 架构到底是指什么？",slug:"_01-架构到底是指什么",normalizedTitle:"01 | 架构到底是指什么？",charIndex:803},{level:2,title:"02 | 架构设计的历史背景",slug:"_02-架构设计的历史背景",normalizedTitle:"02 | 架构设计的历史背景",charIndex:821},{level:2,title:"03 | 架构设计的目的",slug:"_03-架构设计的目的",normalizedTitle:"03 | 架构设计的目的",charIndex:839},{level:2,title:"04 | 复杂度来源：高性能",slug:"_04-复杂度来源-高性能",normalizedTitle:"04 | 复杂度来源：高性能",charIndex:855},{level:2,title:"05 | 复杂度来源：高可用",slug:"_05-复杂度来源-高可用",normalizedTitle:"05 | 复杂度来源：高可用",charIndex:873},{level:2,title:"06 | 复杂度来源：可扩展性",slug:"_06-复杂度来源-可扩展性",normalizedTitle:"06 | 复杂度来源：可扩展性",charIndex:891},{level:2,title:"07 | 复杂度来源：低成本、安全、规模",slug:"_07-复杂度来源-低成本、安全、规模",normalizedTitle:"07 | 复杂度来源：低成本、安全、规模",charIndex:910},{level:2,title:"08 | 架构设计三原则",slug:"_08-架构设计三原则",normalizedTitle:"08 | 架构设计三原则",charIndex:934},{level:2,title:"09 | 架构设计原则案例",slug:"_09-架构设计原则案例",normalizedTitle:"09 | 架构设计原则案例",charIndex:950},{level:2,title:"10 | 架构设计流程：识别复杂度",slug:"_10-架构设计流程-识别复杂度",normalizedTitle:"10 | 架构设计流程：识别复杂度",charIndex:967},{level:2,title:"11 | 架构设计流程：设计备选方案",slug:"_11-架构设计流程-设计备选方案",normalizedTitle:"11 | 架构设计流程：设计备选方案",charIndex:988},{level:2,title:"12 | 架构设计流程：评估和选择备选方案",slug:"_12-架构设计流程-评估和选择备选方案",normalizedTitle:"12 | 架构设计流程：评估和选择备选方案",charIndex:1010},{level:2,title:"13 | 架构设计流程：详细方案设计",slug:"_13-架构设计流程-详细方案设计",normalizedTitle:"13 | 架构设计流程：详细方案设计",charIndex:1035},{level:2,title:"14 | 高性能数据库集群：读写分离",slug:"_14-高性能数据库集群-读写分离",normalizedTitle:"14 | 高性能数据库集群：读写分离",charIndex:1057},{level:2,title:"15 | 高性能数据库集群：分库分表",slug:"_15-高性能数据库集群-分库分表",normalizedTitle:"15 | 高性能数据库集群：分库分表",charIndex:1079},{level:2,title:"16 | 高性能NoSQL",slug:"_16-高性能nosql",normalizedTitle:"16 | 高性能nosql",charIndex:1101},{level:2,title:"17 | 高性能缓存架构",slug:"_17-高性能缓存架构",normalizedTitle:"17 | 高性能缓存架构",charIndex:1118},{level:2,title:"18 | 单服务器高性能模式：PPC与TPC",slug:"_18-单服务器高性能模式-ppc与tpc",normalizedTitle:"18 | 单服务器高性能模式：ppc与tpc",charIndex:1134},{level:2,title:"19 | 单服务器高性能模式：Reactor与Proactor",slug:"_19-单服务器高性能模式-reactor与proactor",normalizedTitle:"19 | 单服务器高性能模式：reactor与proactor",charIndex:1160},{level:2,title:"20 | 高性能负载均衡：分类及架构",slug:"_20-高性能负载均衡-分类及架构",normalizedTitle:"20 | 高性能负载均衡：分类及架构",charIndex:1195},{level:2,title:"21 | 高性能负载均衡：算法",slug:"_21-高性能负载均衡-算法",normalizedTitle:"21 | 高性能负载均衡：算法",charIndex:1217},{level:2,title:"22 | 想成为架构师，你必须知道CAP理论",slug:"_22-想成为架构师-你必须知道cap理论",normalizedTitle:"22 | 想成为架构师，你必须知道cap理论",charIndex:1236},{level:2,title:"23 | 想成为架构师，你必须掌握的CAP细节",slug:"_23-想成为架构师-你必须掌握的cap细节",normalizedTitle:"23 | 想成为架构师，你必须掌握的cap细节",charIndex:1262},{level:2,title:"24 | FMEA方法，排除架构可用性隐患的利器",slug:"_24-fmea方法-排除架构可用性隐患的利器",normalizedTitle:"24 | fmea方法，排除架构可用性隐患的利器",charIndex:1289},{level:2,title:"25 | 高可用存储架构：双机架构",slug:"_25-高可用存储架构-双机架构",normalizedTitle:"25 | 高可用存储架构：双机架构",charIndex:1317},{level:2,title:"26 | 高可用存储架构：集群和分区",slug:"_26-高可用存储架构-集群和分区",normalizedTitle:"26 | 高可用存储架构：集群和分区",charIndex:1338},{level:2,title:"27 | 如何设计计算高可用架构？",slug:"_27-如何设计计算高可用架构",normalizedTitle:"27 | 如何设计计算高可用架构？",charIndex:1360},{level:2,title:"28 | 业务高可用的保障：异地多活架构",slug:"_28-业务高可用的保障-异地多活架构",normalizedTitle:"28 | 业务高可用的保障：异地多活架构",charIndex:1381},{level:2,title:"29 | 异地多活设计4大技巧",slug:"_29-异地多活设计4大技巧",normalizedTitle:"29 | 异地多活设计4大技巧",charIndex:1405},{level:2,title:"30 | 异地多活设计4步走",slug:"_30-异地多活设计4步走",normalizedTitle:"30 | 异地多活设计4步走",charIndex:1424},{level:2,title:"31 | 如何应对接口级的故障？",slug:"_31-如何应对接口级的故障",normalizedTitle:"31 | 如何应对接口级的故障？",charIndex:1442},{level:2,title:"32 | 可扩展架构的基本思想和模式",slug:"_32-可扩展架构的基本思想和模式",normalizedTitle:"32 | 可扩展架构的基本思想和模式",charIndex:1462},{level:2,title:"33 | 传统的可扩展架构模式：分层架构和SOA",slug:"_33-传统的可扩展架构模式-分层架构和soa",normalizedTitle:"33 | 传统的可扩展架构模式：分层架构和soa",charIndex:1484},{level:2,title:"34 | 深入理解微服务架构：银弹 or 焦油坑？",slug:"_34-深入理解微服务架构-银弹-or-焦油坑",normalizedTitle:"34 | 深入理解微服务架构：银弹 or 焦油坑？",charIndex:1512},{level:2,title:"35 | 微服务架构最佳实践 - 方法篇",slug:"_35-微服务架构最佳实践-方法篇",normalizedTitle:"35 | 微服务架构最佳实践 - 方法篇",charIndex:1541},{level:2,title:"36 | 微服务架构最佳实践 - 基础设施篇",slug:"_36-微服务架构最佳实践-基础设施篇",normalizedTitle:"36 | 微服务架构最佳实践 - 基础设施篇",charIndex:1565},{level:2,title:"37 | 微内核架构详解",slug:"_37-微内核架构详解",normalizedTitle:"37 | 微内核架构详解",charIndex:1591},{level:2,title:"38 | 架构师应该如何判断技术演进的方向？",slug:"_38-架构师应该如何判断技术演进的方向",normalizedTitle:"38 | 架构师应该如何判断技术演进的方向？",charIndex:1607},{level:2,title:"39 | 互联网技术演进的模式",slug:"_39-互联网技术演进的模式",normalizedTitle:"39 | 互联网技术演进的模式",charIndex:1633},{level:2,title:"40 | 互联网架构模板：“存储层”技术",slug:"_40-互联网架构模板-存储层-技术",normalizedTitle:"40 | 互联网架构模板：“存储层”技术",charIndex:1652},{level:2,title:"41 | 互联网架构模板：“开发层”和“服务层”技术",slug:"_41-互联网架构模板-开发层-和-服务层-技术",normalizedTitle:"41 | 互联网架构模板：“开发层”和“服务层”技术",charIndex:1676},{level:2,title:"42 | 互联网架构模板：“网络层”技术",slug:"_42-互联网架构模板-网络层-技术",normalizedTitle:"42 | 互联网架构模板：“网络层”技术",charIndex:1706},{level:2,title:"43 | 互联网架构模板：“用户层”和“业务层”技术",slug:"_43-互联网架构模板-用户层-和-业务层-技术",normalizedTitle:"43 | 互联网架构模板：“用户层”和“业务层”技术",charIndex:1730},{level:2,title:"44 | 互联网架构模板：“平台”技术",slug:"_44-互联网架构模板-平台-技术",normalizedTitle:"44 | 互联网架构模板：“平台”技术",charIndex:1760},{level:2,title:"45 | 架构重构内功心法第一式：有的放矢",slug:"_45-架构重构内功心法第一式-有的放矢",normalizedTitle:"45 | 架构重构内功心法第一式：有的放矢",charIndex:1783},{level:2,title:"46 | 架构重构内功心法第二式：合纵连横",slug:"_46-架构重构内功心法第二式-合纵连横",normalizedTitle:"46 | 架构重构内功心法第二式：合纵连横",charIndex:1808},{level:2,title:"47 | 架构重构内功心法第三式：运筹帷幄",slug:"_47-架构重构内功心法第三式-运筹帷幄",normalizedTitle:"47 | 架构重构内功心法第三式：运筹帷幄",charIndex:1833},{level:2,title:"48 | 再谈开源项目：如何选择、使用以及二次开发？",slug:"_48-再谈开源项目-如何选择、使用以及二次开发",normalizedTitle:"48 | 再谈开源项目：如何选择、使用以及二次开发？",charIndex:1858},{level:2,title:"49 | 谈谈App架构的演进",slug:"_49-谈谈app架构的演进",normalizedTitle:"49 | 谈谈app架构的演进",charIndex:1888},{level:2,title:"50 | 架构实战：架构设计文档模板",slug:"_50-架构实战-架构设计文档模板",normalizedTitle:"50 | 架构实战：架构设计文档模板",charIndex:1907},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:1929},{level:2,title:"END",slug:"end",normalizedTitle:"end",charIndex:1935}],headersStr:"ARCHITECTURE 概况 目录 开篇 01 | 架构到底是指什么？ 02 | 架构设计的历史背景 03 | 架构设计的目的 04 | 复杂度来源：高性能 05 | 复杂度来源：高可用 06 | 复杂度来源：可扩展性 07 | 复杂度来源：低成本、安全、规模 08 | 架构设计三原则 09 | 架构设计原则案例 10 | 架构设计流程：识别复杂度 11 | 架构设计流程：设计备选方案 12 | 架构设计流程：评估和选择备选方案 13 | 架构设计流程：详细方案设计 14 | 高性能数据库集群：读写分离 15 | 高性能数据库集群：分库分表 16 | 高性能NoSQL 17 | 高性能缓存架构 18 | 单服务器高性能模式：PPC与TPC 19 | 单服务器高性能模式：Reactor与Proactor 20 | 高性能负载均衡：分类及架构 21 | 高性能负载均衡：算法 22 | 想成为架构师，你必须知道CAP理论 23 | 想成为架构师，你必须掌握的CAP细节 24 | FMEA方法，排除架构可用性隐患的利器 25 | 高可用存储架构：双机架构 26 | 高可用存储架构：集群和分区 27 | 如何设计计算高可用架构？ 28 | 业务高可用的保障：异地多活架构 29 | 异地多活设计4大技巧 30 | 异地多活设计4步走 31 | 如何应对接口级的故障？ 32 | 可扩展架构的基本思想和模式 33 | 传统的可扩展架构模式：分层架构和SOA 34 | 深入理解微服务架构：银弹 or 焦油坑？ 35 | 微服务架构最佳实践 - 方法篇 36 | 微服务架构最佳实践 - 基础设施篇 37 | 微内核架构详解 38 | 架构师应该如何判断技术演进的方向？ 39 | 互联网技术演进的模式 40 | 互联网架构模板：“存储层”技术 41 | 互联网架构模板：“开发层”和“服务层”技术 42 | 互联网架构模板：“网络层”技术 43 | 互联网架构模板：“用户层”和“业务层”技术 44 | 互联网架构模板：“平台”技术 45 | 架构重构内功心法第一式：有的放矢 46 | 架构重构内功心法第二式：合纵连横 47 | 架构重构内功心法第三式：运筹帷幄 48 | 再谈开源项目：如何选择、使用以及二次开发？ 49 | 谈谈App架构的演进 50 | 架构实战：架构设计文档模板 总结 END",content:"# ARCHITECTURE\n\n> Architecture is like teenage sex， everybody talks about it， nobody really knows what is it。\n\n> 架构是一门平衡的艺术\n\n\n# 概况\n\n * 简述\n   * 业务驱动技术，技术解决业务问题。\n   * 不同的技术，通过树状结构，组合在一起，形成了一个完整的架构解决方案，有效完成业务的目标。\n * 权利\n   * 所有的架构分拆，都应该是形成树状的结果\n     * 因为：切分出来的部分的负责人，对这个部分的权利和义务必须是对等的。架构师没有话语权，还架什么构\n     * 架构师必须是一个组织的领导人，有权利调动这个组织的架构，才能够更好的发挥架构师的作用\n * 责任\n   * 找问题\n     * 找出问题的主体，是做架构的首要问题。架构师都要有这个自觉：发现问题永远都比解决问题来的更加重要。\n       * 我们一定要明白，任何找上架构师的问题，绝对都不是真正的问题，因为如果是真正的问题的话，提问题的人肯定都能够自己解决了\n         * 两个问题：如果问题不解决，究竟谁会有利益的损失？如果问题解决了，究竟谁会有收益，谁的收益最大？\n   * 找技术\n     * 准确识别采用什么技术的能力，也是架构师所要具备的能力之一。\n       * 这就要求了解这项技术解决的是谁的问题？什么问题？\n         * 例子：比如当我们需要一个锤子时，手边正好没有，但是却有一只高跟鞋，勉强也可以替代锤子。但是长期来看，这么用不划算，因为价格、耐用性、维护成本相差很多。\n\n----------------------------------------\n\n\n\n\n\n# 目录\n\n * ARCHITECTURE\n   * 概况\n * 目录\n * 开篇\n * 01 | 架构到底是指什么？\n * 02 | 架构设计的历史背景\n * 03 | 架构设计的目的\n * 04 | 复杂度来源：高性能\n * 05 | 复杂度来源：高可用\n * 06 | 复杂度来源：可扩展性\n * 07 | 复杂度来源：低成本、安全、规模\n * 08 | 架构设计三原则\n * 09 | 架构设计原则案例\n * 10 | 架构设计流程：识别复杂度\n * 11 | 架构设计流程：设计备选方案\n * 12 | 架构设计流程：评估和选择备选方案\n * 13 | 架构设计流程：详细方案设计\n * 14 | 高性能数据库集群：读写分离\n * 15 | 高性能数据库集群：分库分表\n * 16 | 高性能NoSQL\n * 17 | 高性能缓存架构\n * 18 | 单服务器高性能模式：PPC与TPC\n * 19 | 单服务器高性能模式：Reactor与Proactor\n * 20 | 高性能负载均衡：分类及架构\n * 21 | 高性能负载均衡：算法\n * 22 | 想成为架构师，你必须知道CAP理论\n * 23 | 想成为架构师，你必须掌握的CAP细节\n * 24 | FMEA方法，排除架构可用性隐患的利器\n * 25 | 高可用存储架构：双机架构\n * 26 | 高可用存储架构：集群和分区\n * 27 | 如何设计计算高可用架构？\n * 28 | 业务高可用的保障：异地多活架构\n * 29 | 异地多活设计4大技巧\n * 30 | 异地多活设计4步走\n * 31 | 如何应对接口级的故障？\n * 32 | 可扩展架构的基本思想和模式\n * 33 | 传统的可扩展架构模式：分层架构和SOA\n * 34 | 深入理解微服务架构：银弹 or 焦油坑？\n * 35 | 微服务架构最佳实践 - 方法篇\n * 36 | 微服务架构最佳实践 - 基础设施篇\n * 37 | 微内核架构详解\n * 38 | 架构师应该如何判断技术演进的方向？\n * 39 | 互联网技术演进的模式\n * 40 | 互联网架构模板：“存储层”技术\n * 41 | 互联网架构模板：“开发层”和“服务层”技术\n * 42 | 互联网架构模板：“网络层”技术\n * 43 | 互联网架构模板：“用户层”和“业务层”技术\n * 44 | 互联网架构模板：“平台”技术\n * 45 | 架构重构内功心法第一式：有的放矢\n * 46 | 架构重构内功心法第二式：合纵连横\n * 47 | 架构重构内功心法第三式：运筹帷幄\n * 48 | 再谈开源项目：如何选择、使用以及二次开发？\n * 49 | 谈谈App架构的演进\n * 50 | 架构实战：架构设计文档模板\n * 总结\n * END\n\n\n\n\n页首\n\n\n# 开篇\n\n * 架构师的核心能力还是技术能力，过硬的技术才是良好沟通的基础\n * 架构设计的思维和程序设计的思维差异很大\n   * 架构设计的关键思维是判断和取舍，程序设计的关键思维是逻辑和实现\n * 本课程的目的\n   * 清楚地理解架构设计相关的概念、本质、目的\n   * 掌握通用的架构设计原则\n   * 掌握标准的架构设计流程\n   * 深入理解已有的架构模式, 熟练使用并创新\n * 架构的主要复杂性\n   * 高可用性、高性能、可伸缩、可扩展、安全性、稳定性、可维护性、健壮性等\n\n\n\n\n页首\n\n\n# 01 | 架构到底是指什么？\n\n * 系统与子系统、模块与组件、框架与架构\n   * 系统与子系统\n     * 二者只是角度(规模)不一样，子系统是系统的一部分, 一个系统可能是另一个更大系统的子系统\n       * 系统: 由一群有关联的个体组成的, 这些个体按照指定的规则运作，产生了新的能力。\n       * 例如，汽车能够载重前进，而发动机、变速器、传动轴、车轮本身都不具备这样的能力。\n   * 模块和组件\n     * 两个概念在实际工作中很容易混淆, 其实它们都是系统的组成部分，只是从不同的角度拆分系统而已\n       * 模块: 从逻辑的角度来拆分系统后，划分模块的主要目的是业务上职责分离\n       * 组件: 从物理的角度来拆分系统后，划分组件的主要目的是技术上单元复用。\n         * 其实，“组件”的英文 component 也可译为“零件”，这样更容易理解一些，“零件”是一个物理的概念，具备“独立且可替换”的特点。\n   * 框架与架构\n     * 框架(Framework)关注的是“规范”，架构(Architecture)关注的是“结构”。从英文名字可以看出不同之处。\n       * 架构可以以不同的角度进行分解，如：业务逻辑、物理部署、开发规范等。这就是 IBM 的 RUP 将软件架构视图分为著名的“4+1 视图”的原因。\n         * 例如，可以思考下 “学生管理系统” 的架构\n           * 业务逻辑：登录注册、个人信息 以及 个人成绩，物理：nginx、web服务器 以及 数据库，开发规范: MVC 架构\n       * 作者将架构重新定义为：软件架构指软件系统的顶层结构。\n         * 架构需要明确: 一群关联个体, 以及个体运作和协作的规则。\n     * 理解\n       * 框架是一种约束，而架构侧重于方向的指导\n       * 架构的结果是系统，系统是利用一系列个体(子系统、模块等)和规则达到既定目标。\n\n\n\n\n页首\n\n\n# 02 | 架构设计的历史背景\n\n * 架构是为了解决复杂性\n   * 演化史\n     * 机器语言 -> 汇编语言 -> 高级语言 -> 第一次软件危机与结构化程序设计 -> 第二次软件危机与面向对象 -> 软件架构\n   * 而只有规模较大的软件系统才会面临软件架构相关的问题，例如：系统规模庞大，内部耦合严重，开发效率低，后续修改和扩展困难, 容易出问题且很难排查和修复；\n   * 随着软件系统规模的增加，计算相关的算法和数据结构不再构成主要的设计问题；当系统由许多部分组成时，整个系统的组织，也就是所说的“软件架构”，导致了一系列新的设计问题。\n * 思考题\n   * 为何结构化编程、面向对象编程、软件工程、架构设计最后都没有成为软件领域的银弹？\n     * 思考: 唯一不变的是变化本身, 业务会随着时间越来越复杂\n\n\n\n\n页首\n\n\n# 03 | 架构设计的目的\n\n * 目的\n   * 解决软件系统复杂度带来的问题\n     * 复杂度包含了业务复杂度、资源、成本、进度、团队状态等因素，并且尽量量化\n     * 一般的一个架构师一般可以支撑20人以上的开发团队\n * 简单的复杂度分析案例\n   * 设计一个大学的学生管理系统，其基本功能包括登录、注册、成绩管理、课程管理等。\n * 思考题\n   * 按照“架构设计的主要目的是为了解决软件复杂度带来的问题”这个指导思想来分析一下你目前的业务系统架构\n\n\n\n\n页首\n\n\n# 04 | 复杂度来源：高性能\n\n * 高性能带来的复杂度主要体现在两方面\n   * 单台计算机内部为了高性能带来的复杂度\n     * 需要考虑如多进程、多线程、进程间通信、多线程并发等技术点\n       * 例如，Nginx 可以用多进程也可以用多线程，JBoss 采用的是多线程；Redis 采用的是单进程，Memcache 采用的是多线程，这些系统都实现了高性能，但内部实现差异却很大。\n   * 多台计算机集群为了高性能带来的复杂度\n     * 例如，淘宝\"双11\"，春节微信红包等\n     * 方案\n       * 任务分配\n         * 集群中每个主机的工作内容一样，都是完整任务流程\n           * 当流量特别高时，任务分配器(如，lvs、nginx、F5等)也会成为瓶颈\n       * 任务分解\n         * 将复杂任务拆解出子任务，再对子任务做高性能\n           * 拆分粒度过细，会带来其他的复杂性。如，调用链太长影响性能等\n         * 优点：\n           * 简单的系统更加容易做到高性能\n           * 可以针对单个任务进行扩展，更有针对性\n         * 例如\n           * 微信后台架构从逻辑上将各个子业务进行了拆分，包括：接入、注册登录、消息、LBS、摇一摇、漂流瓶、其他业务（聊天、视频、朋友圈等）。\n * 思考题\n   * 你所在的业务体系中，高性能的系统采用的是哪种方式？目前是否有改进和提升的空间？\n\n\n\n\n页首\n\n\n# 05 | 复杂度来源：高可用\n\n * 核心：冗余备份与失效转移\n   * 主备：冷备、热备、温备\n   * 具体实践的过程中，存在一个本质的矛盾：通过冗余来实现的高可用系统，状态决策本质上就不可能做到完全正确。\n * 场景\n   * 计算高可用\n     * 有一个特点就是无论在哪台机器上进行计算，同样的算法和输入数据，产出的结果都是一样的\n   * 存储高可用\n     * 难点不在于如何备份数据，而在于如何减少或者规避数据不一致对业务造成的影响。\n     * 存储与计算相比，一个本质上的区别：将数据从一台机器搬到到另一台机器，需要经过线路进行传输。\n       * 线路传输的速度是毫秒级别，同一机房内部能够做到几毫秒；分布在不同地方的机房，传输耗时需要几十甚至上百毫秒。\n         * 例如，从广州机房到北京机房，稳定情况下 ping 延时大约是50ms，不稳定情况下可能达到 1s 甚至更多。\n * 高可用状态决策\n   * 独裁式\n   * 协商式\n     * 协商式决策指的是两个独立的个体通过交流信息，然后根据规则进行决策，最常用的协商式决策就是主备决策。\n       * 协商式决策的架构不复杂，规则也不复杂，其难点在于，如果如果两者的信息交换出现问题（比如主备连接中断），此时状态决策应该怎么做。\n   * 民主式\n     * 民主式决策指的是多个独立的个体通过投票的方式来进行状态决策。例如，ZooKeeper 集群在选举 leader 时就是采用这种方式\n       * 容易产生脑裂，且选举算法复杂\n         * 为了解决脑裂问题，民主式决策的系统一般都采用“投票节点数必须超过系统总节点数一半”规则来处理。\n           * 这种方式虽然解决了脑裂问题，但同时降低了系统整体的可用性，即如果系统不是因为脑裂问题导致投票节点数过少，而真的是因为节点故障，此时系统也不会选出主节点，整个系统就相当于宕机了\n * 思考题\n   * 高性能和高可用是很多系统的核心复杂度，你认为哪个会更复杂一些？理由是什么？\n\n\n\n\n页首\n\n\n# 06 | 复杂度来源：可扩展性\n\n * 设计具备良好可扩展性的系统，有两个基本条件：正确预测变化、完美封装变化\n * 正确预测变化\n   * 唯一不变的是变化\n   * 复杂性在于：不可能每点都考虑可扩展性，也不能不考虑扩展性，所有的预测都有出错可能性\n   * 预测更多的是靠自己的经验、直觉\n * 应对变化\n   * 封装变化，隔离不变\n     * 这也是'设计模式'的思想, '规则引擎'亦是如此\n     * 封装变化常用的方式：提炼出一个“抽象层”和一个“实现层”, 抽象层对外提供相对稳定的接口，实现层根据具体业务定制开发。\n   * 注意：\n     * 太灵活会造成混乱\n * 思考题\n   * 你在具体代码中使用过哪些可扩展的技术？最终的效果如何？\n\n\n\n\n页首\n\n\n# 07 | 复杂度来源：低成本、安全、规模\n\n * 低成本的复杂度体现在：引入新技术或创造新技术\n   * 引入新技术。主要复杂度在于需要去熟悉新技术，并且将新技术与已有技术结合；\n   * 开创新技术。主要复杂度在于需要去创造全新的理念和技术，或组合现有技术或完全创新\n     * 往往只有“创新”才能达到低成本目标，如：\n       * Linkedin 为了处理每天 5 千亿的事件，开发了高效的 Kafka 消息系统。\n       * 新浪微博将传统的 Redis/MC + MySQL 方式，扩展为 Redis/MC + SSD Cache + MySQL 方式，SSD Cache 作为 L2 缓存使用，既解决了 MC/Redis 成本过高，容量小的问题，也解决了穿透 DB 带来的数据库访问压力（来源：https://www.infoq.cn/article/weibo-platform-archieture）\n * 安全的复杂度体现在：功能安全和架构安全\n   * 功能安全(其实就是“防小偷”, 本质是漏洞)\n     * 常见的 XSS 攻击、CSRF 攻击、SQL 注入、Windows 漏洞、密码破解等，本质上是因为系统实现有漏洞。\n   * 架构安全(其实就是“防强盗”, 本质是故意破坏)\n     * 如 DDOS。传统的架构安全主要依靠防火墙，防火墙最基本的功能就是隔离网络，通过将网络划分成不同的区域，制定出不同区域之间的访问控策略来控制不同信任程度区域间传送的数据流。\n * 规模的复杂度体现在：量变引起质变\n   * 功能越来越多\n     * 假设系统间的功能都是两两相关的，系统的复杂度 = 功能数量 + 功能之间的连接数量. 随着功能的增多，复杂度近乎指数的增长。\n   * 数据越来越多\n     * MYSQL单表一般推荐在 5000 万行左右。如果因为业务的发展，单表数据达到了 10 亿行，就会产生很多问题，例如：\n       * 添加索引、修改表结构会很慢，可能需要几个小时，这几个小时内数据库表是无法插入数据的，相当于业务停机了。\n       * 即使有索引，索引的性能也可能会很低，因为数据量太大。\n       * 数据库备份耗时很长。\n     * 如果拆表，则会带来：怎么拆？拆了之后事务和查询等使用方式？等复杂度\n * 思考题\n   * 学习了 6 大复杂度来源后，结合你所在的业务，分析一下主要的复杂度是这其中的哪些部分？是否还有其他复杂度原因？\n\n\n\n\n页首\n\n\n# 08 | 架构设计三原则\n\n * 三原则：合适 > 演化 > 简单\n   * 合适原则\n     * 合适优于业界领先\n     * 真正优秀的架构都是在企业当前人力、条件、业务等各种约束下设计出来的，能够合理地将资源整合在一起并发挥出最大功效，并且能够快速落地。\n     * 常见的失败原因\n       * 没那么多人，却想干那么多活\n       * 没有那么多积累，却想一步登天\n         * 业界领先的方案其实都是“逼”出来的！\n       * 没有那么卓越的业务场景，却幻想灵光一闪成为天才\n         * 没有qq的用户量，却按照qq的体量进行设计\n   * 简单原则\n     * 简单由于复杂：\n       * 越来越精细、越来越复杂是正常的演化，但一步到位时会大大增加复杂度和不可控程度\n       * 架构是在指导演化方向和范围，尽可能的简单时会更健壮\n     * 《UNIX 编程艺术》总结的 KISS（Keep It Simple, Stupid!）原则一样适应于架构设计。\n   * 演化原则\n     * 演化优于一步到位\n     * 根据环境的变化，演化架构进行适应当前阶段\n * 思考题\n   * 这三条架构设计原则是否每次都要全部遵循？是否有优先级？谈谈你的理解，并说说为什么。\n\n\n\n\n页首\n\n\n# 09 | 架构设计原则案例\n\n * 案例\n   * 淘宝网 和 QQ\n * 思考题\n   * 搜索一个互联网大厂（BATJ、TMD 等）的架构发展案例，分析一下其发展过程，看看哪些地方体现了这三条架构设计原则。\n * reference\n   * <淘宝技术这十年>\n\n\n\n\n页首\n\n\n# 10 | 架构设计流程：识别复杂度\n\n * 识别复杂度\n   * 将主要的复杂度问题列出来，然后根据业务、技术、团队等综合情况进行排序，优先解决当前面临的最主要的复杂度问题。\n     * 设计的目标应该以峰值来计算。峰值一般取平均值的 3 倍。\n   * 常见系统的性能量级需要烂熟于心\n     * 例如nginx负载均衡性能是3万左右，mc的读取性能5万左右，kafka号称百万级，zookeeper写入读取2万以上，http请求访问大概在2万左右。\n\n\n\n\n页首\n\n\n# 11 | 架构设计流程：设计备选方案\n\n * 备选方案\n   * 以3-5个为佳\n     * 少于3个，则显得思路狭隘(可以防止思维狭隘，目光短浅，思维盲区等决策陷阱); 多于5个则浪费精力\n   * 备选方案之间要差异明显\n     * 例如，主备方案和集群方案差异就很明显，或者同样是主备方案，用 ZooKeeper 做主备决策和用 Keepalived 做主备决策的差异也很明显。但是都用 ZooKeeper 做主备决策，一个检测周期是 1 分钟，一个检测周期是 5 分钟，这就不是架构上的差异，而是细节上的差异了，不适合做成两个方案。\n   * 备选方案的技术不要局限于已经熟悉的技术方案\n     * 设计架构时，架构师需要将视野放宽，考虑更多可能性。\n * 备选方案不宜过于详细\n   * 备选阶段关注的是技术选型，而不是技术细节，技术选型的差异要比较明显\n   * 备选方案过于详细的缺点：\n     * 耗费了大量的时间和精力。\n     * 将注意力集中到细节中，忽略了整体的技术设计，导致备选方案数量不够或者差异不大。\n     * 评审的时候其他人会被很多细节给绕进去，评审效果很差。\n\n\n\n\n页首\n\n\n# 12 | 架构设计流程：评估和选择备选方案\n\n * 360 度环评\n   * 具体的操作方式为：列出我们需要关注的质量属性点，然后分别从这些质量属性的维度去评估每个方案，再综合挑选适合当时情况的最优方案。\n     * 常见的方案质量属性点有：性能、可用性、硬件成本、项目投入、复杂度、安全性、可扩展性等。\n * 案例: 业务消息的可靠传输\n   * 方案环评\n   * 结论：最终选择备选方案 2，原因有： 排除备选方案 1 的主要原因是可运维性; 并且 Kafka 的主要设计目标是高性能日志传输，而我们的消息队列设计的主要目标是业务消息的可靠传输。 排除备选方案 3 的主要原因是复杂度，目前团队技术实力和人员人员规模（总共 6 人，还有其他中间件系统需要开发和维护） 备选方案 2 的优点就是复杂度不高，也可以很好地融入现有运维体系，可靠性也有保障。\n   * 方案二缺点：\n     * 性能、成本、看起来不优雅\n * 思考题\n   * RocketMQ 和 Kafka 有什么区别，阿里为何选择了RocketMQ ？\n\n\n\n\n页首\n\n\n# 13 | 架构设计流程：详细方案设计\n\n * 详细方案设计就是将方案涉及的关键技术细节给确定下来\n   * 深度理解关键细节点，避免因为遗漏了某个关键技术点或者关键的质量属性造成方案的执行出现问题\n   * 通过分步骤、分阶段、分系统等方式，尽量降低方案执行复杂度\n * 架构师需要做哪些技术验证，或者研究到什么深度以后，才能判断该技术是否适合呢？\n   * 基本原理，优点缺点，关键设计点，架构师至少要安装过，编写demo体验过，确定选型后，要进行性能和可用性测试例如es的索性设计就是关键设计点\n\n\n\n\n页首\n\n\n# 14 | 高性能数据库集群：读写分离\n\n * 高性能数据库集群的两种方式：读写分离、分库分表\n\n * 读写分离\n   \n   * 实现\n     * 搭建主从集群，主负责读写，从只负责读，通过复制主机数据到从节点到达数据一致。\n     * 业务服务器将写操作发送给主节点，读操作分散到从节点。\n     * 注意：\n       * 是主从集群，不是主备集群\n   * 复杂度\n     * 主从复制延迟\n       1. 写操作后的读操作指定发给数据库主服务器\n          * 对业务的侵入和影响较大\n       2. 读从机失败后再读一次主机(二次读取)\n       3. 关键业务读写操作全部指向主机，非关键业务采用读写分离\n     * 分配机制\n       * 程序代码封装\n         * 程序代码封装指在代码中抽象一个数据访问层（所以有的文章也称这种方式为“中间层封装”），实现读写操作分离和数据库服务器连接的管理\n           * 目前开源的实现方案中，淘宝的 TDDL（TTaobao Distributed Data Layer，外号: 头都大了）是比较有名的。\n       * 中间件封装\n         * 中间件对业务服务器提供 SQL 兼容的协议，业务服务器无须自己进行读写分离。\n         * 对于业务服务器来说，访问中间件和访问数据库没有区别，\n           * 现在 MySQL 官方推荐 MySQL Router\n           * 奇虎 360 公司也开源了自己的数据库中间件 Atlas，Atlas 是基于 MySQL Proxy 实现的\n\n * 分库分表\n   \n   * 见下节内容\n\n * 思考题\n   \n   * 数据库读写分离一般应用于什么场景？能支撑多大的业务规模？\n     * 读写分离适用单机并发无法支撑并且读的请求更多的情形。在单机数据库情况下，表上加索引一般对查询有优化作用却影响写入速度，读写分离后可以单独对读库进行优化，写库上减少索引，对读写的能力都有提升，且读的提升更多一些。\n     * 不适用的情况:\n       * 1 如果并发写入特别高，单机写入无法支撑，就不适合这种模式。\n       * 2 通过缓存技术或者程序优化能够满足要求\n\n\n\n\n页首\n\n\n# 15 | 高性能数据库集群：分库分表\n\n * 分库分表：原因\n   * 单个数据库服务器存储的数据量不能太大。\n     * 当数据量达到千万甚至上亿条的时候，单台数据库服务器的存储能力会成为系统的瓶颈，主要体现在这几个方面：\n       * 数据量太大，读写的性能会下降，即使有索引，索引也会变得很大，，性能同样会下降。\n       * 数据文件会变得很大，数据库备份和恢复需要耗费很长时间\n       * 数据文件越大，极端情况下丢失数据的风险越高（例如，机房火灾导致数据库主备机都发生故障）。\n * 分库\n   * join 操作问题、事务问题、成本问题\n     * 业务分库后，原本在同一个数据库中的表分散到不同数据库中，导致无法使用 SQL 的 join 查询。\n     * 原本在同一个数据库中不同的表可以在同一个事务中修改，业务分库后，表分散到不同的数据库中，无法通过事务统一修改。虽然数据库厂商提供了一些分布式事务的解决方案（例如，MySQL 的 XA），但性能实在太低，与高性能存储的目标是相违背的。\n * 分表\n   * 垂直分表\n     * 垂直分表引入的复杂性主要体现在表操作的数量要增加。原来只要一次查询就可以的，现在要两次或者多次查询。\n   * 水平分表\n     * 路由、join操作、count()操作、order by()操作\n * 实现\n   * 分库分表具体的实现方式也是“程序代码封装”和“中间件封装”，但实现会更复杂。\n     * 读写分离实现时只要识别 SQL 操作是读操作还是写操作，通过简单的判断 SELECT、UPDATE、INSERT、DELETE 几个关键字就可以做到\n     * 分库分表的实现除了要判断操作类型外，还要判断 SQL 中具体需要操作的表、操作函数（例如 count 函数)、order by、group by 操作等，然后再根据不同的操作进行不同的处理。\n * 思考题\n   * 你认为什么时候引入分库分表是合适的？是数据库性能不够的时候就开始分库分表么？\n * utility\n   * 如果使用hash进行分表的话，为什么大多方案推荐2的n次方作为表的总数，除了收缩容易还有什么好处吗？\n     * 这个是hash函数实现的一个技巧，当计算hash值的时候，普通做法是取余操作，例如h%len，但如果len是2的N次方，通过位操作性能更高，计算方式为h & (len-1)\n   * 针对mysql，发现如果字段有blob的字段，select 不写这个字段，和写这个字段，效率差异很大，这个是什么原因？\n     * blob的字段是和行数据分开存储的，而且磁盘上并不是连续的，因此select blob字段会让磁盘进入随机IO模式\n\n\n\n\n页首\n\n\n# 16 | 高性能NoSQL\n\n * NoSQL\n   * NoSQL != No SQL，而是 NoSQL = Not Only SQL\n   * 本质上是牺牲 ACID 中的某个或者某几个特性，因此我们不能盲目地迷信 NoSQL 是银弹，而应该将 NoSQL 作为 SQL 的一个有力补充，\n * 常见的 NoSQL 方案分为 4 类\n   * K-V 存储：解决关系数据库无法存储数据结构的问题，以 Redis 为代表。\n   * 文档数据库：解决关系数据库强 schema 约束的问题，以 MongoDB 为代表。\n   * 列式数据库：解决关系数据库大数据场景下的 I/O 问题，以 HBase 为代表。\n   * 全文搜索引擎：解决关系数据库的全文搜索性能问题，以 Elasticsearch 为代表。\n     * 传统的关系型数据库通过索引来达到快速查询的目的，但是在全文搜索的业务场景下，索引也无能为力，主要体现在：\n       * 全文搜索的条件可以随意排列组合，如果通过索引来满足，则索引的数量会非常多。\n       * 全文搜索的模糊匹配方式，索引无法满足，只能用 like 查询，like 查询是整表扫描，效率非常低。\n\n\n\n\n页首\n\n\n# 17 | 高性能缓存架构\n\n * 缓存系统\n   * 缓存穿透: 查询一定不存在的数据时, 查询回源db。流量大(大量的不存在数据请求)时db被压垮\n     * 布隆过滤器、缓存空值(生命周期短)\n   * 缓存击穿：缓存一种非常“热点”的数据，在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，瞬间把后端DB压垮\n     * 互斥锁(mutex key)、不过期(但后台多线程刷新)\n   * 缓存雪崩：设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩\n     * 多副本，并且每个副本设置不同的过期时间(在指定范围内随机)\n     * 双key策略：要缓存的key过期时间是t，key1没有过期时间。当读取不到key时就返回key1的内容，然后触发一个同时更新key和key1的事件\n * 缓存的更新\n   * 1. 同步刷新缓存：当更新了某些信息后，立刻让缓存失效。\n     * 这种做法的优点是用户体验好，缺点是修改一个数据可能需要让很多缓存失效\n   * 2. 适当容忍不一致：例如某东的商品就是这样，我查询的时候显示有货，下单的时候提示我没货了\n   * 3. 关键信息不缓存：库存，价格等不缓存，因为这类信息查询简单，效率高，关系数据库查询性能也很高\n * 思考题\n   * 分享一下你所在的业务发生过哪些因为缓存导致的线上问题？采取了什么样的解决方案？效果如何？\n\n\n\n\n页首\n\n\n# 18 | 单服务器高性能模式：PPC与TPC\n\n * 单服务器高性能模式：PPC 与 TPC\n   * PPC 是 Process Per Connection 的缩写，其含义是指每次有新的连接就新建一个进程去专门处理这个连接的请求，这是传统的 UNIX 网络服务器所采用的模型。\n     * 一般情况下，PPC 方案能处理的并发连接数量最大也就几百。\n   * TPC 是 Thread Per Connection 的缩写，其含义是指每次有新的连接就新建一个线程去专门处理这个连接的请求。\n * 为什么说门户网站是海量连接常量请求的情况？\n   * 海量连接：连接的用户很多\n   * 常量请求：每个用户请求数量不多，大部分都是看完一篇文章再去点击另外的文章\n * 思考题\n   * 什么样的系统比较适合本期所讲的高性能模式？原因是什么？\n     * 常量连接常量请求：例如内部运营系统，管理系统\n\n\n\n\n页首\n\n\n# 19 | 单服务器高性能模式：Reactor与Proactor\n\n * Reactor与Proactor\n   * IO操作分两个阶段\n     * 1、等待数据准备好(读到内核缓存)\n     * 2、将数据从内核读到用户空间(进程空间)\n     * 一般来说1花费的时间远远大于2\n   * 1上阻塞2上也阻塞的是同步阻塞IO\n   * 1上非阻塞2阻塞的是同步非阻塞IO，这讲说的Reactor就是这种模型\n   * 1上非阻塞2上非阻塞是异步非阻塞IO，这讲说的Proactor模型就是这种模型\n\n\n\n\n页首\n\n\n# 20 | 高性能负载均衡：分类及架构\n\n * 高性能集群的复杂性主要体现在:\n   * 需要增加一个任务分配器，以及为任务选择一个合适的任务分配算法。\n * 负载均衡分类，常见的负载均衡系统包括 3 种：\n   * DNS 负载均衡\n   * 硬件负载均衡\n     * 目前业界典型的硬件负载均衡设备有两款：F5 和 A10。\n     * 优点\n       * 功能强大：全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡\n       * 性能强大：软件负载均衡支持到 10 万级并发已经很厉害了，硬件负载均衡可以支持 100 万以上的并发。\n       * 稳定性高：\n       * 支持安全防护：\n     * 缺点: 贵、扩展能力差(可以配置但无法定制)\n   * 软件负载均衡。\n     * 常见的有 Nginx 和 LVS、Haproxy，其中 Nginx 是软件的的 7 层负载均衡，LVS 是 Linux 内核的 4 层负载均衡\n       * Ngxin 的性能是万级，一般的 Linux 服务器上装一个Nginx 大概能到 5 万 / 秒；LVS 的性能是十万级，据说可达到 80 万 / 秒；而 F5 性能是百万级\n     * 优点：简单、便宜、灵活\n     * 缺点：性能一般\n * 组合的基本原则为：\n   * DNS 负载均衡用于实现地理级别的负载均衡；硬件负载均衡用于实现集群级别的负载均衡；软件负载均衡用于实现机器级别的负载均衡。\n * 思考题\n   * 假设你来设计一个日活跃用户 1000 万的论坛的负载均衡集群，你的方案是什么？设计理由是什么？\n     * dau --\x3e 10h/day + 单用户请求 --\x3e qps、tps --\x3e 峰值 ~ qps * (3-5) --\x3e 以峰值来设计\n\n\n\n\n页首\n\n\n# 21 | 高性能负载均衡：算法\n\n * 负载均衡算法：\n   * 轮询\n   * 加权轮询\n     * 解决不同服务器处理能力有差异的问题\n   * 负载最低优先\n     * 站在服务器的角度来进行分配的\n   * 性能最高优先\n     * 站在客户端的角度来进行分配的\n * 思考题\n   * 微信抢红包的高并发架构，应该采取什么样的负载均衡算法？谈谈你的分析和理解\n\n\n\n\n页首\n\n\n# 22 | 想成为架构师，你必须知道CAP理论\n\n * CAP\n   \n   * Consistency、Availability、Partition Tolerance\n     * 对某个指定的客户端来说，读操作保证能够返回最新的写操作结果。\n     * 非故障的节点在合理的时间内返回合理的响应（不是错误和超时的响应）\n     * 当出现网络分区后，系统能够继续“履行职责”\n   * 适合于：有互联和数据共享的分布式系统、关注的是对数据的读写操作\n\n * note\n   \n   * 分布式系统理论上一定会存在 P，所以不可能选择 CA 架构，只能选择 CP 或者 AP 架构\n\n * 思考题\n   \n   * 基于 Paxos 算法构建的分布式系统，属于 CAP 架构中的哪一种？谈谈你的分析和理解。\n     * paxos算法实现的系统是cp，根据Raft的论文描述，工程上目前还没有完全实现paxos算法的系统\n\n\n\n\n页首\n\n\n# 23 | 想成为架构师，你必须掌握的CAP细节\n\n * CAP 关键细节点\n   \n   * CAP 关注的粒度是数据，而不是整个系统。\n     * C 与 A 之间的取舍可以在同一系统内以非常细小的粒度反复发生，而每一次的决策可能因为具体的操作，乃至因为牵涉到特定的数据或用户而有所不同。\n   * CAP 是忽略网络延迟的。\n   * 正常运行情况下，不存在 CP 和 AP 的选择，可以同时满足 CA。\n     * CAP 理论告诉我们分布式系统只能选择 CP 或者 AP，但.其实这里的前提是系统发生了“分区”现象。如果系统没有发生分区现象，也就是说 P 不存在的时候（节点间的网络连接一切正常），我们没有必要放弃 C 或者 A，应该 C 和 A 都可以保证，这就要求架构设计的时候既要考虑分区发生时选择 CP 还是 AP，也要考虑分区没有发生时如何保证 CA。\n   * 放弃并不等于什么都不做，需要为分区恢复后做准备。\n\n * ACID 是数据库管理系统为了保证事务的正确性而提出来的一个理论，ACID 包含四个约束，\n   \n   * Atomicity（原子性）\n     * 一个事务中的所有操作，要么全部完成，要么全部不完成，不会在中间某个环节结束\n   * Consistency（一致性）\n     * 在事务开始之前和事务结束以后，数据库的完整性没有被破坏。\n   * Isolation（隔离性）\n     * 数据库允许多个并发事务同时对数据进行读写和修改的能力。隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）\n   * Durability（持久性）\n     * 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。\n\n * BASE 核心思想是即使无法做到强一致性（CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性。\n   \n   * BASE 是指基本可用（Basically Available）\n     * 分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。\n   * 软状态（ Soft State）\n     * 允许系统存在中间状态，而该中间状态不会影响系统整体可用性。这里的中间状态就是 CAP 理论中的数据不一致。\n   * 最终一致性（ Eventual Consistency）\n     * 系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。\n   * note\n     * BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。\n     * BASE 理论考虑了延时；要求在分区期间牺牲一致性，但分区故障恢复后，系统应该达到最终一致性性\n\n * 思考题\n   \n   * 假如你来设计电商网站的高可用系统，按照 CAP 理论的要求，你会怎么设计？\n\n\n\n\n页首\n\n\n# 24 | FMEA方法，排除架构可用性隐患的利器\n\n * FMEA (Failure mode and effects analysis, 故障模式与影响分析)\n   * 在架构设计领域，FMEA 的具体分析方法是：\n     * 给出初始的架构设计图。\n     * 假设架构中某个部件发生故障。\n     * 分析此故障对系统功能造成的影响。\n     * 根据分析结果，判断架构是否需要进行优化。\n * FMEA 分析的方法其实很简单，就是一个 FMEA 分析表，常见的 FMEA 分析表格包含下面部分。\n   * 功能点\n     * 指的是从用户角度来看的，而不是从系统各个模块功能点划分来看的\n   * 故障模式\n     * 故障模式指的是系统会出现什么样的故障，包括故障点和故障形式。需要特别注意的是，这里的故障模式并不需要给出真正的故障原因，，我们只需要假设出现某种故障现象即可，例如 MySQL 响应时间达到 3 秒。\n     * 故障模式的描述要尽量精确，多使用量化描述，避免使用泛化的描述。例如，推荐使用“MySQL 响应时间达到 3 秒”，而不是“MySQL 响应慢”。\n   * 故障影响\n     * 当发生故障模式中描述的故障时，功能点具体会受到什么影响。故障影响也需要尽量准确描述。例如，推荐使用“20% 的用户无法登录”，而不是“大部分用户无法登录”。\n   * 严重程度\n     * 严重程度指站在业务的角度故障的影响程度，一般分为“致命 / 高 / 中 / 低 / 无”五个档次。严重程度按照这个公式进行评估：严重程度 = 功能点重要程度 × 故障影响范围 × 功能点受损程度。\n   * 故障原因\n   * 故障概率\n     * 这里的概率就是指某个具体故障原因发生的概率。一般分为“高 / 中 / 低”三档即可\n   * 风险程度\n     * 风险程度就是综合严重程度和故障概率来一起判断某个故障的最终等级，风险程度 = 严重程度 × 故障概率。\n   * 已有措施\n     * 针对具体的故障原因，系统现在是否提供了某些措施来应对，包括：检测告警、容错、自恢复等。\n   * 规避措施\n     * 规避措施指为了降低故障发生概率而做的一些事情，可以是技术手段，也可以是管理手段。例如：\n       * 技术手段：为了避免新引入的 MongoDB 丢失数据，在在 MySQL 中冗余一份。\n       * 管理手段：为了降低磁盘坏道的概率，强制统一更换服务时间超过 2 年的磁盘\n   * 解决措施\n     * 解决措施指为了能够解决问题而做的一些事情，一般都是技术手段。例如：\n       * 为了解决密码暴力破解，增加密码重试次数限制。\n       * 为了解决拖库导致数据泄露，将数据库中的敏感数据加密保存。\n       * 为了解决非法访问，增加白名单控制。\n   * 后续规划\n * FMEA实践\n   * 假设我们设计一个最简单的用户管理系统，包含登录和注册两个两个功能，其初始架构是：\n     * MySQL 负责存储，Memcache（以下简称 MC）负责缓存，Server 负责业务处理。\n   * FMEA 分析后，能够有什么样的发现，下表是分析的样例\n   * 经过上表的 FMEA 分析，将“后续规划”列的内容汇总一下，我们最终得到了下面几条需要改进的措施：\n     * MySQL 增加备机。MC 从单机扩展为集群。MySQL 双网卡连接。\n * 思考题 请使用 FMEA 方法分析一下 HDFS 系统的架构，看看 HDFS 是如何应对各种故障的，并且分析一下 HDFS 是否存在高可用问题。\n\n\n\n\n页首\n\n\n# 25 | 高可用存储架构：双机架构\n\n * 双机架构：单机即可解决数据存储情况下，保证高可用\n * 复杂性主要体现在如何应对复制延迟和中断导致的数据不一致问题\n   * 数据如何复制？ 各个节点的职责是什么？ 如何应对复制延迟 和 复制中断？\n * 双击切换：要实现一个完善的切换方案，必须考虑这几个关键的设计点：\n   * 主备状态判断\n     * 状态传递的渠道\n     * 状态检查的内容\n   * 切换决策\n   * 数据冲突解决\n * 常见架构:(根据传递渠道不同)\n   * 互联式、中介式、模拟式、主主复制\n\n\n\n\n页首\n\n\n# 26 | 高可用存储架构：集群和分区\n\n * 数据集中集群\n   * 一主多备、一主多从\n   * 复杂度\n     * 主机如何将数据复制给备机\n       * 主备和主从架构中，只有一条复制通道，而数据集中集群架构中，存在多条复制通道。多条复制通道首先会增大主机复制的压力，某些场景下我们需要考虑如何降低主机复制压力，或者降低主机复制给正常读写带来的压力。\n     * 备机如何检测主机状态\n       * 在数据集中集群架构中，多台备机都需要对主机状态进行判断，而不同的备机判断的结果可能是不同的，如何处理不同备机对主机状态的不同判断，是一个复杂的问题。\n     * 主机故障后，如何决定新的主机\n       * 而在数据集中集群架构中，有多台备机都可以升级为主机，但实际上只能允许一台备机升级为主机，那么究竟选择哪一台备机作为新的主机，备机之间如何协调，这也是一个复杂的问题。\n * 数据分散集群\n   * 数据分散集群指多个服务器组成一个集群，每台服务器又会备份一部分数据。\n   * 复杂度：均衡、容错、可伸缩性\n * 数据分区\n   * 前面我们讨论的主要考虑当部分硬件可能损坏的情况下系统应该如何处理，但对于一些影响非常大的灾难或者事故来说，有可能所有的硬件全部故障。例如，新奥尔良水灾、美加大停电，这时候需要基于地理级别的故障来设计高可用架构，这就是数据分区架构产生的背景。\n   * 数据分区的备份方式：集中式备份、互备式、独立式备份\n\n\n\n\n页首\n\n\n# 27 | 如何设计计算高可用架构？\n\n * 复杂度：任务管理\n * 高可用方式\n   * 主从、主备、集群(对称集群、非对称集群)\n\n\n\n\n页首\n\n\n# 28 | 业务高可用的保障：异地多活架构\n\n * 异地多活架构可以分为：\n   * 同城异区\n   * 跨城异地\n     * 引入了一个看似矛盾的地方：数据不一致业务肯定不会正常，但跨城异地肯定会导致数据不一致。\n       * 重点还是在“数据”上，即根据数据的特性来做不同的架构。如果是强一致性要求的数据，例如银行存款余额、支付宝余额等，这.类数据实际上是无法做到跨城异地多活的。\n   * 跨国异地\n     * 为不同地区用户提供服务\n     * 只读类业务做多活\n       * 例如，谷歌的搜索业务，由于用户搜索资料时，这些资料都已经存在于谷歌的搜索引擎上面，无论是访问英国谷歌，还是访问美国谷歌，搜索结果基本相同，并且对用户来说，也不需要搜索到最新的实时资料，跨国异地的几秒钟网络延迟，对搜索结果是没有什么影响的。\n * 思考题\n   * 假设我们做了前面提到的高可用存储架构中的数据分区备份，又通过自动化运维能够保证 1 分钟就能将全部系统正常启动，那是否意味着没有必要做异地多活了？\n     * 备份系统平常没有流量，如果直接上线可能触发平常测试不到的故障。\n     * 再实时的系统也会有数据延时，如果涉及到金融这种系统，仍然是不敢直接切换的。\n     * 系统运行过程中会有很多中间数据，缓存数据等。系统不经过预热直接把流量倒过来，大流量会直接把系统拖垮\n\n\n\n\n页首\n\n\n# 29 | 异地多活设计4大技巧\n\n * 核心\n   * 采用多种手段，保证绝大部分用户的核心业务异地多活！\n * 技巧\n   * 保证核心业务的异地多活\n   * 保证核心数据最终一致性\n     * 因此异地多活架构面临一个无法彻底解决的矛盾：业务上要求数据快速同步，物理上正好做不到数据快速同步，因此所有数据都实时同步，实际上是一个无法达到的目标。\n       * 尽量减少异地多活机房的距离，搭建高速网络\n       * 尽量减少数据同步，只同步核心业务相关的数据\n       * 保证最终一致性，不保证实时一致性\n   * 采用多种手段同步数据\n     * 数据同步是异地多活架构设计的核心，幸运的是基本上存储系统本身都会有同步的功能。例如，MySQL 的主备复制、Redis 的 Cluster 功能、Elasticsearch 的集群功能。但有时候仅使用这些功能是不够的，需要拓开思路。\n   * 只保证绝大部分用户的异地多活\n\n\n\n\n页首\n\n\n# 30 | 异地多活设计4步走\n\n * 业务分级\n   * 挑选出核心的业务，只为核心业务设计异地多活，降低方案整体复杂度和实现成本。\n * 数据分类\n   * 唯一性、实时性、数据量、可丢性、可恢复性、\n * 数据同步\n   * 存储系统同步\n     * 几乎主流的存储系统都会有自己的同步方案；缺点是这类同步方案都是通用的，无法针对业务数据特点做定制化的控制。\n * 异常处理\n   * 多通道同步\n   * 同步和访问结合\n   * 日志记录\n   * 用户补偿\n\n\n\n\n页首\n\n\n# 31 | 如何应对接口级的故障？\n\n * 核心思想：优先保证核心业务和优先保证绝大部分用户\n * 应对策略：降级、熔断、限流、排队\n   * 降级的目的是应对系统自身的故障，而熔断的目的是应对依赖的外部系统故障的情况\n   * 限流则是从用户访问压力的角度来考虑如何应对故障。限流指只允许系统能够承受的访问量进来，超出系统访问能力的请求将被丢弃。\n * 思考题\n   * 如果你来设计一个整点限量秒杀系统，包括登录、抢购、支付（依赖支付宝）等功能，你会如何设计接口级的故障应对手段？\n\n\n\n\n页首\n\n\n# 32 | 可扩展架构的基本思想和模式\n\n * 架构可扩展模式：包括分层架构、SOA 架构、微服务和微内核等\n   * 如何避免扩展时改动范围太大，是软件架构可扩展性设计的主要思考点\n * 可扩展模式的核心就是拆分，常见的拆分思路有如下三种。\n   * 面向流程拆分：将整个业务流程拆分为几个阶段，每个阶段作为一部分。分层架构。\n   * 面向服务拆分：将系统提供的服务拆分，每个服务作为一部分。SOA、微服务。\n   * 面向功能拆分：将系统提供的功能拆分，每个功能作为一部分。微内核架构。\n\n\n\n\n页首\n\n\n# 33 | 传统的可扩展架构模式：分层架构和SOA\n\n * 分层架构\n   * 例如，C/S 架构、B/S 架构，常见的是 3 层架构（例如，，MVC、MVP 架构）\n   * 分层架构设计最核心的一点就是需要保证各层之间的差异足够清晰，边界足够明显\n   * 分层架构之所以能够较好地支撑系统扩展，本质在于隔离关注点（separation of concerns），即每个层中的组件只会处理本层的逻辑。\n   * 分层时要保证层与层之间的依赖是稳定的，才能真正支撑快速扩展\n * SOA(Service Oriented Architecture)\n   * 三要素：服务、ESB(Enterprise Service Bus)、松耦合\n   * SOA 使用 ESB 来屏蔽异构系统对外提供各种不同的接口方式，以此来达到服务间高效的互联互通。\n   * SOA 更多是在传统企业（例如，制造业、金融业等）落地和推广，在互联网行业并没有大规模地实践和推广。\n     * SOA 解决了传统 IT 系统重复建设和扩展效率低的问题，但其本身也引入了更多的复杂性。SOA 最广为人诟病的就是 ESB，ESB 需要实现与各种系统间的协议转换、数据转换、透明的动态路由等功能。esb集中化的管理带来了性能不佳，厚重等问题。\n     * 想一下 SOA 的提出背景就可以发现，企业在应用 SOA 时时，各种异构的 IT 系统都已经存在很多年了，完全重写或者按照统一标准进行改造的成本是非常大的，只能通过 ESB 方式去适配已经存在的各种异构系统。\n * 思考题\n   * 为什么互联网企业很少采用 SOA 架构？\n\n\n\n\n页首\n\n\n# 34 | 深入理解微服务架构：银弹 or 焦油坑？\n\n * SOA 和微服务对比：\n   * 从以下几方面考虑：服务粒度、服务通信、应用场景\n * 微服务陷阱\n   * 服务划分过细，服务间关系复杂\n   * 服务数量太多，团队效率急剧下降\n   * 调用链太长，性能下降\n   * 调用链太长，问题定位困难\n   * 没有自动化支撑，无法快速交付\n   * 没有服务治理，微服务数量多了后管理混乱\n     * 主要表现在：服务路由、服务故障隔离、服务注册和发现\n\n\n\n\n页首\n\n\n# 35 | 微服务架构最佳实践 - 方法篇\n\n * 服务粒度\n   * 一般来说，3个人开发一个服务为佳：既能够形成有效的讨论、也可以形成一个稳定的团队备份\n   * 基于上述策略，计算出拆分后合适的服务数量\n * 拆分方法\n   * 基于业务逻辑拆分\n   * 基于可扩展拆分\n     * 拆分成稳定服务和变动服务，可以提升项目快速迭代的效率，避免在开发的时候，不小心影响了已有的成熟功能导致线上问题。\n   * 基于可靠性拆分\n     * 避免非核心服务故障影响核心服务\n     * 核心服务高可用方案可以更简单\n     * 能够降低高可用成本\n   * 基于性能拆分\n * 基础设施 ![微服务基础设施](./rsc/arch_meshsrv_ infrastructure.png)\n * 思考题\n   * 参考文章中提到的方法，思考一下你所在的业务微服务架构是否还有可以改进和提升的空间？\n\n\n\n\n页首\n\n\n# 36 | 微服务架构最佳实践 - 基础设施篇\n\n * 基础设施\n   * 自动化测试\n     * 涵盖的范围包括代码级的单元测试、单个系统级的集成测试、系统间的接口测试，系统间的接口测试是基础保障。\n   * 配置中心\n   * 接口框架\n     * 微服务提倡轻量级的通信方式，一般采用 HTTP/REST 或者 RPC 方式统一接口协议。但在实践过程中，光统一接口协议还不够，还需要统一接口传递的数据格式。\n   * API网关\n     * API 网关是外部系统访问的接口，所有的外部系统接⼊系统都需要通过 API 网关，主要包括接入鉴权（是否允许接入）、权限控制（可以访问哪些功能）、传输加密、请求路由、流量控制等功能。\n   * 服务发现\n   * 服务容错\n     * 常见的服务容错包括请求重试、流控和服务隔离。通常情况下，服务容错会集成在服务发现和服务路由系统中。\n   * 服务监控\n     * 微服务节点级的监控和信息收集\n   * 服务追踪\n     * 服务完整流程跟踪分析\n     * 绝大部分请求跟踪的实现技术都基于 Google 的 Dapper 论文《Dapper, a Large-Scale Distributed Systems Tracing Infrastructure》。\n   * 服务安全\n * 思考题\n   * 给你一个由 10 位 Java 高级软件工程师组成的开发团队，采用自研的方式，完成所有的微服务基础设施开发，你预测需要多长时间？理由是什么呢？\n\n\n\n\n页首\n\n\n# 37 | 微内核架构详解\n\n * 微内核架构（Microkernel Architecture），也被称为插件化架构（Plug-in Architecture），是一种面向功能进行拆分的可扩展性架构\n * 微内核架构包含两类组件：核心系统（core system）和插件模块（plug-in modules）\n   * 关键技术有：插件管理、插件连接和插件通信\n     * 插件连接指插件如何连接到核心系统。通常来说，核心系统必须制定插件和核心系统的连接规范，然后插件按照规范实现，核心系统按照规范加载即可。\n * 常见的两种微内核具体实现：\n   * OSGi Open Services Gateway initiative 是一个插件化的标准\n   * 规则引擎\n     * 执行引擎解析配置好的业务流，执行其中的条件和规则，通过这种方式来支持业务的灵活多变。如：Esper，Drools\n     * 一般流程：\n       * 开发人员将业务功能分解提炼为多个规则，将规则保存在规则库中\n       * 业务人员根据业务需要，通过将规则排列组合，配置成业务流程，保存在业务库中。\n       * 规则引擎执行业务流程实现业务功能。\n\n\n\n\n页首\n\n\n# 38 | 架构师应该如何判断技术演进的方向？\n\n * 技术演进的模式: 基于业务发展阶段进行判断\n * 技术创新会推动业务发展，而业务发展也会逼迫技术进步\n * reference\n   * <淘宝技术十年>\n\n\n\n\n页首\n\n\n# 39 | 互联网技术演进的模式\n\n * 互联网业务发展一般分为几个时期(不同时期的差别主要体现在两个方面：复杂性、用户规模)：\n   * 初创期、\n     * 互联网业务刚开始一般都是一个创新的业务点，这个业务点的重点不在于“完善”，而在于“创新”，只有创新才能吸引用户；初创期的业务对技术就一个要求：“快”，能买就买，有开源的就用开源的。\n   * 发展期、\n     * 当业务推出后经过市场验证如果是可行的，则吸引的用户就会越来越多，此时原来不完善的业务就进入了一个快速发展的时期。\n     * 因此会有越来越多的新功能不断地加入到系统中。一般会有以下几个阶段：堆功能期、优化期、架构期\n   * 竞争期\n     * 当业务继续发展，已经形成一定规模后，一定会有竞争对手开始加入行业来竞争，当竞争对手加入后，大家互相学习和模仿，业务更加完善，也不断有新的业务创新出来，而且由于竞争的压力，对技术的要求是更上一层楼了。\n     * 当系统数量越来越多，到了一个临界点后就产生了质变，主要体现在：重复造轮子、系统交互一团乱，解决方案如下：\n       * 平台化: 目的在于解决“重复造轮子”的问题。\n       * 服务化: 目的在于解决“系统交互”的问题，常见的做法是通过消息队列来完成系统间的异步通知，通过服务框架来完成系统间同步调用\n   * 成熟期。\n     * 技术上能做的大动作其实也不多了，更多的是进行优化。\n\n\n\n\n页首\n\n\n# 40 | 互联网架构模板：“存储层”技术\n\n\n\n * 互联网架构模板中的存储层技术\n   \n   * SQL\n     * 单表\n     * 分库分表\n       * 中间件\n         * 技术要求很高，要将分库分表做到自动化和平台化，不是一件容易的事情。所以一般是规模很大的公司才会自己做。例如百度的 DBProxy、淘宝的 TDDL。中小公司建议使用开源方案，例如 MySQL 官方推荐的 MySQL Router、360 开源的数据库中间件 Atlas\n     * 平台化\n       * 当 SQL 服务器越来越多，如果每个业务都基于统一的数据库中间件独立部署自己的 SQL 集群，就会导致新的复杂度问题，具体表现在：\n         * 数据库资源使用率不高，比较浪费。\n         * 各 SQL 集群分开维护，投入的维护成本越来越高\n       * 大公司此时一般都会在 SQL 集群上构建 SQL 存储平台，，以对业务透明的形式提供资源分配、数据备份、迁移、容灾、读写分离、分库分表等一系列服务，例如淘宝的 UMP（Unified MySQL Platform）系统。\n   * NoSQL\n     * 单库\n     * NoSQL集群\n       * NoSQL 方案一般自己本身就提供集群的功能，例如 Memcache 的一致性 Hash 集群、Redis 3.0 的集群，\n     * 平台化\n       * 资源动态按需动态分配：\n       * 资源自动化管理：例如\n       * 故障自动化处理\n   * 小文件存储\n     * 一般在1M以下，但数据量巨大。典型的小文件存储有：淘宝的 TFS、京东 JFS、Facebook 的 Haystack\n   * 大文件存储\n     * 包含业务上的大数据(youtube的视频内容等)、海量的日志数据\n       * 说到大文件，特别要提到 Google 和 Yahoo，Google 的 3 篇大数据论文（Bigtable/Map- Reduce/GFS）开启了一个大数据的时代，而Yahoo 开源的 Hadoop 系列（HDFS、HBase 等），基本上垄断了开源界的大数据处理\n   \n   \n\n * 思考题\n   \n   * 既然存储技术发展到最后都是存储平台，为何没有出现存储平台的开源方案，但云计算却都提供了存储平台方案？\n     * 代价、价值\n\n\n\n\n页首\n\n\n# 41 | 互联网架构模板：“开发层”和“服务层”技术\n\n * 开发层技术\n   * 开发框架\n     * 互联网公司一般会指定一个大的技术方向，然后使用统一的开发框架，这样可以节省沟通和团队协作成本。例如，Java 相关的开发框架 SSH、SpringMVC、Play，Ruby 的 Ruby on Rails，PHP 的 ThinkPHP，Python 的 Django 等。\n   * web服务器\n   * 容器\n     * 腾讯万台规模的 Docker 应用实践\n     * 新浪微博红包的大规模 Docker 集群\n * 服务层技术：服务层的主要目标其实就是为了降低系统间相互关联的复杂度。\n   * 配置中心\n     * 将所有配置集中在一个平台操作，效率高；同时可以制定配置规则检查，避免手误造成损失\n     * 常用“系统标识 + host + port”来标识唯一运行实例\n   * 服务中心\n     * 两种实现方式：服务名字系统（Service Name System） 和 服务总线系统（Service Bus System）\n   * 消息队列\n * 思考题\n   * 使用统一的开发框架和开发语言可以让团队开发效率更高，但这样做会带来什么问题？如何解决？\n     * 开发框架和开发语言，都是有场景限制的，尺有所短，寸有所长\n     * 将业务服务化，对外提供统一的API接口\n     * 在业务规模小的时候采用单一语言单一框架，当规模大了还是应该有一定的灵活性，有一个主力的语言和框架，合适的工作用合适语言和框架，而微服务架构的比较适合混合语言和架构的模式\n\n\n\n\n页首\n\n\n# 42 | 互联网架构模板：“网络层”技术\n\n * 站在网络层的角度整体设计架构，而不是某个具体网络的搭建。\n   \n   * 负载均衡\n     * DNS、Nginx 、LVS 、F5\n   * 多机房\n     * 同城、跨城、跨国\n     * 目的：灾备\n   * 多中心\n     \n     * 要求高：要求每个中心都同时对外提供服务，且业务能够自动在多中心之间切换，故障后不需人工干预或者很少的人工干预就能自动恢复。\n       \n       * 多中心设计的关键就在于“数据一致性”和“数据事务性”。目前没有很成熟的且通用的解决方案，需要基于业务的特性进行详细分析和设计\n     \n     * 正因为多中心设计的复杂性，不一定所有业务都能实现多中心，目前国内的银行、支付宝这类系统就没有完全实现多中心，不然也不会出现挖掘机一铲子下去，支付宝中断 4 小时的故障。\n\n * utility\n   \n   * 两地三中心，是指同城两个机房是双活，异地机房是备份，当同城两个机房都挂掉，异地机房不能接管业务，只能用来备份恢复\n\n\n\n\n页首\n\n\n# 43 | 互联网架构模板：“用户层”和“业务层”技术\n\n * 用户层技术\n   * 用户管理\n     * 单点登录SSO(目前最成熟的开源单点登录方案当属 CAS)、OAuth2.0\n   * 消息推送\n   * 存储云 和 图片云\n     * 普通的文件基本上提供存储和访问就够了，而图片涉及的业务会更多，包括裁剪、压缩、美化、审核、水印等处理，因此通常情况下图片云会拆分为独立的系统对用户提供服务。\n * 业务层技术\n   * 主要挑战：系统越来越庞大，业务越来越多，业务层会越来越复杂\n   * 拆分、合并：合久必分、分久必合，符合高内聚低耦合原则\n * 思考题\n   * 虚拟业务域划分的粒度需要粗一些还是要细一些？你建议虚拟业务域的数量大概是多少，理由是什么？\n\n\n\n\n页首\n\n\n# 44 | 互联网架构模板：“平台”技术\n\n * 运维平台\n   * 职责：资源配置、部署、监控、应急\n   * 核心设计要素：标准化、平台化、自动化、可视化\n * 测试平台\n   * 测试平台的核心目的是提升测试效率，从而提升产品质量，其设计关键就是自动化\n   * 用例管理\n     * 为了能够重复执行测试用例，测试平台需要将用例管理起来，管理的维度包括业务、系统、测试类型、用例代码。例如，网购业务的订单系统的接口测试用例。\n   * 资源管理\n     * 管理执行测试所需的运行环境, 包括硬件（服务器、手机、平板电脑等）、软件（操作系统、数据库、Java 虚拟机等）、业务系统（被测试的系统）\n   * 任务管理\n     * 任务管理的主要职责是将测试用例分配到具体的资源上执行，跟踪任务的执行情况。任务管理是测试平台设计的核心，它将测试平台的各个部分串联起来从而完成自动化测试。\n   * 数据管理 测试任务执行完成后，需要记录各种相关的数据（例如，执行时间、执行结果、用例执行期间的 CPU、内存占用情况等），这些数据具备下面这些作用：展现当前用例的执行情况、作为历史数据，方便后续的测试与历史数据进行对比，从而发现明显的变化趋势。作为大数据的一部分，可以基于测试的任务数据进行一些数据挖掘。\n * 数据平台\n   * 数据平台的核心职责主要包括三部分：数据管理、数据分析和数据应用\n * 管理平台\n   * 管理平台的核心职责就是权限管理，主要分为两部分：身份认证、权限控制，\n * 思考题\n   * 运维平台或者测试平台，有的公司是由中间件团队负责开发，有的是运维和测试团队自己开发，你觉得两种方式各有什么优缺点，分别适用什么场景呢？\n\njira+gitlab+jenkins+nexus+bearychat 最简单的DevOps 平台。如果将生产环境完全交给运维团队的话，个人觉得这个应该可以称为开发平台。输入的是需求，输出的是各种工件。\n\n\n\n\n页首\n\n\n# 45 | 架构重构内功心法第一式：有的放矢\n\n * 系统的架构是不断演化的，少部分架构演化可能需要推倒重来，但绝大部分的架构演化都是通过架构重构来实现的。相比全新的架构设计来说，架构重构对架构师的要求更高，主要体现在：\n   * 业务已经上线，不能停下来\n   * 关联方众多，牵一发动全身\n     * 架构重构涉及的业务关联方很多，不同关联方的资源投入程度、业务发展速度、对架构痛点的敏感度等有很大差异，如何尽量减少对关联方的影响，或者协调关联方统一行动，是一项很大的挑战；而如果是新设计架构，则在新架构上线前，对关联方没有影响。\n   * 旧架构的约束\n     * 在旧的架构基础上进行，会限制架构师的技术选择范围；新架构必须考虑如何将旧架构产生的数据转换过来。\n * 期望通过架构重构来解决所有问题当然是不现实的\n   * 所以架构师的首要任务是从一大堆纷繁复杂的问题中识别出真正要通过架构重构来解决的问题，集中力量快速解决，而不是想着通过架构重构来解决所有的问题。\n   * 对于刚接手一个新系统的架构师或者技术主管来说，一定要控制住“新官上任三把火”的冲动，避免摊大饼式或者运动式的重构和优化。\n * 重点\n   * 总之，架构重构需要架构师既要说得动老板，也镇得住同事；既要技术攻关，又要协调资源；既要保证业务正常发展，又要在指定时间内完成目标……总之就是十八般武艺要样样精通。\n   * 架构师需要透过问题表象看到问题本质，找出真正需要通过架构重构解决的核心问题，从而做到有的放矢，既不会耗费大量的人力和时间投入，又能够解决核心问题。\n * 思考题\n   * 分析一下你目前开发的系统，你觉得需要架构重构吗？原因和理由是什么？\n\n\n\n\n页首\n\n\n# 46 | 架构重构内功心法第二式：合纵连横\n\n * 上下游沟通协调\n   * 在沟通协调时，将技术语言转换为通俗语言，以事实说话，以数据说话，是沟通的关键！\n * 其他相关或者配合的系统的沟通协调\n   * 问题：主要的阻力来自“这对我有什么好处”和“这部分我这边现在不急”\n   * 解决方案；换位思考、合作双赢、关注长期\n\n\n\n\n页首\n\n\n# 47 | 架构重构内功心法第三式：运筹帷幄\n\n * 问题\n   * 通常情况下，需要架构重构的系统，基本上都是因为各种历史原因和历史问题没有及时处理，遗留下来逐渐积累，然后到了一个临界点，，各种问题开始互相作用，集中爆发！到了真正要开始重构的时候，架构师识别出系统关键的复杂度问题后，如果只针对这个复杂度问题进行架构重构，可能会发现还是无法落地，因为很多条件不具备或者有的问题没解决的情况下就是不能做架构重构\n * 重构: 分段实施\n   * 重构的做法，其实就是“分段实施”，将要解决的问题根据优先级、重要性、实施难度等划分为不同的阶段，每个阶段聚焦于一个整体的目标，集中精力和资源解决一类问题。这样做有几个好处:\n     * 每个阶段都有明确目标，做完之后效果明显，团队信心足，后续推进更加容易。\n     * 每个阶段的工作量不会太大，可以和业务并行。\n     * 每个阶段的改动不会太大，降低了总体风险。\n   * 策略\n     * 优先级排序\n     * 问题分类\n       * 将问题按照性质分类，每个阶段集中解决一类问题。\n     * 先易后难\n       * 将问题按照性质分类，每个阶段集中解决一类问题\n     * 循序渐进\n       * 每个阶段的实施：最少 1 个月，最长不要超过 3 个月\n * 思考题\n   * 如果一个架构重构项目最后规划要 2 年才完成，你会怎么处理？\n     * 太久\n\n\n\n\n页首\n\n\n# 48 | 再谈开源项目：如何选择、使用以及二次开发？\n\n软件开发领域有一个流行的原则：DRY，Don’t repeat yourself。\n\n * 选择\n   * 聚焦是否满足业务、\n   * 聚焦是否成熟\n     * 版本号、使用的公司数量、社区活跃程度\n   * 聚焦运维能力\n     * 开源项目日志是否齐全、是否有维护工具可以看到系统运行状况、是否有故障检测和恢复的能力\n * 使用\n   * 深入研究，仔细测试\n     * 通读开源项目的设计文档或者白皮书，了解其设计原理。\n     * 核对每个配置项的作用和影响，识别出关键配置项。\n     * 进行多种场景的性能测试\n     * 进行压力测试，连续跑几天，观察 CPU、内存、磁盘 I/O 等指标波动\n     * 进行故障测试：kill、断电、拔网线、重启 100 次以上、切换等\n   * 小心应用，灰度发布\n   * 做好应急，以防万一\n * 二次开发\n   * 保持纯洁，加以包装\n     * 内外全改的缺点：投入太大、失去了跟随原项目演进的能力(差异太大导致源项目的改动无法合并到自己的分支)\n   * 发明你要的轮子\n     * 没有完全适合你的轮子！\n\n\n\n\n页首\n\n\n# 49 | 谈谈App架构的演进\n\n * 复习一下我的专栏所讲述的架构设计理念\n   * 架构是系统的顶层结构\n   * 架构设计的主要目的是为了解决软件系统复杂度带来的问题。\n   * 架构设计需要遵循三个主要原则：合适原则、简单原则、演化原则。\n   * 架构设计首先要掌握业界已经成熟的各种架构模式，然后再进行优化、调整、创新。\n * App架构演进\n   * web app、原生App、Hybrid App、组件化 & 容器化、跨平台 App\n     * 组件化 & 容器化\n       * 微信 Android 客户端架构演进之路\n       * Atlas：手淘 Native 容器化框架和思考\n     * 跨平台\n       * Flutter\n * 思考题\n   * 你认为 App 架构接下来会如何演进？谈谈你的思考和分析。\n\n\n\n\n页首\n\n\n# 50 | 架构实战：架构设计文档模板\n\n * 备选方案模板：目的是供选择一个方案落地实施\n   * 需求介绍：主要描述需求的背景、目标、范围等\n   * 需求分析：主要全方位地描述需求相关的信息\n     * 5W: Who(利益干系人)、When、What(产出)、Why(需要解决的问题)、Where(应用场景)\n     * 1H：关键业务流程。\n     * 8C: 指的是 8 个约束和限制，Constraints，包括性能 Performance、成本 Cost、时间 Time、可靠性 Reliability、安全性 Security、合规性 Compliance、技术性 Technology、兼容性 Compatibility\n   * 复杂度分析：包含高可用、高性能、可扩展等\n   * 备选方案：至少 3 个备选方案，每个备选方案需要描述关键的实现，无须描述具体的实现细节\n   * 备选方案评估: 备选方案 360 度环评, 注意备选方案评估的内容会根据评估会议的结果进行修改\n * 架构设计模板：目的是详细描述细化方案\n   * 总体方案\n     * 总体方案需要从整体上描述方案的结构，其核心内容就是架构图，以及针对架构图的描述，包括模块或者子系统的职责描述、核心流程\n   * 架构总览\n     * 架构总览给出架构图以及架构的描述\n   * 核心流程\n   * 详细设计\n     * 详细设计需要描述具体的实现细节\n     * 高可用、高性能、高可扩展\n     * 安全设计\n     * 其他设计\n       * 其他设计包括上述以外的其他设计考虑点，例如指定开发语言、符合公司的某些标准等，如果篇幅较长，也可以独立进行描述]\n     * 部署方案\n       * 部署方案主要包括硬件要求、服务器部署方式、组网方式等\n   * 架构演进规划\n     * 通常情况下，规划和设计的需求比较完善，但如果一次性全部做完，项目周期可能会很长，因此可以采取分阶段实施，即：第一期做什么、第二期做什么，以此类推\n\n\n\n\n页首\n\n\n# 总结\n\n> 关于如何在专业领域内提升：著名的“10000 小时定律” 坚持梦想、坚持学习、坚持(持续)输出\n\n * 架构师的内功主要包含三部分：判断力、执行力、创新力\n   * 判断力：能够准确判断系统的复杂度在哪里，就像武侠高手一样，能准确地看出对手的破绽和弱点。\n   * 执行力：能够使用合适的方案解决复杂度问题，就像武侠高手一样，能选择合适的招式或者方法打败对手。\n   * 创新力：能够创造新的解决方案解决复杂度问题，就像武侠世界里，小一些的创新是创新招式，而武学宗师能够创立新的武学或者心法\n * 从程序员到架构师的成长之路，总的指导原则是(以上三方面的能力主要来源)：经验、视野、思考\n * 技术成长之路分为：\n   * 工程师\n     * 在别人的指导下完成开发，基础技能积累阶段\n   * 高级工程师\n     * 独立完成开发，包括需求分析、方案设计、编码实现，其中需求分析和方案设计已经包含了“判断”和“选择”，只是范围相对来说小一些，更多是在已有架构下进行设计。\n     * 积累方案设计经验，简单来说就是业务当前用到的相关技术的设计经验。\n     * 高级工程师阶段相比工程师阶段，有两个典型的差异：深度(how -> why)、理论(成熟的设计经验)\n   * 技术专家\n     * 某个领域的专家，通俗地讲，只要是这个领域的问题，技术专家都可以解决。\n     * 技术专家与高级工程师的一个典型区别就是，高级工程师主要是在已有的架构框架下完成设计，而技术专家会根据需要修改、扩展、扩展、优化架构。\n     * 从高级工程师成长为技术专家，主要需要“拓展技术宽度”，因为一个“领域”必然会涉及众多的技术面。常见的拓展技术宽度的方法有：\n       * 学习业界成熟的开源方案、研究业界的经验分享\n     * 需要注意的是，拓展技术宽度并不意味着仅仅只是知道一个技术名词，而是要深入去理解每个技术的原理、优缺点、应用场景\n   * 初级架构师\n     * 典型特征就是能够“独立完成一个系统的架构设计”，可以是从 从 0 到 1 设计一个新系统，也可以是将架构从 1.0 重构到 2.0。\n     * 初级架构师和技术专家的典型区别是：架构师是基于完善的架构设计方法论的指导来进行架构设计，而技术专家更多的是基于经验进行架构设计。\n       * 简单来说，即使是同样一个方案，初级架构师能够清晰地阐述架构设计的理由和原因，而技术专家可能就是因为自己曾经这样做过，或者看到别人这样做过而选择设计方案。\n   * 从技术专家成长为初级架构师，最主要的是形成自己的“架构设计方法论\".主要的手段有：\n     * 系统学习架构设计方法论，包括订阅专栏或者阅读书籍等\n     * 深入研究成熟开源系统的架构设计，这个手段在技术专家阶段也会用到，但关注点不一样，同样是研究开源系统，技术专家阶段聚焦于如何更好地应用开源项目；初级架构师阶段聚焦于学习其架构设计原理和思想，例如 Kafka 的文档中就有关于消息队列架构设计的分析和取舍。\n     * 结合架构设计方法论，分析和总结自己团队甚至公司的各种系统的架构设计优缺点，尝试思考架构重构方案。\n   * 中级架构师\n     * 典型特征是“能够完成复杂系统的架构设计”，包含高性能、高可用、可扩展、海量存储等复杂系统，例如设计一个和 Kafka 性能匹敌的消息队列系统、将业务改造为异地多活、设计一个总共 100 人参与开发的业务系统等。\n     * 中级架构师与初级架构师的典型区别在于系统复杂度的不同，\n     * 从初级架构师成长为中级架构师，最关键的是“技术深度和技术理论的积累”，\n   * 高级架构师\n     * 典型特征是“创造新的架构模式”\n     * 高级架构师与中级架构师相比，典型区别在于“创造性”，高级架构师能够创造新的架构模式，开创新的技术潮流。\n\n\n\n\n页首\n\n\n# END\n\n * recommend\n   * 《unix网络编程卷1》《tcp/ip协议卷1》《unix高级编程》《linux系统编程》《高性能mysql》\n * 两种高效的服务器设计模型：\n   * Reactor和Proactor模型\n * SSO(Single Sign On)流程\n   * https://www.cnblogs.com/ywlaker/p/6113927.html\n * MVC\n   * https://draveness.me/mvx\n * 微服务\n   * 微服务架构的理论基础 - 康威定律\n * 架构师的核心能力：\n   * 抽象，提炼，把握关键，预测未来，当然还有沟通（撕逼）😃\n * 学习开源项目：以我学习 Elasticsearch 为例，具体的做法是：\n   * 搭建一个单机伪集群，搭建完成后看看安装路径下的文件和目录，看看配置文件有哪些配置项，不同的配置项会有什么样的影响。\n   * 执行常用的操作，例如创建索引，插入、删除、查询文档，查看一下各种输出\n   * 研究其基本原理，例如索引、分片、副本等，研究的时候要多思考，例如索引应该如何建，分片数量和副本数量对系统有什么影响等。\n   * 和其他类似系统对比，例如 Solr、Sphinx，研究其优点、缺点、适用场景。\n   * 模拟一个案例看看怎么应用。例如，假设我用 Elasticsearch 来存储淘宝的商品信息，我应该如何设计索引和分片。\n   * 查看业界使用的案例，思考一下别人为何这么用；看看别人测试的结果，大概了解性能范围。\n   * 如果某部分特别有兴趣或者很关键，可能去看源码，例如 Elasticsearch 的选举算法\n   * 如果确定要引入，会进行性能和可用性测试。",normalizedContent:"# architecture\n\n> architecture is like teenage sex， everybody talks about it， nobody really knows what is it。\n\n> 架构是一门平衡的艺术\n\n\n# 概况\n\n * 简述\n   * 业务驱动技术，技术解决业务问题。\n   * 不同的技术，通过树状结构，组合在一起，形成了一个完整的架构解决方案，有效完成业务的目标。\n * 权利\n   * 所有的架构分拆，都应该是形成树状的结果\n     * 因为：切分出来的部分的负责人，对这个部分的权利和义务必须是对等的。架构师没有话语权，还架什么构\n     * 架构师必须是一个组织的领导人，有权利调动这个组织的架构，才能够更好的发挥架构师的作用\n * 责任\n   * 找问题\n     * 找出问题的主体，是做架构的首要问题。架构师都要有这个自觉：发现问题永远都比解决问题来的更加重要。\n       * 我们一定要明白，任何找上架构师的问题，绝对都不是真正的问题，因为如果是真正的问题的话，提问题的人肯定都能够自己解决了\n         * 两个问题：如果问题不解决，究竟谁会有利益的损失？如果问题解决了，究竟谁会有收益，谁的收益最大？\n   * 找技术\n     * 准确识别采用什么技术的能力，也是架构师所要具备的能力之一。\n       * 这就要求了解这项技术解决的是谁的问题？什么问题？\n         * 例子：比如当我们需要一个锤子时，手边正好没有，但是却有一只高跟鞋，勉强也可以替代锤子。但是长期来看，这么用不划算，因为价格、耐用性、维护成本相差很多。\n\n----------------------------------------\n\n\n\n\n\n# 目录\n\n * architecture\n   * 概况\n * 目录\n * 开篇\n * 01 | 架构到底是指什么？\n * 02 | 架构设计的历史背景\n * 03 | 架构设计的目的\n * 04 | 复杂度来源：高性能\n * 05 | 复杂度来源：高可用\n * 06 | 复杂度来源：可扩展性\n * 07 | 复杂度来源：低成本、安全、规模\n * 08 | 架构设计三原则\n * 09 | 架构设计原则案例\n * 10 | 架构设计流程：识别复杂度\n * 11 | 架构设计流程：设计备选方案\n * 12 | 架构设计流程：评估和选择备选方案\n * 13 | 架构设计流程：详细方案设计\n * 14 | 高性能数据库集群：读写分离\n * 15 | 高性能数据库集群：分库分表\n * 16 | 高性能nosql\n * 17 | 高性能缓存架构\n * 18 | 单服务器高性能模式：ppc与tpc\n * 19 | 单服务器高性能模式：reactor与proactor\n * 20 | 高性能负载均衡：分类及架构\n * 21 | 高性能负载均衡：算法\n * 22 | 想成为架构师，你必须知道cap理论\n * 23 | 想成为架构师，你必须掌握的cap细节\n * 24 | fmea方法，排除架构可用性隐患的利器\n * 25 | 高可用存储架构：双机架构\n * 26 | 高可用存储架构：集群和分区\n * 27 | 如何设计计算高可用架构？\n * 28 | 业务高可用的保障：异地多活架构\n * 29 | 异地多活设计4大技巧\n * 30 | 异地多活设计4步走\n * 31 | 如何应对接口级的故障？\n * 32 | 可扩展架构的基本思想和模式\n * 33 | 传统的可扩展架构模式：分层架构和soa\n * 34 | 深入理解微服务架构：银弹 or 焦油坑？\n * 35 | 微服务架构最佳实践 - 方法篇\n * 36 | 微服务架构最佳实践 - 基础设施篇\n * 37 | 微内核架构详解\n * 38 | 架构师应该如何判断技术演进的方向？\n * 39 | 互联网技术演进的模式\n * 40 | 互联网架构模板：“存储层”技术\n * 41 | 互联网架构模板：“开发层”和“服务层”技术\n * 42 | 互联网架构模板：“网络层”技术\n * 43 | 互联网架构模板：“用户层”和“业务层”技术\n * 44 | 互联网架构模板：“平台”技术\n * 45 | 架构重构内功心法第一式：有的放矢\n * 46 | 架构重构内功心法第二式：合纵连横\n * 47 | 架构重构内功心法第三式：运筹帷幄\n * 48 | 再谈开源项目：如何选择、使用以及二次开发？\n * 49 | 谈谈app架构的演进\n * 50 | 架构实战：架构设计文档模板\n * 总结\n * end\n\n\n\n\n页首\n\n\n# 开篇\n\n * 架构师的核心能力还是技术能力，过硬的技术才是良好沟通的基础\n * 架构设计的思维和程序设计的思维差异很大\n   * 架构设计的关键思维是判断和取舍，程序设计的关键思维是逻辑和实现\n * 本课程的目的\n   * 清楚地理解架构设计相关的概念、本质、目的\n   * 掌握通用的架构设计原则\n   * 掌握标准的架构设计流程\n   * 深入理解已有的架构模式, 熟练使用并创新\n * 架构的主要复杂性\n   * 高可用性、高性能、可伸缩、可扩展、安全性、稳定性、可维护性、健壮性等\n\n\n\n\n页首\n\n\n# 01 | 架构到底是指什么？\n\n * 系统与子系统、模块与组件、框架与架构\n   * 系统与子系统\n     * 二者只是角度(规模)不一样，子系统是系统的一部分, 一个系统可能是另一个更大系统的子系统\n       * 系统: 由一群有关联的个体组成的, 这些个体按照指定的规则运作，产生了新的能力。\n       * 例如，汽车能够载重前进，而发动机、变速器、传动轴、车轮本身都不具备这样的能力。\n   * 模块和组件\n     * 两个概念在实际工作中很容易混淆, 其实它们都是系统的组成部分，只是从不同的角度拆分系统而已\n       * 模块: 从逻辑的角度来拆分系统后，划分模块的主要目的是业务上职责分离\n       * 组件: 从物理的角度来拆分系统后，划分组件的主要目的是技术上单元复用。\n         * 其实，“组件”的英文 component 也可译为“零件”，这样更容易理解一些，“零件”是一个物理的概念，具备“独立且可替换”的特点。\n   * 框架与架构\n     * 框架(framework)关注的是“规范”，架构(architecture)关注的是“结构”。从英文名字可以看出不同之处。\n       * 架构可以以不同的角度进行分解，如：业务逻辑、物理部署、开发规范等。这就是 ibm 的 rup 将软件架构视图分为著名的“4+1 视图”的原因。\n         * 例如，可以思考下 “学生管理系统” 的架构\n           * 业务逻辑：登录注册、个人信息 以及 个人成绩，物理：nginx、web服务器 以及 数据库，开发规范: mvc 架构\n       * 作者将架构重新定义为：软件架构指软件系统的顶层结构。\n         * 架构需要明确: 一群关联个体, 以及个体运作和协作的规则。\n     * 理解\n       * 框架是一种约束，而架构侧重于方向的指导\n       * 架构的结果是系统，系统是利用一系列个体(子系统、模块等)和规则达到既定目标。\n\n\n\n\n页首\n\n\n# 02 | 架构设计的历史背景\n\n * 架构是为了解决复杂性\n   * 演化史\n     * 机器语言 -> 汇编语言 -> 高级语言 -> 第一次软件危机与结构化程序设计 -> 第二次软件危机与面向对象 -> 软件架构\n   * 而只有规模较大的软件系统才会面临软件架构相关的问题，例如：系统规模庞大，内部耦合严重，开发效率低，后续修改和扩展困难, 容易出问题且很难排查和修复；\n   * 随着软件系统规模的增加，计算相关的算法和数据结构不再构成主要的设计问题；当系统由许多部分组成时，整个系统的组织，也就是所说的“软件架构”，导致了一系列新的设计问题。\n * 思考题\n   * 为何结构化编程、面向对象编程、软件工程、架构设计最后都没有成为软件领域的银弹？\n     * 思考: 唯一不变的是变化本身, 业务会随着时间越来越复杂\n\n\n\n\n页首\n\n\n# 03 | 架构设计的目的\n\n * 目的\n   * 解决软件系统复杂度带来的问题\n     * 复杂度包含了业务复杂度、资源、成本、进度、团队状态等因素，并且尽量量化\n     * 一般的一个架构师一般可以支撑20人以上的开发团队\n * 简单的复杂度分析案例\n   * 设计一个大学的学生管理系统，其基本功能包括登录、注册、成绩管理、课程管理等。\n * 思考题\n   * 按照“架构设计的主要目的是为了解决软件复杂度带来的问题”这个指导思想来分析一下你目前的业务系统架构\n\n\n\n\n页首\n\n\n# 04 | 复杂度来源：高性能\n\n * 高性能带来的复杂度主要体现在两方面\n   * 单台计算机内部为了高性能带来的复杂度\n     * 需要考虑如多进程、多线程、进程间通信、多线程并发等技术点\n       * 例如，nginx 可以用多进程也可以用多线程，jboss 采用的是多线程；redis 采用的是单进程，memcache 采用的是多线程，这些系统都实现了高性能，但内部实现差异却很大。\n   * 多台计算机集群为了高性能带来的复杂度\n     * 例如，淘宝\"双11\"，春节微信红包等\n     * 方案\n       * 任务分配\n         * 集群中每个主机的工作内容一样，都是完整任务流程\n           * 当流量特别高时，任务分配器(如，lvs、nginx、f5等)也会成为瓶颈\n       * 任务分解\n         * 将复杂任务拆解出子任务，再对子任务做高性能\n           * 拆分粒度过细，会带来其他的复杂性。如，调用链太长影响性能等\n         * 优点：\n           * 简单的系统更加容易做到高性能\n           * 可以针对单个任务进行扩展，更有针对性\n         * 例如\n           * 微信后台架构从逻辑上将各个子业务进行了拆分，包括：接入、注册登录、消息、lbs、摇一摇、漂流瓶、其他业务（聊天、视频、朋友圈等）。\n * 思考题\n   * 你所在的业务体系中，高性能的系统采用的是哪种方式？目前是否有改进和提升的空间？\n\n\n\n\n页首\n\n\n# 05 | 复杂度来源：高可用\n\n * 核心：冗余备份与失效转移\n   * 主备：冷备、热备、温备\n   * 具体实践的过程中，存在一个本质的矛盾：通过冗余来实现的高可用系统，状态决策本质上就不可能做到完全正确。\n * 场景\n   * 计算高可用\n     * 有一个特点就是无论在哪台机器上进行计算，同样的算法和输入数据，产出的结果都是一样的\n   * 存储高可用\n     * 难点不在于如何备份数据，而在于如何减少或者规避数据不一致对业务造成的影响。\n     * 存储与计算相比，一个本质上的区别：将数据从一台机器搬到到另一台机器，需要经过线路进行传输。\n       * 线路传输的速度是毫秒级别，同一机房内部能够做到几毫秒；分布在不同地方的机房，传输耗时需要几十甚至上百毫秒。\n         * 例如，从广州机房到北京机房，稳定情况下 ping 延时大约是50ms，不稳定情况下可能达到 1s 甚至更多。\n * 高可用状态决策\n   * 独裁式\n   * 协商式\n     * 协商式决策指的是两个独立的个体通过交流信息，然后根据规则进行决策，最常用的协商式决策就是主备决策。\n       * 协商式决策的架构不复杂，规则也不复杂，其难点在于，如果如果两者的信息交换出现问题（比如主备连接中断），此时状态决策应该怎么做。\n   * 民主式\n     * 民主式决策指的是多个独立的个体通过投票的方式来进行状态决策。例如，zookeeper 集群在选举 leader 时就是采用这种方式\n       * 容易产生脑裂，且选举算法复杂\n         * 为了解决脑裂问题，民主式决策的系统一般都采用“投票节点数必须超过系统总节点数一半”规则来处理。\n           * 这种方式虽然解决了脑裂问题，但同时降低了系统整体的可用性，即如果系统不是因为脑裂问题导致投票节点数过少，而真的是因为节点故障，此时系统也不会选出主节点，整个系统就相当于宕机了\n * 思考题\n   * 高性能和高可用是很多系统的核心复杂度，你认为哪个会更复杂一些？理由是什么？\n\n\n\n\n页首\n\n\n# 06 | 复杂度来源：可扩展性\n\n * 设计具备良好可扩展性的系统，有两个基本条件：正确预测变化、完美封装变化\n * 正确预测变化\n   * 唯一不变的是变化\n   * 复杂性在于：不可能每点都考虑可扩展性，也不能不考虑扩展性，所有的预测都有出错可能性\n   * 预测更多的是靠自己的经验、直觉\n * 应对变化\n   * 封装变化，隔离不变\n     * 这也是'设计模式'的思想, '规则引擎'亦是如此\n     * 封装变化常用的方式：提炼出一个“抽象层”和一个“实现层”, 抽象层对外提供相对稳定的接口，实现层根据具体业务定制开发。\n   * 注意：\n     * 太灵活会造成混乱\n * 思考题\n   * 你在具体代码中使用过哪些可扩展的技术？最终的效果如何？\n\n\n\n\n页首\n\n\n# 07 | 复杂度来源：低成本、安全、规模\n\n * 低成本的复杂度体现在：引入新技术或创造新技术\n   * 引入新技术。主要复杂度在于需要去熟悉新技术，并且将新技术与已有技术结合；\n   * 开创新技术。主要复杂度在于需要去创造全新的理念和技术，或组合现有技术或完全创新\n     * 往往只有“创新”才能达到低成本目标，如：\n       * linkedin 为了处理每天 5 千亿的事件，开发了高效的 kafka 消息系统。\n       * 新浪微博将传统的 redis/mc + mysql 方式，扩展为 redis/mc + ssd cache + mysql 方式，ssd cache 作为 l2 缓存使用，既解决了 mc/redis 成本过高，容量小的问题，也解决了穿透 db 带来的数据库访问压力（来源：https://www.infoq.cn/article/weibo-platform-archieture）\n * 安全的复杂度体现在：功能安全和架构安全\n   * 功能安全(其实就是“防小偷”, 本质是漏洞)\n     * 常见的 xss 攻击、csrf 攻击、sql 注入、windows 漏洞、密码破解等，本质上是因为系统实现有漏洞。\n   * 架构安全(其实就是“防强盗”, 本质是故意破坏)\n     * 如 ddos。传统的架构安全主要依靠防火墙，防火墙最基本的功能就是隔离网络，通过将网络划分成不同的区域，制定出不同区域之间的访问控策略来控制不同信任程度区域间传送的数据流。\n * 规模的复杂度体现在：量变引起质变\n   * 功能越来越多\n     * 假设系统间的功能都是两两相关的，系统的复杂度 = 功能数量 + 功能之间的连接数量. 随着功能的增多，复杂度近乎指数的增长。\n   * 数据越来越多\n     * mysql单表一般推荐在 5000 万行左右。如果因为业务的发展，单表数据达到了 10 亿行，就会产生很多问题，例如：\n       * 添加索引、修改表结构会很慢，可能需要几个小时，这几个小时内数据库表是无法插入数据的，相当于业务停机了。\n       * 即使有索引，索引的性能也可能会很低，因为数据量太大。\n       * 数据库备份耗时很长。\n     * 如果拆表，则会带来：怎么拆？拆了之后事务和查询等使用方式？等复杂度\n * 思考题\n   * 学习了 6 大复杂度来源后，结合你所在的业务，分析一下主要的复杂度是这其中的哪些部分？是否还有其他复杂度原因？\n\n\n\n\n页首\n\n\n# 08 | 架构设计三原则\n\n * 三原则：合适 > 演化 > 简单\n   * 合适原则\n     * 合适优于业界领先\n     * 真正优秀的架构都是在企业当前人力、条件、业务等各种约束下设计出来的，能够合理地将资源整合在一起并发挥出最大功效，并且能够快速落地。\n     * 常见的失败原因\n       * 没那么多人，却想干那么多活\n       * 没有那么多积累，却想一步登天\n         * 业界领先的方案其实都是“逼”出来的！\n       * 没有那么卓越的业务场景，却幻想灵光一闪成为天才\n         * 没有qq的用户量，却按照qq的体量进行设计\n   * 简单原则\n     * 简单由于复杂：\n       * 越来越精细、越来越复杂是正常的演化，但一步到位时会大大增加复杂度和不可控程度\n       * 架构是在指导演化方向和范围，尽可能的简单时会更健壮\n     * 《unix 编程艺术》总结的 kiss（keep it simple, stupid!）原则一样适应于架构设计。\n   * 演化原则\n     * 演化优于一步到位\n     * 根据环境的变化，演化架构进行适应当前阶段\n * 思考题\n   * 这三条架构设计原则是否每次都要全部遵循？是否有优先级？谈谈你的理解，并说说为什么。\n\n\n\n\n页首\n\n\n# 09 | 架构设计原则案例\n\n * 案例\n   * 淘宝网 和 qq\n * 思考题\n   * 搜索一个互联网大厂（batj、tmd 等）的架构发展案例，分析一下其发展过程，看看哪些地方体现了这三条架构设计原则。\n * reference\n   * <淘宝技术这十年>\n\n\n\n\n页首\n\n\n# 10 | 架构设计流程：识别复杂度\n\n * 识别复杂度\n   * 将主要的复杂度问题列出来，然后根据业务、技术、团队等综合情况进行排序，优先解决当前面临的最主要的复杂度问题。\n     * 设计的目标应该以峰值来计算。峰值一般取平均值的 3 倍。\n   * 常见系统的性能量级需要烂熟于心\n     * 例如nginx负载均衡性能是3万左右，mc的读取性能5万左右，kafka号称百万级，zookeeper写入读取2万以上，http请求访问大概在2万左右。\n\n\n\n\n页首\n\n\n# 11 | 架构设计流程：设计备选方案\n\n * 备选方案\n   * 以3-5个为佳\n     * 少于3个，则显得思路狭隘(可以防止思维狭隘，目光短浅，思维盲区等决策陷阱); 多于5个则浪费精力\n   * 备选方案之间要差异明显\n     * 例如，主备方案和集群方案差异就很明显，或者同样是主备方案，用 zookeeper 做主备决策和用 keepalived 做主备决策的差异也很明显。但是都用 zookeeper 做主备决策，一个检测周期是 1 分钟，一个检测周期是 5 分钟，这就不是架构上的差异，而是细节上的差异了，不适合做成两个方案。\n   * 备选方案的技术不要局限于已经熟悉的技术方案\n     * 设计架构时，架构师需要将视野放宽，考虑更多可能性。\n * 备选方案不宜过于详细\n   * 备选阶段关注的是技术选型，而不是技术细节，技术选型的差异要比较明显\n   * 备选方案过于详细的缺点：\n     * 耗费了大量的时间和精力。\n     * 将注意力集中到细节中，忽略了整体的技术设计，导致备选方案数量不够或者差异不大。\n     * 评审的时候其他人会被很多细节给绕进去，评审效果很差。\n\n\n\n\n页首\n\n\n# 12 | 架构设计流程：评估和选择备选方案\n\n * 360 度环评\n   * 具体的操作方式为：列出我们需要关注的质量属性点，然后分别从这些质量属性的维度去评估每个方案，再综合挑选适合当时情况的最优方案。\n     * 常见的方案质量属性点有：性能、可用性、硬件成本、项目投入、复杂度、安全性、可扩展性等。\n * 案例: 业务消息的可靠传输\n   * 方案环评\n   * 结论：最终选择备选方案 2，原因有： 排除备选方案 1 的主要原因是可运维性; 并且 kafka 的主要设计目标是高性能日志传输，而我们的消息队列设计的主要目标是业务消息的可靠传输。 排除备选方案 3 的主要原因是复杂度，目前团队技术实力和人员人员规模（总共 6 人，还有其他中间件系统需要开发和维护） 备选方案 2 的优点就是复杂度不高，也可以很好地融入现有运维体系，可靠性也有保障。\n   * 方案二缺点：\n     * 性能、成本、看起来不优雅\n * 思考题\n   * rocketmq 和 kafka 有什么区别，阿里为何选择了rocketmq ？\n\n\n\n\n页首\n\n\n# 13 | 架构设计流程：详细方案设计\n\n * 详细方案设计就是将方案涉及的关键技术细节给确定下来\n   * 深度理解关键细节点，避免因为遗漏了某个关键技术点或者关键的质量属性造成方案的执行出现问题\n   * 通过分步骤、分阶段、分系统等方式，尽量降低方案执行复杂度\n * 架构师需要做哪些技术验证，或者研究到什么深度以后，才能判断该技术是否适合呢？\n   * 基本原理，优点缺点，关键设计点，架构师至少要安装过，编写demo体验过，确定选型后，要进行性能和可用性测试例如es的索性设计就是关键设计点\n\n\n\n\n页首\n\n\n# 14 | 高性能数据库集群：读写分离\n\n * 高性能数据库集群的两种方式：读写分离、分库分表\n\n * 读写分离\n   \n   * 实现\n     * 搭建主从集群，主负责读写，从只负责读，通过复制主机数据到从节点到达数据一致。\n     * 业务服务器将写操作发送给主节点，读操作分散到从节点。\n     * 注意：\n       * 是主从集群，不是主备集群\n   * 复杂度\n     * 主从复制延迟\n       1. 写操作后的读操作指定发给数据库主服务器\n          * 对业务的侵入和影响较大\n       2. 读从机失败后再读一次主机(二次读取)\n       3. 关键业务读写操作全部指向主机，非关键业务采用读写分离\n     * 分配机制\n       * 程序代码封装\n         * 程序代码封装指在代码中抽象一个数据访问层（所以有的文章也称这种方式为“中间层封装”），实现读写操作分离和数据库服务器连接的管理\n           * 目前开源的实现方案中，淘宝的 tddl（ttaobao distributed data layer，外号: 头都大了）是比较有名的。\n       * 中间件封装\n         * 中间件对业务服务器提供 sql 兼容的协议，业务服务器无须自己进行读写分离。\n         * 对于业务服务器来说，访问中间件和访问数据库没有区别，\n           * 现在 mysql 官方推荐 mysql router\n           * 奇虎 360 公司也开源了自己的数据库中间件 atlas，atlas 是基于 mysql proxy 实现的\n\n * 分库分表\n   \n   * 见下节内容\n\n * 思考题\n   \n   * 数据库读写分离一般应用于什么场景？能支撑多大的业务规模？\n     * 读写分离适用单机并发无法支撑并且读的请求更多的情形。在单机数据库情况下，表上加索引一般对查询有优化作用却影响写入速度，读写分离后可以单独对读库进行优化，写库上减少索引，对读写的能力都有提升，且读的提升更多一些。\n     * 不适用的情况:\n       * 1 如果并发写入特别高，单机写入无法支撑，就不适合这种模式。\n       * 2 通过缓存技术或者程序优化能够满足要求\n\n\n\n\n页首\n\n\n# 15 | 高性能数据库集群：分库分表\n\n * 分库分表：原因\n   * 单个数据库服务器存储的数据量不能太大。\n     * 当数据量达到千万甚至上亿条的时候，单台数据库服务器的存储能力会成为系统的瓶颈，主要体现在这几个方面：\n       * 数据量太大，读写的性能会下降，即使有索引，索引也会变得很大，，性能同样会下降。\n       * 数据文件会变得很大，数据库备份和恢复需要耗费很长时间\n       * 数据文件越大，极端情况下丢失数据的风险越高（例如，机房火灾导致数据库主备机都发生故障）。\n * 分库\n   * join 操作问题、事务问题、成本问题\n     * 业务分库后，原本在同一个数据库中的表分散到不同数据库中，导致无法使用 sql 的 join 查询。\n     * 原本在同一个数据库中不同的表可以在同一个事务中修改，业务分库后，表分散到不同的数据库中，无法通过事务统一修改。虽然数据库厂商提供了一些分布式事务的解决方案（例如，mysql 的 xa），但性能实在太低，与高性能存储的目标是相违背的。\n * 分表\n   * 垂直分表\n     * 垂直分表引入的复杂性主要体现在表操作的数量要增加。原来只要一次查询就可以的，现在要两次或者多次查询。\n   * 水平分表\n     * 路由、join操作、count()操作、order by()操作\n * 实现\n   * 分库分表具体的实现方式也是“程序代码封装”和“中间件封装”，但实现会更复杂。\n     * 读写分离实现时只要识别 sql 操作是读操作还是写操作，通过简单的判断 select、update、insert、delete 几个关键字就可以做到\n     * 分库分表的实现除了要判断操作类型外，还要判断 sql 中具体需要操作的表、操作函数（例如 count 函数)、order by、group by 操作等，然后再根据不同的操作进行不同的处理。\n * 思考题\n   * 你认为什么时候引入分库分表是合适的？是数据库性能不够的时候就开始分库分表么？\n * utility\n   * 如果使用hash进行分表的话，为什么大多方案推荐2的n次方作为表的总数，除了收缩容易还有什么好处吗？\n     * 这个是hash函数实现的一个技巧，当计算hash值的时候，普通做法是取余操作，例如h%len，但如果len是2的n次方，通过位操作性能更高，计算方式为h & (len-1)\n   * 针对mysql，发现如果字段有blob的字段，select 不写这个字段，和写这个字段，效率差异很大，这个是什么原因？\n     * blob的字段是和行数据分开存储的，而且磁盘上并不是连续的，因此select blob字段会让磁盘进入随机io模式\n\n\n\n\n页首\n\n\n# 16 | 高性能nosql\n\n * nosql\n   * nosql != no sql，而是 nosql = not only sql\n   * 本质上是牺牲 acid 中的某个或者某几个特性，因此我们不能盲目地迷信 nosql 是银弹，而应该将 nosql 作为 sql 的一个有力补充，\n * 常见的 nosql 方案分为 4 类\n   * k-v 存储：解决关系数据库无法存储数据结构的问题，以 redis 为代表。\n   * 文档数据库：解决关系数据库强 schema 约束的问题，以 mongodb 为代表。\n   * 列式数据库：解决关系数据库大数据场景下的 i/o 问题，以 hbase 为代表。\n   * 全文搜索引擎：解决关系数据库的全文搜索性能问题，以 elasticsearch 为代表。\n     * 传统的关系型数据库通过索引来达到快速查询的目的，但是在全文搜索的业务场景下，索引也无能为力，主要体现在：\n       * 全文搜索的条件可以随意排列组合，如果通过索引来满足，则索引的数量会非常多。\n       * 全文搜索的模糊匹配方式，索引无法满足，只能用 like 查询，like 查询是整表扫描，效率非常低。\n\n\n\n\n页首\n\n\n# 17 | 高性能缓存架构\n\n * 缓存系统\n   * 缓存穿透: 查询一定不存在的数据时, 查询回源db。流量大(大量的不存在数据请求)时db被压垮\n     * 布隆过滤器、缓存空值(生命周期短)\n   * 缓存击穿：缓存一种非常“热点”的数据，在某个时间点过期的时候，恰好在这个时间点对这个key有大量的并发请求过来，瞬间把后端db压垮\n     * 互斥锁(mutex key)、不过期(但后台多线程刷新)\n   * 缓存雪崩：设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到db，db瞬时压力过重雪崩\n     * 多副本，并且每个副本设置不同的过期时间(在指定范围内随机)\n     * 双key策略：要缓存的key过期时间是t，key1没有过期时间。当读取不到key时就返回key1的内容，然后触发一个同时更新key和key1的事件\n * 缓存的更新\n   * 1. 同步刷新缓存：当更新了某些信息后，立刻让缓存失效。\n     * 这种做法的优点是用户体验好，缺点是修改一个数据可能需要让很多缓存失效\n   * 2. 适当容忍不一致：例如某东的商品就是这样，我查询的时候显示有货，下单的时候提示我没货了\n   * 3. 关键信息不缓存：库存，价格等不缓存，因为这类信息查询简单，效率高，关系数据库查询性能也很高\n * 思考题\n   * 分享一下你所在的业务发生过哪些因为缓存导致的线上问题？采取了什么样的解决方案？效果如何？\n\n\n\n\n页首\n\n\n# 18 | 单服务器高性能模式：ppc与tpc\n\n * 单服务器高性能模式：ppc 与 tpc\n   * ppc 是 process per connection 的缩写，其含义是指每次有新的连接就新建一个进程去专门处理这个连接的请求，这是传统的 unix 网络服务器所采用的模型。\n     * 一般情况下，ppc 方案能处理的并发连接数量最大也就几百。\n   * tpc 是 thread per connection 的缩写，其含义是指每次有新的连接就新建一个线程去专门处理这个连接的请求。\n * 为什么说门户网站是海量连接常量请求的情况？\n   * 海量连接：连接的用户很多\n   * 常量请求：每个用户请求数量不多，大部分都是看完一篇文章再去点击另外的文章\n * 思考题\n   * 什么样的系统比较适合本期所讲的高性能模式？原因是什么？\n     * 常量连接常量请求：例如内部运营系统，管理系统\n\n\n\n\n页首\n\n\n# 19 | 单服务器高性能模式：reactor与proactor\n\n * reactor与proactor\n   * io操作分两个阶段\n     * 1、等待数据准备好(读到内核缓存)\n     * 2、将数据从内核读到用户空间(进程空间)\n     * 一般来说1花费的时间远远大于2\n   * 1上阻塞2上也阻塞的是同步阻塞io\n   * 1上非阻塞2阻塞的是同步非阻塞io，这讲说的reactor就是这种模型\n   * 1上非阻塞2上非阻塞是异步非阻塞io，这讲说的proactor模型就是这种模型\n\n\n\n\n页首\n\n\n# 20 | 高性能负载均衡：分类及架构\n\n * 高性能集群的复杂性主要体现在:\n   * 需要增加一个任务分配器，以及为任务选择一个合适的任务分配算法。\n * 负载均衡分类，常见的负载均衡系统包括 3 种：\n   * dns 负载均衡\n   * 硬件负载均衡\n     * 目前业界典型的硬件负载均衡设备有两款：f5 和 a10。\n     * 优点\n       * 功能强大：全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡\n       * 性能强大：软件负载均衡支持到 10 万级并发已经很厉害了，硬件负载均衡可以支持 100 万以上的并发。\n       * 稳定性高：\n       * 支持安全防护：\n     * 缺点: 贵、扩展能力差(可以配置但无法定制)\n   * 软件负载均衡。\n     * 常见的有 nginx 和 lvs、haproxy，其中 nginx 是软件的的 7 层负载均衡，lvs 是 linux 内核的 4 层负载均衡\n       * ngxin 的性能是万级，一般的 linux 服务器上装一个nginx 大概能到 5 万 / 秒；lvs 的性能是十万级，据说可达到 80 万 / 秒；而 f5 性能是百万级\n     * 优点：简单、便宜、灵活\n     * 缺点：性能一般\n * 组合的基本原则为：\n   * dns 负载均衡用于实现地理级别的负载均衡；硬件负载均衡用于实现集群级别的负载均衡；软件负载均衡用于实现机器级别的负载均衡。\n * 思考题\n   * 假设你来设计一个日活跃用户 1000 万的论坛的负载均衡集群，你的方案是什么？设计理由是什么？\n     * dau --\x3e 10h/day + 单用户请求 --\x3e qps、tps --\x3e 峰值 ~ qps * (3-5) --\x3e 以峰值来设计\n\n\n\n\n页首\n\n\n# 21 | 高性能负载均衡：算法\n\n * 负载均衡算法：\n   * 轮询\n   * 加权轮询\n     * 解决不同服务器处理能力有差异的问题\n   * 负载最低优先\n     * 站在服务器的角度来进行分配的\n   * 性能最高优先\n     * 站在客户端的角度来进行分配的\n * 思考题\n   * 微信抢红包的高并发架构，应该采取什么样的负载均衡算法？谈谈你的分析和理解\n\n\n\n\n页首\n\n\n# 22 | 想成为架构师，你必须知道cap理论\n\n * cap\n   \n   * consistency、availability、partition tolerance\n     * 对某个指定的客户端来说，读操作保证能够返回最新的写操作结果。\n     * 非故障的节点在合理的时间内返回合理的响应（不是错误和超时的响应）\n     * 当出现网络分区后，系统能够继续“履行职责”\n   * 适合于：有互联和数据共享的分布式系统、关注的是对数据的读写操作\n\n * note\n   \n   * 分布式系统理论上一定会存在 p，所以不可能选择 ca 架构，只能选择 cp 或者 ap 架构\n\n * 思考题\n   \n   * 基于 paxos 算法构建的分布式系统，属于 cap 架构中的哪一种？谈谈你的分析和理解。\n     * paxos算法实现的系统是cp，根据raft的论文描述，工程上目前还没有完全实现paxos算法的系统\n\n\n\n\n页首\n\n\n# 23 | 想成为架构师，你必须掌握的cap细节\n\n * cap 关键细节点\n   \n   * cap 关注的粒度是数据，而不是整个系统。\n     * c 与 a 之间的取舍可以在同一系统内以非常细小的粒度反复发生，而每一次的决策可能因为具体的操作，乃至因为牵涉到特定的数据或用户而有所不同。\n   * cap 是忽略网络延迟的。\n   * 正常运行情况下，不存在 cp 和 ap 的选择，可以同时满足 ca。\n     * cap 理论告诉我们分布式系统只能选择 cp 或者 ap，但.其实这里的前提是系统发生了“分区”现象。如果系统没有发生分区现象，也就是说 p 不存在的时候（节点间的网络连接一切正常），我们没有必要放弃 c 或者 a，应该 c 和 a 都可以保证，这就要求架构设计的时候既要考虑分区发生时选择 cp 还是 ap，也要考虑分区没有发生时如何保证 ca。\n   * 放弃并不等于什么都不做，需要为分区恢复后做准备。\n\n * acid 是数据库管理系统为了保证事务的正确性而提出来的一个理论，acid 包含四个约束，\n   \n   * atomicity（原子性）\n     * 一个事务中的所有操作，要么全部完成，要么全部不完成，不会在中间某个环节结束\n   * consistency（一致性）\n     * 在事务开始之前和事务结束以后，数据库的完整性没有被破坏。\n   * isolation（隔离性）\n     * 数据库允许多个并发事务同时对数据进行读写和修改的能力。隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable）\n   * durability（持久性）\n     * 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。\n\n * base 核心思想是即使无法做到强一致性（cap 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性。\n   \n   * base 是指基本可用（basically available）\n     * 分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。\n   * 软状态（ soft state）\n     * 允许系统存在中间状态，而该中间状态不会影响系统整体可用性。这里的中间状态就是 cap 理论中的数据不一致。\n   * 最终一致性（ eventual consistency）\n     * 系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。\n   * note\n     * base 理论本质上是对 cap 的延伸和补充，更具体地说，是对 cap 中 ap 方案的一个补充。\n     * base 理论考虑了延时；要求在分区期间牺牲一致性，但分区故障恢复后，系统应该达到最终一致性性\n\n * 思考题\n   \n   * 假如你来设计电商网站的高可用系统，按照 cap 理论的要求，你会怎么设计？\n\n\n\n\n页首\n\n\n# 24 | fmea方法，排除架构可用性隐患的利器\n\n * fmea (failure mode and effects analysis, 故障模式与影响分析)\n   * 在架构设计领域，fmea 的具体分析方法是：\n     * 给出初始的架构设计图。\n     * 假设架构中某个部件发生故障。\n     * 分析此故障对系统功能造成的影响。\n     * 根据分析结果，判断架构是否需要进行优化。\n * fmea 分析的方法其实很简单，就是一个 fmea 分析表，常见的 fmea 分析表格包含下面部分。\n   * 功能点\n     * 指的是从用户角度来看的，而不是从系统各个模块功能点划分来看的\n   * 故障模式\n     * 故障模式指的是系统会出现什么样的故障，包括故障点和故障形式。需要特别注意的是，这里的故障模式并不需要给出真正的故障原因，，我们只需要假设出现某种故障现象即可，例如 mysql 响应时间达到 3 秒。\n     * 故障模式的描述要尽量精确，多使用量化描述，避免使用泛化的描述。例如，推荐使用“mysql 响应时间达到 3 秒”，而不是“mysql 响应慢”。\n   * 故障影响\n     * 当发生故障模式中描述的故障时，功能点具体会受到什么影响。故障影响也需要尽量准确描述。例如，推荐使用“20% 的用户无法登录”，而不是“大部分用户无法登录”。\n   * 严重程度\n     * 严重程度指站在业务的角度故障的影响程度，一般分为“致命 / 高 / 中 / 低 / 无”五个档次。严重程度按照这个公式进行评估：严重程度 = 功能点重要程度 × 故障影响范围 × 功能点受损程度。\n   * 故障原因\n   * 故障概率\n     * 这里的概率就是指某个具体故障原因发生的概率。一般分为“高 / 中 / 低”三档即可\n   * 风险程度\n     * 风险程度就是综合严重程度和故障概率来一起判断某个故障的最终等级，风险程度 = 严重程度 × 故障概率。\n   * 已有措施\n     * 针对具体的故障原因，系统现在是否提供了某些措施来应对，包括：检测告警、容错、自恢复等。\n   * 规避措施\n     * 规避措施指为了降低故障发生概率而做的一些事情，可以是技术手段，也可以是管理手段。例如：\n       * 技术手段：为了避免新引入的 mongodb 丢失数据，在在 mysql 中冗余一份。\n       * 管理手段：为了降低磁盘坏道的概率，强制统一更换服务时间超过 2 年的磁盘\n   * 解决措施\n     * 解决措施指为了能够解决问题而做的一些事情，一般都是技术手段。例如：\n       * 为了解决密码暴力破解，增加密码重试次数限制。\n       * 为了解决拖库导致数据泄露，将数据库中的敏感数据加密保存。\n       * 为了解决非法访问，增加白名单控制。\n   * 后续规划\n * fmea实践\n   * 假设我们设计一个最简单的用户管理系统，包含登录和注册两个两个功能，其初始架构是：\n     * mysql 负责存储，memcache（以下简称 mc）负责缓存，server 负责业务处理。\n   * fmea 分析后，能够有什么样的发现，下表是分析的样例\n   * 经过上表的 fmea 分析，将“后续规划”列的内容汇总一下，我们最终得到了下面几条需要改进的措施：\n     * mysql 增加备机。mc 从单机扩展为集群。mysql 双网卡连接。\n * 思考题 请使用 fmea 方法分析一下 hdfs 系统的架构，看看 hdfs 是如何应对各种故障的，并且分析一下 hdfs 是否存在高可用问题。\n\n\n\n\n页首\n\n\n# 25 | 高可用存储架构：双机架构\n\n * 双机架构：单机即可解决数据存储情况下，保证高可用\n * 复杂性主要体现在如何应对复制延迟和中断导致的数据不一致问题\n   * 数据如何复制？ 各个节点的职责是什么？ 如何应对复制延迟 和 复制中断？\n * 双击切换：要实现一个完善的切换方案，必须考虑这几个关键的设计点：\n   * 主备状态判断\n     * 状态传递的渠道\n     * 状态检查的内容\n   * 切换决策\n   * 数据冲突解决\n * 常见架构:(根据传递渠道不同)\n   * 互联式、中介式、模拟式、主主复制\n\n\n\n\n页首\n\n\n# 26 | 高可用存储架构：集群和分区\n\n * 数据集中集群\n   * 一主多备、一主多从\n   * 复杂度\n     * 主机如何将数据复制给备机\n       * 主备和主从架构中，只有一条复制通道，而数据集中集群架构中，存在多条复制通道。多条复制通道首先会增大主机复制的压力，某些场景下我们需要考虑如何降低主机复制压力，或者降低主机复制给正常读写带来的压力。\n     * 备机如何检测主机状态\n       * 在数据集中集群架构中，多台备机都需要对主机状态进行判断，而不同的备机判断的结果可能是不同的，如何处理不同备机对主机状态的不同判断，是一个复杂的问题。\n     * 主机故障后，如何决定新的主机\n       * 而在数据集中集群架构中，有多台备机都可以升级为主机，但实际上只能允许一台备机升级为主机，那么究竟选择哪一台备机作为新的主机，备机之间如何协调，这也是一个复杂的问题。\n * 数据分散集群\n   * 数据分散集群指多个服务器组成一个集群，每台服务器又会备份一部分数据。\n   * 复杂度：均衡、容错、可伸缩性\n * 数据分区\n   * 前面我们讨论的主要考虑当部分硬件可能损坏的情况下系统应该如何处理，但对于一些影响非常大的灾难或者事故来说，有可能所有的硬件全部故障。例如，新奥尔良水灾、美加大停电，这时候需要基于地理级别的故障来设计高可用架构，这就是数据分区架构产生的背景。\n   * 数据分区的备份方式：集中式备份、互备式、独立式备份\n\n\n\n\n页首\n\n\n# 27 | 如何设计计算高可用架构？\n\n * 复杂度：任务管理\n * 高可用方式\n   * 主从、主备、集群(对称集群、非对称集群)\n\n\n\n\n页首\n\n\n# 28 | 业务高可用的保障：异地多活架构\n\n * 异地多活架构可以分为：\n   * 同城异区\n   * 跨城异地\n     * 引入了一个看似矛盾的地方：数据不一致业务肯定不会正常，但跨城异地肯定会导致数据不一致。\n       * 重点还是在“数据”上，即根据数据的特性来做不同的架构。如果是强一致性要求的数据，例如银行存款余额、支付宝余额等，这.类数据实际上是无法做到跨城异地多活的。\n   * 跨国异地\n     * 为不同地区用户提供服务\n     * 只读类业务做多活\n       * 例如，谷歌的搜索业务，由于用户搜索资料时，这些资料都已经存在于谷歌的搜索引擎上面，无论是访问英国谷歌，还是访问美国谷歌，搜索结果基本相同，并且对用户来说，也不需要搜索到最新的实时资料，跨国异地的几秒钟网络延迟，对搜索结果是没有什么影响的。\n * 思考题\n   * 假设我们做了前面提到的高可用存储架构中的数据分区备份，又通过自动化运维能够保证 1 分钟就能将全部系统正常启动，那是否意味着没有必要做异地多活了？\n     * 备份系统平常没有流量，如果直接上线可能触发平常测试不到的故障。\n     * 再实时的系统也会有数据延时，如果涉及到金融这种系统，仍然是不敢直接切换的。\n     * 系统运行过程中会有很多中间数据，缓存数据等。系统不经过预热直接把流量倒过来，大流量会直接把系统拖垮\n\n\n\n\n页首\n\n\n# 29 | 异地多活设计4大技巧\n\n * 核心\n   * 采用多种手段，保证绝大部分用户的核心业务异地多活！\n * 技巧\n   * 保证核心业务的异地多活\n   * 保证核心数据最终一致性\n     * 因此异地多活架构面临一个无法彻底解决的矛盾：业务上要求数据快速同步，物理上正好做不到数据快速同步，因此所有数据都实时同步，实际上是一个无法达到的目标。\n       * 尽量减少异地多活机房的距离，搭建高速网络\n       * 尽量减少数据同步，只同步核心业务相关的数据\n       * 保证最终一致性，不保证实时一致性\n   * 采用多种手段同步数据\n     * 数据同步是异地多活架构设计的核心，幸运的是基本上存储系统本身都会有同步的功能。例如，mysql 的主备复制、redis 的 cluster 功能、elasticsearch 的集群功能。但有时候仅使用这些功能是不够的，需要拓开思路。\n   * 只保证绝大部分用户的异地多活\n\n\n\n\n页首\n\n\n# 30 | 异地多活设计4步走\n\n * 业务分级\n   * 挑选出核心的业务，只为核心业务设计异地多活，降低方案整体复杂度和实现成本。\n * 数据分类\n   * 唯一性、实时性、数据量、可丢性、可恢复性、\n * 数据同步\n   * 存储系统同步\n     * 几乎主流的存储系统都会有自己的同步方案；缺点是这类同步方案都是通用的，无法针对业务数据特点做定制化的控制。\n * 异常处理\n   * 多通道同步\n   * 同步和访问结合\n   * 日志记录\n   * 用户补偿\n\n\n\n\n页首\n\n\n# 31 | 如何应对接口级的故障？\n\n * 核心思想：优先保证核心业务和优先保证绝大部分用户\n * 应对策略：降级、熔断、限流、排队\n   * 降级的目的是应对系统自身的故障，而熔断的目的是应对依赖的外部系统故障的情况\n   * 限流则是从用户访问压力的角度来考虑如何应对故障。限流指只允许系统能够承受的访问量进来，超出系统访问能力的请求将被丢弃。\n * 思考题\n   * 如果你来设计一个整点限量秒杀系统，包括登录、抢购、支付（依赖支付宝）等功能，你会如何设计接口级的故障应对手段？\n\n\n\n\n页首\n\n\n# 32 | 可扩展架构的基本思想和模式\n\n * 架构可扩展模式：包括分层架构、soa 架构、微服务和微内核等\n   * 如何避免扩展时改动范围太大，是软件架构可扩展性设计的主要思考点\n * 可扩展模式的核心就是拆分，常见的拆分思路有如下三种。\n   * 面向流程拆分：将整个业务流程拆分为几个阶段，每个阶段作为一部分。分层架构。\n   * 面向服务拆分：将系统提供的服务拆分，每个服务作为一部分。soa、微服务。\n   * 面向功能拆分：将系统提供的功能拆分，每个功能作为一部分。微内核架构。\n\n\n\n\n页首\n\n\n# 33 | 传统的可扩展架构模式：分层架构和soa\n\n * 分层架构\n   * 例如，c/s 架构、b/s 架构，常见的是 3 层架构（例如，，mvc、mvp 架构）\n   * 分层架构设计最核心的一点就是需要保证各层之间的差异足够清晰，边界足够明显\n   * 分层架构之所以能够较好地支撑系统扩展，本质在于隔离关注点（separation of concerns），即每个层中的组件只会处理本层的逻辑。\n   * 分层时要保证层与层之间的依赖是稳定的，才能真正支撑快速扩展\n * soa(service oriented architecture)\n   * 三要素：服务、esb(enterprise service bus)、松耦合\n   * soa 使用 esb 来屏蔽异构系统对外提供各种不同的接口方式，以此来达到服务间高效的互联互通。\n   * soa 更多是在传统企业（例如，制造业、金融业等）落地和推广，在互联网行业并没有大规模地实践和推广。\n     * soa 解决了传统 it 系统重复建设和扩展效率低的问题，但其本身也引入了更多的复杂性。soa 最广为人诟病的就是 esb，esb 需要实现与各种系统间的协议转换、数据转换、透明的动态路由等功能。esb集中化的管理带来了性能不佳，厚重等问题。\n     * 想一下 soa 的提出背景就可以发现，企业在应用 soa 时时，各种异构的 it 系统都已经存在很多年了，完全重写或者按照统一标准进行改造的成本是非常大的，只能通过 esb 方式去适配已经存在的各种异构系统。\n * 思考题\n   * 为什么互联网企业很少采用 soa 架构？\n\n\n\n\n页首\n\n\n# 34 | 深入理解微服务架构：银弹 or 焦油坑？\n\n * soa 和微服务对比：\n   * 从以下几方面考虑：服务粒度、服务通信、应用场景\n * 微服务陷阱\n   * 服务划分过细，服务间关系复杂\n   * 服务数量太多，团队效率急剧下降\n   * 调用链太长，性能下降\n   * 调用链太长，问题定位困难\n   * 没有自动化支撑，无法快速交付\n   * 没有服务治理，微服务数量多了后管理混乱\n     * 主要表现在：服务路由、服务故障隔离、服务注册和发现\n\n\n\n\n页首\n\n\n# 35 | 微服务架构最佳实践 - 方法篇\n\n * 服务粒度\n   * 一般来说，3个人开发一个服务为佳：既能够形成有效的讨论、也可以形成一个稳定的团队备份\n   * 基于上述策略，计算出拆分后合适的服务数量\n * 拆分方法\n   * 基于业务逻辑拆分\n   * 基于可扩展拆分\n     * 拆分成稳定服务和变动服务，可以提升项目快速迭代的效率，避免在开发的时候，不小心影响了已有的成熟功能导致线上问题。\n   * 基于可靠性拆分\n     * 避免非核心服务故障影响核心服务\n     * 核心服务高可用方案可以更简单\n     * 能够降低高可用成本\n   * 基于性能拆分\n * 基础设施 ![微服务基础设施](./rsc/arch_meshsrv_ infrastructure.png)\n * 思考题\n   * 参考文章中提到的方法，思考一下你所在的业务微服务架构是否还有可以改进和提升的空间？\n\n\n\n\n页首\n\n\n# 36 | 微服务架构最佳实践 - 基础设施篇\n\n * 基础设施\n   * 自动化测试\n     * 涵盖的范围包括代码级的单元测试、单个系统级的集成测试、系统间的接口测试，系统间的接口测试是基础保障。\n   * 配置中心\n   * 接口框架\n     * 微服务提倡轻量级的通信方式，一般采用 http/rest 或者 rpc 方式统一接口协议。但在实践过程中，光统一接口协议还不够，还需要统一接口传递的数据格式。\n   * api网关\n     * api 网关是外部系统访问的接口，所有的外部系统接⼊系统都需要通过 api 网关，主要包括接入鉴权（是否允许接入）、权限控制（可以访问哪些功能）、传输加密、请求路由、流量控制等功能。\n   * 服务发现\n   * 服务容错\n     * 常见的服务容错包括请求重试、流控和服务隔离。通常情况下，服务容错会集成在服务发现和服务路由系统中。\n   * 服务监控\n     * 微服务节点级的监控和信息收集\n   * 服务追踪\n     * 服务完整流程跟踪分析\n     * 绝大部分请求跟踪的实现技术都基于 google 的 dapper 论文《dapper, a large-scale distributed systems tracing infrastructure》。\n   * 服务安全\n * 思考题\n   * 给你一个由 10 位 java 高级软件工程师组成的开发团队，采用自研的方式，完成所有的微服务基础设施开发，你预测需要多长时间？理由是什么呢？\n\n\n\n\n页首\n\n\n# 37 | 微内核架构详解\n\n * 微内核架构（microkernel architecture），也被称为插件化架构（plug-in architecture），是一种面向功能进行拆分的可扩展性架构\n * 微内核架构包含两类组件：核心系统（core system）和插件模块（plug-in modules）\n   * 关键技术有：插件管理、插件连接和插件通信\n     * 插件连接指插件如何连接到核心系统。通常来说，核心系统必须制定插件和核心系统的连接规范，然后插件按照规范实现，核心系统按照规范加载即可。\n * 常见的两种微内核具体实现：\n   * osgi open services gateway initiative 是一个插件化的标准\n   * 规则引擎\n     * 执行引擎解析配置好的业务流，执行其中的条件和规则，通过这种方式来支持业务的灵活多变。如：esper，drools\n     * 一般流程：\n       * 开发人员将业务功能分解提炼为多个规则，将规则保存在规则库中\n       * 业务人员根据业务需要，通过将规则排列组合，配置成业务流程，保存在业务库中。\n       * 规则引擎执行业务流程实现业务功能。\n\n\n\n\n页首\n\n\n# 38 | 架构师应该如何判断技术演进的方向？\n\n * 技术演进的模式: 基于业务发展阶段进行判断\n * 技术创新会推动业务发展，而业务发展也会逼迫技术进步\n * reference\n   * <淘宝技术十年>\n\n\n\n\n页首\n\n\n# 39 | 互联网技术演进的模式\n\n * 互联网业务发展一般分为几个时期(不同时期的差别主要体现在两个方面：复杂性、用户规模)：\n   * 初创期、\n     * 互联网业务刚开始一般都是一个创新的业务点，这个业务点的重点不在于“完善”，而在于“创新”，只有创新才能吸引用户；初创期的业务对技术就一个要求：“快”，能买就买，有开源的就用开源的。\n   * 发展期、\n     * 当业务推出后经过市场验证如果是可行的，则吸引的用户就会越来越多，此时原来不完善的业务就进入了一个快速发展的时期。\n     * 因此会有越来越多的新功能不断地加入到系统中。一般会有以下几个阶段：堆功能期、优化期、架构期\n   * 竞争期\n     * 当业务继续发展，已经形成一定规模后，一定会有竞争对手开始加入行业来竞争，当竞争对手加入后，大家互相学习和模仿，业务更加完善，也不断有新的业务创新出来，而且由于竞争的压力，对技术的要求是更上一层楼了。\n     * 当系统数量越来越多，到了一个临界点后就产生了质变，主要体现在：重复造轮子、系统交互一团乱，解决方案如下：\n       * 平台化: 目的在于解决“重复造轮子”的问题。\n       * 服务化: 目的在于解决“系统交互”的问题，常见的做法是通过消息队列来完成系统间的异步通知，通过服务框架来完成系统间同步调用\n   * 成熟期。\n     * 技术上能做的大动作其实也不多了，更多的是进行优化。\n\n\n\n\n页首\n\n\n# 40 | 互联网架构模板：“存储层”技术\n\n\n\n * 互联网架构模板中的存储层技术\n   \n   * sql\n     * 单表\n     * 分库分表\n       * 中间件\n         * 技术要求很高，要将分库分表做到自动化和平台化，不是一件容易的事情。所以一般是规模很大的公司才会自己做。例如百度的 dbproxy、淘宝的 tddl。中小公司建议使用开源方案，例如 mysql 官方推荐的 mysql router、360 开源的数据库中间件 atlas\n     * 平台化\n       * 当 sql 服务器越来越多，如果每个业务都基于统一的数据库中间件独立部署自己的 sql 集群，就会导致新的复杂度问题，具体表现在：\n         * 数据库资源使用率不高，比较浪费。\n         * 各 sql 集群分开维护，投入的维护成本越来越高\n       * 大公司此时一般都会在 sql 集群上构建 sql 存储平台，，以对业务透明的形式提供资源分配、数据备份、迁移、容灾、读写分离、分库分表等一系列服务，例如淘宝的 ump（unified mysql platform）系统。\n   * nosql\n     * 单库\n     * nosql集群\n       * nosql 方案一般自己本身就提供集群的功能，例如 memcache 的一致性 hash 集群、redis 3.0 的集群，\n     * 平台化\n       * 资源动态按需动态分配：\n       * 资源自动化管理：例如\n       * 故障自动化处理\n   * 小文件存储\n     * 一般在1m以下，但数据量巨大。典型的小文件存储有：淘宝的 tfs、京东 jfs、facebook 的 haystack\n   * 大文件存储\n     * 包含业务上的大数据(youtube的视频内容等)、海量的日志数据\n       * 说到大文件，特别要提到 google 和 yahoo，google 的 3 篇大数据论文（bigtable/map- reduce/gfs）开启了一个大数据的时代，而yahoo 开源的 hadoop 系列（hdfs、hbase 等），基本上垄断了开源界的大数据处理\n   \n   \n\n * 思考题\n   \n   * 既然存储技术发展到最后都是存储平台，为何没有出现存储平台的开源方案，但云计算却都提供了存储平台方案？\n     * 代价、价值\n\n\n\n\n页首\n\n\n# 41 | 互联网架构模板：“开发层”和“服务层”技术\n\n * 开发层技术\n   * 开发框架\n     * 互联网公司一般会指定一个大的技术方向，然后使用统一的开发框架，这样可以节省沟通和团队协作成本。例如，java 相关的开发框架 ssh、springmvc、play，ruby 的 ruby on rails，php 的 thinkphp，python 的 django 等。\n   * web服务器\n   * 容器\n     * 腾讯万台规模的 docker 应用实践\n     * 新浪微博红包的大规模 docker 集群\n * 服务层技术：服务层的主要目标其实就是为了降低系统间相互关联的复杂度。\n   * 配置中心\n     * 将所有配置集中在一个平台操作，效率高；同时可以制定配置规则检查，避免手误造成损失\n     * 常用“系统标识 + host + port”来标识唯一运行实例\n   * 服务中心\n     * 两种实现方式：服务名字系统（service name system） 和 服务总线系统（service bus system）\n   * 消息队列\n * 思考题\n   * 使用统一的开发框架和开发语言可以让团队开发效率更高，但这样做会带来什么问题？如何解决？\n     * 开发框架和开发语言，都是有场景限制的，尺有所短，寸有所长\n     * 将业务服务化，对外提供统一的api接口\n     * 在业务规模小的时候采用单一语言单一框架，当规模大了还是应该有一定的灵活性，有一个主力的语言和框架，合适的工作用合适语言和框架，而微服务架构的比较适合混合语言和架构的模式\n\n\n\n\n页首\n\n\n# 42 | 互联网架构模板：“网络层”技术\n\n * 站在网络层的角度整体设计架构，而不是某个具体网络的搭建。\n   \n   * 负载均衡\n     * dns、nginx 、lvs 、f5\n   * 多机房\n     * 同城、跨城、跨国\n     * 目的：灾备\n   * 多中心\n     \n     * 要求高：要求每个中心都同时对外提供服务，且业务能够自动在多中心之间切换，故障后不需人工干预或者很少的人工干预就能自动恢复。\n       \n       * 多中心设计的关键就在于“数据一致性”和“数据事务性”。目前没有很成熟的且通用的解决方案，需要基于业务的特性进行详细分析和设计\n     \n     * 正因为多中心设计的复杂性，不一定所有业务都能实现多中心，目前国内的银行、支付宝这类系统就没有完全实现多中心，不然也不会出现挖掘机一铲子下去，支付宝中断 4 小时的故障。\n\n * utility\n   \n   * 两地三中心，是指同城两个机房是双活，异地机房是备份，当同城两个机房都挂掉，异地机房不能接管业务，只能用来备份恢复\n\n\n\n\n页首\n\n\n# 43 | 互联网架构模板：“用户层”和“业务层”技术\n\n * 用户层技术\n   * 用户管理\n     * 单点登录sso(目前最成熟的开源单点登录方案当属 cas)、oauth2.0\n   * 消息推送\n   * 存储云 和 图片云\n     * 普通的文件基本上提供存储和访问就够了，而图片涉及的业务会更多，包括裁剪、压缩、美化、审核、水印等处理，因此通常情况下图片云会拆分为独立的系统对用户提供服务。\n * 业务层技术\n   * 主要挑战：系统越来越庞大，业务越来越多，业务层会越来越复杂\n   * 拆分、合并：合久必分、分久必合，符合高内聚低耦合原则\n * 思考题\n   * 虚拟业务域划分的粒度需要粗一些还是要细一些？你建议虚拟业务域的数量大概是多少，理由是什么？\n\n\n\n\n页首\n\n\n# 44 | 互联网架构模板：“平台”技术\n\n * 运维平台\n   * 职责：资源配置、部署、监控、应急\n   * 核心设计要素：标准化、平台化、自动化、可视化\n * 测试平台\n   * 测试平台的核心目的是提升测试效率，从而提升产品质量，其设计关键就是自动化\n   * 用例管理\n     * 为了能够重复执行测试用例，测试平台需要将用例管理起来，管理的维度包括业务、系统、测试类型、用例代码。例如，网购业务的订单系统的接口测试用例。\n   * 资源管理\n     * 管理执行测试所需的运行环境, 包括硬件（服务器、手机、平板电脑等）、软件（操作系统、数据库、java 虚拟机等）、业务系统（被测试的系统）\n   * 任务管理\n     * 任务管理的主要职责是将测试用例分配到具体的资源上执行，跟踪任务的执行情况。任务管理是测试平台设计的核心，它将测试平台的各个部分串联起来从而完成自动化测试。\n   * 数据管理 测试任务执行完成后，需要记录各种相关的数据（例如，执行时间、执行结果、用例执行期间的 cpu、内存占用情况等），这些数据具备下面这些作用：展现当前用例的执行情况、作为历史数据，方便后续的测试与历史数据进行对比，从而发现明显的变化趋势。作为大数据的一部分，可以基于测试的任务数据进行一些数据挖掘。\n * 数据平台\n   * 数据平台的核心职责主要包括三部分：数据管理、数据分析和数据应用\n * 管理平台\n   * 管理平台的核心职责就是权限管理，主要分为两部分：身份认证、权限控制，\n * 思考题\n   * 运维平台或者测试平台，有的公司是由中间件团队负责开发，有的是运维和测试团队自己开发，你觉得两种方式各有什么优缺点，分别适用什么场景呢？\n\njira+gitlab+jenkins+nexus+bearychat 最简单的devops 平台。如果将生产环境完全交给运维团队的话，个人觉得这个应该可以称为开发平台。输入的是需求，输出的是各种工件。\n\n\n\n\n页首\n\n\n# 45 | 架构重构内功心法第一式：有的放矢\n\n * 系统的架构是不断演化的，少部分架构演化可能需要推倒重来，但绝大部分的架构演化都是通过架构重构来实现的。相比全新的架构设计来说，架构重构对架构师的要求更高，主要体现在：\n   * 业务已经上线，不能停下来\n   * 关联方众多，牵一发动全身\n     * 架构重构涉及的业务关联方很多，不同关联方的资源投入程度、业务发展速度、对架构痛点的敏感度等有很大差异，如何尽量减少对关联方的影响，或者协调关联方统一行动，是一项很大的挑战；而如果是新设计架构，则在新架构上线前，对关联方没有影响。\n   * 旧架构的约束\n     * 在旧的架构基础上进行，会限制架构师的技术选择范围；新架构必须考虑如何将旧架构产生的数据转换过来。\n * 期望通过架构重构来解决所有问题当然是不现实的\n   * 所以架构师的首要任务是从一大堆纷繁复杂的问题中识别出真正要通过架构重构来解决的问题，集中力量快速解决，而不是想着通过架构重构来解决所有的问题。\n   * 对于刚接手一个新系统的架构师或者技术主管来说，一定要控制住“新官上任三把火”的冲动，避免摊大饼式或者运动式的重构和优化。\n * 重点\n   * 总之，架构重构需要架构师既要说得动老板，也镇得住同事；既要技术攻关，又要协调资源；既要保证业务正常发展，又要在指定时间内完成目标……总之就是十八般武艺要样样精通。\n   * 架构师需要透过问题表象看到问题本质，找出真正需要通过架构重构解决的核心问题，从而做到有的放矢，既不会耗费大量的人力和时间投入，又能够解决核心问题。\n * 思考题\n   * 分析一下你目前开发的系统，你觉得需要架构重构吗？原因和理由是什么？\n\n\n\n\n页首\n\n\n# 46 | 架构重构内功心法第二式：合纵连横\n\n * 上下游沟通协调\n   * 在沟通协调时，将技术语言转换为通俗语言，以事实说话，以数据说话，是沟通的关键！\n * 其他相关或者配合的系统的沟通协调\n   * 问题：主要的阻力来自“这对我有什么好处”和“这部分我这边现在不急”\n   * 解决方案；换位思考、合作双赢、关注长期\n\n\n\n\n页首\n\n\n# 47 | 架构重构内功心法第三式：运筹帷幄\n\n * 问题\n   * 通常情况下，需要架构重构的系统，基本上都是因为各种历史原因和历史问题没有及时处理，遗留下来逐渐积累，然后到了一个临界点，，各种问题开始互相作用，集中爆发！到了真正要开始重构的时候，架构师识别出系统关键的复杂度问题后，如果只针对这个复杂度问题进行架构重构，可能会发现还是无法落地，因为很多条件不具备或者有的问题没解决的情况下就是不能做架构重构\n * 重构: 分段实施\n   * 重构的做法，其实就是“分段实施”，将要解决的问题根据优先级、重要性、实施难度等划分为不同的阶段，每个阶段聚焦于一个整体的目标，集中精力和资源解决一类问题。这样做有几个好处:\n     * 每个阶段都有明确目标，做完之后效果明显，团队信心足，后续推进更加容易。\n     * 每个阶段的工作量不会太大，可以和业务并行。\n     * 每个阶段的改动不会太大，降低了总体风险。\n   * 策略\n     * 优先级排序\n     * 问题分类\n       * 将问题按照性质分类，每个阶段集中解决一类问题。\n     * 先易后难\n       * 将问题按照性质分类，每个阶段集中解决一类问题\n     * 循序渐进\n       * 每个阶段的实施：最少 1 个月，最长不要超过 3 个月\n * 思考题\n   * 如果一个架构重构项目最后规划要 2 年才完成，你会怎么处理？\n     * 太久\n\n\n\n\n页首\n\n\n# 48 | 再谈开源项目：如何选择、使用以及二次开发？\n\n软件开发领域有一个流行的原则：dry，don’t repeat yourself。\n\n * 选择\n   * 聚焦是否满足业务、\n   * 聚焦是否成熟\n     * 版本号、使用的公司数量、社区活跃程度\n   * 聚焦运维能力\n     * 开源项目日志是否齐全、是否有维护工具可以看到系统运行状况、是否有故障检测和恢复的能力\n * 使用\n   * 深入研究，仔细测试\n     * 通读开源项目的设计文档或者白皮书，了解其设计原理。\n     * 核对每个配置项的作用和影响，识别出关键配置项。\n     * 进行多种场景的性能测试\n     * 进行压力测试，连续跑几天，观察 cpu、内存、磁盘 i/o 等指标波动\n     * 进行故障测试：kill、断电、拔网线、重启 100 次以上、切换等\n   * 小心应用，灰度发布\n   * 做好应急，以防万一\n * 二次开发\n   * 保持纯洁，加以包装\n     * 内外全改的缺点：投入太大、失去了跟随原项目演进的能力(差异太大导致源项目的改动无法合并到自己的分支)\n   * 发明你要的轮子\n     * 没有完全适合你的轮子！\n\n\n\n\n页首\n\n\n# 49 | 谈谈app架构的演进\n\n * 复习一下我的专栏所讲述的架构设计理念\n   * 架构是系统的顶层结构\n   * 架构设计的主要目的是为了解决软件系统复杂度带来的问题。\n   * 架构设计需要遵循三个主要原则：合适原则、简单原则、演化原则。\n   * 架构设计首先要掌握业界已经成熟的各种架构模式，然后再进行优化、调整、创新。\n * app架构演进\n   * web app、原生app、hybrid app、组件化 & 容器化、跨平台 app\n     * 组件化 & 容器化\n       * 微信 android 客户端架构演进之路\n       * atlas：手淘 native 容器化框架和思考\n     * 跨平台\n       * flutter\n * 思考题\n   * 你认为 app 架构接下来会如何演进？谈谈你的思考和分析。\n\n\n\n\n页首\n\n\n# 50 | 架构实战：架构设计文档模板\n\n * 备选方案模板：目的是供选择一个方案落地实施\n   * 需求介绍：主要描述需求的背景、目标、范围等\n   * 需求分析：主要全方位地描述需求相关的信息\n     * 5w: who(利益干系人)、when、what(产出)、why(需要解决的问题)、where(应用场景)\n     * 1h：关键业务流程。\n     * 8c: 指的是 8 个约束和限制，constraints，包括性能 performance、成本 cost、时间 time、可靠性 reliability、安全性 security、合规性 compliance、技术性 technology、兼容性 compatibility\n   * 复杂度分析：包含高可用、高性能、可扩展等\n   * 备选方案：至少 3 个备选方案，每个备选方案需要描述关键的实现，无须描述具体的实现细节\n   * 备选方案评估: 备选方案 360 度环评, 注意备选方案评估的内容会根据评估会议的结果进行修改\n * 架构设计模板：目的是详细描述细化方案\n   * 总体方案\n     * 总体方案需要从整体上描述方案的结构，其核心内容就是架构图，以及针对架构图的描述，包括模块或者子系统的职责描述、核心流程\n   * 架构总览\n     * 架构总览给出架构图以及架构的描述\n   * 核心流程\n   * 详细设计\n     * 详细设计需要描述具体的实现细节\n     * 高可用、高性能、高可扩展\n     * 安全设计\n     * 其他设计\n       * 其他设计包括上述以外的其他设计考虑点，例如指定开发语言、符合公司的某些标准等，如果篇幅较长，也可以独立进行描述]\n     * 部署方案\n       * 部署方案主要包括硬件要求、服务器部署方式、组网方式等\n   * 架构演进规划\n     * 通常情况下，规划和设计的需求比较完善，但如果一次性全部做完，项目周期可能会很长，因此可以采取分阶段实施，即：第一期做什么、第二期做什么，以此类推\n\n\n\n\n页首\n\n\n# 总结\n\n> 关于如何在专业领域内提升：著名的“10000 小时定律” 坚持梦想、坚持学习、坚持(持续)输出\n\n * 架构师的内功主要包含三部分：判断力、执行力、创新力\n   * 判断力：能够准确判断系统的复杂度在哪里，就像武侠高手一样，能准确地看出对手的破绽和弱点。\n   * 执行力：能够使用合适的方案解决复杂度问题，就像武侠高手一样，能选择合适的招式或者方法打败对手。\n   * 创新力：能够创造新的解决方案解决复杂度问题，就像武侠世界里，小一些的创新是创新招式，而武学宗师能够创立新的武学或者心法\n * 从程序员到架构师的成长之路，总的指导原则是(以上三方面的能力主要来源)：经验、视野、思考\n * 技术成长之路分为：\n   * 工程师\n     * 在别人的指导下完成开发，基础技能积累阶段\n   * 高级工程师\n     * 独立完成开发，包括需求分析、方案设计、编码实现，其中需求分析和方案设计已经包含了“判断”和“选择”，只是范围相对来说小一些，更多是在已有架构下进行设计。\n     * 积累方案设计经验，简单来说就是业务当前用到的相关技术的设计经验。\n     * 高级工程师阶段相比工程师阶段，有两个典型的差异：深度(how -> why)、理论(成熟的设计经验)\n   * 技术专家\n     * 某个领域的专家，通俗地讲，只要是这个领域的问题，技术专家都可以解决。\n     * 技术专家与高级工程师的一个典型区别就是，高级工程师主要是在已有的架构框架下完成设计，而技术专家会根据需要修改、扩展、扩展、优化架构。\n     * 从高级工程师成长为技术专家，主要需要“拓展技术宽度”，因为一个“领域”必然会涉及众多的技术面。常见的拓展技术宽度的方法有：\n       * 学习业界成熟的开源方案、研究业界的经验分享\n     * 需要注意的是，拓展技术宽度并不意味着仅仅只是知道一个技术名词，而是要深入去理解每个技术的原理、优缺点、应用场景\n   * 初级架构师\n     * 典型特征就是能够“独立完成一个系统的架构设计”，可以是从 从 0 到 1 设计一个新系统，也可以是将架构从 1.0 重构到 2.0。\n     * 初级架构师和技术专家的典型区别是：架构师是基于完善的架构设计方法论的指导来进行架构设计，而技术专家更多的是基于经验进行架构设计。\n       * 简单来说，即使是同样一个方案，初级架构师能够清晰地阐述架构设计的理由和原因，而技术专家可能就是因为自己曾经这样做过，或者看到别人这样做过而选择设计方案。\n   * 从技术专家成长为初级架构师，最主要的是形成自己的“架构设计方法论\".主要的手段有：\n     * 系统学习架构设计方法论，包括订阅专栏或者阅读书籍等\n     * 深入研究成熟开源系统的架构设计，这个手段在技术专家阶段也会用到，但关注点不一样，同样是研究开源系统，技术专家阶段聚焦于如何更好地应用开源项目；初级架构师阶段聚焦于学习其架构设计原理和思想，例如 kafka 的文档中就有关于消息队列架构设计的分析和取舍。\n     * 结合架构设计方法论，分析和总结自己团队甚至公司的各种系统的架构设计优缺点，尝试思考架构重构方案。\n   * 中级架构师\n     * 典型特征是“能够完成复杂系统的架构设计”，包含高性能、高可用、可扩展、海量存储等复杂系统，例如设计一个和 kafka 性能匹敌的消息队列系统、将业务改造为异地多活、设计一个总共 100 人参与开发的业务系统等。\n     * 中级架构师与初级架构师的典型区别在于系统复杂度的不同，\n     * 从初级架构师成长为中级架构师，最关键的是“技术深度和技术理论的积累”，\n   * 高级架构师\n     * 典型特征是“创造新的架构模式”\n     * 高级架构师与中级架构师相比，典型区别在于“创造性”，高级架构师能够创造新的架构模式，开创新的技术潮流。\n\n\n\n\n页首\n\n\n# end\n\n * recommend\n   * 《unix网络编程卷1》《tcp/ip协议卷1》《unix高级编程》《linux系统编程》《高性能mysql》\n * 两种高效的服务器设计模型：\n   * reactor和proactor模型\n * sso(single sign on)流程\n   * https://www.cnblogs.com/ywlaker/p/6113927.html\n * mvc\n   * https://draveness.me/mvx\n * 微服务\n   * 微服务架构的理论基础 - 康威定律\n * 架构师的核心能力：\n   * 抽象，提炼，把握关键，预测未来，当然还有沟通（撕逼）😃\n * 学习开源项目：以我学习 elasticsearch 为例，具体的做法是：\n   * 搭建一个单机伪集群，搭建完成后看看安装路径下的文件和目录，看看配置文件有哪些配置项，不同的配置项会有什么样的影响。\n   * 执行常用的操作，例如创建索引，插入、删除、查询文档，查看一下各种输出\n   * 研究其基本原理，例如索引、分片、副本等，研究的时候要多思考，例如索引应该如何建，分片数量和副本数量对系统有什么影响等。\n   * 和其他类似系统对比，例如 solr、sphinx，研究其优点、缺点、适用场景。\n   * 模拟一个案例看看怎么应用。例如，假设我用 elasticsearch 来存储淘宝的商品信息，我应该如何设计索引和分片。\n   * 查看业界使用的案例，思考一下别人为何这么用；看看别人测试的结果，大概了解性能范围。\n   * 如果某部分特别有兴趣或者很关键，可能去看源码，例如 elasticsearch 的选举算法\n   * 如果确定要引入，会进行性能和可用性测试。",charsets:{cjk:!0}},{title:"持续交付(极客时间)摘要",frontmatter:{title:"持续交付(极客时间)摘要",date:"2020-04-13T00:00:00.000Z",description:"Devops 持续交付(极客时间)摘要",permalink:null,categories:["blog","xnote"],tags:[null]},regularPath:"/blog/xnote/rnote_geekbang_devops.html",relativePath:"blog/xnote/rnote_geekbang_devops.md",key:"v-680803e5",path:"/blog/xnote/rnote_geekbang_devops.html",headers:[{level:2,title:"第01讲 持续交付到底有什么价值？",slug:"第01讲-持续交付到底有什么价值",normalizedTitle:"第01讲 持续交付到底有什么价值？",charIndex:18},{level:2,title:"第02讲 影响持续交付的因素有哪些？",slug:"第02讲-影响持续交付的因素有哪些",normalizedTitle:"第02讲 影响持续交付的因素有哪些？",charIndex:303},{level:2,title:"第03讲 持续交付和DevOps是一对好基友",slug:"第03讲-持续交付和devops是一对好基友",normalizedTitle:"第03讲 持续交付和devops是一对好基友",charIndex:394},{level:2,title:"第04讲 一切的源头，代码分支策略的选择",slug:"第04讲-一切的源头-代码分支策略的选择",normalizedTitle:"第04讲 一切的源头，代码分支策略的选择",charIndex:637},{level:2,title:"第05讲 手把手教你依赖管理",slug:"第05讲-手把手教你依赖管理",normalizedTitle:"第05讲 手把手教你依赖管理",charIndex:1178},{level:2,title:"第06讲 代码回滚，你真的理解吗？",slug:"第06讲-代码回滚-你真的理解吗",normalizedTitle:"第06讲 代码回滚，你真的理解吗？",charIndex:1399},{level:2,title:"第07讲 “两个披萨”团队的代码管理实际案例",slug:"第07讲-两个披萨-团队的代码管理实际案例",normalizedTitle:"第07讲 “两个披萨”团队的代码管理实际案例",charIndex:1493},{level:2,title:"第08讲 测试环境要多少？从现实需求说起",slug:"第08讲-测试环境要多少-从现实需求说起",normalizedTitle:"第08讲 测试环境要多少？从现实需求说起",charIndex:1695},{level:2,title:"第09讲 测试环境要多少？从成本与效率说起",slug:"第09讲-测试环境要多少-从成本与效率说起",normalizedTitle:"第09讲 测试环境要多少？从成本与效率说起",charIndex:1982},{level:2,title:"第10讲 让环境自己说话，论环境自描述的重要性",slug:"第10讲-让环境自己说话-论环境自描述的重要性",normalizedTitle:"第10讲 让环境自己说话，论环境自描述的重要性",charIndex:2122},{level:2,title:"第11讲 “配置”是把双刃剑，带你了解各种配置方法",slug:"第11讲-配置-是把双刃剑-带你了解各种配置方法",normalizedTitle:"第11讲 “配置”是把双刃剑，带你了解各种配置方法",charIndex:2277},{level:2,title:"第12讲 极限挑战，如何做到分钟级搭建环境？",slug:"第12讲-极限挑战-如何做到分钟级搭建环境",normalizedTitle:"第12讲 极限挑战，如何做到分钟级搭建环境？",charIndex:2429},{level:2,title:"第13讲 容器技术真的是环境管理的救星吗？",slug:"第13讲-容器技术真的是环境管理的救星吗",normalizedTitle:"第13讲 容器技术真的是环境管理的救星吗？",charIndex:2512},{level:2,title:"第14讲 如何做到构建的提速，再提速！",slug:"第14讲-如何做到构建的提速-再提速",normalizedTitle:"第14讲 如何做到构建的提速，再提速！",charIndex:2778},{level:2,title:"第15讲 构建检测，无规矩不成方圆",slug:"第15讲-构建检测-无规矩不成方圆",normalizedTitle:"第15讲 构建检测，无规矩不成方圆",charIndex:3113},{level:2,title:"第16讲 构建资源的弹性伸缩",slug:"第16讲-构建资源的弹性伸缩",normalizedTitle:"第16讲 构建资源的弹性伸缩",charIndex:3192},{level:2,title:"第17讲 容器镜像构建的那些事儿",slug:"第17讲-容器镜像构建的那些事儿",normalizedTitle:"第17讲 容器镜像构建的那些事儿",charIndex:3546},{level:2,title:"第18讲 如何做好容器镜像的个性化及合规检查？",slug:"第18讲-如何做好容器镜像的个性化及合规检查",normalizedTitle:"第18讲 如何做好容器镜像的个性化及合规检查？",charIndex:3738},{level:2,title:"第19讲 发布是持续交付的最后一公里",slug:"第19讲-发布是持续交付的最后一公里",normalizedTitle:"第19讲 发布是持续交付的最后一公里",charIndex:3930},{level:2,title:"第20讲 Immutable！任何变更都需要发布",slug:"第20讲-immutable-任何变更都需要发布",normalizedTitle:"第20讲 immutable！任何变更都需要发布",charIndex:4566},{level:2,title:"第21讲 发布系统一定要注意用户体验",slug:"第21讲-发布系统一定要注意用户体验",normalizedTitle:"第21讲 发布系统一定要注意用户体验",charIndex:4699},{level:2,title:"第22讲 发布系统的核心架构和功能设计",slug:"第22讲-发布系统的核心架构和功能设计",normalizedTitle:"第22讲 发布系统的核心架构和功能设计",charIndex:5013},{level:2,title:"第23讲 业务及系统架构对发布的影响",slug:"第23讲-业务及系统架构对发布的影响",normalizedTitle:"第23讲 业务及系统架构对发布的影响",charIndex:5150},{level:2,title:"第24讲 如何利用监控保障发布质量？",slug:"第24讲-如何利用监控保障发布质量",normalizedTitle:"第24讲 如何利用监控保障发布质量？",charIndex:5347},{level:2,title:"第25讲 代码静态检查实践",slug:"第25讲-代码静态检查实践",normalizedTitle:"第25讲 代码静态检查实践",charIndex:5526},{level:2,title:"第26讲 越来越重要的破坏性测试",slug:"第26讲-越来越重要的破坏性测试",normalizedTitle:"第26讲 越来越重要的破坏性测试",charIndex:5657},{level:2,title:"第27讲 利用Mock与回放技术助力自动化回归",slug:"第27讲-利用mock与回放技术助力自动化回归",normalizedTitle:"第27讲 利用mock与回放技术助力自动化回归",charIndex:5756},{level:2,title:"第28讲 持续交付为什么要平台化设计？",slug:"第28讲-持续交付为什么要平台化设计",normalizedTitle:"第28讲 持续交付为什么要平台化设计？",charIndex:6381},{level:2,title:"第29讲 计算资源也是交付的内容",slug:"第29讲-计算资源也是交付的内容",normalizedTitle:"第29讲 计算资源也是交付的内容",charIndex:6729},{level:2,title:"第30讲 持续交付中有哪些宝贵数据？",slug:"第30讲-持续交付中有哪些宝贵数据",normalizedTitle:"第30讲 持续交付中有哪些宝贵数据？",charIndex:6758},{level:2,title:"第31讲 了解移动App的持续交付生命周期",slug:"第31讲-了解移动app的持续交付生命周期",normalizedTitle:"第31讲 了解移动app的持续交付生命周期",charIndex:6860},{level:2,title:"第32讲 细谈移动APP的交付流水线（pipeline）",slug:"第32讲-细谈移动app的交付流水线-pipeline",normalizedTitle:"第32讲 细谈移动app的交付流水线（pipeline）",charIndex:6886},{level:2,title:"第33讲 进阶，如何进一步提升移动APP的交付效率？",slug:"第33讲-进阶-如何进一步提升移动app的交付效率",normalizedTitle:"第33讲 进阶，如何进一步提升移动app的交付效率？",charIndex:6940},{level:2,title:"第34讲 快速构建持续交付系统（一）：需求分析",slug:"第34讲-快速构建持续交付系统-一-需求分析",normalizedTitle:"第34讲 快速构建持续交付系统（一）：需求分析",charIndex:7064},{level:2,title:"第35讲 快速构建持续交付系统（二）：GitLab 解决代码管理问题",slug:"第35讲-快速构建持续交付系统-二-gitlab-解决代码管理问题",normalizedTitle:"第35讲 快速构建持续交付系统（二）：gitlab 解决代码管理问题",charIndex:7283},{level:2,title:"第36讲 快速构建持续交付系统（三）：Jenkins 解决集成打包问题",slug:"第36讲-快速构建持续交付系统-三-jenkins-解决集成打包问题",normalizedTitle:"第36讲 快速构建持续交付系统（三）：jenkins 解决集成打包问题",charIndex:7425},{level:2,title:"第37讲 快速构建持续交付系统（四）：Ansible 解决自动部署问题",slug:"第37讲-快速构建持续交付系统-四-ansible-解决自动部署问题",normalizedTitle:"第37讲 快速构建持续交付系统（四）：ansible 解决自动部署问题",charIndex:7517},{level:2,title:"第38讲 持续交付专栏特别放送 | 答疑解惑",slug:"第38讲-持续交付专栏特别放送-答疑解惑",normalizedTitle:"第38讲 持续交付专栏特别放送 | 答疑解惑",charIndex:7734},{level:2,title:"第39讲 持续交付专栏特别放送 | 高效学习指南",slug:"第39讲-持续交付专栏特别放送-高效学习指南",normalizedTitle:"第39讲 持续交付专栏特别放送 | 高效学习指南",charIndex:8003},{level:2,title:"第40讲 结束语 | 越痛苦的事，越要经常做",slug:"第40讲-结束语-越痛苦的事-越要经常做",normalizedTitle:"第40讲 结束语 | 越痛苦的事，越要经常做",charIndex:8205},{level:2,title:"END",slug:"end",normalizedTitle:"end",charIndex:8446}],headersStr:"第01讲 持续交付到底有什么价值？ 第02讲 影响持续交付的因素有哪些？ 第03讲 持续交付和DevOps是一对好基友 第04讲 一切的源头，代码分支策略的选择 第05讲 手把手教你依赖管理 第06讲 代码回滚，你真的理解吗？ 第07讲 “两个披萨”团队的代码管理实际案例 第08讲 测试环境要多少？从现实需求说起 第09讲 测试环境要多少？从成本与效率说起 第10讲 让环境自己说话，论环境自描述的重要性 第11讲 “配置”是把双刃剑，带你了解各种配置方法 第12讲 极限挑战，如何做到分钟级搭建环境？ 第13讲 容器技术真的是环境管理的救星吗？ 第14讲 如何做到构建的提速，再提速！ 第15讲 构建检测，无规矩不成方圆 第16讲 构建资源的弹性伸缩 第17讲 容器镜像构建的那些事儿 第18讲 如何做好容器镜像的个性化及合规检查？ 第19讲 发布是持续交付的最后一公里 第20讲 Immutable！任何变更都需要发布 第21讲 发布系统一定要注意用户体验 第22讲 发布系统的核心架构和功能设计 第23讲 业务及系统架构对发布的影响 第24讲 如何利用监控保障发布质量？ 第25讲 代码静态检查实践 第26讲 越来越重要的破坏性测试 第27讲 利用Mock与回放技术助力自动化回归 第28讲 持续交付为什么要平台化设计？ 第29讲 计算资源也是交付的内容 第30讲 持续交付中有哪些宝贵数据？ 第31讲 了解移动App的持续交付生命周期 第32讲 细谈移动APP的交付流水线（pipeline） 第33讲 进阶，如何进一步提升移动APP的交付效率？ 第34讲 快速构建持续交付系统（一）：需求分析 第35讲 快速构建持续交付系统（二）：GitLab 解决代码管理问题 第36讲 快速构建持续交付系统（三）：Jenkins 解决集成打包问题 第37讲 快速构建持续交付系统（四）：Ansible 解决自动部署问题 第38讲 持续交付专栏特别放送 | 答疑解惑 第39讲 持续交付专栏特别放送 | 高效学习指南 第40讲 结束语 | 越痛苦的事，越要经常做 END",content:"# Devops 持续交付\n\n\n# 第01讲 持续交付到底有什么价值？\n\n * 定义\n   * 持续集成 : 从编码到构建再到测试的反复持续过程\n   * 持续部署 : 将可交付产品，快速且安全地交付用户使用的一套方法和系统\n   * 持续交付 : 包含 持续集成、测试自动化 以及 持续部署，囊括 开发、测试、部署、运维、运营 等等\n * 持续交付的隐性价值\n   * 对：cto、team leader、产品经理、程序员 而言\n     * 技术选型、标准落地、部门协作、知识传承、关注业务、节奏平稳、提高工作效率和质量\n * 如何评估持续交付的价值\n * 常见的持续交付平台架构\n   * \n\n\n# 第02讲 影响持续交付的因素有哪些？\n\n * 影响因素\n   * 组织和文化因素\n   * 流程因素\n   * 架构因素\n\n    康威定律：组织结构决定软件架构\n\n\n1\n\n\n\n# 第03讲 持续交付和DevOps是一对好基友\n\n * 认识 DevOps\n   * 一组技术\n     * 包括自动化运维、持续交付、高频部署、Docker 等内容\n     * Docker，就是为了解决 DevOps 所提倡的“基础设施即代码”\n   * 一个职能\n   * 一种文化\n   * 一种组织架构\n * 总结\n   * DevOps本质其实是一种鼓励协作的研发文化\n   * 持续交付与 DevOps 所追求的最终目标是一致的，即快速向用户交付高质量的软件产品\n\n\n# 第04讲 一切的源头，代码分支策略的选择\n\n * 分支策略\n   * 主干开发（Trunk Based Development，简称 TBD）\n     * Google 和 Facebook 都在用主干开发\n     * 特性\n       * 没有 feature branch，所以都在主干开发，减少分支合并的麻烦\n       * 使用 feature toggle(特性切换) 保证不成熟功能不会被发布\n         * 特性切换太多会导致逻辑混乱、代码更脆弱，更难测试、理解和维护、更难提供技术支持，而且更不安全。\n           * 代码更脆弱：特性切换会将 未经测试的代码引入生产环境 它们引发的问题可能会在无意间暴露出来\n       * 可能会出现 一粒老鼠屎坏了一锅粥 的现象\n     * 集成效率高，冲突少，但对团队个人的开发能力有较高要求\n   * 分支开发(branch model)\n     * Git Flow(hotfix、release) -> Github Flow(pull request) -> Gitlab Flow(生产、环境以及发布分支)\n     * 有利于并行开发，需要一定的流程保证，能保证主干代码质量\n\n\n# 第05讲 手把手教你依赖管理\n\n * 举例\n   * 操作系统的依赖管理工具：\n     * 比如 CentOS 的 yum，Debian 的 apt，Arch 的 Packman，macOS 的 Homebrew；\n   * 编程语言的依赖管理工具：\n     * 比如 Java 的 Maven，.Net 的 nuget，Node.js 的 npm，Golang 的 go get，Python 的 pip，Ruby 的 Gem\n\n\n# 第06讲 代码回滚，你真的理解吗？\n\n * 方式\n   * roll back 到过去的某个版本\n   * 新增commit，移除对应功能\n * reset --hard 的使用\n\n\n# 第07讲 “两个披萨”团队的代码管理实际案例\n\n * “两个披萨”团队\n   * 在亚马逊内部有所谓的“两个披萨”团队\n   * 指的是团队的人数不能多到两个披萨饼还不够吃的地步\n   * 就是说，团队要小到让每个成员都能做出显著贡献，并且相互依赖，有共同目标，以及统一的成功标准，这样团队的工作效率才会高。\n * 使用 gitlab---issue---feature branch 开发模式\n\n\n# 第08讲 测试环境要多少？从现实需求说起\n\n * 问题\n   * 测试环境结构\n   * 好的测试环境标准\n * 环境模型(五套环境)\n   * 开发环境\n     * user：开发\n   * 功能测试环境\n     * user：测试\n   * 验收测试环境\n     * user：产品经理、测试\n   * 预发布环境\n     * user：测试、运维\n     * 特点: 应用已经进入了生产网络，和真实的生产应用共享同一套数据库等等基础设施。\n     * 方式：a: 金丝雀发布，使用真实流量机器; b: 一组不接入真实流量的机器\n   * 生产环境\n\n\n# 第09讲 测试环境要多少？从成本与效率说起\n\n * 成本\n   * 机器资源成本\n   * 管理成本：配置、测试数据等\n   * 流程成功：沟通成本、测试成本等\n * 效率\n   * 在抽象公共环境的基础之上，可以通过泳道的方式隔离相关测试应用\n   * 降低配置复杂度\n\n\n# 第10讲 让环境自己说话，论环境自描述的重要性\n\n * 问题\n   * 环境配置是非常复杂的，直接影响你的环境治理能力，而环境治理能力又直接影响着持续交付的能力。\n * 自描述\n   * 通过环境标准化，利用环境的自描述文件，让环境能讲清楚自己的作用、依赖，以及状态，而不是由外部配置来解释这些内容。\n\n\n# 第11讲 “配置”是把双刃剑，带你了解各种配置方法\n\n * 各种配置\n   * 构建时配置\n   * 打包时配置\n   * 运行时配置\n     * 配置中心\n       * apollo ：https://github.com/ctripcorp/apollo\n * 痛\n   * 回滚配置\n\n\n# 第12讲 极限挑战，如何做到分钟级搭建环境？\n\n市场上主流的开源配置管理工具有 Puppet、Chef、Ansible、SaltStack 等 并行、缓存池\n\n\n# 第13讲 容器技术真的是环境管理的救星吗？\n\n * 容器优点\n   * 帮我们重新定义了交付标准： 容器技术统一了软件环境和软件代码，交付产物中既包括了软件环境，又包括了软件代码。\n * 不可变基础设施（Immutable Infrastructure）\n   * 理念：\n     * 对于容器来说，遵循的是不可变基础设施的理念，也就是说任何变化，包括代码、环境、配置的变更，都需要重新制作镜像，产生一个新的版本。\n   * 问题：\n     * 会将原本简单的修改，复杂化，如：只是想安装curl，但是却要重新生产镜像\n\n\n# 第14讲 如何做到构建的提速，再提速！\n\n * 方法\n   * 升级硬件资源\n   * 搭建私有仓库\n     * 使用 createrepo 搭建 CentOS 的 yum 仓库；\n     * 使用 Nexus 搭建 Java 的 Maven 仓库；\n     * 使用 cnpm 搭建 NodeJS 的 npm 仓库；\n     * 使用 pypiserver 搭建 Python 的 pip 仓库；\n     * 使用 GitLab 搭建代码仓库；\n     * 使用 Harbor 搭建 Docker 镜像仓库\n   * 使用本地缓存\n   * 规范构建流程，通过异步方式解决旁支流程的执行；\n   * 善用构建工具，根据实际情况合理发挥的工具特性。\n\n\n# 第15讲 构建检测，无规矩不成方圆\n\n * 检测\n   * 环境：软件版本、编译工具版本、操作系统等\n   * 依赖：依赖关系检查\n   * ...\n\n\n# 第16讲 构建资源的弹性伸缩\n\n * 持续集成工具\n   * Travis CI、Circle CI、Jenkins CI\n * Jenkins Master 高可用架构的\n   * 单个 Jenkins Master\n     * 目前普遍的 Jenkins 搭建方案是：一个 Jenkins Master 搭配多个 Jenkins Slave。\n     * 单个 Jenkins Master 在任务量大时，会成为系统中的瓶颈\n   * 多个 Jenkins Master\n     * 对jenkins封装，自定义高可用多master架构\n * Jenkins Slave 弹性伸缩方案\n   * 构建环境：容器化\n   * 资源伸缩\n     * 通过容器化，与kubernetes 结合\n\n\n# 第17讲 容器镜像构建的那些事儿\n\n * docker hub\n   * https://hub.docker.com/\n * 用容器来构建容器镜像有两种方式：(主要依据：使用宿主的docker daemon 还是容器内独立 docker daemon)\n   * Docker Out Of Docker（DooD）\n   * Docker In Docker（DinD）\n\n\n# 第18讲 如何做好容器镜像的个性化及合规检查？\n\n * 容器镜像个性化 +总结了以下三种方法： 自定义环境脚本； 平台化环境选项与服务集市； 自定义镜像发布。\n * 合规检查\n   * 比对各个 layer，是否有官方base镜像的layer\n   * 工具：\n     * CoreOS Clair，Docker Security Scanning，Drydock，...\n\n\n# 第19讲 发布是持续交付的最后一公里\n\n * 部署 和 发布\n   * 应用被部署，并不代表就是发布了，比如旁路运行（dark launch）方式\n   * 发布：rollout，部署：deploy\n * 发布系统期望\n   * 一个易用、快速、稳定、容错力强，必要时有能力迅速回滚\n * 单节点部署流程\n   * download: 下载新的版本，不执行覆盖；\n   * markdown: 通知上游调用方，自己现在为暂停服务状态；\n   * install : 运行命令 load 变更重启服务；\n   * verify : 验证服务的健康状况以及预热；\n   * markup : 通知上游调用方，自己服务恢复正常。\n * 集群部署方式：\n   * 灰度发布\n     * 蓝绿发布\n       * 发布新版本到一套新的集群，验证通过后，流控处理把流量引入新机器，待全部流量切换完成，等待一段时间没有异常的话，老版本服务器下线。\n     * 滚动发布\n       * 从集群服务器中挑选一批，停止上面的服务并更新为新版本，进行验证，验证完毕后接入流量。重复此步骤，直到遍历完所有机器。\n     * 金丝雀发布\n       * 从集群中挑选特定服务器或一小批符合要求的特征用户，对其进行版本更新及验证，随后逐步更新剩余服务器。\n   * 灰度发布系统：\n     * Tars : https://github.com/ctripcorp/tars\n\n\n# 第20讲 Immutable！任何变更都需要发布\n\n * 不可变基础设施(Immutable Infrastructure)\n   * 前提：无状态\n   * 保证: 环境、顺序、配置这些基础设施在测试环节和生产环节的一致性\n   * 与虚拟机的本质差异点\n\n\n# 第21讲 发布系统一定要注意用户体验\n\n * 发布系统组成：\n   * 1 张页面展示发布信息\n     * 能够展示发布当时的绝大多数信息、数据和内容，这个页面既要全面，又要精准\n   * 2 个操作按钮简化使用\n     * 页面上最多同时展示两个按钮：发布、中断、重试\n   * 3 种发布结果\n     * 成功、失败、中断\n   * 4 类操作选择\n     * 开始发布、停止发布、发布回退、发布重试\n   * 5 个发布步骤\n     * 同第19讲中的'单节点部署流程'\n   * 6 大页面主要内容\n     * 集群、实例、发布日志、发布历史、发布批次(分批次发布)、发布操作(操作按钮集中的区域)\n\n\n# 第22讲 发布系统的核心架构和功能设计\n\n * 核心\n   * DeploymentConfig\n   * Deployment\n   * DeployBatch\n   * DeployTarget\n   * 发布状态流转\n * 功能\n   * 服务降级、熔断机制\n\n\n# 第23讲 业务及系统架构对发布的影响\n\n * 影响\n   * 单机单应用还是单机多应用？\n   * 增量发布还是全量发布？\n   * 如何控制服务的 Markup 和 Markdown？\n   * 检查、预热和点火机制(点火：verify流程的自动化)\n   * 如何保证堡垒流量？\n     * 软负载 + header中附加堡垒标记，保证堡垒机的流量只在上下游服务的堡垒机中流转。\n\n\n# 第24讲 如何利用监控保障发布质量？\n\n * 监控\n   * 用户侧监控，关注的是用户真正感受到的访问速度和结果；\n   * 网络监控，即 CDN 与核心网络的监控；\n   * 业务监控，关注的是核心业务指标的波动；\n   * 应用监控，即服务调用链的监控，一般在框架层面统一定义解决方案；\n   * 系统监控，即基础设施、虚拟机及操作系统的监控。\n\n\n# 第25讲 代码静态检查实践\n\n * 测试管理\n   * 代码静态检查\n   * 破坏性测试\n   * Mock 与 回放\n * 静态检查平台\n   * SonarQube\n * 静态检查工具\n   * FindBugs、PMD 和 Checkstyle\n\n\n# 第26讲 越来越重要的破坏性测试\n\n * 维度\n   * 单点维度：\n   * 系统维度：压测、暴力测试、阻断链路等\n * 混沌工程\n   * Netflix : Chaos Monkey\n\n\n# 第27讲 利用Mock与回放技术助力自动化回归\n\n * 持续交付中的测试难点\n   * 测试数据的准备与清理\n   * 分布式系统的依赖\n   * 测试用例的高度仿真\n * 方案\n   * Mock\n     * 说明\n       * 如果某个对象在测试过程中依赖于另一个复杂对象，而这个复杂对象又很难被从测试过程中剥离出来，那么就可以利用 Mock 去模拟并代替这个复杂对象。\n     * 基于对象和类的 Mock\n       * Mockito 或者 EasyMock。\n       * 通常用在单元测试阶段\n     * 基于微服务的 Mock\n       * Weir Mock 和 Mock Server\n   * 回放\n     * 说明\n       * 记录实际用户在生产环境的操作，然后在测试环境中回放。\n     * 拦截记录用户操作方案：\n       * 在统一的 SLB 上做统一的拦截和复制转发处理。\n         * 容易影响自身路由服务\n       * 在集群中扩容一台服务器，在该服务器上启动一个软交换负责复制和转发用户请求，而真正的用户请求，仍由该服务器进行处理。\n         * 结合云平台，使用时申请服务器，不需要时释放，风险低\n     * 方案\n       * 按照正常的操作记录时间间隔，按记录顺序回放\n       * 压缩操作记录的时间间隔，按记录顺序，形成压力回放\n\n\n# 第28讲 持续交付为什么要平台化设计？\n\n * 持续交付最核心的五大部分内容，包括：\n   * 配置管理、环境管理、构建集成、发布及监控、测试管理。\n * 平台化\n   * 自己搭台，让其他人唱戏\n * 持续交付平台核心模块\n   * 代码管理\n     * 常与代码审核、静态扫描和分支管理等模块相联系；\n   * 集成编译\n     * 常与依赖管理、单元测试、加密打包等模块相联系；\n   * 环境管理\n     * 常与资源申请、配置管理、路由管理等模块相联系；\n   * 发布部署\n     * 需要监控模块和流控模块的支持\n * 标准先行\n   * 研发任何系统，首先要记住一句话：“标准先行”\n   * 对持续交付平台的设计来说，最重要的标准是定义各个模块交付产物的标准。\n\n\n# 第29讲 计算资源也是交付的内容\n\n * 云计算\n\n\n# 第30讲 持续交付中有哪些宝贵数据？\n\n * 系统优化\n   * 数据说话，从数据角度分析找到优化方向\n * 系统指标\n   * 稳定性指标\n   * 性能指标\n   * 持续交付能力成熟度指标\n\n\n# 第31讲 了解移动App的持续交付生命周期\n\n\n# 第32讲 细谈移动APP的交付流水线（pipeline）\n\n * 发布快车模式\n   * 定期发车\n\n\n# 第33讲 进阶，如何进一步提升移动APP的交付效率？\n\n * 优化交付流程：针对开发、构建、测试、发布进行优化\n * 优化构建方式：\n   * 扁平化依赖管理\n   * 二进制交付\n * 优化发布方式:\n   * 测试用户集，需要定期更换\n\n\n# 第34讲 快速构建持续交付系统（一）：需求分析\n\n * 对各个主要模块的具体需求：\n   * 代码与配置：需要 code review，以及静态代码扫描；\n   * 构建与集成：能同时支持 Jar、War、Docker，以及 App，版本管理可追溯，支持高并发；\n   * 打包与发布：同时支持 Jar、War、Docker、App 的发布，以及统一的部署标准；\n   * 自动化测试：通过 TestNG 驱动，实现全自动测试。\n\n\n# 第35讲 快速构建持续交付系统（二）：GitLab 解决代码管理问题\n\n * gitlib 安装\n   * 使用官方的 Docker 镜像或一键安装包 Omnibus 安装 GitLab\n * 目的\n   * 自己动手实际搭建一套 GitLab，以及配套的 Sonar 服务\n\n\n# 第36讲 快速构建持续交付系统（三）：Jenkins 解决集成打包问题\n\n * jenkins 安装\n   * gitlab\n   * maven\n   * pipeline\n\n\n# 第37讲 快速构建持续交付系统（四）：Ansible 解决自动部署问题\n\n * 配置管理工具\n   * Ansible、Chef、Puppet、Salt\n   * Ansible Tower : 一个可视化工具，可以帮助更好地管理整个部署过程\n * 持续交付平台\n   * 直接考虑搭建持续交付平台 Spinnaker\n   * Spinnaker 是 Netflix 的开源项目，致力于解除持续交付平台和云平台之间的耦合。\n\n\n# 第38讲 持续交付专栏特别放送 | 答疑解惑\n\n * 如何处理数据库发布和回滚？\n   * 对数据库变更满足以下要求时，基本上就没有回滚需要了：\n     * 第一，与业务相关的，只能新增字段，不能删除字段，也不能修改已有字段的定义，并且新增字段必须有默认值。\n     * 第二，对于必须要修改原有数据库结构的场景，则必须由 DBA 操作，不纳入持续交付流程。\n * Immutable\n   * k8s + docker\n * 破坏性测试\n   * DR演练(灾难恢复)\n * GitLab HA\n   * Sharding\n\n\n# 第39讲 持续交付专栏特别放送 | 高效学习指南\n\n * 推荐\n   * 持续交付：发布可靠软件的系统方法\n   * 凤凰项目\n   * 官方文档。这里我有一个建议，就是在学习和运用开源系统和工具时，要先通读官方文档。这些文档都是作者心血和智慧的结晶，从中你定可以收获颇丰。\n * 建议\n   * 持续交付体系中涉及到很多开源软件，如果你想做好持续交付，那就一定要去理解它们，而不只是使用它们。\n\n\n# 第40讲 结束语 | 越痛苦的事，越要经常做\n\n * 越痛苦的事，越要经常做\n   * 第一痛，要比架构师懂得多\n   * 第二痛，要比开发人员动作快\n   * 第三痛，要比 QA 团队眼睛尖\n   * 第四痛，要比运营人员“心脏大”\n     * 顶得住压力、受得住委屈\n   * 第五痛，要比产品经理还会“吹”\n     * 做持续交付，真的要足够会包装自己。因为你要推广你的系统、要找到你的种子用户；你要讲道理、讲技术、做演示，讲 PPT。这些技能，真的是缺一不可。\n\n\n# END\n\n * reference\n   * 依赖治理、灰度发布、故障演练，阿里电商故障演练系统的设计与实战经验\n   * 压测1\n   * 压测2",normalizedContent:"# devops 持续交付\n\n\n# 第01讲 持续交付到底有什么价值？\n\n * 定义\n   * 持续集成 : 从编码到构建再到测试的反复持续过程\n   * 持续部署 : 将可交付产品，快速且安全地交付用户使用的一套方法和系统\n   * 持续交付 : 包含 持续集成、测试自动化 以及 持续部署，囊括 开发、测试、部署、运维、运营 等等\n * 持续交付的隐性价值\n   * 对：cto、team leader、产品经理、程序员 而言\n     * 技术选型、标准落地、部门协作、知识传承、关注业务、节奏平稳、提高工作效率和质量\n * 如何评估持续交付的价值\n * 常见的持续交付平台架构\n   * \n\n\n# 第02讲 影响持续交付的因素有哪些？\n\n * 影响因素\n   * 组织和文化因素\n   * 流程因素\n   * 架构因素\n\n    康威定律：组织结构决定软件架构\n\n\n1\n\n\n\n# 第03讲 持续交付和devops是一对好基友\n\n * 认识 devops\n   * 一组技术\n     * 包括自动化运维、持续交付、高频部署、docker 等内容\n     * docker，就是为了解决 devops 所提倡的“基础设施即代码”\n   * 一个职能\n   * 一种文化\n   * 一种组织架构\n * 总结\n   * devops本质其实是一种鼓励协作的研发文化\n   * 持续交付与 devops 所追求的最终目标是一致的，即快速向用户交付高质量的软件产品\n\n\n# 第04讲 一切的源头，代码分支策略的选择\n\n * 分支策略\n   * 主干开发（trunk based development，简称 tbd）\n     * google 和 facebook 都在用主干开发\n     * 特性\n       * 没有 feature branch，所以都在主干开发，减少分支合并的麻烦\n       * 使用 feature toggle(特性切换) 保证不成熟功能不会被发布\n         * 特性切换太多会导致逻辑混乱、代码更脆弱，更难测试、理解和维护、更难提供技术支持，而且更不安全。\n           * 代码更脆弱：特性切换会将 未经测试的代码引入生产环境 它们引发的问题可能会在无意间暴露出来\n       * 可能会出现 一粒老鼠屎坏了一锅粥 的现象\n     * 集成效率高，冲突少，但对团队个人的开发能力有较高要求\n   * 分支开发(branch model)\n     * git flow(hotfix、release) -> github flow(pull request) -> gitlab flow(生产、环境以及发布分支)\n     * 有利于并行开发，需要一定的流程保证，能保证主干代码质量\n\n\n# 第05讲 手把手教你依赖管理\n\n * 举例\n   * 操作系统的依赖管理工具：\n     * 比如 centos 的 yum，debian 的 apt，arch 的 packman，macos 的 homebrew；\n   * 编程语言的依赖管理工具：\n     * 比如 java 的 maven，.net 的 nuget，node.js 的 npm，golang 的 go get，python 的 pip，ruby 的 gem\n\n\n# 第06讲 代码回滚，你真的理解吗？\n\n * 方式\n   * roll back 到过去的某个版本\n   * 新增commit，移除对应功能\n * reset --hard 的使用\n\n\n# 第07讲 “两个披萨”团队的代码管理实际案例\n\n * “两个披萨”团队\n   * 在亚马逊内部有所谓的“两个披萨”团队\n   * 指的是团队的人数不能多到两个披萨饼还不够吃的地步\n   * 就是说，团队要小到让每个成员都能做出显著贡献，并且相互依赖，有共同目标，以及统一的成功标准，这样团队的工作效率才会高。\n * 使用 gitlab---issue---feature branch 开发模式\n\n\n# 第08讲 测试环境要多少？从现实需求说起\n\n * 问题\n   * 测试环境结构\n   * 好的测试环境标准\n * 环境模型(五套环境)\n   * 开发环境\n     * user：开发\n   * 功能测试环境\n     * user：测试\n   * 验收测试环境\n     * user：产品经理、测试\n   * 预发布环境\n     * user：测试、运维\n     * 特点: 应用已经进入了生产网络，和真实的生产应用共享同一套数据库等等基础设施。\n     * 方式：a: 金丝雀发布，使用真实流量机器; b: 一组不接入真实流量的机器\n   * 生产环境\n\n\n# 第09讲 测试环境要多少？从成本与效率说起\n\n * 成本\n   * 机器资源成本\n   * 管理成本：配置、测试数据等\n   * 流程成功：沟通成本、测试成本等\n * 效率\n   * 在抽象公共环境的基础之上，可以通过泳道的方式隔离相关测试应用\n   * 降低配置复杂度\n\n\n# 第10讲 让环境自己说话，论环境自描述的重要性\n\n * 问题\n   * 环境配置是非常复杂的，直接影响你的环境治理能力，而环境治理能力又直接影响着持续交付的能力。\n * 自描述\n   * 通过环境标准化，利用环境的自描述文件，让环境能讲清楚自己的作用、依赖，以及状态，而不是由外部配置来解释这些内容。\n\n\n# 第11讲 “配置”是把双刃剑，带你了解各种配置方法\n\n * 各种配置\n   * 构建时配置\n   * 打包时配置\n   * 运行时配置\n     * 配置中心\n       * apollo ：https://github.com/ctripcorp/apollo\n * 痛\n   * 回滚配置\n\n\n# 第12讲 极限挑战，如何做到分钟级搭建环境？\n\n市场上主流的开源配置管理工具有 puppet、chef、ansible、saltstack 等 并行、缓存池\n\n\n# 第13讲 容器技术真的是环境管理的救星吗？\n\n * 容器优点\n   * 帮我们重新定义了交付标准： 容器技术统一了软件环境和软件代码，交付产物中既包括了软件环境，又包括了软件代码。\n * 不可变基础设施（immutable infrastructure）\n   * 理念：\n     * 对于容器来说，遵循的是不可变基础设施的理念，也就是说任何变化，包括代码、环境、配置的变更，都需要重新制作镜像，产生一个新的版本。\n   * 问题：\n     * 会将原本简单的修改，复杂化，如：只是想安装curl，但是却要重新生产镜像\n\n\n# 第14讲 如何做到构建的提速，再提速！\n\n * 方法\n   * 升级硬件资源\n   * 搭建私有仓库\n     * 使用 createrepo 搭建 centos 的 yum 仓库；\n     * 使用 nexus 搭建 java 的 maven 仓库；\n     * 使用 cnpm 搭建 nodejs 的 npm 仓库；\n     * 使用 pypiserver 搭建 python 的 pip 仓库；\n     * 使用 gitlab 搭建代码仓库；\n     * 使用 harbor 搭建 docker 镜像仓库\n   * 使用本地缓存\n   * 规范构建流程，通过异步方式解决旁支流程的执行；\n   * 善用构建工具，根据实际情况合理发挥的工具特性。\n\n\n# 第15讲 构建检测，无规矩不成方圆\n\n * 检测\n   * 环境：软件版本、编译工具版本、操作系统等\n   * 依赖：依赖关系检查\n   * ...\n\n\n# 第16讲 构建资源的弹性伸缩\n\n * 持续集成工具\n   * travis ci、circle ci、jenkins ci\n * jenkins master 高可用架构的\n   * 单个 jenkins master\n     * 目前普遍的 jenkins 搭建方案是：一个 jenkins master 搭配多个 jenkins slave。\n     * 单个 jenkins master 在任务量大时，会成为系统中的瓶颈\n   * 多个 jenkins master\n     * 对jenkins封装，自定义高可用多master架构\n * jenkins slave 弹性伸缩方案\n   * 构建环境：容器化\n   * 资源伸缩\n     * 通过容器化，与kubernetes 结合\n\n\n# 第17讲 容器镜像构建的那些事儿\n\n * docker hub\n   * https://hub.docker.com/\n * 用容器来构建容器镜像有两种方式：(主要依据：使用宿主的docker daemon 还是容器内独立 docker daemon)\n   * docker out of docker（dood）\n   * docker in docker（dind）\n\n\n# 第18讲 如何做好容器镜像的个性化及合规检查？\n\n * 容器镜像个性化 +总结了以下三种方法： 自定义环境脚本； 平台化环境选项与服务集市； 自定义镜像发布。\n * 合规检查\n   * 比对各个 layer，是否有官方base镜像的layer\n   * 工具：\n     * coreos clair，docker security scanning，drydock，...\n\n\n# 第19讲 发布是持续交付的最后一公里\n\n * 部署 和 发布\n   * 应用被部署，并不代表就是发布了，比如旁路运行（dark launch）方式\n   * 发布：rollout，部署：deploy\n * 发布系统期望\n   * 一个易用、快速、稳定、容错力强，必要时有能力迅速回滚\n * 单节点部署流程\n   * download: 下载新的版本，不执行覆盖；\n   * markdown: 通知上游调用方，自己现在为暂停服务状态；\n   * install : 运行命令 load 变更重启服务；\n   * verify : 验证服务的健康状况以及预热；\n   * markup : 通知上游调用方，自己服务恢复正常。\n * 集群部署方式：\n   * 灰度发布\n     * 蓝绿发布\n       * 发布新版本到一套新的集群，验证通过后，流控处理把流量引入新机器，待全部流量切换完成，等待一段时间没有异常的话，老版本服务器下线。\n     * 滚动发布\n       * 从集群服务器中挑选一批，停止上面的服务并更新为新版本，进行验证，验证完毕后接入流量。重复此步骤，直到遍历完所有机器。\n     * 金丝雀发布\n       * 从集群中挑选特定服务器或一小批符合要求的特征用户，对其进行版本更新及验证，随后逐步更新剩余服务器。\n   * 灰度发布系统：\n     * tars : https://github.com/ctripcorp/tars\n\n\n# 第20讲 immutable！任何变更都需要发布\n\n * 不可变基础设施(immutable infrastructure)\n   * 前提：无状态\n   * 保证: 环境、顺序、配置这些基础设施在测试环节和生产环节的一致性\n   * 与虚拟机的本质差异点\n\n\n# 第21讲 发布系统一定要注意用户体验\n\n * 发布系统组成：\n   * 1 张页面展示发布信息\n     * 能够展示发布当时的绝大多数信息、数据和内容，这个页面既要全面，又要精准\n   * 2 个操作按钮简化使用\n     * 页面上最多同时展示两个按钮：发布、中断、重试\n   * 3 种发布结果\n     * 成功、失败、中断\n   * 4 类操作选择\n     * 开始发布、停止发布、发布回退、发布重试\n   * 5 个发布步骤\n     * 同第19讲中的'单节点部署流程'\n   * 6 大页面主要内容\n     * 集群、实例、发布日志、发布历史、发布批次(分批次发布)、发布操作(操作按钮集中的区域)\n\n\n# 第22讲 发布系统的核心架构和功能设计\n\n * 核心\n   * deploymentconfig\n   * deployment\n   * deploybatch\n   * deploytarget\n   * 发布状态流转\n * 功能\n   * 服务降级、熔断机制\n\n\n# 第23讲 业务及系统架构对发布的影响\n\n * 影响\n   * 单机单应用还是单机多应用？\n   * 增量发布还是全量发布？\n   * 如何控制服务的 markup 和 markdown？\n   * 检查、预热和点火机制(点火：verify流程的自动化)\n   * 如何保证堡垒流量？\n     * 软负载 + header中附加堡垒标记，保证堡垒机的流量只在上下游服务的堡垒机中流转。\n\n\n# 第24讲 如何利用监控保障发布质量？\n\n * 监控\n   * 用户侧监控，关注的是用户真正感受到的访问速度和结果；\n   * 网络监控，即 cdn 与核心网络的监控；\n   * 业务监控，关注的是核心业务指标的波动；\n   * 应用监控，即服务调用链的监控，一般在框架层面统一定义解决方案；\n   * 系统监控，即基础设施、虚拟机及操作系统的监控。\n\n\n# 第25讲 代码静态检查实践\n\n * 测试管理\n   * 代码静态检查\n   * 破坏性测试\n   * mock 与 回放\n * 静态检查平台\n   * sonarqube\n * 静态检查工具\n   * findbugs、pmd 和 checkstyle\n\n\n# 第26讲 越来越重要的破坏性测试\n\n * 维度\n   * 单点维度：\n   * 系统维度：压测、暴力测试、阻断链路等\n * 混沌工程\n   * netflix : chaos monkey\n\n\n# 第27讲 利用mock与回放技术助力自动化回归\n\n * 持续交付中的测试难点\n   * 测试数据的准备与清理\n   * 分布式系统的依赖\n   * 测试用例的高度仿真\n * 方案\n   * mock\n     * 说明\n       * 如果某个对象在测试过程中依赖于另一个复杂对象，而这个复杂对象又很难被从测试过程中剥离出来，那么就可以利用 mock 去模拟并代替这个复杂对象。\n     * 基于对象和类的 mock\n       * mockito 或者 easymock。\n       * 通常用在单元测试阶段\n     * 基于微服务的 mock\n       * weir mock 和 mock server\n   * 回放\n     * 说明\n       * 记录实际用户在生产环境的操作，然后在测试环境中回放。\n     * 拦截记录用户操作方案：\n       * 在统一的 slb 上做统一的拦截和复制转发处理。\n         * 容易影响自身路由服务\n       * 在集群中扩容一台服务器，在该服务器上启动一个软交换负责复制和转发用户请求，而真正的用户请求，仍由该服务器进行处理。\n         * 结合云平台，使用时申请服务器，不需要时释放，风险低\n     * 方案\n       * 按照正常的操作记录时间间隔，按记录顺序回放\n       * 压缩操作记录的时间间隔，按记录顺序，形成压力回放\n\n\n# 第28讲 持续交付为什么要平台化设计？\n\n * 持续交付最核心的五大部分内容，包括：\n   * 配置管理、环境管理、构建集成、发布及监控、测试管理。\n * 平台化\n   * 自己搭台，让其他人唱戏\n * 持续交付平台核心模块\n   * 代码管理\n     * 常与代码审核、静态扫描和分支管理等模块相联系；\n   * 集成编译\n     * 常与依赖管理、单元测试、加密打包等模块相联系；\n   * 环境管理\n     * 常与资源申请、配置管理、路由管理等模块相联系；\n   * 发布部署\n     * 需要监控模块和流控模块的支持\n * 标准先行\n   * 研发任何系统，首先要记住一句话：“标准先行”\n   * 对持续交付平台的设计来说，最重要的标准是定义各个模块交付产物的标准。\n\n\n# 第29讲 计算资源也是交付的内容\n\n * 云计算\n\n\n# 第30讲 持续交付中有哪些宝贵数据？\n\n * 系统优化\n   * 数据说话，从数据角度分析找到优化方向\n * 系统指标\n   * 稳定性指标\n   * 性能指标\n   * 持续交付能力成熟度指标\n\n\n# 第31讲 了解移动app的持续交付生命周期\n\n\n# 第32讲 细谈移动app的交付流水线（pipeline）\n\n * 发布快车模式\n   * 定期发车\n\n\n# 第33讲 进阶，如何进一步提升移动app的交付效率？\n\n * 优化交付流程：针对开发、构建、测试、发布进行优化\n * 优化构建方式：\n   * 扁平化依赖管理\n   * 二进制交付\n * 优化发布方式:\n   * 测试用户集，需要定期更换\n\n\n# 第34讲 快速构建持续交付系统（一）：需求分析\n\n * 对各个主要模块的具体需求：\n   * 代码与配置：需要 code review，以及静态代码扫描；\n   * 构建与集成：能同时支持 jar、war、docker，以及 app，版本管理可追溯，支持高并发；\n   * 打包与发布：同时支持 jar、war、docker、app 的发布，以及统一的部署标准；\n   * 自动化测试：通过 testng 驱动，实现全自动测试。\n\n\n# 第35讲 快速构建持续交付系统（二）：gitlab 解决代码管理问题\n\n * gitlib 安装\n   * 使用官方的 docker 镜像或一键安装包 omnibus 安装 gitlab\n * 目的\n   * 自己动手实际搭建一套 gitlab，以及配套的 sonar 服务\n\n\n# 第36讲 快速构建持续交付系统（三）：jenkins 解决集成打包问题\n\n * jenkins 安装\n   * gitlab\n   * maven\n   * pipeline\n\n\n# 第37讲 快速构建持续交付系统（四）：ansible 解决自动部署问题\n\n * 配置管理工具\n   * ansible、chef、puppet、salt\n   * ansible tower : 一个可视化工具，可以帮助更好地管理整个部署过程\n * 持续交付平台\n   * 直接考虑搭建持续交付平台 spinnaker\n   * spinnaker 是 netflix 的开源项目，致力于解除持续交付平台和云平台之间的耦合。\n\n\n# 第38讲 持续交付专栏特别放送 | 答疑解惑\n\n * 如何处理数据库发布和回滚？\n   * 对数据库变更满足以下要求时，基本上就没有回滚需要了：\n     * 第一，与业务相关的，只能新增字段，不能删除字段，也不能修改已有字段的定义，并且新增字段必须有默认值。\n     * 第二，对于必须要修改原有数据库结构的场景，则必须由 dba 操作，不纳入持续交付流程。\n * immutable\n   * k8s + docker\n * 破坏性测试\n   * dr演练(灾难恢复)\n * gitlab ha\n   * sharding\n\n\n# 第39讲 持续交付专栏特别放送 | 高效学习指南\n\n * 推荐\n   * 持续交付：发布可靠软件的系统方法\n   * 凤凰项目\n   * 官方文档。这里我有一个建议，就是在学习和运用开源系统和工具时，要先通读官方文档。这些文档都是作者心血和智慧的结晶，从中你定可以收获颇丰。\n * 建议\n   * 持续交付体系中涉及到很多开源软件，如果你想做好持续交付，那就一定要去理解它们，而不只是使用它们。\n\n\n# 第40讲 结束语 | 越痛苦的事，越要经常做\n\n * 越痛苦的事，越要经常做\n   * 第一痛，要比架构师懂得多\n   * 第二痛，要比开发人员动作快\n   * 第三痛，要比 qa 团队眼睛尖\n   * 第四痛，要比运营人员“心脏大”\n     * 顶得住压力、受得住委屈\n   * 第五痛，要比产品经理还会“吹”\n     * 做持续交付，真的要足够会包装自己。因为你要推广你的系统、要找到你的种子用户；你要讲道理、讲技术、做演示，讲 ppt。这些技能，真的是缺一不可。\n\n\n# end\n\n * reference\n   * 依赖治理、灰度发布、故障演练，阿里电商故障演练系统的设计与实战经验\n   * 压测1\n   * 压测2",charsets:{cjk:!0}},{title:"Google 技能评分卡",frontmatter:{title:"Google 技能评分卡",date:"2020-04-03T00:00:00.000Z",categories:["skill"],keywords:["skill level"],description:"Google 技能评分卡",permalink:null,tags:[null]},regularPath:"/blog/xnote/rnote_google_skill_level.html",relativePath:"blog/xnote/rnote_google_skill_level.md",key:"v-155cc502",path:"/blog/xnote/rnote_google_skill_level.html",headersStr:null,content:"# Google 技能评分卡\n\n0. You are unfamiliar with the subject area.\n    - 你对领域不了解。\n\n1. You can read/understand the most fundamental aspects of the subject area.\n    - 你能够阅读和理解领域的最基本方面。\n\n2. Ability to implement small changes, understand basic principles and able to figure out additional details with minimal help.\n    - 能够实施小的变更，理解基本原则，并且能够在最少的帮助下找出更多细节。\n\n3. Basic proficiency in a subject area without relying on help.\n    - 在不依赖帮助的情况下对领域有基本的熟练程度。\n\n4. You are comfirtable with the subject area and all routine work on it: For software areas - ability to develop medium programs using all basic language features w/o book, awareness of more esoteric feature(with book).\nFor systems areas - understanding of many fundamentals of networking and systems administration, ability to run a small network of system including recovery, debugging and nontrivial troubleshooting that relies on the knowledge of internals.\n    - 你对领域和所有日常工作都很熟悉：对于软件，能够在不参考书本的情况下使用基本的语言特性开发中型程序，能够通过书本了解更深奥的特性。\n对于系统，理解网络和系统管理的许多基础知识，能够依赖内在知识运转小型系统网络，包括恢复、调试、排除重要故障。\n\n5. An even lower degree of reliance on reference materials. Deeper skills in a field or specific technology in the subject area.\n    - 对参考材料的依赖程度更低。对领域的某一部分/特定技术具备深度的技能。\n\n6. Ability to develop large programs and systems from scratch. Understanding of low level details and internals. Ability to design / deploy most large, distributed systems from scratch.\n    - 能够从零开发大型程序和系统。理解底层和内部细节。能够从零设计和部署大多数大型分布式系统。\n\n7. You understand and make use of most lesser known language features, technologies, and associated internals. Ability to automate significant amounts of systems administration.\n    - 你理解并应用大多数鲜为人知的语言特性、技术和相关的内部知识。能够自动化大量系统管理。\n\n8. Deep understanding of corner cases, esoteric features, protocols and systems including “theory of operation”. Demonstrated ability to design, deploy and own very critical or large infrastructure, build accompanying automation.\n    - 深度理解角落案例、深奥特性、协议和系统，包括这些行为背后的原理(知其所以然)。具备设计、部署、管理关键或者大型基础架构能力，并构建\n相应的自动化。\n\n9. Could have written the book about the subject area but didn’t; works with standards committees on defining new standards and methodologies.\n    - 能够撰写领域书籍，但是尚未付诸行动(撰写书籍)。能够与标准委员会一起制定新的标准和方法。\n\n10. Wrote the book on the subject area(there actually has to be a book). Recognized industry expert in the field, might have invented it\n    - 写过领域内的书籍(实际上必须出版了书籍)。领域内公认的专家，也许已经在领域内有所创新。\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n----------------------------------------\n\n * Subject Areas:\n\n    TCP/IP Networking (OSI stack, DNS etc)\n    Unix/Linux internals\n    Unix/Linux Systems administration\n    Algorithms and Data Structures\n    C\n    C++\n    Python\n    Java\n    Perl\n    Go\n    Shell Scripting (sh, Bash, ksh, csh)\n    SQL and/or Database Admin\n    Scripting language of your choice (not already mentioned) \n    People Management\n    Project Management\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n",normalizedContent:"# google 技能评分卡\n\n0. you are unfamiliar with the subject area.\n    - 你对领域不了解。\n\n1. you can read/understand the most fundamental aspects of the subject area.\n    - 你能够阅读和理解领域的最基本方面。\n\n2. ability to implement small changes, understand basic principles and able to figure out additional details with minimal help.\n    - 能够实施小的变更，理解基本原则，并且能够在最少的帮助下找出更多细节。\n\n3. basic proficiency in a subject area without relying on help.\n    - 在不依赖帮助的情况下对领域有基本的熟练程度。\n\n4. you are comfirtable with the subject area and all routine work on it: for software areas - ability to develop medium programs using all basic language features w/o book, awareness of more esoteric feature(with book).\nfor systems areas - understanding of many fundamentals of networking and systems administration, ability to run a small network of system including recovery, debugging and nontrivial troubleshooting that relies on the knowledge of internals.\n    - 你对领域和所有日常工作都很熟悉：对于软件，能够在不参考书本的情况下使用基本的语言特性开发中型程序，能够通过书本了解更深奥的特性。\n对于系统，理解网络和系统管理的许多基础知识，能够依赖内在知识运转小型系统网络，包括恢复、调试、排除重要故障。\n\n5. an even lower degree of reliance on reference materials. deeper skills in a field or specific technology in the subject area.\n    - 对参考材料的依赖程度更低。对领域的某一部分/特定技术具备深度的技能。\n\n6. ability to develop large programs and systems from scratch. understanding of low level details and internals. ability to design / deploy most large, distributed systems from scratch.\n    - 能够从零开发大型程序和系统。理解底层和内部细节。能够从零设计和部署大多数大型分布式系统。\n\n7. you understand and make use of most lesser known language features, technologies, and associated internals. ability to automate significant amounts of systems administration.\n    - 你理解并应用大多数鲜为人知的语言特性、技术和相关的内部知识。能够自动化大量系统管理。\n\n8. deep understanding of corner cases, esoteric features, protocols and systems including “theory of operation”. demonstrated ability to design, deploy and own very critical or large infrastructure, build accompanying automation.\n    - 深度理解角落案例、深奥特性、协议和系统，包括这些行为背后的原理(知其所以然)。具备设计、部署、管理关键或者大型基础架构能力，并构建\n相应的自动化。\n\n9. could have written the book about the subject area but didn’t; works with standards committees on defining new standards and methodologies.\n    - 能够撰写领域书籍，但是尚未付诸行动(撰写书籍)。能够与标准委员会一起制定新的标准和方法。\n\n10. wrote the book on the subject area(there actually has to be a book). recognized industry expert in the field, might have invented it\n    - 写过领域内的书籍(实际上必须出版了书籍)。领域内公认的专家，也许已经在领域内有所创新。\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n----------------------------------------\n\n * subject areas:\n\n    tcp/ip networking (osi stack, dns etc)\n    unix/linux internals\n    unix/linux systems administration\n    algorithms and data structures\n    c\n    c++\n    python\n    java\n    perl\n    go\n    shell scripting (sh, bash, ksh, csh)\n    sql and/or database admin\n    scripting language of your choice (not already mentioned) \n    people management\n    project management\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n",charsets:{cjk:!0}},{title:"Home",frontmatter:{home:!0,heroText:"Jiao's blog",tagline:"知行合一 --- 技术博客，代码中的点点滴滴",features:[{title:"语言",details:"Python、C/C++、Go 等语言",link:"/blog/lang/",imgUrl:"/img/icon_lang.png"},{title:"前沿",details:"AI、图像处理等相关技术",link:"/blog/skills/",imgUrl:"/img/icon_ai.png"},{title:"其他",details:"文档、技巧、总结等文章",link:"/blog/xnote/",imgUrl:"/img/icon_write.png"}],postList:"simple",simplePostListLength:15},regularPath:"/",relativePath:"index.md",key:"v-16de7e50",path:"/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/03/31, 13:54:53",lastUpdatedTimestamp:1648734893e3},{title:"更多",frontmatter:{title:"更多",date:"2020-12-25T00:00:00.000Z",permalink:"/more/",sidebar:!1,article:!1},regularPath:"/more/",relativePath:"more/README.md",key:"v-02e3228c",path:"/more/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/03/31, 13:54:53",lastUpdatedTimestamp:1648734893e3},{title:"关于",frontmatter:{title:"关于",date:"2020-12-25T00:00:00.000Z",permalink:"/more/about/",sidebar:!1,article:!1},regularPath:"/more/about.html",relativePath:"more/about.md",key:"v-4bfbd5e5",path:"/more/about/",headers:[{level:2,title:"📚Blog",slug:"📚blog",normalizedTitle:"📚blog",charIndex:2},{level:2,title:"🎨Theme",slug:"🎨theme",normalizedTitle:"🎨theme",charIndex:88},{level:2,title:"🐼Me",slug:"🐼me",normalizedTitle:"🐼me",charIndex:130},{level:2,title:"✉️ 联系",slug:"联系",normalizedTitle:"✉️ 联系",charIndex:148}],headersStr:"📚Blog 🎨Theme 🐼Me ✉️ 联系",content:"# 📚Blog\n\n这是一个兼具博客文章、知识管理、文档查找的个人网站，欢迎交换友链 ( •̀ ω •́ )✧\n\n提示\n\n文章内容仅是我个人的小总结，如有误还请指正。\n\n\n# 🎨Theme\n\n本站使用vuepress-theme-vdoing搭建✧\n\n\n# 🐼Me\n\n\n\n本人↓↓↓\n\n\n# ✉️ 联系\n\n * WeChat or QQ: 929843628\n * Email: 929843628@qq.com\n * GitHub: https://github.com/joyous-x\n\n🎉🎉✨欢迎与我 联系↑ 共同进步 Blog Source",normalizedContent:"# 📚blog\n\n这是一个兼具博客文章、知识管理、文档查找的个人网站，欢迎交换友链 ( • ω • )✧\n\n提示\n\n文章内容仅是我个人的小总结，如有误还请指正。\n\n\n# 🎨theme\n\n本站使用vuepress-theme-vdoing搭建✧\n\n\n# 🐼me\n\n\n\n本人↓↓↓\n\n\n# ✉️ 联系\n\n * wechat or qq: 929843628\n * email: 929843628@qq.com\n * github: https://github.com/joyous-x\n\n🎉🎉✨欢迎与我 联系↑ 共同进步 blog source",charsets:{cjk:!0},lastUpdated:"2022/03/31, 13:54:53",lastUpdatedTimestamp:1648734893e3},{title:"收藏夹",frontmatter:{title:"收藏夹",date:"2021-01-19T00:00:00.000Z",permalink:"/more/favorites/",article:!1},regularPath:"/more/favorites.html",relativePath:"more/favorites.md",key:"v-19beb85e",path:"/more/favorites/",headers:[{level:2,title:"社区",slug:"社区",normalizedTitle:"社区",charIndex:35},{level:2,title:"图库 & 壁纸",slug:"图库-壁纸",normalizedTitle:"图库 &amp; 壁纸",charIndex:null},{level:3,title:"矢量图(Icon)",slug:"矢量图-icon",normalizedTitle:"矢量图(icon)",charIndex:386},{level:3,title:"Logo",slug:"logo",normalizedTitle:"logo",charIndex:605},{level:3,title:"图片工具",slug:"图片工具",normalizedTitle:"图片工具",charIndex:758},{level:2,title:"设计",slug:"设计",normalizedTitle:"设计",charIndex:978},{level:3,title:"配色",slug:"配色",normalizedTitle:"配色",charIndex:1262},{level:2,title:"产品",slug:"产品",normalizedTitle:"产品",charIndex:1432},{level:3,title:"交互",slug:"交互",normalizedTitle:"交互",charIndex:1078},{level:2,title:"在线工具",slug:"在线工具",normalizedTitle:"在线工具",charIndex:1641},{level:3,title:"实用",slug:"实用",normalizedTitle:"实用",charIndex:1650},{level:3,title:"CSS",slug:"css",normalizedTitle:"css",charIndex:1770},{level:3,title:"Emoji表情",slug:"emoji表情",normalizedTitle:"emoji表情",charIndex:2e3},{level:3,title:"科学上网",slug:"科学上网",normalizedTitle:"科学上网",charIndex:2100},{level:3,title:"CDN加速",slug:"cdn加速",normalizedTitle:"cdn加速",charIndex:2159},{level:2,title:"有趣",slug:"有趣",normalizedTitle:"有趣",charIndex:214}],excerpt:'<div class="custom-block tip"><p class="custom-block-title">提示</p>\n<p>收集一些常用的页面，持续整理中...</p>\n</div>\n<h1 id="收藏夹"><a class="header-anchor" href="#收藏夹">#</a> 收藏夹</h1>\n',headersStr:"社区 图库 & 壁纸 矢量图(Icon) Logo 图片工具 设计 配色 产品 交互 在线工具 实用 CSS Emoji表情 科学上网 CDN加速 有趣",content:"提示\n\n收集一些常用的页面，持续整理中...\n\n\n# 收藏夹\n\n\n# 社区\n\n * 掘金 一个帮助开发者成长的社区\n * 简书 有很多频道的创作社区\n * 思否 解决技术问题的社区\n * stack overflow 同上，外网的\n * InfoQ\n * V2EX\n * 鱼塘热榜 划水网站，收集了很多网站，当天热门文章\n * Github followers 全球排名\n * 牛油果烤面包 - 听硅谷从业人员谈论科技趋势和其他有趣的话题\n\n\n# 图库 & 壁纸\n\n * wallhaven 壁纸网站-\n * freepik banner 图库\n * 觅元素一天免费下载十张 psd\n * 虎克 Ps 学习教程\n * pexels 高清免费图片\n * pixabay 高清免费图片\n * alphacoders 手机壁纸\n * konachan 高质量二次元图片\n\n\n# 矢量图(Icon)\n\n * Pngtree\n * Icons8\n * Iconfinder\n * iconfactory\n * feather 矢量图标(open source)\n * iconfont 矢量图标(阿里巴巴)\n * easyicon easyicon图标库\n * Undraw 免费的矢量插画\n * icomoon 矢量图标库\n * cssicon 所有的 icon 都是纯 css 画的 缺点：icon 不够多\n\n\n# Logo\n\n * Logojoy ai 在线制作 logo，做出来的 logo 质量还不错\n * brandmark 在线制作 logo 网站\n * instant 在线制作 logo 网站\n * namecheap 在线制作 logo 网站\n * logo-maker 在线制作 logo 网站\n\n\n# 图片工具\n\n * tinypng图片压缩 压缩png很有用\n * Squoosh 谷歌出品在线免费图片压缩工具\n * iloveimg 在线编辑图片：缩放、剪裁、压缩\n * waifu2x 通过卷积网络放大图片(github开源)\n * vectormagic 转换矢量图\n * vectorizer 真正的 png 转 svg 神器\n * 在线AI图片处理 黑白修复、无损放大、动漫化、铅笔画等。\n * remove AI抠图\n * 稿定设计 键式设计工具+智能抠图\n * vectorizer 真正的 png 转 svg 神器\n\n\n# 设计\n\n * 创造师导航\n * 设计师网址导航\n * uimovement 能从这个网站找到不少动画交互的灵感\n * awwwards是一个一个专门为设计精美的网站以及富有创意的网站颁奖的网站\n * dribbble 经常能在上面找到很多有创意好看的 gif 或者图片\n * designcap 在线海报设计\n * design.youzan 有赞设计原则\n\n * Canva 可画 生成插画、封面、海报、头像等\n\n * 搞定设计 可以抠图\n * UI 中国\n\n\n# 配色\n\n * uigradients 渐变色生成工具\n * Flat UI 色表 Flat UI 色表\n * 0to255 颜色梯度\n * colorhunt 另一个配色网站\n * uigradients 渐变色网站\n * coolors 帮你在线配色的网站 你能找到不少配色灵感\n * colorkitty 从你的图片中提取配色\n\n\n# 产品\n\n * 产品大牛 什么有很多完整的产品原型可以借鉴\n * 磨刀 快速出 ui 原型\n\n\n# 交互\n\n * Can't Unsee 强烈建议前端、客户端、UI 开发的同学玩下，检查一下自己对设计稿的敏感度怎么样\n * 微交互 里面收集了市面上很多很好的微交互例子 值得学习\n * Little Big Details 同上，一个国外微交互汇集网站\n * cruip 登录页的各种页面设计，可以免费下载模板\n\n\n# 在线工具\n\n\n# 实用\n\n * 正则可视化\n * Linux命令手册\n * 代码图片生成器\n * Github shields 徽章图标\n * 大力盘 百度网盘搜索\n * 来画视频 像做 PPT 一样做短视频\n * 优品 PPT\n * 比格 PPT\n\n\n# CSS\n\n * CSS Tricks CSS技巧收集与演示\n * CSS生成器\n * CSS渐变生成器\n * CSS3-Box Shadow(阴影)\n * 3D字体\n * css-tricks css技巧文章\n * You-need-to-know-css CSS的各种DEMO，很全\n * CSS triangle generator 帮你快速用 css 做出三角形\n * clippy 在线帮你使用 css clip-path 做出各种形状的图形\n\n\n# Emoji表情\n\n * emoji表情\n * emoji表情备忘录\n * gitmoji 通过 emoji 表达 git 的操作内容\n\n> windows系统下按Win+.快速打开表情选择框\n\n\n# 科学上网\n\n * 谷歌chrome商店访问助手\n * 谷歌云(GCP)一键搭建 V2Ray 让你畅快科学上网\n\n\n# CDN加速\n\n * jsDelivr 国外的一家优秀的公共 CDN 服务提供商\n * unpkg cdn 服务\n\n\n# 有趣\n\n * awesome-comment 里面收集了很多有趣的代码注释\n * text-img 都将图片转化为 ascii 用来写注释\n * weird-fonts 将普通字母转化为 特殊 unicode\n * magi ai 搜索神器，超屌\n * Comixify 一个波兰团队做了非常好玩的工具，可以把视频自动转成漫画，上图是他们提供的 demo，效果很棒。",normalizedContent:"提示\n\n收集一些常用的页面，持续整理中...\n\n\n# 收藏夹\n\n\n# 社区\n\n * 掘金 一个帮助开发者成长的社区\n * 简书 有很多频道的创作社区\n * 思否 解决技术问题的社区\n * stack overflow 同上，外网的\n * infoq\n * v2ex\n * 鱼塘热榜 划水网站，收集了很多网站，当天热门文章\n * github followers 全球排名\n * 牛油果烤面包 - 听硅谷从业人员谈论科技趋势和其他有趣的话题\n\n\n# 图库 & 壁纸\n\n * wallhaven 壁纸网站-\n * freepik banner 图库\n * 觅元素一天免费下载十张 psd\n * 虎克 ps 学习教程\n * pexels 高清免费图片\n * pixabay 高清免费图片\n * alphacoders 手机壁纸\n * konachan 高质量二次元图片\n\n\n# 矢量图(icon)\n\n * pngtree\n * icons8\n * iconfinder\n * iconfactory\n * feather 矢量图标(open source)\n * iconfont 矢量图标(阿里巴巴)\n * easyicon easyicon图标库\n * undraw 免费的矢量插画\n * icomoon 矢量图标库\n * cssicon 所有的 icon 都是纯 css 画的 缺点：icon 不够多\n\n\n# logo\n\n * logojoy ai 在线制作 logo，做出来的 logo 质量还不错\n * brandmark 在线制作 logo 网站\n * instant 在线制作 logo 网站\n * namecheap 在线制作 logo 网站\n * logo-maker 在线制作 logo 网站\n\n\n# 图片工具\n\n * tinypng图片压缩 压缩png很有用\n * squoosh 谷歌出品在线免费图片压缩工具\n * iloveimg 在线编辑图片：缩放、剪裁、压缩\n * waifu2x 通过卷积网络放大图片(github开源)\n * vectormagic 转换矢量图\n * vectorizer 真正的 png 转 svg 神器\n * 在线ai图片处理 黑白修复、无损放大、动漫化、铅笔画等。\n * remove ai抠图\n * 稿定设计 键式设计工具+智能抠图\n * vectorizer 真正的 png 转 svg 神器\n\n\n# 设计\n\n * 创造师导航\n * 设计师网址导航\n * uimovement 能从这个网站找到不少动画交互的灵感\n * awwwards是一个一个专门为设计精美的网站以及富有创意的网站颁奖的网站\n * dribbble 经常能在上面找到很多有创意好看的 gif 或者图片\n * designcap 在线海报设计\n * design.youzan 有赞设计原则\n\n * canva 可画 生成插画、封面、海报、头像等\n\n * 搞定设计 可以抠图\n * ui 中国\n\n\n# 配色\n\n * uigradients 渐变色生成工具\n * flat ui 色表 flat ui 色表\n * 0to255 颜色梯度\n * colorhunt 另一个配色网站\n * uigradients 渐变色网站\n * coolors 帮你在线配色的网站 你能找到不少配色灵感\n * colorkitty 从你的图片中提取配色\n\n\n# 产品\n\n * 产品大牛 什么有很多完整的产品原型可以借鉴\n * 磨刀 快速出 ui 原型\n\n\n# 交互\n\n * can't unsee 强烈建议前端、客户端、ui 开发的同学玩下，检查一下自己对设计稿的敏感度怎么样\n * 微交互 里面收集了市面上很多很好的微交互例子 值得学习\n * little big details 同上，一个国外微交互汇集网站\n * cruip 登录页的各种页面设计，可以免费下载模板\n\n\n# 在线工具\n\n\n# 实用\n\n * 正则可视化\n * linux命令手册\n * 代码图片生成器\n * github shields 徽章图标\n * 大力盘 百度网盘搜索\n * 来画视频 像做 ppt 一样做短视频\n * 优品 ppt\n * 比格 ppt\n\n\n# css\n\n * css tricks css技巧收集与演示\n * css生成器\n * css渐变生成器\n * css3-box shadow(阴影)\n * 3d字体\n * css-tricks css技巧文章\n * you-need-to-know-css css的各种demo，很全\n * css triangle generator 帮你快速用 css 做出三角形\n * clippy 在线帮你使用 css clip-path 做出各种形状的图形\n\n\n# emoji表情\n\n * emoji表情\n * emoji表情备忘录\n * gitmoji 通过 emoji 表达 git 的操作内容\n\n> windows系统下按win+.快速打开表情选择框\n\n\n# 科学上网\n\n * 谷歌chrome商店访问助手\n * 谷歌云(gcp)一键搭建 v2ray 让你畅快科学上网\n\n\n# cdn加速\n\n * jsdelivr 国外的一家优秀的公共 cdn 服务提供商\n * unpkg cdn 服务\n\n\n# 有趣\n\n * awesome-comment 里面收集了很多有趣的代码注释\n * text-img 都将图片转化为 ascii 用来写注释\n * weird-fonts 将普通字母转化为 特殊 unicode\n * magi ai 搜索神器，超屌\n * comixify 一个波兰团队做了非常好玩的工具，可以把视频自动转成漫画，上图是他们提供的 demo，效果很棒。",charsets:{cjk:!0},lastUpdated:"2022/03/31, 13:54:53",lastUpdatedTimestamp:1648734893e3},{title:"友情链接",frontmatter:{title:"友情链接",date:"2020-12-25T00:00:00.000Z",permalink:"/more/friends/",article:!1,sidebar:!1},regularPath:"/more/friends.html",relativePath:"more/friends.md",key:"v-5b31b7d6",path:"/more/friends/",headers:[{level:3,title:"友链申请",slug:"友链申请",normalizedTitle:"友链申请",charIndex:539}],headersStr:"友链申请",content:"麋鹿鲁哟\n\n大道至简，知易行难\n\nXAOXUU\n\n#IOS #Volantis主题作者\n\n- name: 麋鹿鲁哟\n  desc: 大道至简，知易行难\n  avatar: https://cdn.jsdelivr.net/gh/xugaoyi/image_store/blog/20200122153807.jpg # 可选\n  link: https://www.cnblogs.com/miluluyo/ # 可选\n  bgColor: '#CBEAFA' # 可选，默认var(--bodyBg)。颜色值有#号时请添加单引号\n  textColor: '#6854A1' # 可选，默认var(--textColor)\n- name: XAOXUU\n  desc: '#IOS #Volantis主题作者'\n  avatar: https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/avatar/avatar.png\n  link: https://xaoxuu.com\n  bgColor: '#B9D59C'\n  textColor: '#3B551F'\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 友链申请\n\n与我 联系 或者 在本页面评论区留言您的友链信息，格式：(点击代码块右上角一键复制)\n\n- name: Jiao's blog # 昵称\n  desc: 知行合一 # 介绍\n  avatar: '/img/avatar.png' # 头像\n  link: https://.com/  # 链接\n\n\n1\n2\n3\n4\n\n\n申请前记得先添加本站哦~",normalizedContent:"麋鹿鲁哟\n\n大道至简，知易行难\n\nxaoxuu\n\n#ios #volantis主题作者\n\n- name: 麋鹿鲁哟\n  desc: 大道至简，知易行难\n  avatar: https://cdn.jsdelivr.net/gh/xugaoyi/image_store/blog/20200122153807.jpg # 可选\n  link: https://www.cnblogs.com/miluluyo/ # 可选\n  bgcolor: '#cbeafa' # 可选，默认var(--bodybg)。颜色值有#号时请添加单引号\n  textcolor: '#6854a1' # 可选，默认var(--textcolor)\n- name: xaoxuu\n  desc: '#ios #volantis主题作者'\n  avatar: https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/avatar/avatar.png\n  link: https://xaoxuu.com\n  bgcolor: '#b9d59c'\n  textcolor: '#3b551f'\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 友链申请\n\n与我 联系 或者 在本页面评论区留言您的友链信息，格式：(点击代码块右上角一键复制)\n\n- name: jiao's blog # 昵称\n  desc: 知行合一 # 介绍\n  avatar: '/img/avatar.png' # 头像\n  link: https://.com/  # 链接\n\n\n1\n2\n3\n4\n\n\n申请前记得先添加本站哦~",charsets:{cjk:!0},lastUpdated:"2022/03/31, 13:54:53",lastUpdatedTimestamp:1648734893e3}],themeConfig:{nav:[{text:"首页",link:"/"},{text:"Blog",link:"/blog/",items:[{text:"语言",link:"/blog/lang/",items:[{text:"Language",link:"/blog/lang/"}]},{text:"设计",link:"/blog/design/",items:[{text:"Design",link:"/blog/design/"}]},{text:"网络",link:"/blog/network/",items:[{text:"Network",link:"/blog/network/"}]},{text:"数据库",link:"/blog/database/",items:[{text:"Database",link:"/blog/database/"}]},{text:"平台",link:"/blog/platform/",items:[{text:"Platform",link:"/blog/platform/"}]},{text:"技能",link:"/blog/skills/",items:[{text:"Devops",link:"/blog/skills/##Devops"},{text:"AI",link:"/blog/skills/##Ai"}]},{text:"应用",link:"/blog/utilization/",items:[{text:"Utilization",link:"/blog/utilization/"}]},{text:"杂项",link:"/blog/utility/",items:[{text:"ReadNote",link:"/blog/utility/##Rnote"},{text:"Tools",link:"/blog/utility/##Tools"}]}]},{text:"更多",link:"/more/",items:[{text:"关于",link:"/more/about/"},{text:"友情链接",link:"/more/friends/"},{text:"收藏",link:"/more/favorites/",items:[{text:"favorites",link:"/more/favorites/"}]}]},{text:"索引",link:"/index/",items:[{text:"分类",link:"/index/categories/"},{text:"标签",link:"/index/tags/"},{text:"归档",link:"/index/archives/"}]}],sidebarDepth:2,logo:"/img/web_logo.png",repo:"joyous-x/blog",searchMaxSuggestions:10,lastUpdated:"上次更新",docsDir:"docs",editLinks:!1,editLinkText:"编辑",sidebar:{},author:{name:"Jiao",link:"https://github.com/joyous-x"},blogger:{avatar:"/img/avatar.png",name:"Jiao",slogan:"知行合一"},social:{icons:[{iconClass:"icon-youjian",title:"发邮件",link:"mailto:929843628@qq.com"},{iconClass:"icon-github",title:"GitHub",link:"https://github.com/joyous-x"},{iconClass:"icon-erji",title:"听音乐",link:"https://music.163.com"}]},footer:{createYear:2020,copyrightInfo:'Jiao | <a href="https://github.com/joyous-x/blog/blob/master/LICENSE" target="_blank">MIT License</a>'},htmlModules:{homeSidebarB:'\x3c!-- 纵向自适应 --\x3e\n    <ins class="adsbygoogle"\n        style="display:block;padding: 0.95rem;"\n        data-ad-client="ca-pub-7828333725993554"\n        data-ad-slot="7802654582"\n        data-ad-format="auto"\n        data-full-width-responsive="true"></ins>\n    <script>\n        (adsbygoogle = window.adsbygoogle || []).push({});\n    <\/script>',sidebarB:'\x3c!-- 正方形 --\x3e\n      <ins class="adsbygoogle"\n          style="display:block"\n          data-ad-client="ca-pub-7828333725993554"\n          data-ad-slot="3508773082"\n          data-ad-format="auto"\n          data-full-width-responsive="true"></ins>\n      <script>\n          (adsbygoogle = window.adsbygoogle || []).push({});\n      <\/script>',pageT:'\x3c!-- 固定100% * 90px可显示，max-height:90px未见显示--\x3e\n     <ins class="adsbygoogle"\n          style="display:inline-block;width:100%;max-height:90px"\n          data-ad-client="ca-pub-7828333725993554"\n          data-ad-slot="6625304284"></ins>\n      <script>\n          (adsbygoogle = window.adsbygoogle || []).push({});\n      <\/script>',pageB:'\x3c!-- 横向自适应 --\x3e\n      <ins class="adsbygoogle"\n          style="display:block"\n          data-ad-client="ca-pub-7828333725993554"\n          data-ad-slot="6620245489"\n          data-ad-format="auto"\n          data-full-width-responsive="true"></ins>\n      <script>\n          (adsbygoogle = window.adsbygoogle || []).push({});\n      <\/script>',windowRB:'\x3c!-- 固定160*160px --\x3e\n      <ins class="adsbygoogle"\n          style="display:inline-block;max-width:160px;max-height:160px"\n          data-ad-client="ca-pub-7828333725993554"\n          data-ad-slot="8377369658"></ins>\n      <script>\n          (adsbygoogle = window.adsbygoogle || []).push({});\n      <\/script>\n      '}}},Zs=(t(133),t(205),t(144),t(216)),Js=t(217),nl=(t(368),t(228),t(43));var el={computed:{$filterPosts:function(){return this.$site.pages.filter((function(n){var e=n.frontmatter,t=e.pageComponent,r=e.article,o=e.home;return!(t||!1===r||!0===o)}))},$sortPosts:function(){return(n=this.$filterPosts).sort((function(n,e){var t=n.frontmatter.sticky,r=e.frontmatter.sticky;return t&&r?t==r?Object(nl.a)(n,e):t-r:t&&!r?-1:!t&&r?1:Object(nl.a)(n,e)})),n;var n},$sortPostsByDate:function(){return(n=this.$filterPosts).sort((function(n,e){return Object(nl.a)(n,e)})),n;var n},$groupPosts:function(){return function(n){for(var e={},t={},r=function(r,o){var a=n[r].frontmatter,i=a.categories,s=a.tags;"array"===Object(nl.n)(i)&&i.forEach((function(t){t&&(e[t]||(e[t]=[]),e[t].push(n[r]))})),"array"===Object(nl.n)(s)&&s.forEach((function(e){e&&(t[e]||(t[e]=[]),t[e].push(n[r]))}))},o=0,a=n.length;o<a;o++)r(o);return{categories:e,tags:t}}(this.$sortPosts)},$categoriesAndTags:function(){return function(n){var e=[],t=[];for(var r in n.categories)e.push({key:r,length:n.categories[r].length});for(var o in n.tags)t.push({key:o,length:n.tags[o].length});return{categories:e,tags:t}}(this.$groupPosts)}}};Ro.component(Zs.default),Ro.component(Js.default);function tl(n){return n.toString().padStart(2,"0")}t(373);Ro.component("Badge",(function(){return Promise.all([t.e(0),t.e(12)]).then(t.bind(null,728))})),Ro.component("CodeBlock",(function(){return Promise.resolve().then(t.bind(null,216))})),Ro.component("CodeGroup",(function(){return Promise.resolve().then(t.bind(null,217))}));t(374),t(136),t(375),t(376);var rl,ol,al=t(39),il=(t(379),t(134),t(215)),sl=t.n(il),ll=t(100);"valine"===(ol="gitalk")?t.e(105).then(t.t.bind(null,625,7)).then((function(n){return n.default})):"gitalk"===ol&&Promise.all([t.e(0),t.e(104)]).then(t.t.bind(null,626,7)).then((function(){return t.e(102).then(t.t.bind(null,627,7))})).then((function(n){return rl=n.default}));function cl(n,e){var t={};return Reflect.ownKeys(n).forEach((function(r){if("string"==typeof n[r])try{t[r]=sl.a.render(n[r],e)}catch(e){console.warn('Comment config option error at key named "'.concat(r,'"')),console.warn("More info: ".concat(e.message)),t[r]=n[r]}else t[r]=n[r]})),t}console.log('How to use "'.concat("gitalk",'" in ').concat(ll.name,"@v").concat(ll.version,":"),ll.homepage);var dl={render:function(n,e){var t=document.createElement("div");t.id=e,document.querySelector("main.page").appendChild(t),new rl(cl({clientID:"874ae7777f9ba6ae4dc8",clientSecret:"8c75a7494bc02652016bd5d0ccef60717a383b5d",repo:"blog_comment",owner:"joyous-x",admin:["joyous-x"],pagerDirection:"last",id:"<%- (frontmatter.permalink || frontmatter.to.path).slice(-16) %>",title:"「评论」<%- frontmatter.title %>",labels:["Gitalk","Comment"],body:"页面：<%- window.location.origin + (frontmatter.to.path || window.location.pathname) %>"},{frontmatter:n})).render(e)},clear:function(n){var e=document.querySelector("#".concat(n));return e&&e.remove(),!0}},pl=null;function ul(n){return dl.clear("vuepress-plugin-comment")}function ml(n){return!1!==n.comment&&!1!==n.comments}function fl(n){if(clearTimeout(pl),document.querySelector("main.page"))return dl.render(n,"vuepress-plugin-comment");pl=setTimeout((function(){return fl(n)}),200)}var hl={mounted:function(){var n=this;pl=setTimeout((function(){var e=Object(al.a)({to:{},from:{}},n.$frontmatter);ul()&&ml(e)&&fl(e)}),1e3),this.$router.afterEach((function(e,t){if(!e||!t||e.path!==t.path){var r=Object(al.a)({to:e,from:t},n.$frontmatter);ul()&&ml(r)&&fl(r)}}))}},gl=Object(Ks.a)(hl,(function(){var n=this.$createElement;return(this._self._c||n)("div")}),[],!1,null,null,null).exports,vl=(t(384),{props:{color:{required:!1,default:"rgb(66, 185, 131)"}}}),bl=(t(385),Object(Ks.a)(vl,(function(){var n=this.$createElement;return(this._self._c||n)("div",{staticClass:"spinner",style:{background:this.color}})}),[],!1,null,"1bbcb91a",null).exports),yl={name:"Mermaid",props:{id:{type:String,required:!1,default:function(){return"diagram_"+Date.now()}},graph:{type:String,required:!1}},data:function(){return{svg:void 0}},computed:{graphData:function(){return this.graph?this.graph:this.$slots.default[0].text}},render:function(n){return void 0===this.svg?n("Loading"):n("div",{class:["mermaid-diagram"],domProps:{innerHTML:this.svg,style:"width: 100%"}})},mounted:function(){var n=this;t.e(103).then(t.t.bind(null,628,7)).then((function(e){e.initialize(Object(al.a)({startOnLoad:!0},{})),e.render(n.id,n.graphData,(function(e){n.svg=e}))}))},components:{Loading:bl}},xl=[function(n){n.Vue,n.options,n.router,n.siteData},function(n){var e=n.Vue,t=(n.options,n.router,n.siteData);t.pages.map((function(n){var e=n.frontmatter,r=e.date,o=e.author;"string"==typeof r&&"Z"===r.charAt(r.length-1)&&(n.frontmatter.date=function(n){n instanceof Date||(n=new Date(n));return"".concat(n.getUTCFullYear(),"-").concat(tl(n.getUTCMonth()+1),"-").concat(tl(n.getUTCDate())," ").concat(tl(n.getUTCHours()),":").concat(tl(n.getUTCMinutes()),":").concat(tl(n.getUTCSeconds()))}(r)),o?n.author=o:t.themeConfig.author&&(n.author=t.themeConfig.author)})),e.mixin(el)},{},function(n){n.Vue.mixin({computed:{$dataBlock:function(){return this.$options.__data__block__}}})},{},{},function(n){n.router;"undefined"!=typeof window&&function(){var n=document.createElement("script"),e=window.location.protocol.split(":")[0];n.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(n,t)}()},{},function(n){n.Vue.component("Comment",gl)},function(n){n.Vue.component(yl.name,yl)}],_l=["Comment"];t(137);t(209);function kl(n,e){return(kl=Object.setPrototypeOf||function(n,e){return n.__proto__=e,n})(n,e)}t(210);function wl(n){return(wl=Object.setPrototypeOf?Object.getPrototypeOf:function(n){return n.__proto__||Object.getPrototypeOf(n)})(n)}function Tl(n,e){if(e&&("object"===Ci(e)||"function"==typeof e))return e;if(void 0!==e)throw new TypeError("Derived constructors may only return object or undefined");return function(n){if(void 0===n)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return n}(n)}function Sl(n){var e=function(){if("undefined"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Reflect.construct(Boolean,[],(function(){}))),!0}catch(n){return!1}}();return function(){var t,r=wl(n);if(e){var o=wl(this).constructor;t=Reflect.construct(r,arguments,o)}else t=r.apply(this,arguments);return Tl(this,t)}}var Pl=function(n){!function(n,e){if("function"!=typeof e&&null!==e)throw new TypeError("Super expression must either be null or a function");n.prototype=Object.create(e&&e.prototype,{constructor:{value:n,writable:!0,configurable:!0}}),Object.defineProperty(n,"prototype",{writable:!1}),e&&kl(n,e)}(t,n);var e=Sl(t);function t(){return ps(this,t),e.apply(this,arguments)}return ms(t)}(function(){function n(){ps(this,n),this.store=new Ro({data:{state:{}}})}return ms(n,[{key:"$get",value:function(n){return this.store.state[n]}},{key:"$set",value:function(n,e){Ro.set(this.store.state,n,e)}},{key:"$emit",value:function(){var n;(n=this.store).$emit.apply(n,arguments)}},{key:"$on",value:function(){var n;(n=this.store).$on.apply(n,arguments)}}]),n}());Object.assign(Pl.prototype,{getPageAsyncComponent:Gi,getLayoutAsyncComponent:Hi,getAsyncComponent:Vi,getVueComponent:$i});var Cl={install:function(n){var e=new Pl;n.$vuepress=e,n.prototype.$vuepress=e}};function Il(n){n.beforeEach((function(e,t,r){if(El(n,e.path))r();else if(/(\/|\.html)$/.test(e.path))if(/\/$/.test(e.path)){var o=e.path.replace(/\/$/,"")+".html";El(n,o)?r(o):r()}else r();else{var a=e.path+"/",i=e.path+".html";El(n,i)?r(i):El(n,a)?r(a):r()}}))}function El(n,e){var t=e.toLowerCase();return n.options.routes.some((function(n){return n.path.toLowerCase()===t}))}var Al={props:{pageKey:String,slotKey:{type:String,default:"default"}},render:function(n){var e=this.pageKey||this.$parent.$page.key;return Ki("pageKey",e),Ro.component(e)||Ro.component(e,Gi(e)),Ro.component(e)?n(e):n("")}},Dl={functional:!0,props:{slotKey:String,required:!0},render:function(n,e){var t=e.props,r=e.slots;return n("div",{class:["content__".concat(t.slotKey)]},r()[t.slotKey])}},Ol={computed:{openInNewWindowTitle:function(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Ll=(t(387),t(388),Object(Ks.a)(Ol,(function(){var n=this.$createElement,e=this._self._c||n;return e("span",[e("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[e("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),e("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),e("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports);function jl(){return(jl=o(regeneratorRuntime.mark((function n(e){var t,r,o,a;return regeneratorRuntime.wrap((function(n){for(;;)switch(n.prev=n.next){case 0:return t="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:Ys.routerBase||Ys.base,Il(r=new Si({base:t,mode:"history",fallback:!1,routes:Qs,scrollBehavior:function(n,e,t){return t||(n.hash?!Ro.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(n.hash)}:{x:0,y:0})}})),o={},n.prev=4,n.next=7,Promise.all(xl.filter((function(n){return"function"==typeof n})).map((function(n){return n({Vue:Ro,options:o,router:r,siteData:Ys,isServer:e})})));case 7:n.next=12;break;case 9:n.prev=9,n.t0=n.catch(4),console.error(n.t0);case 12:return a=new Ro(Object.assign(o,{router:r,render:function(n){return n("div",{attrs:{id:"app"}},[n("RouterView",{ref:"layout"}),n("div",{class:"global-ui"},_l.map((function(e){return n(e)})))])}})),n.abrupt("return",{app:a,router:r});case 14:case"end":return n.stop()}}),n,null,[[4,9]])})))).apply(this,arguments)}Ro.config.productionTip=!1,Ro.use(Si),Ro.use(Cl),Ro.mixin(function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:Ro;Pi(e),t.$vuepress.$set("siteData",e);var r=n(t.$vuepress.$get("siteData")),o=new r,a=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(o)),i={};return Object.keys(a).reduce((function(n,e){return e.startsWith("$")&&(n[e]=a[e].get),n}),i),{computed:i}}((function(n){return function(){function e(){ps(this,e)}return ms(e,[{key:"setPage",value:function(n){this.__page=n}},{key:"$site",get:function(){return n}},{key:"$themeConfig",get:function(){return this.$site.themeConfig}},{key:"$frontmatter",get:function(){return this.$page.frontmatter}},{key:"$localeConfig",get:function(){var n,e,t=this.$site.locales,r=void 0===t?{}:t;for(var o in r)"/"===o?e=r[o]:0===this.$page.path.indexOf(o)&&(n=r[o]);return n||e||{}}},{key:"$siteTitle",get:function(){return this.$localeConfig.title||this.$site.title||""}},{key:"$canonicalUrl",get:function(){var n=this.$page.frontmatter.canonicalUrl;return"string"==typeof n&&n}},{key:"$title",get:function(){var n=this.$page,e=this.$page.frontmatter.metaTitle;if("string"==typeof e)return e;var t=this.$siteTitle,r=n.frontmatter.home?null:n.frontmatter.title||n.title;return t?r?r+" | "+t:t:r||"VuePress"}},{key:"$description",get:function(){var n=function(n){if(n){var e=n.filter((function(n){return"description"===n.name}))[0];if(e)return e.content}}(this.$page.frontmatter.meta);return n||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}},{key:"$lang",get:function(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}},{key:"$localePath",get:function(){return this.$localeConfig.path||"/"}},{key:"$themeLocaleConfig",get:function(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}},{key:"$page",get:function(){return this.__page?this.__page:function(n,e){for(var t=0;t<n.length;t++){var r=n[t];if(r.path.toLowerCase()===e.toLowerCase())return r}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}}]),e}()}),Ys)),Ro.component("Content",Al),Ro.component("ContentSlotsDistributor",Dl),Ro.component("OutboundLink",Ll),Ro.component("ClientOnly",{functional:!0,render:function(n,e){var t=e.parent,r=e.children;if(t._isMounted)return r;t.$once("hook:mounted",(function(){t.$forceUpdate()}))}}),Ro.component("Layout",Hi("Layout")),Ro.component("NotFound",Hi("NotFound")),Ro.prototype.$withBase=function(n){var e=this.$site.base;return"/"===n.charAt(0)?e+n.slice(1):n},window.__VUEPRESS__={version:"1.9.7",hash:"70f2ba7"},function(n){return jl.apply(this,arguments)}(!1).then((function(n){var e=n.app;n.router.onReady((function(){e.$mount("#app")}))}))}]);