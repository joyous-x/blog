(window.webpackJsonp=window.webpackJsonp||[]).push([[63],{588:function(t,a,e){"use strict";e.r(a);var n=e(15),_=Object(n.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h2",{attrs:{id:"_1-动漫风格转换"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-动漫风格转换"}},[t._v("#")]),t._v(" 1. 动漫风格转换")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("GAN")]),t._v(" "),e("th",[t._v("Type")]),t._v(" "),e("th",[t._v("Code")]),t._v(" "),e("th",[t._v("Online")]),t._v(" "),e("th",[t._v("Note")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("CartoonGAN")]),t._v(" "),e("td",[t._v("pytorch")]),t._v(" "),e("td",[t._v("https://github.com/znxlwm/pytorch-CartoonGAN")]),t._v(" "),e("td",[t._v("x")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("CartoonGAN")]),t._v(" "),e("td",[t._v("tensorflow")]),t._v(" "),e("td",[t._v("https://github.com/mnicnc404/CartoonGan-tensorflow")]),t._v(" "),e("td",[t._v("自带预训练")]),t._v(" "),e("td",[t._v("预训练模型: http://cg.cs.tsinghua.edu.cn/people/~Yongjin/CartoonGAN-Models.rar， 效果较差（图片细节保留不足）")])]),t._v(" "),e("tr",[e("td",[t._v("AnimeGAN")]),t._v(" "),e("td",[t._v("tensorflow")]),t._v(" "),e("td",[t._v("https://github.com/TachibanaYoshino/AnimeGAN")]),t._v(" "),e("td",[t._v("x")]),t._v(" "),e("td",[t._v("pytorch 实现：https://github.com/XuHangkun/AnimeGAN_in_Pytorch")])]),t._v(" "),e("tr",[e("td",[t._v("AnimeGANv2")]),t._v(" "),e("td",[t._v("tensorflow")]),t._v(" "),e("td",[t._v("https://github.com/TachibanaYoshino/AnimeGANv2")]),t._v(" "),e("td",[t._v("x ｜ 效果未知")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("White-box Cartoon")]),t._v(" "),e("td",[t._v("tensorflow")]),t._v(" "),e("td",[t._v("https://github.com/SystemErrorWang/White-box-Cartoonization")]),t._v(" "),e("td",[t._v("自带预训练")]),t._v(" "),e("td",[t._v("效果最好，应用：https://github.com/margaretmz/cartoonizer-with-tflite")])])])]),t._v(" "),e("p",[e("em",[t._v("https://github.com/zhen8838/AnimeStylized 用 pytorch 实现了以上几种 GAN，但是训练出的效果和原版有差异")])]),t._v(" "),e("h3",{attrs:{id:"相关阅读"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#相关阅读"}},[t._v("#")]),t._v(" 相关阅读")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://www.gwern.net/Faces#background",target:"_blank",rel:"noopener noreferrer"}},[t._v("Making Anime Faces With StyleGAN"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/76574388",target:"_blank",rel:"noopener noreferrer"}},[t._v("AnimeGAN将现实照片动漫化，超越清华的CartoonGAN"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/151858534",target:"_blank",rel:"noopener noreferrer"}},[t._v("AI灵魂画手——扒一扒抖音爆款”变身漫画“后的技术事"),e("OutboundLink")],1)])]),t._v(" "),e("h2",{attrs:{id:"_2-真人眨眼睛"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-真人眨眼睛"}},[t._v("#")]),t._v(" 2. 真人眨眼睛")]),t._v(" "),e("p",[t._v("GANimation: Anatomically-aware Facial Animation from a Single Image")]),t._v(" "),e("p",[t._v("An Out-of-the-Box Replicate of GANimation using PyTorch, pretrained weights are available!\nhttps://github.com/donydchen/ganimation_replicate")]),t._v(" "),e("h3",{attrs:{id:"facial-action-units-introduce"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#facial-action-units-introduce"}},[t._v("#")]),t._v(" "),e("a",{attrs:{href:"https://imotions.com/blog/facial-action-coding-system/#main-action-units",target:"_blank",rel:"noopener noreferrer"}},[t._v("facial-action-units introduce"),e("OutboundLink")],1)]),t._v(" "),e("h3",{attrs:{id:"paper-flnet-landmark-driven-fetching-and-learning-network-for-faithful-talking-facial-animation-synthesis"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#paper-flnet-landmark-driven-fetching-and-learning-network-for-faithful-talking-facial-animation-synthesis"}},[t._v("#")]),t._v(" paper : FLNet: Landmark Driven Fetching and Learning Network for Faithful Talking Facial Animation Synthesis")]),t._v(" "),e("ul",[e("li",[t._v("Facial Action Units (AUs) Based Methods\n"),e("ul",[e("li",[t._v("GANimation: Anatomically-aware Facial Animation from a Single Image")])])]),t._v(" "),e("li",[t._v("Landmark Driven Methods\n"),e("ul",[e("li",[t._v("First Order Motion Model for Image Animation （自监督特征点识别）")])])])]),t._v(" "),e("p",[t._v("FLNet 融合了以上两个方法")]),t._v(" "),e("h2",{attrs:{id:"_3-扣图"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-扣图"}},[t._v("#")]),t._v(" 3. 扣图")]),t._v(" "),e("p",[t._v("人脸识别：https://github.com/cmusatyalab/openface\nhttps://github.com/Hsintao/pfld_106_face_landmarks\nhttps://github.com/polarisZhao/PFLD-pytorch")]),t._v(" "),e("h2",{attrs:{id:"_4-scaling"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-scaling"}},[t._v("#")]),t._v(" 4. Scaling")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("name")]),t._v(" "),e("th",[t._v("attr")]),t._v(" "),e("th",[t._v("note")]),t._v(" "),e("th",[t._v("github")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("video2x")]),t._v(" "),e("td",[t._v("x")]),t._v(" "),e("td",[t._v("只是应用框架，需要下述算法驱动")]),t._v(" "),e("td",[t._v("https://github.com/k4yt3x/video2x")])]),t._v(" "),e("tr",[e("td",[t._v("Real-SR")]),t._v(" "),e("td",[t._v("x")]),t._v(" "),e("td",[t._v("winner of CVPR NTIRE 2020 Challenge on Real-World Super-Resolution")]),t._v(" "),e("td",[t._v("https://github.com/Tencent/Real-SR")])]),t._v(" "),e("tr",[e("td",[t._v("BSRGAN ｜ x ｜ 2021")]),t._v(" "),e("td",[t._v("https://github.com/cszn/BSRGAN")]),t._v(" "),e("td"),t._v(" "),e("td")])])]),t._v(" "),e("p",[t._v("USRNet ｜ x ｜ CVPR 2020 ｜ https://github.com/cszn/USRNet\nwaifu2x | x | x | https://github.com/nagadomi/waifu2x/\nRCAN ｜ x ｜ ECCV 2018 ｜ https://github.com/xinntao/BasicSR\nESRGAN | 比 RCAN 更晚出现，虽然 PSNR 值比 RCAN 稍低，但视觉效果更高 | ECCV 2018 | https://github.com/xinntao/ESRGAN\nAnime4K | x | non-machine-learning based | https://github.com/bloc97/Anime4K\nSRMD | x | CVPR 2018 | https://github.com/cszn/KAIR")]),t._v(" "),e("p",[t._v("reference：https://blog.csdn.net/gwplovekimi/article/details/83041627")]),t._v(" "),e("h3",{attrs:{id:"去燥"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#去燥"}},[t._v("#")]),t._v(" 去燥")]),t._v(" "),e("ul",[e("li",[t._v("hdrnet\n"),e("ul",[e("li",[t._v("https://github.com/google/hdrnet\n"),e("ul",[e("li",[t._v("https://groups.csail.mit.edu/graphics/hdrnet/")])])]),t._v(" "),e("li",[t._v("https://github.com/creotiv/hdrnet-pytorch")])])]),t._v(" "),e("li",[t._v("Image-Adaptive-3DLUT\n"),e("ul",[e("li",[t._v("https://github.com/HuiZeng/Image-Adaptive-3DLUT")])])])]),t._v(" "),e("h2",{attrs:{id:"_5-优质模型"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-优质模型"}},[t._v("#")]),t._v(" 5. 优质模型")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("Name")]),t._v(" "),e("th",[t._v("Description")]),t._v(" "),e("th",[t._v("Type")]),t._v(" "),e("th",[t._v("Code")]),t._v(" "),e("th",[t._v("Note")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("face-alignment")]),t._v(" "),e("td",[t._v("2D and 3D Face alignment library")]),t._v(" "),e("td",[t._v("pytorch")]),t._v(" "),e("td",[t._v("https://github.com/1adrianb/face-alignment")]),t._v(" "),e("td",[t._v("x")])]),t._v(" "),e("tr",[e("td",[t._v("face_recognition")]),t._v(" "),e("td",[t._v("simplest facial recognition api")]),t._v(" "),e("td",[t._v("dlib")]),t._v(" "),e("td",[t._v("https://github.com/ageitgey/face_recognition")]),t._v(" "),e("td",[t._v("x")])]),t._v(" "),e("tr",[e("td",[t._v("first-order-model")]),t._v(" "),e("td",[t._v("the source code for the paper First Order Motion Model for Image Animation")]),t._v(" "),e("td",[t._v("pytorch")]),t._v(" "),e("td",[t._v("https://github.com/AliaksandrSiarohin/first-order-model")]),t._v(" "),e("td",[t._v("x")])]),t._v(" "),e("tr",[e("td",[t._v("MMDetection")]),t._v(" "),e("td",[t._v("最强的目标检测")]),t._v(" "),e("td",[t._v("pytorch")]),t._v(" "),e("td",[t._v("https://github.com/open-mmlab/mmdetection")]),t._v(" "),e("td",[t._v("x")])]),t._v(" "),e("tr",[e("td",[t._v("Bringing-Old-Photos-Back-to-Life")]),t._v(" "),e("td",[t._v("Bringing Old Photo Back to Life (CVPR 2020 oral)")]),t._v(" "),e("td",[t._v("pytorch")]),t._v(" "),e("td",[t._v("https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life")]),t._v(" "),e("td",[t._v("x")])])])]),t._v(" "),e("p",[t._v("头像动态：https://github.com/alievk/avatarify-python\n动漫识别：https://github.com/soruly/trace.moe ：（数据源：https://anilist.co/anime）")]),t._v(" "),e("p",[t._v("Models\nhttps://github.com/tensorflow/models")]),t._v(" "),e("p",[t._v("垃圾分类：\nhttps://github.com/wusaifei/garbage_classify")]),t._v(" "),e("h2",{attrs:{id:"_6-notes"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_6-notes"}},[t._v("#")]),t._v(" 6. Notes")]),t._v(" "),e("h3",{attrs:{id:"_1-杂项记录"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-杂项记录"}},[t._v("#")]),t._v(" 1. 杂项记录")]),t._v(" "),e("ol",[e("li",[t._v("tensorflow 版本")])]),t._v(" "),e("ul",[e("li",[t._v("tensorflow==1.12.0 -> python[version='>=3.6,❤️.7.0a0']")])]),t._v(" "),e("ol",{attrs:{start:"2"}},[e("li",[t._v("图片读取")])]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("Lib")]),t._v(" "),e("th",[t._v("Type")]),t._v(" "),e("th",[t._v("Channels")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("opencv")]),t._v(" "),e("td",[t._v("numpy 类型")]),t._v(" "),e("td",[t._v("默认 BGR，shape 为 HWC")])]),t._v(" "),e("tr",[e("td",[t._v("PIL")]),t._v(" "),e("td",[t._v("PIL中的具体的类型")]),t._v(" "),e("td",[t._v("根据图像格式：一般为 RGB，shape 为 HWC")])])])]),t._v(" "),e("p",[t._v("pytorch 中使用 torchvision.datasets 模块读取图像，输出的数据类型为 PILImage，并且图像中的每一个数据大小范围已经不再是[0,255]，而是[0,1].")]),t._v(" "),e("ol",{attrs:{start:"3"}},[e("li",[t._v("常用数据集：imagenet")])]),t._v(" "),e("h3",{attrs:{id:"_2-深度阅读"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-深度阅读"}},[t._v("#")]),t._v(" 2. 深度阅读")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/79959150",target:"_blank",rel:"noopener noreferrer"}},[t._v("训练GANs一年我学到的10个教训"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://cloud.tencent.com/developer/article/1120709",target:"_blank",rel:"noopener noreferrer"}},[t._v("纵览轻量化卷积神经网络：SqueezeNet、MobileNet、ShuffleNet、Xception"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/weixin_40170902/article/details/80092628",target:"_blank",rel:"noopener noreferrer"}},[t._v("机器学习：各种优化器Optimizer的总结与比较"),e("OutboundLink")],1)])]),t._v(" "),e("p",[t._v("理解 Normalize： https://blog.csdn.net/qq_35027690/article/details/103742697\nSoftmax：https://zhuanlan.zhihu.com/p/67759205")]),t._v(" "),e("p",[t._v("https://tools.fun/")])])}),[],!1,null,null,null);a.default=_.exports}}]);